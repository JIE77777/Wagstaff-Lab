# Wagstaff-Lab Snapshot (full)

## Snapshot Meta
```yaml
mode: full
profile: full
generated: 2026-01-13T09:16:18+08:00
max_file_bytes: 300000
max_total_bytes: 8000000
redaction: on
```

## Environment
```yaml
Time: 2026-01-13T09:16:18+08:00
User: steam
Host: VM-8-2-ubuntu (Linux 6.8.0-49-generic)
Platform: Linux-6.8.0-49-generic-x86_64-with-glibc2.39
Python: 3.10.19 ($HOME/miniconda3/envs/dst_lab/bin/python3)
Conda Env: dst_lab
```

## Git Status
```yaml
Branch: main [DIRTY]
Commit: 336ed22
Message: Release v2.2: Registry-driven architecture, new SOPs, and documentation
Changes: modified=9, untracked=2
---
PROJECT_STATUS.json   |   21 +-
 bin/dst_tool.sh       |   81 +-
 devtools/installer.py |   18 +-
 devtools/pm.py        |   25 +-
 devtools/snapshot.py  | 1055 ++++++++++++++++++------
 project_context.txt   | 2146 +++++--------------------------------------------
 src/analyzer.py       |    2 +-
 src/registry.py       |   12 +-
 src/wiki.py           |    2 +-
 9 files changed, 1142 insertions(+), 2220 deletions(-)
```

## Project Structure
```text
â”œâ”€â”€ bin
â”‚   â”œâ”€â”€ boot.sh
â”‚   â”œâ”€â”€ dst_tool.sh
â”‚   â”œâ”€â”€ pm
â”‚   â”œâ”€â”€ wagstaff
â”‚   â””â”€â”€ Wagstaff-Lab
â”œâ”€â”€ conf
â”‚   â”œâ”€â”€ settings.ini
â”‚   â””â”€â”€ snapshot_profile.json
â”œâ”€â”€ data
â”‚   â””â”€â”€ reports
â”‚       â”œâ”€â”€ asset_registry.md
â”‚       â””â”€â”€ recipe_distribution.md
â”œâ”€â”€ devtools
â”‚   â”œâ”€â”€ installer.py
â”‚   â”œâ”€â”€ pm.py
â”‚   â”œâ”€â”€ reporter.py
â”‚   â””â”€â”€ snapshot.py
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ analyzer.py
â”‚   â”œâ”€â”€ doctor.py
â”‚   â”œâ”€â”€ engine.py
â”‚   â”œâ”€â”€ explorer.py
â”‚   â”œâ”€â”€ guide.py
â”‚   â”œâ”€â”€ registry.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ wiki.py
â”œâ”€â”€ tests
â”‚   â””â”€â”€ test_recipes.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ PROJECT_STATUS.json
â”œâ”€â”€ README.md
â””â”€â”€ setup.sh
```

## Tool Registry (src/registry.py)
| alias | file | folder | type | usage | desc |
|---|---|---|---|---|---|
| - | guide.py | src | Core | Wagstaff-Lab | Wagstaff-Lab æ§åˆ¶å°ä¸»é¢æ¿ |
| doctor | doctor.py | src | Src | wagstaff doctor | ç¯å¢ƒé…ç½®ä¸ä¾èµ–å¥åº·æ£€æŸ¥ |
| wiki | wiki.py | src | Src | wagstaff wiki <item_code> | ç‰©å“/é…æ–¹/æ•°å€¼æŸ¥è¯¢ç™¾ç§‘ |
| exp | explorer.py | src | Src | wagstaff exp | æºç ç»“æ„æµè§ˆä¸æ·±åº¦åˆ†æ |
| pm | pm.py | devtools | Dev | pm [ui\|obj\|add\|done\|log] | é¡¹ç›®è¿›åº¦ä¸ä»»åŠ¡ç®¡ç† |
| report | reporter.py | devtools | Dev | wagstaff report [assets\|recipes\|all] | ç”Ÿæˆå…¨æœèµ„äº§/é…æ–¹åˆ†å¸ƒæŠ¥å‘Š |
| snap | snapshot.py | devtools | Dev | wagstaff snap [--mode core\|full\|custom] [--config conf/snapshot_profile.json] | ç”Ÿæˆé¡¹ç›®å…¨æ¯ä»£ç å¿«ç…§ |
| install | installer.py | devtools | Dev | python3 devtools/installer.py | ç¯å¢ƒæ³¨å†Œä¸å®‰è£…å‘å¯¼ |

## Internal Dependency Map (python)
- devtools/installer.py  ->  src/registry.py
- devtools/reporter.py  ->  src/engine.py
- src/engine.py  ->  src/analyzer.py
- src/engine.py  ->  src/utils.py
- src/explorer.py  ->  src/analyzer.py
- src/explorer.py  ->  src/engine.py
- src/guide.py  ->  src/registry.py
- src/wiki.py  ->  src/engine.py
- tests/test_recipes.py  ->  src/engine.py

## Project State (PROJECT_STATUS.json)
```text
DEV MANIFESTO:
* æ¶æ„åˆ†å±‚ï¼šEngineè´Ÿè´£åº•å±‚I/Oï¼ŒToolè´Ÿè´£äº¤äº’ï¼Œç¦æ­¢UIæ··å…¥åº•å±‚
* å•æ–‡ä»¶å¯ç”¨ï¼šè„šæœ¬å¿…é¡»åŸå­åŒ–ï¼Œèƒ½ç‹¬ç«‹è¿è¡Œï¼Œæ‹’ç»å¼ºè€¦åˆ
* è·¯å¾„è‡ªé€‚åº”ï¼šç¦æ­¢ç¡¬ç¼–ç ç»å¯¹è·¯å¾„ï¼Œå¿…é¡»é€šè¿‡ __file__ åŠ¨æ€å®šä½
* æ•°æ®æŒä¹…åŒ–ï¼šæ‰«æç»“æœå’Œæ—¥å¿—å¿…é¡»å†™å…¥æ–‡ä»¶ï¼Œä¸ä»…é™äºæ§åˆ¶å°è¾“å‡º
* ç¨³å¥é™çº§ï¼šä¼˜å…ˆZipè¯»å–ï¼Œå¤±è´¥åˆ™é™çº§Folder
--------------------
OBJECTIVE: Wagstaff Lab v2.0 æ¶æ„å‡çº§ä¸æƒ…æŠ¥æŒä¹…åŒ–

TASKS: (8/8 done)
1. [x] é‡æ„ Wiki å’Œ Explorer ä½¿ç”¨ Engine
2. [x] å®ç°æƒ…æŠ¥æ‰«æç»“æœä¿å­˜åˆ° data/reports/
3. [x] åˆ›å»º src/guide.py é¡¹ç›®æ¦‚å†µé¢æ¿
4. [x] åˆ›å»º devtools/installer.py å¹¶å°è£… bin/wagstaff å‘½ä»¤
5. [x] æ–‡æ¡£åŒ–ï¼šåœ¨ README.md ä¸­è®°å½•æ–°å·¥å…·æ¥å…¥ SOP
6. [x] é‡æ„å·¥å…·æ³¨å†Œé€»è¾‘ï¼šå¼•å…¥ src/registry.py å®ç°å•ä¸€æ•°æ®æº
7. [x] Hotfix(pm): ä¿®å¤ STATUS_FILE è·¯å¾„ä¾èµ–å¹¶å®ç°åŸå­åŒ–å†™å…¥ (.tmp -> rename)
8. [x] Hotfix(installer): ä¼˜åŒ– wagstaff åŒ…è£…è„šæœ¬ï¼Œä¿®å¤æ— å‚æŠ¥é”™å¹¶å¼•å…¥ exec è¿›ç¨‹æ›¿æ¢

RECENT LOGS:
* [2026-01-12 23:33] 
* [2026-01-12 23:33] test
* [2026-01-12 23:33] test
* [2026-01-12 23:33] 
* [2026-01-12 23:34] test
```

## Included Full Files

### File: bin/boot.sh
> size=2250B, sha256=524c5d2d4996
```bash
#!/bin/bash
# =========================================================
# Wagstaff-Lab Bootloader (å¯åŠ¨å¼•å¯¼ç¨‹åº)
# èŒè´£: è®¾ç½®ç¯å¢ƒåº“(LD_LIBRARY_PATH)å¹¶å¯åŠ¨ DST äºŒè¿›åˆ¶æ–‡ä»¶
# =========================================================

# --- 1. å®šä½é…ç½® ---
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
CONFIG_FILE="$PROJECT_ROOT/conf/settings.ini"

# --- 2. ç®€æ˜“é…ç½®è¯»å–å™¨ ---
read_config() {
    local section=$1
    local key=$2
    local val=$(awk -F ' = ' -v section="[$section]" -v key="$key" '
        $0 == section { in_section=1; next }
        /^\[/ { in_section=0 }
        in_section && $1 == key { print $2; exit }
    ' "$CONFIG_FILE")
    echo "${val/\~/$HOME}"
}

# --- 3. åŠ è½½æ ¸å¿ƒå˜é‡ ---
INSTALL_DIR=$(read_config "PATHS" "DST_ROOT")
CLUSTER_NAME=$(read_config "SERVER" "CLUSTER_NAME")

# --- 4. ç¯å¢ƒæ£€æŸ¥ ---
if [ -z "$INSTALL_DIR" ] || [ -z "$CLUSTER_NAME" ]; then
    echo "âŒ [Boot] é”™è¯¯: æ— æ³•è¯»å–é…ç½®ï¼Œè¯·æ£€æŸ¥ conf/settings.ini"
    exit 1
fi

BIN_DIR="$INSTALL_DIR/bin"

# --- 5. è®¾ç½®ä¾èµ–åº“ (å…³é”®æ­¥éª¤) ---
# è¿™æ˜¯è®© Linux èƒ½è¿è¡Œ DST çš„æ ¸å¿ƒé­”æ³•
export LD_LIBRARY_PATH="$BIN_DIR/lib32:$BIN_DIR:$LD_LIBRARY_PATH"

# --- 6. è¿›å…¥æ‰§è¡Œç›®å½• ---
# å¿…é¡»è¿›å…¥ bin ç›®å½•ï¼Œå¦åˆ™æ¸¸æˆæ‰¾ä¸åˆ° data
cd "$BIN_DIR" || { echo "âŒ [Boot] æ‰¾ä¸åˆ°ç›®å½•: $BIN_DIR"; exit 1; }

echo "âš¡ [Boot] æ­£åœ¨åˆå§‹åŒ– Wagstaff å¼•æ“..."
echo "   - æ¸¸æˆæ ¹ç›®å½•: $INSTALL_DIR"
echo "   - å­˜æ¡£ç°‡åç§°: $CLUSTER_NAME"

# --- 7. å¯åŠ¨è¿›ç¨‹ (Master) ---
# ä½¿ç”¨ -dmS è®©å®ƒåœ¨åå° Screen è¿è¡Œ
screen -dmS "DST_Master" ./dontstarve_dedicated_server_nullrenderer -console -cluster "$CLUSTER_NAME" -shard Master
echo "âœ… [Boot] åœ°é¢æœåŠ¡å™¨ (Master) å·²å¯åŠ¨"

# --- 8. å¯åŠ¨è¿›ç¨‹ (Caves) ---
# åªæœ‰å½“å­˜æ¡£ä¸­å­˜åœ¨ Caves æ–‡ä»¶å¤¹æ—¶æ‰å¯åŠ¨ï¼Œæˆ–è€…ä½ å¯ä»¥é€‰æ‹©å¼ºåˆ¶å¯åŠ¨
# è¿™é‡Œä¸ºäº†ç¨³å¦¥ï¼Œæˆ‘ä»¬ç›´æ¥å¯åŠ¨ï¼Œå¦‚æœæ²¡æ´ç©´é…ç½®æ¸¸æˆä¼šè‡ªåŠ¨åœæ­¢ Caves è¿›ç¨‹ï¼Œæ— ä¼¤å¤§é›…
screen -dmS "DST_Caves" ./dontstarve_dedicated_server_nullrenderer -console -cluster "$CLUSTER_NAME" -shard Caves
echo "âœ… [Boot] æ´ç©´æœåŠ¡å™¨ (Caves) å·²å¯åŠ¨"

echo "âœ¨ å¯åŠ¨åºåˆ—å®Œæˆã€‚"
```

### File: bin/dst_tool.sh
> size=12532B, sha256=a626b7bec4b0
```bash
#!/bin/bash

# =========================================================
# Wagstaff-Lab Control Center v6.1
# æ¨¡å—åŒ– DST æœåŠ¡å™¨ç®¡ç†è„šæœ¬
# =========================================================

# --- 1. ç¯å¢ƒåˆå§‹åŒ– ---

# è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„ (bin/)
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
# å®šä½é¡¹ç›®æ ¹ç›®å½• (Wagstaff-Lab/)
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE="$PROJECT_ROOT/conf/settings.ini"

# --- 2. é…ç½®è¯»å–å‡½æ•° (INI Parser) ---
# ç”¨é€”ï¼šä» settings.ini è¯»å–å˜é‡ï¼Œå¹¶è‡ªåŠ¨å°† ~ æ›¿æ¢ä¸º $HOME
read_config() {
    local section=$1
    local key=$2
    local val=$(awk -F ' = ' -v section="[$section]" -v key="$key" '
        $0 == section { in_section=1; next }
        /^\[/ { in_section=0 }
        in_section && $1 == key { print $2; exit }
    ' "$CONFIG_FILE")
    
    # æ›¿æ¢ ~ ä¸ºå½“å‰ç”¨æˆ· Home ç›®å½•
    echo "${val/\~/$HOME}"
}

# --- 3. åŠ è½½å˜é‡ ---
if [ ! -f "$CONFIG_FILE" ]; then
    echo "âŒ é”™è¯¯: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ $CONFIG_FILE"
    exit 1
fi

DST_DIR=$(read_config "PATHS" "DST_ROOT")
STEAMCMD_DIR=$(read_config "PATHS" "STEAMCMD_DIR")
BACKUP_REPO=$(read_config "PATHS" "BACKUP_DIR")
CLUSTER_NAME=$(read_config "SERVER" "CLUSTER_NAME")
KLEI_HOME=$(read_config "SERVER" "KLEI_HOME")

# [å…³é”®ä¿®æ”¹] å¯åŠ¨è„šæœ¬æŒ‡å‘åŒç›®å½•ä¸‹çš„ boot.sh
START_SCRIPT="$SCRIPT_DIR/boot.sh"

# æ—¥å¿—è·¯å¾„
LOG_MASTER="$KLEI_HOME/$CLUSTER_NAME/Master/server_log.txt"
LOG_CAVES="$KLEI_HOME/$CLUSTER_NAME/Caves/server_log.txt"

# å¯»æ‰¾ Conda Python ç¯å¢ƒ (ä¼˜å…ˆæ‰¾ dst_lab)
PYTHON_EXEC="$HOME/miniconda3/envs/dst_lab/bin/python"
if [ ! -f "$PYTHON_EXEC" ]; then
    # å¤‡ç”¨ï¼šå°è¯•ç³»ç»Ÿ python3
    PYTHON_EXEC=$(which python3)
fi

# ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
mkdir -p "$BACKUP_REPO"

# --- é¢œè‰²å®šä¹‰ ---
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
WHITE='\033[1;37m'
NC='\033[0m' # No Color

trap 'echo -e "\n${YELLOW}>> è¿”å›ä¸»èœå•...${NC}"; sleep 0.5' SIGINT

# ================= è¾…åŠ©å‡½æ•° =================

print_line() { echo -e "${CYAN}----------------------------------------${NC}"; }
pause() { echo -e "\n${WHITE}æŒ‰å›è½¦é”®ç»§ç»­...${NC}"; read -r; }

# [Security] è§£æç»å¯¹è·¯å¾„ï¼ˆä¼˜å…ˆ realpathï¼Œç¼ºå¤±åˆ™ç”¨ python3ï¼‰
resolve_path() {
    local p="$1"
    if command -v realpath >/dev/null 2>&1; then
        realpath -m "$p"
        return $?
    fi
    python3 - "$p" <<'PY'
import os, sys
try:
    print(os.path.realpath(os.path.expanduser(sys.argv[1])))
except:
    sys.exit(1)
PY
}

# [Security] é«˜å±åˆ é™¤ï¼šä»…å…è®¸åˆ é™¤ KLEI_HOME/CLUSTER_NAME ä¸”åšäºŒæ¬¡ç¡®è®¤
safe_delete_cluster_dir() {
    local base="$KLEI_HOME"
    local cluster="$CLUSTER_NAME"
    local target="$base/$cluster"

    if [ -z "$base" ] || [ -z "$cluster" ]; then
        echo -e "${RED}âŒ KLEI_HOME æˆ– CLUSTER_NAME ä¸ºç©ºï¼Œæ‹’ç»åˆ é™¤${NC}"
        return 1
    fi

    local base_real target_real
    base_real="$(resolve_path "$base")" || return 1
    target_real="$(resolve_path "$target")" || return 1

    # æŠ¤æ 1: ç›®æ ‡ä¸èƒ½æ˜¯ /ã€HOMEã€KLEI_HOME æœ¬èº«
    if [ "$target_real" = "/" ] || [ "$target_real" = "$HOME" ] || [ "$target_real" = "$base_real" ]; then
        echo -e "${RED}âŒ ç›®æ ‡è·¯å¾„å¼‚å¸¸ (ç³»ç»Ÿç›®å½•ä¿æŠ¤)ï¼Œæ‹’ç»åˆ é™¤: $target_real${NC}"
        return 1
    fi

    # æŠ¤æ 2: ç›®æ ‡å¿…é¡»ä¸¥æ ¼ä½äº KLEI_HOME ç›®å½•æ ‘ä¸‹
    case "$target_real" in
        "$base_real"/*) ;;
        *)
            echo -e "${RED}âŒ ç›®æ ‡ä¸åœ¨ KLEI_HOME ä¸‹ (è¶Šæƒä¿æŠ¤)ï¼Œæ‹’ç»åˆ é™¤${NC}"
            echo -e "   KLEI_HOME: $base_real"
            echo -e "   TARGET:    $target_real"
            return 1
            ;;
    esac

    if [ ! -d "$target_real" ]; then
        echo -e "${RED}âŒ å­˜æ¡£ç›®å½•ä¸å­˜åœ¨: $target_real${NC}"
        return 1
    fi

    echo -e "${YELLOW}ğŸ§¹ è­¦å‘Šï¼šå³å°†å½»åº•åˆ é™¤æ—§å­˜æ¡£ç›®å½•:${NC}"
    echo -e "${RED}   $target_real${NC}"
    
    # æŠ¤æ 3: ä¸¥æ ¼æ–‡æœ¬ç¡®è®¤
    read -p "è¯·è¾“å…¥ä»¥ä¸‹å†…å®¹ç¡®è®¤åˆ é™¤: DELETE $target_real : " confirm_del
    if [ "$confirm_del" != "DELETE $target_real" ]; then
        echo -e "${YELLOW}ğŸš« è¾“å…¥ä¸åŒ¹é…ï¼Œå·²å–æ¶ˆåˆ é™¤æ“ä½œ${NC}"
        return 1
    fi

    echo -e "${RED}ğŸ”¥ æ­£åœ¨æ‰§è¡Œé”€æ¯...${NC}"
    rm -rf -- "$target_real"
    return 0
}


check_status() {
    local master_status="${RED}ğŸ”´ æœªè¿è¡Œ${NC}"
    local caves_status="${RED}ğŸ”´ æœªè¿è¡Œ${NC}"
    if screen -ls | grep -q "DST_Master"; then master_status="${GREEN}ğŸŸ¢ è¿è¡Œä¸­${NC}"; fi
    if screen -ls | grep -q "DST_Caves"; then caves_status="${GREEN}ğŸŸ¢ è¿è¡Œä¸­${NC}"; fi
    echo -e "   åœ°é¢: $master_status    æ´ç©´: $caves_status"
}

# æŸ¥çœ‹æ—¥å¿—å‡½æ•°
view_log() {
    local logfile="$1"; local name="$2"
    if [ -f "$logfile" ]; then
        echo -e "${CYAN}ğŸ“º ç›‘è§† $name æ—¥å¿— (Ctrl+C é€€å‡º)${NC}"
        tail -f "$logfile"
    else
        echo -e "${RED}âŒ æ— æ—¥å¿—æ–‡ä»¶: $logfile${NC}"; pause
    fi
}

# å‘é€æŒ‡ä»¤çš„æ ¸å¿ƒå‡½æ•°
send_cmd_to_master() {
    local cmd="$1"
    local desc="$2"
    if ! screen -ls | grep -q "DST_Master"; then
        echo -e "${RED}âŒ åœ°é¢æœæœªè¿è¡Œ${NC}"; pause; return
    fi
    echo -e "${BLUE}ğŸ“¡ $desc${NC}"
    screen -S "DST_Master" -p 0 -X eval "stuff \"$cmd\015\""
    echo -e "${YELLOW}â³ æŒ‡ä»¤å·²å‘é€${NC}"; sleep 1
}

# ================= æ ¸å¿ƒåŠŸèƒ½æ¨¡å— =================

start_server() {
    print_line
    if screen -ls | grep -q "DST_Master"; then
        echo -e "${YELLOW}âš ï¸  æœåŠ¡å™¨å·²åœ¨è¿è¡Œï¼${NC}"; pause; return
    fi
    echo -e "${GREEN}ğŸš€ è°ƒç”¨å¯åŠ¨å¼•å¯¼ç¨‹åº (Bootloader)...${NC}"
    
    # æ£€æŸ¥å¯åŠ¨è„šæœ¬æ˜¯å¦å­˜åœ¨
    if [ -f "$START_SCRIPT" ]; then
        # æ‰§è¡Œ boot.sh
        "$START_SCRIPT"
    else
        echo -e "${RED}âŒ æ‰¾ä¸åˆ°å¯åŠ¨å™¨: $START_SCRIPT${NC}"
        echo "è¯·æ£€æŸ¥ bin/boot.sh æ˜¯å¦å­˜åœ¨ã€‚"
    fi
    pause
}

graceful_stop() {
    print_line
    echo -e "${YELLOW}ğŸ›‘ å‘é€åœæœä¿¡å·...${NC}"
    if ! screen -ls | grep -qE "DST_Master|DST_Caves"; then
        echo -e "${RED}âš ï¸  æœåŠ¡å™¨æœªè¿è¡Œ${NC}"; pause; return
    fi

    # å‘é€å…³é—­æŒ‡ä»¤
    for target in "DST_Master" "DST_Caves"; do
        if screen -list | grep -q "$target"; then
            screen -S "$target" -p 0 -X eval 'stuff "c_shutdown(true)\015"'
        fi
    done

    echo -e "${BLUE}â³ ç­‰å¾…å­˜æ¡£ä¿å­˜ (æœ€å¤š40ç§’)...${NC}"
    for ((i=1; i<=40; i++)); do
        if ! screen -list | grep -qE "DST_Master|DST_Caves"; then
            echo -e "\n${GREEN}âœ… æœåŠ¡å™¨å·²å…³é—­${NC}"; pause; return
        fi
        if tail -n 10 "$LOG_MASTER" 2>/dev/null | grep -q "Shutting down"; then
            echo -e "\n${GREEN}âœ… ç›‘æµ‹åˆ°å…³æœºä¿¡å·${NC}"; break
        fi
        echo -n "."; sleep 0.5
    done
    
    # æ¸…ç†æ®‹ä½™è¿›ç¨‹
    screen -list | grep -E "DST_Master|DST_Caves" | cut -d. -f1 | xargs -r -I{} screen -S {} -X quit
    echo -e "\n${GREEN}âœ… è¿›ç¨‹å·²ç»ˆæ­¢${NC}"; pause
}

restart_server() {
    print_line
    if screen -ls | grep -qE "DST_Master|DST_Caves"; then
        original_pause_def="$(declare -f pause)"; pause() { :; } 
        graceful_stop
        eval "$original_pause_def"
    fi
    read -p "æ˜¯å¦é¡ºä¾¿æ›´æ–°æ¸¸æˆ? (y/n): " up_c
    if [[ "$up_c" == "y" ]]; then update_game; fi
    start_server
}

update_game() {
    print_line
    echo -e "${BLUE}â¬‡ï¸  è°ƒç”¨ SteamCMD æ›´æ–°...${NC}"
    "$STEAMCMD_DIR/steamcmd.sh" +force_install_dir "$DST_DIR" +login anonymous +app_update 343050 validate +quit
    echo -e "${GREEN}âœ… æ›´æ–°å®Œæˆ${NC}"; pause
}

# --- å¤‡ä»½/æ¢å¤ç³»ç»Ÿ ---
create_backup() {
    print_line
    local ts=$(date +"%Y%m%d_%H%M%S")
    if [ ! -d "$KLEI_HOME/$CLUSTER_NAME" ]; then echo -e "${RED}âŒ å­˜æ¡£ä¸å­˜åœ¨: $KLEI_HOME/$CLUSTER_NAME${NC}"; pause; return; fi
    
    echo -e "${CYAN}ğŸ’¾ æ‰“åŒ…å­˜æ¡£: $CLUSTER_NAME ...${NC}"
    tar -zcf "$BACKUP_REPO/backup_${ts}.tar.gz" -C "$KLEI_HOME" "$CLUSTER_NAME"
    echo -e "${GREEN}âœ… å¤‡ä»½å·²åˆ›å»º: backup_${ts}.tar.gz${NC}"; pause
}

restore_backup() {
    print_line
    files=($(ls -1t "$BACKUP_REPO"/*.tar.gz 2>/dev/null))
    if [ ${#files[@]} -eq 0 ]; then echo -e "${RED}âŒ å¤‡ä»½åº“ä¸ºç©º${NC}"; pause; return; fi

    echo -e "${CYAN}ğŸ“‚ æœ€è¿‘å¤‡ä»½:${NC}"
    i=0
    for file in "${files[@]}"; do
        echo -e " [$i] $(basename "$file")"
        ((i++)); if [ $i -ge 10 ]; then break; fi
    done
    
    read -p "é€‰æ‹©åºå· (qé€€å‡º): " c
    if [[ "$c" == "q" ]]; then return; fi
    if ! [[ "$c" =~ ^[0-9]+$ ]] || [ "$c" -ge "$i" ]; then echo "âŒ æ— æ•ˆ"; pause; return; fi

    read -p "âš ï¸  é«˜å±æ“ä½œ: ç¡®è®¤è¦†ç›–å½“å‰å­˜æ¡£? (YES/n): " confirm
    if [[ "$confirm" != "YES" ]]; then return; fi

    # è‡ªåŠ¨åœæœ
    if screen -ls | grep -qE "DST_Master|DST_Caves"; then
        original_pause_def="$(declare -f pause)"; pause() { :; } 
        graceful_stop
        eval "$original_pause_def"
    fi

    echo -e "${YELLOW}ğŸ§¹ å‡†å¤‡æ¸…ç†æ—§å­˜æ¡£...${NC}"
    if ! safe_delete_cluster_dir; then
        echo -e "${RED}âŒ åˆ é™¤æ­¥éª¤å¤±è´¥æˆ–è¢«å–æ¶ˆï¼Œå·²ä¸­æ­¢å›æ¡£æµç¨‹${NC}"
        pause
        return
    fi
    echo -e "${BLUE}ğŸ“¦ è§£å‹å¤‡ä»½...${NC}"
    tar -zxf "${files[$c]}" -C "$KLEI_HOME"
    echo -e "${GREEN}âœ… å›æ¡£æˆåŠŸ${NC}"
    read -p "ç«‹å³å¯åŠ¨? (y/n): " sn
    if [[ "$sn" == "y" ]]; then start_server; else pause; fi
}

# --- Wagstaff å·¥å…·ç®±é›†æˆ ---
run_explorer() {
    local script_path="$PROJECT_ROOT/src/explorer.py"
    if [ -f "$script_path" ]; then
        "$PYTHON_EXEC" "$script_path"
    else
        echo -e "${RED}âŒ æ‰¾ä¸åˆ°å·¥å…·è„šæœ¬: $script_path${NC}"
        pause
    fi
}

run_wiki() {
    local script_path="$PROJECT_ROOT/src/wiki.py"
    if [ ! -f "$script_path" ]; then
        echo -e "${RED}âŒ æ‰¾ä¸åˆ° Wiki è„šæœ¬: $script_path${NC}"; pause; return
    fi

    echo -e "${CYAN}ğŸ“š è¯·è¾“å…¥ç‰©å“ä»£ç è¿›è¡ŒæŸ¥è¯¢ (ä¾‹å¦‚ spear, log, meat)${NC}"
    read -p "ç‰©å“ä»£ç : " item_code
    if [ -n "$item_code" ]; then
        "$PYTHON_EXEC" "$script_path" "$item_code"
    fi
    pause
}
console_menu() {
    while true; do
        clear
        echo -e "   ğŸ® ${CYAN}æ§åˆ¶å°æŒ‡ä»¤ä¸­å¿ƒ${NC} ğŸ®"
        check_status
        echo "--------------------------------"
        echo "1. ğŸ’¾ ç«‹å³ä¿å­˜ (c_save)"
        echo "2. âª å›æ»š1å¤© (c_rollback)"
        echo "3. ğŸ“¢ å‘é€å…¬å‘Š (c_announce)"
        echo "4. â˜ ï¸  é‡ç½®ä¸–ç•Œ (c_regenerateworld)"
        echo "5. ğŸ‘¥ åˆ—å‡ºç©å®¶"
        echo "0. ğŸ”™ è¿”å›"
        echo "--------------------------------"
        read -p "æŒ‡ä»¤: " cc
        case $cc in
            1) send_cmd_to_master "c_save()" "ç«‹å³ä¿å­˜" ;;
            2) send_cmd_to_master "c_rollback(1)" "å›æ»š1å¤©" ;;
            3) read -p "å†…å®¹: " m; send_cmd_to_master "c_announce(\"$m\")" "å…¬å‘Š" ;;
            4) read -p "è¾“å…¥ YES ç¡®è®¤é‡ç½®: " r; [[ "$r" == "YES" ]] && send_cmd_to_master "c_regenerateworld()" "é‡ç½®ä¸–ç•Œ" ;;
            5) send_cmd_to_master "c_listallplayers()" "ç©å®¶åˆ—è¡¨" ;;
            0) return ;;
        esac
    done
}

# ================= ä¸»å¾ªç¯ =================
while true; do
    clear
    echo "==========================================="
    echo -e " ğŸ¦… ${CYAN}Wagstaff-Lab æ§åˆ¶å° v6.1${NC} ğŸ¦…"
    echo "==========================================="
    check_status
    echo -e "${CYAN}--- è¿ç»´ç®¡ç† ---${NC}"
    echo "1. ğŸš€ å¯åŠ¨æœåŠ¡å™¨      2. ğŸ›‘ åœæ­¢æœåŠ¡å™¨"
    echo "3. ğŸ”„ é‡å¯æœåŠ¡å™¨      4. â¬‡ï¸  æ›´æ–°ç‰ˆæœ¬"
    echo -e "${CYAN}--- æ•°æ®ä¸å·¥å…· ---${NC}"
    echo "5. ğŸ’¾ åˆ›å»ºå¤‡ä»½        6. âª æ¢å¤å­˜æ¡£"
    echo "7. ğŸ“œ æŸ¥çœ‹æ—¥å¿—        8. ğŸ® å‘é€æŒ‡ä»¤"
    echo -e "9. ğŸ”¬ ${YELLOW}æºç é€è§†é•œ (Explorer)${NC}"
    echo -e "10.ğŸ“š ${GREEN}Wagstaff ç™¾ç§‘ (Wiki)${NC}"
    echo "0. ğŸšª é€€å‡º"
    echo "==========================================="
    
    read -p "é€‰é¡¹: " choice

    case $choice in
        1) start_server ;;
        2) graceful_stop ;;
        3) restart_server ;;
        4) update_game ;;
        5) create_backup ;;
        6) restore_backup ;;
        7) view_log "$LOG_MASTER" "Master" ;; 
        8) console_menu ;;
        9) run_explorer ;; 
	10) run_wiki ;;
        0) echo -e "${GREEN}å†è§ï¼Œç ”ç©¶å‘˜ã€‚${NC}"; exit 0 ;;
        *) echo "æ— æ•ˆ"; sleep 0.5 ;;
    esac
done
```

### File: conf/snapshot_profile.json
> size=693B, sha256=b57b53db44d5
```json
{
  "name": "llm-pack",
  "default_action": "omit",
  "full": [
    "src/**/*.py",
    "bin/boot.sh",
    "bin/dst_tool.sh",
    "conf/settings.ini",
    "PROJECT_STATUS.json",
    "README.md",
    "tests/**/*.py"
  ],
  "stub": [
    "devtools/**/*.py",
    "data/reports/**/*.md",
    "bin/wagstaff",
    "bin/pm",
    "bin/Wagstaff-Lab"
  ],
  "omit": [
    "snapshots/**",
    "project_context.txt"
  ],
  "options": {
    "max_file_bytes": 120000,
    "max_total_bytes": 900000,
    "inventory_limit": 250,
    "include_tree": true,
    "include_env": true,
    "include_git": true,
    "include_registry_summary": true,
    "include_import_graph": true,
    "include_status": true
  }
}
```

### File: data/reports/asset_registry.md
> size=2096B, sha256=45c762a51673
```markdown
# Wagstaff Asset Registry

| Category | Total Definitions | Top File |
|----------|-------------------|----------|
| Prefabs | 2381 | `scripts/prefabs/meats.lua` |
| Widgets | 2096 | `scripts/widgets/controls.lua` |
| LootTables | 183 | `scripts/prefabs/deciduoustrees.lua` |
| Brains | 103 | `scripts/prefabs/pigman.lua` |
| STRINGS | 45 | `scripts/strings.lua` |

## Detailed Breakdown

### Prefabs
- `scripts/prefabs/meats.lua`: 30
- `scripts/prefabs/boat.lua`: 19
- `scripts/prefabs/rocks.lua`: 13
- `scripts/prefabs/archive_props.lua`: 13
- `scripts/prefabs/explode_small.lua`: 10
- `scripts/prefabs/staff.lua`: 9
- `scripts/prefabs/planted_tree.lua`: 8
- `scripts/prefabs/hound.lua`: 8
- `scripts/prefabs/wagstaff_npc.lua`: 8
- `scripts/prefabs/spider.lua`: 8

### Widgets
- `scripts/widgets/controls.lua`: 35
- `scripts/screens/playerhud.lua`: 32
- `scripts/screens/lobbyscreen.lua`: 16
- `scripts/screens/multiplayermainscreen.lua`: 15
- `scripts/widgets/redux/templates.lua`: 14
- `scripts/widgets/statusdisplays.lua`: 14
- `scripts/screens/serverlistingscreen.lua`: 14
- `scripts/screens/redux/multiplayermainscreen.lua`: 14
- `scripts/screens/servercreationscreen.lua`: 14
- `scripts/screens/modconfigurationscreen.lua`: 13

### LootTables
- `scripts/prefabs/deciduoustrees.lua`: 7
- `scripts/prefabs/evergreens.lua`: 7
- `scripts/prefabs/moon_altar.lua`: 6
- `scripts/prefabs/farm_plants.lua`: 5
- `scripts/prefabs/merm.lua`: 4
- `scripts/prefabs/veggies.lua`: 4
- `scripts/prefabs/perdshrine.lua`: 4
- `scripts/prefabs/pigman.lua`: 4
- `scripts/prefabs/monkey.lua`: 4
- `scripts/prefabs/oceantree.lua`: 4

### Brains
- `scripts/prefabs/pigman.lua`: 4
- `scripts/prefabs/merm.lua`: 2
- `scripts/prefabs/wobster.lua`: 2
- `scripts/brains/wobysmallbrain.lua`: 2
- `scripts/prefabs/ghost.lua`: 2
- `scripts/prefabs/slurtle.lua`: 2
- `scripts/prefabs/spider.lua`: 2
- `scripts/prefabs/monkey.lua`: 2
- `scripts/brains/catcoonbrain.lua`: 1
- `scripts/brains/pigbrain.lua`: 1

### STRINGS
- `scripts/strings.lua`: 37
- `scripts/skin_strings.lua`: 7
- `scripts/strings_pretranslated.lua`: 1
```

### File: data/reports/recipe_distribution.md
> size=1655B, sha256=e177df3496c5
```markdown
# Wagstaff Recipe Distribution

## Function Usage
- **Recipe2**: 881
- **DeconstructRecipe**: 111
- **Recipe**: 56
- **DoRecipeClick**: 11
- **AddCookerRecipe**: 9
- **SetRecipeUnlocked**: 4
- **ClearAllUnlockedRecipes**: 3
- **UpdateRecipes**: 2
- **OnRecipeDirty**: 2
- **SetRecipe**: 2
- **SetupRecipeIngredientDetails**: 1
- **AddRecipeCard**: 1
- **TestRecipes**: 1
- **RemoveAllRecipes**: 1
- **CanBlueprintRandomRecipe**: 1
- **CleanupDupRecipes**: 1
- **IsRecipeValidForFilter**: 1
- **IsRecipeValidForStation**: 1
- **DeclareLimitedCraftingRecipe**: 1
- **ShouldHintRecipe**: 1
- **PickRandomRecipe**: 1

## File Hotspots (Top 20)
- `scripts/recipes.lua`: 997 recipes
- `scripts/prefabs/quagmire.lua`: 52 recipes
- `scripts/cooking.lua`: 10 recipes
- `scripts/prefabs/hermithouse.lua`: 7 recipes
- `scripts/widgets/redux/craftingmenu_widget.lua`: 3 recipes
- `scripts/prefabs/cookingrecipecard.lua`: 3 recipes
- `scripts/prefabs/hermitcrab_teashop.lua`: 2 recipes
- `scripts/widgets/recipepopup.lua`: 2 recipes
- `scripts/widgets/redux/craftingmenu_pinslot.lua`: 2 recipes
- `scripts/widgets/redux/quagmire_recipebook.lua`: 1 recipes
- `scripts/widgets/controllercrafting_singletab.lua`: 1 recipes
- `scripts/components/quagmire_recipeprices.lua`: 1 recipes
- `scripts/modutil.lua`: 1 recipes
- `scripts/widgets/ingredientui.lua`: 1 recipes
- `scripts/components/quagmire_recipebook.lua`: 1 recipes
- `scripts/prefabs/blueprint.lua`: 1 recipes
- `scripts/widgets/controllercrafting.lua`: 1 recipes
- `scripts/widgets/craftslot.lua`: 1 recipes
- `scripts/quagmire_recipebook.lua`: 1 recipes
- `scripts/widgets/quagmire_recipepopup.lua`: 1 recipes
```

### File: devtools/installer.py
> size=3586B, sha256=b1feb4cd296f
```python
#!/usr/bin/env python3
import os
import sys
from pathlib import Path
from rich.console import Console

# å¼•å…¥æ³¨å†Œè¡¨
sys.path.append(os.path.join(os.path.dirname(__file__), "../src"))
from registry import get_tools

console = Console()

CURRENT_FILE = Path(__file__).resolve()
PROJECT_ROOT = CURRENT_FILE.parent.parent
BIN_DIR = PROJECT_ROOT / "bin"
SRC_DIR = PROJECT_ROOT / "src"
DEV_DIR = PROJECT_ROOT / "devtools"

def get_shell_config():
    home = Path.home()
    shell = os.environ.get("SHELL", "")
    if "zsh" in shell: return home / ".zshrc"
    elif "bash" in shell: return home / ".bashrc"
    else: return home / ".profile"

def create_wrappers():
    # 1. åˆ›å»º 'Wagstaff-Lab' ä¸»å…¥å£
    main_wrapper = BIN_DIR / "Wagstaff-Lab"
    with open(main_wrapper, 'w') as f:
        f.write('#!/bin/bash\n')
        f.write(f'python3 "{SRC_DIR}/guide.py" "$@"\n')
    os.chmod(main_wrapper, 0o755)
    
    # 2. åˆ›å»º 'pm' å¿«æ·æŒ‡ä»¤
    pm_wrapper = BIN_DIR / "pm"
    with open(pm_wrapper, 'w') as f:
        f.write('#!/bin/bash\n')
        f.write(f'python3 "{DEV_DIR}/pm.py" "$@"\n')
    os.chmod(pm_wrapper, 0o755)

    # 3. åŠ¨æ€åˆ›å»º 'wagstaff' å·¥å…·ç®± (åŸºäº Registry)
    ws_wrapper = BIN_DIR / "wagstaff"
    with open(ws_wrapper, 'w') as f:
        f.write('#!/bin/bash\n')
        
        # [ä¿®å¤é€»è¾‘] æ›´åŠ ç¨³å¥çš„å‚æ•°å¤„ç†
        # 1. è·å–ç¬¬ä¸€ä¸ªå‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸ºç©ºå­—ç¬¦ä¸² (é˜²æ­¢ unbound variable æŠ¥é”™)
        f.write('TOOL="${1:-}"\n')
        
        # 2. å¦‚æœå‚æ•°ä¸ºç©ºï¼Œç›´æ¥è½¬äº¤æ§åˆ¶æƒç»™ä¸»é¢æ¿ (exec æ›¿æ¢è¿›ç¨‹)
        f.write('if [ -z "$TOOL" ]; then\n')
        f.write(f'  exec "{main_wrapper}" "$@"\n')
        f.write('fi\n')
        
        # 3. åªæœ‰åœ¨æœ‰å‚æ•°æ—¶æ‰ shift
        f.write('shift\n')
        
        f.write('case "$TOOL" in\n')
        
        # --- åŠ¨æ€ç”Ÿæˆ Case åˆ†æ”¯ ---
        tools = get_tools()
        registered_aliases = []
        
        for tool in tools:
            alias = tool.get('alias')
            if not alias: continue # è·³è¿‡æ²¡æœ‰åˆ«åçš„å·¥å…·
            
            folder = tool.get('folder', 'src')
            if folder == 'src': abs_path = SRC_DIR
            elif folder == 'devtools': abs_path = DEV_DIR
            else: abs_path = PROJECT_ROOT / folder
            
            f.write(f'  {alias}) python3 "{abs_path}/{tool["file"]}" "$@" ;;\n')
            registered_aliases.append(f"{alias} ({tool['desc']})")
        # ------------------------

        # é»˜è®¤æƒ…å†µä¹Ÿè½¬äº¤ç»™ä¸»é¢æ¿
        f.write(f'  *) exec "{main_wrapper}" "$@" ;;\n') 
        f.write('esac\n')
    os.chmod(ws_wrapper, 0o755)
    
    console.print(f"[green]âœ… æŒ‡ä»¤æ³¨å†ŒæˆåŠŸ (Registry Driven)[/green]")
    console.print(f"   å·²è‡ªåŠ¨æ³¨å†Œ {len(registered_aliases)} ä¸ªå­å‘½ä»¤åˆ° 'wagstaff'")

def register_to_path():
    rc_file = get_shell_config()
    bin_path_str = str(BIN_DIR)
    
    if not rc_file.exists(): return

    content = rc_file.read_text()
    if f'export PATH="{bin_path_str}:$PATH"' in content:
        console.print("[dim]âš¡ ç¯å¢ƒå˜é‡å·²å°±ç»ª[/dim]")
    else:
        try:
            with open(rc_file, 'a') as f:
                f.write(f'\n# Wagstaff-Lab Environment\nexport PATH="{bin_path_str}:$PATH"\n')
            console.print(f"[green]âœ… PATH å·²æ›´æ–°[/green]")
        except Exception:
            pass

def main():
    console.print("[bold blue]ğŸ”§ Wagstaff-Lab è‡ªåŠ¨åŒ–æ³¨å†Œä¸­å¿ƒ[/bold blue]")
    create_wrappers()
    register_to_path()

if __name__ == "__main__":
    main()
```

### File: devtools/pm.py
> size=4956B, sha256=21cc6d8ef466
```python
#!/usr/bin/env python3
import os
import json
import sys
from pathlib import Path
from datetime import datetime
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.prompt import Prompt, IntPrompt

console = Console()

# [ä¿®å¤] é”å®šç»å¯¹è·¯å¾„ï¼Œä¸å†ä¾èµ–å½“å‰å·¥ä½œç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parent.parent
STATUS_FILE = PROJECT_ROOT / "PROJECT_STATUS.json"

class ProjectManager:
    def __init__(self):
        self.data = self._load()

    def _load(self):
        # [ä¼˜åŒ–] ä½¿ç”¨ Path å¯¹è±¡æ£€æŸ¥æ–‡ä»¶
        if STATUS_FILE.exists():
            with open(STATUS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"objective": "Unset", "tasks": [], "logs": [], "guidelines": []}

    def _save(self):
        # [ä¼˜åŒ–] åŸå­å†™å…¥ï¼šå…ˆå†™ .tmp å†é‡å‘½åï¼Œé˜²æ­¢æ•°æ®æŸå
        tmp = STATUS_FILE.with_name(STATUS_FILE.name + ".tmp")
        with open(tmp, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, indent=2, ensure_ascii=False)
        tmp.replace(STATUS_FILE)

    def set_objective(self, obj):
        self.data["objective"] = obj
        self._save()
        console.print(f"[green]âœ… ç›®æ ‡æ›´æ–°:[/green] {obj}")

    def add_task(self, task):
        self.data["tasks"].append({"desc": task, "status": "todo", "time": str(datetime.now())})
        self._save()
        console.print(f"[green]âœ… ä»»åŠ¡+1:[/green] {task}")
    
    def add_rule(self, rule):
        if "guidelines" not in self.data: self.data["guidelines"] = []
        self.data["guidelines"].append(rule)
        self._save()
        console.print(f"[bold magenta]ğŸ“œ å®—æ—¨å½•å…¥:[/bold magenta] {rule}")

    def complete_task(self, index):
        if 0 <= index < len(self.data["tasks"]):
            self.data["tasks"][index]["status"] = "done"
            self._save()
            console.print(f"[green]ğŸ‰ å®Œæˆ:[/green] {self.data['tasks'][index]['desc']}")
        else:
            console.print("[red]âŒ ç´¢å¼•æ— æ•ˆ[/red]")

    def log_entry(self, msg):
        self.data["logs"].append(f"[{datetime.now().strftime('%Y-%m-%d %H:%M')}] {msg}")
        if len(self.data["logs"]) > 10: self.data["logs"].pop(0)
        self._save()
        console.print("[green]ğŸ“ æ—¥å¿—å·²è®°å½•[/green]")

    def show_status(self):
        console.clear()
        console.print(Panel(f"[bold blue]ğŸ¯ ç›®æ ‡: {self.data.get('objective', 'Unset')}[/bold blue]"))
        
        t_table = Table(title="ä»»åŠ¡æ¸…å•", box=None)
        t_table.add_column("ID", style="dim"); t_table.add_column("çŠ¶æ€"); t_table.add_column("å†…å®¹")
        for i, t in enumerate(self.data["tasks"]):
            status = "âœ…" if t["status"] == "done" else "â¬œ"
            style = "dim strike" if t["status"] == "done" else "bold"
            t_table.add_row(str(i), status, f"[{style}]{t['desc']}[/{style}]")
        console.print(t_table)
        
        if self.data.get("logs"):
            console.print("\n[dim]ğŸ“œ æœ€è¿‘æ—¥å¿—:[/dim]")
            for l in self.data["logs"][-3:]:
                console.print(f"  {l}")

    def interactive_mode(self):
        while True:
            self.show_status()
            console.print("\n[bold cyan]æ“ä½œèœå•:[/bold cyan]")
            console.print("1. [green]âœ… å®Œæˆä»»åŠ¡[/]  2. [blue]â• æ–°å¢ä»»åŠ¡[/]  3. [magenta]ğŸ“ å†™æ—¥å¿—[/]  4. [yellow]ğŸ¯ æ”¹ç›®æ ‡[/]  0. [red]é€€å‡º[/]")
            
            choice = Prompt.ask("é€‰æ‹©æ“ä½œ", choices=["0", "1", "2", "3", "4"], default="0")
            
            if choice == "0": break
            elif choice == "1":
                idx = IntPrompt.ask("è¾“å…¥ä»»åŠ¡ID")
                self.complete_task(idx)
            elif choice == "2":
                desc = Prompt.ask("è¾“å…¥ä»»åŠ¡æè¿°")
                self.add_task(desc)
            elif choice == "3":
                log = Prompt.ask("è¾“å…¥æ—¥å¿—å†…å®¹")
                self.log_entry(log)
            elif choice == "4":
                obj = Prompt.ask("è¾“å…¥æ–°ç›®æ ‡")
                self.set_objective(obj)
            
            if choice != "0":
                input("\næŒ‰å›è½¦ç»§ç»­...")

def main():
    pm = ProjectManager()
    if len(sys.argv) > 1:
        cmd = sys.argv[1]
        content = " ".join(sys.argv[2:])
        
        if cmd == "obj": pm.set_objective(content)
        elif cmd == "add": pm.add_task(content)
        elif cmd == "rule": pm.add_rule(content)
        elif cmd == "done":
            # [ä¿®å¤] å¢åŠ å‚æ•°æ£€æŸ¥
            if len(sys.argv) < 3:
                console.print("[red]ç”¨æ³•: pm done <task_id>[/red]")
                return
            pm.complete_task(int(sys.argv[2]))
        elif cmd == "log": pm.log_entry(content)
        elif cmd == "ui": pm.interactive_mode()
        else: pm.show_status()
    else:
        pm.interactive_mode()

if __name__ == "__main__":
    main()
```

### File: devtools/reporter.py
> size=4763B, sha256=915b1577a0aa
```python
#!/usr/bin/env python3
import os
import sys
import re
from collections import Counter, defaultdict
from rich.console import Console
from rich.progress import track

# æŒ‚è½½ src å¹¶å¼•å…¥å¼•æ“
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "src"))
from engine import WagstaffEngine

console = Console()

# === [ä¿®å¤] åŠ¨æ€å®šä½é¡¹ç›®è·¯å¾„ ===
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
REPORT_DIR = os.path.join(PROJECT_ROOT, "data", "reports")

class WagstaffReporter:
    def __init__(self):
        # å¯åŠ¨å¼•æ“ï¼Œä¸éœ€è¦åŠ è½½æ•°æ®åº“(æˆ‘ä»¬åªåšæ­£åˆ™æ‰«æ)
        self.engine = WagstaffEngine(load_db=False, silent=True)
        self._ensure_report_dir()

    def _ensure_report_dir(self):
        if not os.path.exists(REPORT_DIR):
            os.makedirs(REPORT_DIR)
            console.print(f"[green]ğŸ“ åˆ›å»ºæŠ¥å‘Šç›®å½•: {REPORT_DIR}[/green]")

    def generate_asset_report(self):
        """æ‰«æå…¨æœèµ„äº§åˆ†å¸ƒ"""
        console.print("[bold blue]ğŸ“¡ æ­£åœ¨ç”Ÿæˆèµ„äº§åˆ†å¸ƒæŠ¥å‘Š...[/bold blue]")
        
        TARGETS = {
            "STRINGS": re.compile(r'STRINGS\.[A-Z0-9_]+\s*='),
            "Prefabs": re.compile(r'\bPrefab\s*\('),
            "LootTables": re.compile(r'\bSetLoot\s*\(|\bSetChanceLoot\s*\('),
            "Brains": re.compile(r'require\s*[\("\']brains/'),
            "Widgets": re.compile(r'require\s*[\("\']widgets/'),
        }
        
        stats = defaultdict(Counter)
        lua_files = [f for f in self.engine.file_list if f.endswith(".lua")]
        
        for fname in track(lua_files, description="Scanning Assets..."):
            content = self.engine.read_file(fname)
            if not content: continue
            clean = re.sub(r'--.*$', '', content, flags=re.MULTILINE)
            
            for cat, pattern in TARGETS.items():
                matches = pattern.findall(clean)
                if matches:
                    stats[cat][fname] += len(matches)

        out_path = os.path.join(REPORT_DIR, "asset_registry.md")
        with open(out_path, 'w', encoding='utf-8') as f:
            f.write("# Wagstaff Asset Registry\n\n")
            f.write("| Category | Total Definitions | Top File |\n")
            f.write("|----------|-------------------|----------|\n")
            for cat, file_counts in stats.items():
                total = sum(file_counts.values())
                top_file = file_counts.most_common(1)[0][0]
                f.write(f"| {cat} | {total} | `{top_file}` |\n")
            
            f.write("\n## Detailed Breakdown\n")
            for cat, file_counts in stats.items():
                f.write(f"\n### {cat}\n")
                for fname, count in file_counts.most_common(10):
                    f.write(f"- `{fname}`: {count}\n")
        console.print(f"[green]âœ… æŠ¥å‘Šå·²ä¿å­˜: {out_path}[/green]")

    def generate_recipe_report(self):
        """æ‰«æé…æ–¹åˆ†å¸ƒ"""
        console.print("[bold blue]ğŸ³ æ­£åœ¨ç”Ÿæˆé…æ–¹åˆ†å¸ƒæŠ¥å‘Š...[/bold blue]")
        
        pattern = re.compile(r'^\s*([a-zA-Z0-9_]*Recipe[a-zA-Z0-9_]*)\s*\(', re.MULTILINE)
        stats = Counter()
        file_stats = defaultdict(int)
        
        lua_files = [f for f in self.engine.file_list if f.endswith(".lua")]
        
        for fname in track(lua_files, description="Scanning Recipes..."):
            content = self.engine.read_file(fname)
            if not content: continue
            clean = re.sub(r'--.*$', '', content, flags=re.MULTILINE)
            
            matches = pattern.findall(clean)
            for m in matches:
                if "Get" in m or "Find" in m: continue
                stats[m] += 1
                file_stats[fname] += 1

        out_path = os.path.join(REPORT_DIR, "recipe_distribution.md")
        with open(out_path, 'w', encoding='utf-8') as f:
            f.write("# Wagstaff Recipe Distribution\n\n")
            f.write("## Function Usage\n")
            for func, count in stats.most_common():
                f.write(f"- **{func}**: {count}\n")
            f.write("\n## File Hotspots (Top 20)\n")
            for fname, count in sorted(file_stats.items(), key=lambda x:x[1], reverse=True)[:20]:
                f.write(f"- `{fname}`: {count} recipes\n")

        console.print(f"[green]âœ… æŠ¥å‘Šå·²ä¿å­˜: {out_path}[/green]")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python reporter.py [assets|recipes|all]")
        sys.exit(1)
    reporter = WagstaffReporter()
    cmd = sys.argv[1]
    if cmd == "assets" or cmd == "all": reporter.generate_asset_report()
    if cmd == "recipes" or cmd == "all": reporter.generate_recipe_report()
```

### File: devtools/snapshot.py
> size=35893B, sha256=c7a204308811
```python
#!/usr/bin/env python3
"""
Wagstaff-Lab Snapshot Generator (v4)

Goals:
- Make snapshots practical for LLM collaboration as the repo grows.
- Provide 3 modes:
  1) full   : archive-grade, include everything (bounded by limits)
  2) core   : LLM-grade, include core business code fully + overview + progress; summarize framework
  3) custom : user-defined export rules via JSON config + CLI overrides

Output is a single markdown-ish text file (safe to paste into LLMs).
"""

from __future__ import annotations

import argparse
import ast
import hashlib
import json
import os
import platform
import re
import subprocess
import sys
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path, PurePosixPath
from typing import Dict, Iterable, List, Optional, Sequence, Tuple


PROJECT_ROOT = Path(__file__).resolve().parent.parent
DEFAULT_CORE_OUTPUT = PROJECT_ROOT / "project_context.txt"
DEFAULT_SNAPSHOT_DIR = PROJECT_ROOT / "snapshots"

IGNORE_DIRS = {
    ".git",
    "__pycache__",
    ".pytest_cache",
    ".mypy_cache",
    ".ruff_cache",
    "logs",
    "env",
    "venv",
    ".venv",
    ".idea",
    ".vscode",
    "dist",
    "build",
    ".cache",
    "snapshots",  # prevent recursive growth from previous outputs
}

DEFAULT_IGNORE_FILES = {
    "project_context.txt",
    ".DS_Store",
    "id_rsa",
    "id_ed25519",
    "known_hosts",
}

DEFAULT_IGNORE_GLOBS: List[str] = [
    "**/*.swp",
    "**/*.swo",
    "**/*.tmp",
    "**/*.bak",
    "**/*.log",
    "**/*.zip",
    "**/*.tar",
    "**/*.tar.gz",
    "**/*.gz",
    "**/*.7z",
    "**/*.rar",
    "**/*.png",
    "**/*.jpg",
    "**/*.jpeg",
    "**/*.webp",
    "**/*.pdf",
    "**/*.mp4",
    "**/*.mov",
    "**/*.sqlite",
    "**/*.db",
    "**/.env",
    "**/.env.*",
    "**/*.pem",
    "**/*.key",
]

REDACT_KEYS = (
    "PASSWORD",
    "PASSWD",
    "PWD",
    "SECRET",
    "TOKEN",
    "API_KEY",
    "ACCESS_KEY",
    "PRIVATE_KEY",
    "OPENAI_API_KEY",
)

HOME_STR = str(Path.home())
ROOT_STR = str(PROJECT_ROOT)


@dataclass(frozen=True)
class ReadResult:
    text: str
    truncated: bool
    size_bytes: int
    sha256_12: str


@dataclass
class Profile:
    name: str
    default_action: str  # "full" | "stub" | "omit"
    full_globs: List[str]
    stub_globs: List[str]
    omit_globs: List[str]
    max_file_bytes: int
    max_total_bytes: int
    inventory_limit: int = 200
    include_tree: bool = True
    include_env: bool = True
    include_git: bool = True
    include_registry_summary: bool = True
    include_import_graph: bool = True
    include_status: bool = True


def _run_cmd(args: Sequence[str]) -> Tuple[int, str]:
    try:
        out = subprocess.check_output(list(args), cwd=PROJECT_ROOT, text=True, stderr=subprocess.DEVNULL)
        return 0, out.strip()
    except subprocess.CalledProcessError as e:
        return e.returncode, (e.output or "").strip()
    except Exception:
        return 1, ""


def _is_git_repo() -> bool:
    return (PROJECT_ROOT / ".git").exists()


def _to_rel_posix(p: Path) -> PurePosixPath:
    return PurePosixPath(p.relative_to(PROJECT_ROOT).as_posix())


def _match_any(rel_posix: PurePosixPath, patterns: Iterable[str]) -> bool:
    for pat in patterns:
        if rel_posix.match(pat):
            return True
    return False


def should_ignore(path: Path, ignore_files: set[str], ignore_globs: Sequence[str]) -> bool:
    try:
        rel = _to_rel_posix(path)
    except Exception:
        return True

    if any(part in IGNORE_DIRS for part in rel.parts):
        return True
    if path.name in ignore_files:
        return True
    if _match_any(rel, ignore_globs):
        return True
    return False


def list_candidate_files(ignore_files: set[str], ignore_globs: Sequence[str]) -> List[Path]:
    """
    Prefer git for stable, growth-friendly inventory:
      git ls-files -co --exclude-standard
    Falls back to filesystem walk if not a git repo.
    """
    files: List[Path] = []
    if _is_git_repo():
        rc, out = _run_cmd(["git", "ls-files", "-co", "--exclude-standard"])
        if rc == 0 and out:
            for line in out.splitlines():
                line = line.strip()
                if not line:
                    continue
                p = (PROJECT_ROOT / line).resolve()
                if p.is_file() and not should_ignore(p, ignore_files, ignore_globs):
                    files.append(p)
            files.sort(key=lambda x: _to_rel_posix(x).as_posix())
            return files

    # fallback: filesystem walk
    for p in PROJECT_ROOT.rglob("*"):
        if p.is_file() and not should_ignore(p, ignore_files, ignore_globs):
            files.append(p)
    files.sort(key=lambda x: _to_rel_posix(x).as_posix())
    return files


def _looks_binary(sample: bytes) -> bool:
    if b"\x00" in sample:
        return True
    if not sample:
        return False
    text_chars = b"\t\n\r\b" + bytes(range(32, 127))
    nontext = sum(1 for b in sample if b not in text_chars)
    return (nontext / max(1, len(sample))) > 0.30


def _sha256_12(path: Path) -> str:
    h = hashlib.sha256()
    with path.open("rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()[:12]


def _normalize_paths(text: str) -> str:
    # reduce host-specific noise
    if HOME_STR and HOME_STR not in ("/", "\\"):
        text = text.replace(HOME_STR, "$HOME")
    if ROOT_STR:
        text = text.replace(ROOT_STR, "$PROJECT_ROOT")
    return text


def _redact(text: str) -> str:
    out_lines: List[str] = []
    for line in text.splitlines():
        stripped = line.strip()
        upper = stripped.upper()

        # KEY=... or KEY: ... (allow spaces)
        redacted = False
        for k in REDACT_KEYS:
            if upper.startswith(k + "=") or upper.startswith(k + ":") or upper.startswith(k + " =") or upper.startswith(k + " :"):
                # split on first ':' or '=' present
                m = re.search(r"[:=]", stripped)
                if m:
                    idx = m.start()
                    prefix = stripped[:idx].rstrip()
                    sep = stripped[idx]
                    out_lines.append(f"{prefix}{sep} ***REDACTED***")
                else:
                    out_lines.append(f"{k}=***REDACTED***")
                redacted = True
                break
        if redacted:
            continue

***REDACTED PRIVATE KEY BLOCK***
            out_lines.append("***REDACTED PRIVATE KEY BLOCK***")
            continue

        out_lines.append(line)

    return "\n".join(out_lines)


def _postprocess_text(text: str, redact: bool) -> str:
    text = _normalize_paths(text)
    if redact:
        text = _redact(text)
    return text


def read_text_snippet(path: Path, max_file_bytes: int, redact: bool) -> Optional[ReadResult]:
    try:
        size = path.stat().st_size
    except Exception:
        return None

    # quick binary guard
    try:
        with path.open("rb") as f:
            head = f.read(min(4096, size))
            if _looks_binary(head):
                return None
    except Exception:
        return None

    try:
        sha12 = _sha256_12(path)
    except Exception:
        sha12 = "Unknown"

    truncated = False
    try:
        if size <= max_file_bytes:
            raw = path.read_text(encoding="utf-8", errors="replace")
        else:
            truncated = True
            # keep total payload roughly within max_file_bytes (+marker), not 2x
            head_bytes = max(1, max_file_bytes // 2)
            tail_bytes = max(1, max_file_bytes - head_bytes)

            with path.open("rb") as f:
                head_chunk = f.read(head_bytes)
                if size > tail_bytes:
                    f.seek(-tail_bytes, os.SEEK_END)
                tail_chunk = f.read(tail_bytes)
            raw = (
                head_chunk.decode("utf-8", errors="replace")
                + "\n\n... [TRUNCATED: middle omitted] ...\n\n"
                + tail_chunk.decode("utf-8", errors="replace")
            )
    except Exception:
        return None

    text = _postprocess_text(raw, redact=redact)
    return ReadResult(text=text, truncated=truncated, size_bytes=size, sha256_12=sha12)


def detect_lang(path: Path) -> str:
    ext = path.suffix.lower()
    if ext == ".py":
        return "python"
    if ext == ".sh":
        return "bash"
    if ext in (".md", ".markdown"):
        return "markdown"
    if ext == ".ini":
        return "toml"
    if ext == ".json":
        return "json"
    if ext in (".yml", ".yaml"):
        return "yaml"
    if ext in (".txt", ".patch"):
        return "text"
    return ""


def generate_tree(root: Path, ignore_files: set[str], ignore_globs: Sequence[str], limit_lines: int = 5000) -> str:
    lines: List[str] = []

    def walk(dir_path: Path, prefix: str = "") -> None:
        if len(lines) >= limit_lines:
            lines.append(prefix + "... [TREE TRUNCATED]")
            return
        try:
            entries = sorted(dir_path.iterdir(), key=lambda p: (not p.is_dir(), p.name.lower()))
        except PermissionError:
            lines.append(f"{prefix}â””â”€â”€ [Permission Denied]")
            return

        filtered: List[Path] = []
        for p in entries:
            if p.name in IGNORE_DIRS:
                continue
            if should_ignore(p, ignore_files, ignore_globs):
                continue
            filtered.append(p)

        for i, p in enumerate(filtered):
            if len(lines) >= limit_lines:
                lines.append(prefix + "... [TREE TRUNCATED]")
                return
            pointer = "â””â”€â”€ " if i == len(filtered) - 1 else "â”œâ”€â”€ "
            lines.append(f"{prefix}{pointer}{p.name}")
            if p.is_dir():
                extension = "    " if pointer == "â””â”€â”€ " else "â”‚   "
                walk(p, prefix + extension)

    walk(root, "")
    return "\n".join(lines)


def _format_env(minimal: bool) -> str:
    now = datetime.now().astimezone().isoformat(timespec="seconds")
    info: List[str] = []
    info.append(f"Time: {now}")
    if not minimal:
        info.append(f"User: {os.getenv('USER') or os.getenv('USERNAME') or 'Unknown'}")
        info.append(f"Host: {platform.node()} ({platform.system()} {platform.release()})")
    info.append(f"Platform: {platform.platform()}")
    info.append(f"Python: {platform.python_version()} ({sys.executable})")
    info.append(f"Conda Env: {os.getenv('CONDA_DEFAULT_ENV', 'None')}")
    return _postprocess_text("\n".join(info), redact=True)


def _format_git() -> str:
    if not _is_git_repo():
        return "Git: Not a repository"

    def cmd(args: List[str]) -> str:
        rc, out = _run_cmd(args)
        return out if rc == 0 and out else "Unknown"

    branch = cmd(["git", "rev-parse", "--abbrev-ref", "HEAD"])
    commit = cmd(["git", "rev-parse", "--short", "HEAD"])
    msg = cmd(["git", "log", "-1", "--pretty=%B"]).replace("\n", " ").strip()
    porcelain = cmd(["git", "status", "--porcelain"])
    is_dirty = porcelain not in ("", "Unknown")
    dirty_mark = " [DIRTY]" if is_dirty else " [CLEAN]"

    modified = 0
    untracked = 0
    if porcelain not in ("", "Unknown"):
        for line in porcelain.splitlines():
            if line.startswith("??"):
                untracked += 1
            else:
                modified += 1

    out_lines = [
        f"Branch: {branch}{dirty_mark}",
        f"Commit: {commit}",
        f"Message: {msg}",
        f"Changes: modified={modified}, untracked={untracked}",
    ]

    diff_stat = cmd(["git", "diff", "--stat"])
    if diff_stat not in ("", "Unknown"):
        lines = diff_stat.splitlines()
        if len(lines) > 20:
            lines = lines[:20] + ["... (diff --stat truncated)"]
        out_lines.append("---")
        out_lines.extend(lines)

    return _postprocess_text("\n".join(out_lines), redact=True)


# --------- Core-mode helpers: status + registry + deps ---------

def render_project_status(status_path: Path) -> str:
    if not status_path.exists():
        return "No project status file found."

    try:
        data = json.loads(status_path.read_text(encoding="utf-8"))
    except Exception:
        return "Error reading project status."

    out: List[str] = []
    guidelines = data.get("guidelines") or []
    if guidelines:
        out.append("DEV MANIFESTO:")
        for rule in guidelines:
            out.append(f"* {rule}")
        out.append("-" * 20)

    objective = data.get("objective")
    if objective is not None:
        out.append(f"OBJECTIVE: {objective}")

    tasks = data.get("tasks") or []
    if tasks:
        done = sum(1 for t in tasks if t.get("status") == "done")
        out.append(f"\nTASKS: ({done}/{len(tasks)} done)")
        for i, t in enumerate(tasks, start=1):
            status = t.get("status", "todo")
            mark = "[x]" if status == "done" else "[ ]"
            desc = t.get("desc", "")
            out.append(f"{i}. {mark} {desc}")

    logs = data.get("logs") or []
    if logs:
        out.append("\nRECENT LOGS:")
        for l in logs[-5:]:
            out.append(f"* {l}")

    return _postprocess_text("\n".join(out).rstrip(), redact=True)


def try_load_registry_tools() -> List[Dict]:
    reg = PROJECT_ROOT / "src" / "registry.py"
    if not reg.exists():
        return []
    try:
        import importlib.util
        spec = importlib.util.spec_from_file_location("wagstaff_registry", reg)
        if spec is None or spec.loader is None:
            return []
        mod = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(mod)  # type: ignore[attr-defined]
        tools = getattr(mod, "TOOLS", None)
        if isinstance(tools, list):
            return tools
        fn = getattr(mod, "get_tools", None)
        if callable(fn):
            t = fn()
            return t if isinstance(t, list) else []
        return []
    except Exception:
        return []


def render_registry_summary() -> str:
    tools = try_load_registry_tools()
    if not tools:
        return "Registry not found or unreadable."

    lines: List[str] = []
    lines.append("| alias | file | folder | type | usage | desc |")
    lines.append("|---|---|---|---|---|---|")
    for t in tools:
        alias = t.get("alias") or "-"
        file = t.get("file") or "-"
        folder = t.get("folder") or "src"
        typ = t.get("type") or "-"
        usage = (t.get("usage") or "").replace("|", "\\|")
        desc = (t.get("desc") or "").replace("|", "\\|")
        lines.append(f"| {alias} | {file} | {folder} | {typ} | {usage} | {desc} |")

    return _postprocess_text("\n".join(lines), redact=True)


def build_internal_import_graph(py_files: List[Path]) -> List[Tuple[str, str]]:
    """
    Returns edges (src_rel -> dst_rel) for internal imports only.
    """
    module_map: Dict[str, str] = {}
    for p in py_files:
        rel = _to_rel_posix(p).as_posix()
        if rel.startswith("src/") or rel.startswith("devtools/"):
            module_map[p.stem] = rel

    edges: List[Tuple[str, str]] = []
    for p in py_files:
        rel_src = _to_rel_posix(p).as_posix()
        try:
            text = p.read_text(encoding="utf-8", errors="replace")
            tree = ast.parse(text)
        except Exception:
            continue

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for n in node.names:
                    top = (n.name or "").split(".")[0]
                    if top in module_map and module_map[top] != rel_src:
                        edges.append((rel_src, module_map[top]))
            elif isinstance(node, ast.ImportFrom):
                if not node.module:
                    continue
                top = node.module.split(".")[0]
                if top in module_map and module_map[top] != rel_src:
                    edges.append((rel_src, module_map[top]))

    return sorted(set(edges))


def render_import_graph(edges: List[Tuple[str, str]], limit: int = 200) -> str:
    if not edges:
        return "(no internal imports detected)"
    out: List[str] = []
    for i, (a, b) in enumerate(edges):
        if i >= limit:
            out.append("... (graph truncated)")
            break
        out.append(f"- {a}  ->  {b}")
    return _postprocess_text("\n".join(out), redact=True)


# --------- Stub generation ---------

def _shorten(s: str, max_len: int = 60) -> str:
    s = " ".join(s.split())
    return s if len(s) <= max_len else (s[: max_len - 3] + "...")


def _unparse(node: ast.AST) -> str:
    try:
        return ast.unparse(node)  # py>=3.9
    except Exception:
        return ""


def _fmt_arg(a: ast.arg) -> str:
    s = a.arg
    if a.annotation is not None:
        ann = _unparse(a.annotation)
        if ann:
            s += f": {ann}"
    return s


def _summ_default(expr: ast.AST) -> str:
    s = _unparse(expr) or "..."
    return _shorten(s, 40)


def format_func_signature(fn: ast.AST) -> str:
    name = getattr(fn, "name", "func")
    args: ast.arguments = getattr(
        fn,
        "args",
        ast.arguments(posonlyargs=[], args=[], vararg=None, kwonlyargs=[], kw_defaults=[], kwarg=None, defaults=[]),
    )

    pos = list(args.posonlyargs) + list(args.args)
    defaults = list(args.defaults or [])
    default_offset = len(pos) - len(defaults)

    parts: List[str] = []

    for i, a in enumerate(args.posonlyargs):
        item = _fmt_arg(a)
        if i >= default_offset:
            item += f"={_summ_default(defaults[i - default_offset])}"
        parts.append(item)
    if args.posonlyargs:
        parts.append("/")

    for j, a in enumerate(args.args):
        i = len(args.posonlyargs) + j
        item = _fmt_arg(a)
        if i >= default_offset:
            item += f"={_summ_default(defaults[i - default_offset])}"
        parts.append(item)

    if args.vararg is not None:
        parts.append("*" + _fmt_arg(args.vararg))
    elif args.kwonlyargs:
        parts.append("*")

    for a, d in zip(args.kwonlyargs, args.kw_defaults):
        item = _fmt_arg(a)
        if d is not None:
            item += f"={_summ_default(d)}"
        parts.append(item)

    if args.kwarg is not None:
        parts.append("**" + _fmt_arg(args.kwarg))

    ret = ""
    returns = getattr(fn, "returns", None)
    if returns is not None:
        r = _unparse(returns)
        if r:
            ret = f" -> {r}"

    return f"def {name}({', '.join(parts)}){ret}: ..."


def summarize_python_constants(tree: ast.Module, max_items: int = 20) -> List[str]:
    lines: List[str] = []
    count = 0

    for node in tree.body:
        if isinstance(node, ast.Assign):
            names = [t.id for t in node.targets if isinstance(t, ast.Name)]
            if not names:
                continue
            for n in names:
                if not (n.isupper() or n.endswith("_PATH") or n.endswith("_FILE") or n.endswith("_DIR")):
                    continue
                if count >= max_items:
                    lines.append("... (constants truncated)")
                    return lines
                val = node.value
                if isinstance(val, ast.List):
                    lines.append(f"{n} = list(len={len(val.elts)})")
                elif isinstance(val, ast.Dict):
                    lines.append(f"{n} = dict(len={len(val.keys)})")
                else:
                    v = _unparse(val)
                    lines.append(f"{n} = {_shorten(v or '...', 80)}")
                count += 1
        elif isinstance(node, ast.AnnAssign) and isinstance(node.target, ast.Name):
            n = node.target.id
            if not (n.isupper() or n.endswith("_PATH") or n.endswith("_FILE") or n.endswith("_DIR")):
                continue
            if count >= max_items:
                lines.append("... (constants truncated)")
                return lines
            v = _unparse(node.value) if node.value is not None else "..."
            lines.append(f"{n} = {_shorten(v or '...', 80)}")
            count += 1

    return lines


def python_interface_stub(text: str) -> str:
    """
    Returns a compact interface-oriented representation:
    - module docstring (first line)
    - key constants (bounded)
    - classes/functions signatures
    """
    try:
        tree = ast.parse(text)
    except Exception:
        head = "\n".join(text.splitlines()[:60])
        return head + ("\n... (stub fallback; parse failed)" if len(text.splitlines()) > 60 else "")

    out: List[str] = []

    doc = ast.get_docstring(tree) or ""
    if doc:
        out.append(f'""" {_shorten(doc.splitlines()[0], 120)} """')
        out.append("")

    consts = summarize_python_constants(tree)
    if consts:
        out.append("# Key constants")
        out.extend(consts)
        out.append("")

    out.append("# API (signatures)")
    for node in tree.body:
        if isinstance(node, ast.ClassDef):
            bases = [_unparse(b) for b in node.bases] if node.bases else []
            base_str = f"({', '.join([b for b in bases if b])})" if bases else ""
            cdoc = ast.get_docstring(node) or ""
            cdoc_1 = f"  # {_shorten(cdoc.splitlines()[0], 80)}" if cdoc else ""
            out.append(f"class {node.name}{base_str}: ...{cdoc_1}")

            for item in node.body:
                if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    sig = format_func_signature(item)
                    mdoc = ast.get_docstring(item) or ""
                    if mdoc:
                        sig += f"  # {_shorten(mdoc.splitlines()[0], 80)}"
                    out.append("    " + sig)
            out.append("")
        elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
            sig = format_func_signature(node)
            fdoc = ast.get_docstring(node) or ""
            if fdoc:
                sig += f"  # {_shorten(fdoc.splitlines()[0], 80)}"
            out.append(sig)

    return "\n".join(out).rstrip()


def shell_function_stub(text: str) -> str:
    names = re.findall(r"^\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*\(\)\s*\{", text, flags=re.MULTILINE)
    out: List[str] = []
    if names:
        out.append("# Functions")
        for n in sorted(set(names)):
            out.append(f"- {n}()")
        out.append("")

    head = "\n".join(text.splitlines()[:80])
    out.append("# Head (first 80 lines)")
    out.append(head)
    if len(text.splitlines()) > 80:
        out.append("\n... (shell stub truncated)")
    return "\n".join(out).rstrip()


def markdown_stub(text: str, max_lines: int = 120) -> str:
    lines = text.splitlines()
    head = "\n".join(lines[:max_lines])
    if len(lines) <= max_lines:
        return head
    return head + "\n... (markdown stub truncated)"


def make_stub(path: Path, max_file_bytes: int, redact: bool) -> Optional[ReadResult]:
    rr = read_text_snippet(path, max_file_bytes=max_file_bytes, redact=redact)
    if rr is None:
        return None

    lang = detect_lang(path)
    raw = rr.text

    if lang == "python":
        stub = python_interface_stub(raw)
    elif lang == "bash":
        stub = shell_function_stub(raw)
    elif lang == "markdown":
        stub = markdown_stub(raw)
    else:
        stub = "\n".join(raw.splitlines()[:120])
        if len(raw.splitlines()) > 120:
            stub += "\n... (stub truncated)"

    stub_text = _postprocess_text(stub, redact=redact)
    return ReadResult(text=stub_text, truncated=True, size_bytes=rr.size_bytes, sha256_12=rr.sha256_12)


# --------- Profiles ---------

def builtin_profile(name: str) -> Profile:
    name = name.lower().strip()
    if name == "full":
        return Profile(
            name="full",
            default_action="full",
            full_globs=[],
            stub_globs=[],
            omit_globs=["project_context.txt"],
            max_file_bytes=300_000,
            max_total_bytes=8_000_000,
            inventory_limit=1000,
        )

    # core (default)
    return Profile(
        name="core",
        default_action="omit",
        full_globs=[
            "src/**/*.py",
            "bin/dst_tool.sh",
            "bin/boot.sh",
            "conf/settings.ini",
            "PROJECT_STATUS.json",
            "README.md",
            "setup.sh",
            "tests/**/*.py",
        ],
        stub_globs=[
            "devtools/**/*.py",
            "bin/wagstaff",
            "bin/pm",
            "bin/Wagstaff-Lab",
            "data/reports/**/*.md",
            "*.patch",
            ".gitignore",
        ],
        omit_globs=[
            "project_context.txt",
            "snapshots/**",
        ],
        max_file_bytes=120_000,
        max_total_bytes=900_000,
        inventory_limit=250,
    )


def load_custom_profile(path: Path) -> Optional[Profile]:
    if not path.exists():
        return None
    try:
        data = json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return None

    name = str(data.get("name") or "custom")
    default_action = str(data.get("default_action") or "omit")
    full_globs = list(data.get("full") or [])
    stub_globs = list(data.get("stub") or [])
    omit_globs = list(data.get("omit") or [])

    opts = data.get("options") or {}
    max_file = int(opts.get("max_file_bytes") or 120_000)
    max_total = int(opts.get("max_total_bytes") or 900_000)
    inv_lim = int(opts.get("inventory_limit") or 250)

    return Profile(
        name=name,
        default_action=default_action,
        full_globs=full_globs,
        stub_globs=stub_globs,
        omit_globs=omit_globs,
        max_file_bytes=max_file,
        max_total_bytes=max_total,
        inventory_limit=inv_lim,
        include_tree=bool(opts.get("include_tree", True)),
        include_env=bool(opts.get("include_env", True)),
        include_git=bool(opts.get("include_git", True)),
        include_registry_summary=bool(opts.get("include_registry_summary", True)),
        include_import_graph=bool(opts.get("include_import_graph", True)),
        include_status=bool(opts.get("include_status", True)),
    )


def classify_file(rel: PurePosixPath, profile: Profile) -> str:
    if _match_any(rel, profile.omit_globs):
        return "omit"
    if _match_any(rel, profile.full_globs):
        return "full"
    if _match_any(rel, profile.stub_globs):
        return "stub"
    return profile.default_action


def estimate_tokens(text: str) -> int:
    return max(1, len(text) // 4)


def main(argv: Optional[Sequence[str]] = None) -> int:
    parser = argparse.ArgumentParser(description="Generate Wagstaff-Lab snapshot (LLM-friendly).")
    parser.add_argument("--mode", choices=["core", "full", "custom"], default="core")
    parser.add_argument("-o", "--output", default="")
    parser.add_argument("--config", default="", help="Custom profile JSON (used in --mode custom).")
    parser.add_argument("--full", dest="full_globs", action="append", default=[], help="Add a FULL glob (custom).")
    parser.add_argument("--stub", dest="stub_globs", action="append", default=[], help="Add a STUB glob (custom).")
    parser.add_argument("--omit", dest="omit_globs", action="append", default=[], help="Add an OMIT glob (custom).")
    parser.add_argument("--max-file-bytes", type=int, default=0)
    parser.add_argument("--max-total-bytes", type=int, default=0)
    parser.add_argument("--no-redact", action="store_true")
    parser.add_argument("--no-tree", action="store_true")
    parser.add_argument("--no-deps", action="store_true")
    parser.add_argument("--no-inventory", action="store_true")
    parser.add_argument("--stdout", action="store_true")
    args = parser.parse_args(list(argv) if argv is not None else None)

    # profile selection
    if args.mode == "custom":
        cfg_path = Path(args.config) if args.config else (PROJECT_ROOT / "conf" / "snapshot_profile.json")
        if not cfg_path.is_absolute():
            cfg_path = (PROJECT_ROOT / cfg_path).resolve()
        prof = load_custom_profile(cfg_path) or builtin_profile("core")
        prof.full_globs.extend([g for g in args.full_globs if g])
        prof.stub_globs.extend([g for g in args.stub_globs if g])
        prof.omit_globs.extend([g for g in args.omit_globs if g])
    else:
        prof = builtin_profile(args.mode)

    if args.max_file_bytes and args.max_file_bytes > 0:
        prof.max_file_bytes = int(args.max_file_bytes)
    if args.max_total_bytes and args.max_total_bytes > 0:
        prof.max_total_bytes = int(args.max_total_bytes)

    if args.no_tree:
        prof.include_tree = False
    if args.no_deps:
        prof.include_import_graph = False

    redact = not args.no_redact

    # output path
    if args.output:
        out_path = Path(args.output)
        if not out_path.is_absolute():
            out_path = (PROJECT_ROOT / out_path).resolve()
    else:
        if args.mode == "full":
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            DEFAULT_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
            out_path = DEFAULT_SNAPSHOT_DIR / f"snapshot_full_{ts}.md"
        else:
            out_path = DEFAULT_CORE_OUTPUT

    ignore_files = set(DEFAULT_IGNORE_FILES) | {out_path.name}
    ignore_globs = list(DEFAULT_IGNORE_GLOBS)

    candidates = list_candidate_files(ignore_files=ignore_files, ignore_globs=ignore_globs)

    full_files: List[Path] = []
    stub_files: List[Path] = []
    omit_files: List[Path] = []

    for p in candidates:
        rel = _to_rel_posix(p)
        action = classify_file(rel, prof)
        if action == "full":
            full_files.append(p)
        elif action == "stub":
            stub_files.append(p)
        else:
            omit_files.append(p)

    report: List[str] = []
    report.append(f"# Wagstaff-Lab Snapshot ({args.mode})")
    report.append("")
    report.append("## Snapshot Meta")
    report.append("```yaml")
    report.append(f"mode: {args.mode}")
    report.append(f"profile: {prof.name}")
    report.append(f"generated: {datetime.now().astimezone().isoformat(timespec='seconds')}")
    report.append(f"max_file_bytes: {prof.max_file_bytes}")
    report.append(f"max_total_bytes: {prof.max_total_bytes}")
    report.append(f"redaction: {'on' if redact else 'off'}")
    report.append("```")

    if prof.include_env:
        report.append("")
        report.append("## Environment")
        report.append("```yaml")
        report.append(_format_env(minimal=(args.mode != "full")))
        report.append("```")

    if prof.include_git:
        report.append("")
        report.append("## Git Status")
        report.append("```yaml")
        report.append(_format_git())
        report.append("```")

    if prof.include_tree:
        report.append("")
        report.append("## Project Structure")
        report.append("```text")
        report.append(generate_tree(PROJECT_ROOT, ignore_files=ignore_files, ignore_globs=ignore_globs))
        report.append("```")

    if prof.include_registry_summary:
        report.append("")
        report.append("## Tool Registry (src/registry.py)")
        report.append(render_registry_summary())

    if prof.include_import_graph:
        py_files = [p for p in candidates if p.suffix.lower() == ".py"]
        edges = build_internal_import_graph(py_files)
        report.append("")
        report.append("## Internal Dependency Map (python)")
        report.append(render_import_graph(edges))

    if prof.include_status:
        report.append("")
        report.append("## Project State (PROJECT_STATUS.json)")
        report.append("```text")
        report.append(render_project_status(PROJECT_ROOT / "PROJECT_STATUS.json"))
        report.append("```")

    # content inclusion with budget (counts embedded file text only)
    total_embedded = 0
    included_full = 0
    included_stub = 0
    truncated_files = 0
    skipped_binary = 0
    skipped_budget = 0

    def can_add(payload_bytes: int) -> bool:
        return (total_embedded + payload_bytes) <= prof.max_total_bytes

    if full_files:
        report.append("")
        report.append("## Included Full Files")
    for p in full_files:
        rr = read_text_snippet(p, max_file_bytes=prof.max_file_bytes, redact=redact)
        if rr is None:
            skipped_binary += 1
            continue
        payload_bytes = len(rr.text.encode("utf-8", errors="replace"))
        if not can_add(payload_bytes):
            skipped_budget += 1
            continue

        rel = _to_rel_posix(p).as_posix()
        report.append("")
        report.append(f"### File: {rel}")
        report.append(f"> size={rr.size_bytes}B, sha256={rr.sha256_12}" + (" (TRUNCATED)" if rr.truncated else ""))
        report.append(f"```{detect_lang(p)}".rstrip())
        report.append(rr.text)
        report.append("```")

        included_full += 1
        if rr.truncated:
            truncated_files += 1
        total_embedded += payload_bytes

    if stub_files:
        report.append("")
        report.append("## Stubbed Files (interfaces / summaries)")
    for p in stub_files:
        rr = make_stub(p, max_file_bytes=prof.max_file_bytes, redact=redact)
        if rr is None:
            skipped_binary += 1
            continue
        payload_bytes = len(rr.text.encode("utf-8", errors="replace"))
        if not can_add(payload_bytes):
            skipped_budget += 1
            continue

        rel = _to_rel_posix(p).as_posix()
        report.append("")
        report.append(f"### File: {rel} (STUB)")
        report.append(f"> size={rr.size_bytes}B, sha256={rr.sha256_12} (STUB)")
        report.append(f"```{detect_lang(p)}".rstrip())
        report.append(rr.text)
        report.append("```")

        included_stub += 1
        total_embedded += payload_bytes
        truncated_files += 1

    if (not args.no_inventory) and omit_files:
        report.append("")
        report.append("## Omitted Inventory (for completeness)")
        report.append("```text")
        report.append("path | size(B) | sha256_12")
        report.append("-" * 60)

        shown = 0
        for p in omit_files:
            if shown >= prof.inventory_limit:
                report.append(f"... ({len(omit_files) - shown} more omitted)")
                break
            try:
                size = p.stat().st_size
            except Exception:
                size = -1
            if shown < 50 or args.mode == "full":
                try:
                    sha = _sha256_12(p)
                except Exception:
                    sha = "Unknown"
            else:
                sha = "-"
            rel = _to_rel_posix(p).as_posix()
            report.append(f"{rel} | {size} | {sha}")
            shown += 1

        report.append("```")

    report.append("")
    report.append("## Snapshot Summary")
    report.append("```yaml")
    report.append(f"full_included: {included_full}/{len(full_files)}")
    report.append(f"stub_included: {included_stub}/{len(stub_files)}")
    report.append(f"omitted: {len(omit_files)}")
    report.append(f"skipped_binary: {skipped_binary}")
    report.append(f"skipped_budget: {skipped_budget}")
    report.append(f"files_truncated_or_stubbed: {truncated_files}")
    report.append(f"embedded_bytes: {total_embedded}")
    report.append("```")

    final_text = "\n".join(report)
    report.append("")
    report.append("## Token Estimate (rough)")
    report.append("```text")
    report.append(f"chars: {len(final_text)}")
    report.append(f"estimated_tokens(~chars/4): {estimate_tokens(final_text)}")
    report.append("```")

    final_text = "\n".join(report)

    if args.stdout:
        sys.stdout.write(final_text)
        return 0

    out_path.write_text(final_text, encoding="utf-8")
    print(f"âœ… Snapshot written to: {out_path}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
```

### File: src/analyzer.py
> size=8479B, sha256=770bfc436a2c
```python
#!/usr/bin/env python3
import re

# ==========================================
# 1. å…¨å±€æ•°å€¼è§£æå™¨ (TuningResolver)
# ==========================================
class TuningResolver:
    def __init__(self, content):
        self.raw_map = {}
        if content:
            self._parse_tuning(content)

    def _parse_tuning(self, content):
        clean_content = re.sub(r'\blocal\s+', '', content)
        pattern = re.compile(r'([a-zA-Z0-9_]+)\s*=\s*([^,\r\n]+)')
        for name, raw_val in pattern.findall(clean_content):
            clean_val = raw_val.split('--')[0].strip()
            try:
                self.raw_map[name] = float(clean_val)
            except ValueError:
                self.raw_map[name] = clean_val

    def _trace_value(self, start_key):
        path = []
        current_key = start_key
        visited = set()
        for _ in range(5):
            if current_key in visited: break
            visited.add(current_key)
            val = self.raw_map.get(current_key)
            if val is None: break
            if isinstance(val, float):
                path.append(f"[bold cyan]{val}[/bold cyan]")
                break
            if isinstance(val, str):
                if val in self.raw_map:
                    path.append(f"[yellow]{val}[/yellow]")
                    current_key = val
                else:
                    path.append(f"[white]{val}[/white]")
                    break
        if not path: return None
        return " âœ ".join(path)

    def enrich(self, text):
        if not text or "TUNING." not in text: return text
        def replace_match(match):
            full_key = match.group(1)
            short_key = full_key.replace("TUNING.", "")
            trace_str = self._trace_value(short_key)
            if trace_str:
                return f"{full_key} [dim]({trace_str})[/dim]"
            return full_key
        return re.sub(r'(TUNING\.[A-Z0-9_]+)', replace_match, text)

# ==========================================
# 2. Lua æ–‡ä»¶åˆ†æå™¨ (LuaAnalyzer)
# ==========================================
class LuaAnalyzer:
    def __init__(self, content):
        self.content = content
        self.structure = {
            "assets": [], "components": [], "helpers": [],
            "stategraph": None, "brain": None, "events": [], "tags": []
        }
        self.parse()

    def parse(self):
        self._extract_tables()
        self._extract_components_robust()
        self._extract_standard_helpers()
        self._extract_logic()

    def _clean_value(self, raw_val):
        val = re.sub(r'--.*', '', raw_val)
        return " ".join(val.split())

    def _extract_tables(self):
        asset_pattern = re.compile(r'Asset\s*\(\s*["\'](.*?)["\']\s*,\s*["\'](.*?)["\']\s*\)')
        for match in asset_pattern.findall(self.content):
            self.structure["assets"].append({"type": match[0], "path": match[1]})

    def _extract_standard_helpers(self):
        helper_pattern = re.compile(r'^\s*(Make[a-zA-Z0-9_]+)\s*\(', re.MULTILINE)
        found = set()
        for match in helper_pattern.findall(self.content):
            if match not in found:
                self.structure["helpers"].append(match)
                found.add(match)

    def _extract_components_robust(self):
        added_comps = set()
        add_pattern = re.compile(r'inst:AddComponent\s*\(\s*["\'](.*?)["\']\s*\)')
        for match in add_pattern.findall(self.content):
            added_comps.add(match)
        for comp_name in added_comps:
            comp_data = {"name": comp_name, "methods": [], "properties": []}
            method_pattern = re.compile(r'components\.' + re.escape(comp_name) + r'[:\.]([a-zA-Z0-9_]+)\s*\((.*?)\)', re.DOTALL)
            for m in method_pattern.findall(self.content):
                func_name = m[0]
                clean_args = self._clean_value(m[1])
                if len(clean_args) > 50: clean_args = clean_args[:47] + "..."
                comp_data["methods"].append(f"{func_name}({clean_args})")
            prop_pattern = re.compile(r'components\.' + re.escape(comp_name) + r'\.([a-zA-Z0-9_]+)\s*=\s*(.+)')
            for p in prop_pattern.findall(self.content):
                prop_name = p[0]
                raw_val = p[1].strip()
                if raw_val.startswith("function"):
                    comp_data["properties"].append(f"{prop_name} = [Function]")
                    continue
                clean_val = self._clean_value(raw_val)
                comp_data["properties"].append(f"{prop_name} = {clean_val}")
            self.structure["components"].append(comp_data)

    def _extract_logic(self):
        brain = re.search(r'inst:SetBrain\s*\(\s*require\s*\(\s*["\'](.*?)["\']\s*\)\s*\)', self.content)
        if brain: self.structure["brain"] = brain.group(1)
        sg = re.search(r'inst:SetStateGraph\s*\(\s*["\'](.*?)["\']\s*\)', self.content)
        if sg: self.structure["stategraph"] = sg.group(1)
        tags = re.findall(r'[^--]inst:AddTag\s*\(\s*["\'](.*?)["\']\s*\)', self.content)
        self.structure["tags"] = list(set(tags))
        events = re.findall(r'inst:ListenForEvent\s*\(\s*["\'](.*?)["\']', self.content)
        self.structure["events"] = list(set(events))

    def get_report(self):
        return self.structure

# ==========================================
# 3. é…æ–¹è§£æå™¨ (RecipeAnalyzer) - [FINAL]
# ==========================================
class RecipeAnalyzer:
    def __init__(self, content):
        self.raw_content = content
        self.recipes = {}
        self.aliases = {}
        if content:
            self._parse()

    def _clean_comments(self):
        return re.sub(r'--.*$', '', self.raw_content, flags=re.MULTILINE)

    def _extract_table_block(self, content, start_index):
        # å †æ ˆå¼æå– {...}
        start_brace = content.find('{', start_index)
        if start_brace == -1: return None, start_index

        balance = 1
        for i in range(start_brace + 1, len(content)):
            char = content[i]
            if char == '{':
                balance += 1
            elif char == '}':
                balance -= 1
            if balance == 0:
                return content[start_brace+1 : i], i + 1
        return None, start_index

    def _parse(self):
        clean_content = self._clean_comments()
        
        # [æ ¸å¿ƒä¿®å¤]
        # 1. \bRecipe: ç¡®ä¿åŒ¹é…å•è¯å¼€å¤´ï¼Œæ’é™¤ DeconstructRecipe
        # 2. 2?: å…¼å®¹ Recipe å’Œ Recipe2
        # 3. \(: ç¡®ä¿æ˜¯å‡½æ•°è°ƒç”¨
        iter_pattern = re.compile(r'\bRecipe2?\s*\(\s*["\'](.*?)["\']', re.DOTALL)
        
        for match in iter_pattern.finditer(clean_content):
            name = match.group(1)
            cursor = match.end()
            
            # æå–æˆåˆ†è¡¨
            ing_block, new_cursor = self._extract_table_block(clean_content, cursor)
            
            if ing_block:
                ingredients = []
                # è§£æ Ingredient
                ing_pattern = re.compile(r'Ingredient\s*\(\s*["\'](.*?)["\']\s*,\s*([^,\)]+)')
                for item, amount in ing_pattern.findall(ing_block):
                    ingredients.append({"item": item, "amount": amount.strip()})
                
                # å°è¯•æå–åç»­å‚æ•° (Tab, Tech)
                remainder = clean_content[new_cursor:].split(')')[0]
                parts = [p.strip() for p in remainder.split(',') if p.strip()]
                
                # Recipe å’Œ Recipe2 çš„å‚æ•°ä½ç½®ç•¥æœ‰ä¸åŒï¼Œä½†é€šå¸¸ Tab å’Œ Tech éƒ½åœ¨å‰é¢
                # è¿™é‡Œåšä¸ªç®€å•çš„é˜²å¾¡å¼æå–
                tab = "UNKNOWN"
                tech = "UNKNOWN"
                
                for p in parts:
                    if "TECH." in p: tech = p
                    if "RECIPETABS." in p: tab = p

                self.recipes[name] = {
                    "ingredients": ingredients,
                    "tab": tab,
                    "tech": tech
                }
                
                # å»ºç«‹ç´¢å¼•
                self.aliases[name.lower()] = name
                self.aliases[name.replace("_", "").lower()] = name

    def get(self, query_name):
        q = query_name.lower()
        real_name = self.aliases.get(q)
        if not real_name:
            real_name = self.aliases.get(q.replace("_", ""))
        
        if real_name:
            return real_name, self.recipes[real_name]
        return None, None
```

### File: src/doctor.py
> size=7012B, sha256=69d9d480c023
```python
#!/usr/bin/env python3
import os
import sys
import shutil
import subprocess
import configparser
from pathlib import Path
from rich.console import Console
from rich.table import Table
from rich.panel import Panel

console = Console()
PROJECT_ROOT = Path(__file__).resolve().parent.parent
CONFIG_PATH = PROJECT_ROOT / "conf" / "settings.ini"


def _expand(p: str) -> str:
    return os.path.expanduser(p.strip())


def _cfg_get(cfg: configparser.ConfigParser, section: str, key: str) -> str:
    try:
        v = cfg.get(section, key, fallback="").strip()
    except Exception:
        v = ""
    return _expand(v) if v else ""


def _status(level: str) -> str:
    if level == "PASS":
        return "[green]PASS[/green]"
    if level == "WARN":
        return "[yellow]WARN[/yellow]"
    return "[red]FAIL[/red]"


def _check_path_exists(path: Path, kind: str, fix: str = ""):
    if kind == "file":
        ok = path.is_file()
    elif kind == "dir":
        ok = path.is_dir()
    else:
        ok = path.exists()
    level = "PASS" if ok else "FAIL"
    return ok, level, str(path), fix


def main() -> int:
    console.print(Panel("[bold cyan]Wagstaff Doctor[/bold cyan]\nç¯å¢ƒä¸é…ç½®å¥åº·æ£€æŸ¥", border_style="cyan"))

    table = Table(title="Health Checks", box=None, show_header=True, header_style="bold cyan")
    table.add_column("Check", style="bold")
    table.add_column("Status", justify="center")
    table.add_column("Details", style="dim")
    table.add_column("Fix Hint", style="green")

    fail = 0
    warn = 0

    # 1) config file
    ok, level, details, fix = _check_path_exists(CONFIG_PATH, "file", "ç¡®è®¤ conf/settings.ini å­˜åœ¨å¹¶å¯è¯»")
    table.add_row("conf/settings.ini", _status(level), details, fix)
    if not ok:
        fail += 1
        console.print(table)
        return 1

    cfg = configparser.ConfigParser()
    try:
        cfg.read(CONFIG_PATH)
    except Exception as e:
        table.add_row("parse settings.ini", _status("FAIL"), str(e), "æ£€æŸ¥ ini æ ¼å¼")
        console.print(table)
        return 1

    dst_root = _cfg_get(cfg, "PATHS", "DST_ROOT")
    steamcmd_dir = _cfg_get(cfg, "PATHS", "STEAMCMD_DIR")
    backup_dir = _cfg_get(cfg, "PATHS", "BACKUP_DIR")
    cluster = _cfg_get(cfg, "SERVER", "CLUSTER_NAME")
    klei_home = _cfg_get(cfg, "SERVER", "KLEI_HOME")

    # 2) key fields present
    for k, v, hint in [
        ("DST_ROOT", dst_root, "åœ¨ conf/settings.ini é…ç½® PATHS.DST_ROOT"),
        ("STEAMCMD_DIR", steamcmd_dir, "åœ¨ conf/settings.ini é…ç½® PATHS.STEAMCMD_DIR"),
        ("BACKUP_DIR", backup_dir, "åœ¨ conf/settings.ini é…ç½® PATHS.BACKUP_DIR"),
        ("CLUSTER_NAME", cluster, "åœ¨ conf/settings.ini é…ç½® SERVER.CLUSTER_NAME"),
        ("KLEI_HOME", klei_home, "åœ¨ conf/settings.ini é…ç½® SERVER.KLEI_HOME"),
    ]:
        ok = bool(v)
        level = "PASS" if ok else "FAIL"
        table.add_row(f"config: {k}", _status(level), v or "(empty)", hint if not ok else "")
        if not ok:
            fail += 1

    # 3) DST root + binaries
    if dst_root:
        dst_root_p = Path(dst_root)
        ok, level, details, fix = _check_path_exists(dst_root_p, "dir", "ç¡®è®¤ DST å·²å®‰è£…åˆ°è¯¥ç›®å½•")
        table.add_row("DST_ROOT exists", _status(level), details, fix if level != "PASS" else "")
        if not ok:
            fail += 1

        bin_exe = dst_root_p / "bin" / "dontstarve_dedicated_server_nullrenderer"
        ok, level, details, fix = _check_path_exists(bin_exe, "file", "DST_ROOT/bin ä¸‹åº”å­˜åœ¨ dedicated server å¯æ‰§è¡Œæ–‡ä»¶")
        table.add_row("DST binary", _status(level), details, fix if level != "PASS" else "")
        if not ok:
            fail += 1

        scripts_zip = dst_root_p / "data" / "databundles" / "scripts.zip"
        scripts_dir = dst_root_p / "data" / "scripts"
        ok_zip = scripts_zip.is_file()
        ok_dir = scripts_dir.is_dir()
        level = "PASS" if (ok_zip or ok_dir) else "FAIL"
        details = f"zip={scripts_zip} ({'ok' if ok_zip else 'missing'}), dir={scripts_dir} ({'ok' if ok_dir else 'missing'})"
        table.add_row("scripts source", _status(level), details, "ç¡®ä¿ scripts.zip å­˜åœ¨æˆ– data/scripts å¯ç”¨" if level != "PASS" else "")
        if level != "PASS":
            fail += 1

    # 4) steamcmd
    if steamcmd_dir:
        steamcmd = Path(steamcmd_dir) / "steamcmd.sh"
        ok, level, details, fix = _check_path_exists(steamcmd, "file", "ç¡®è®¤ SteamCMD å·²å®‰è£…ä¸” steamcmd.sh å­˜åœ¨")
        table.add_row("steamcmd.sh", _status(level), details, fix if level != "PASS" else "")
        if not ok:
            fail += 1

    # 5) screen
    screen_path = shutil.which("screen")
    if not screen_path:
        table.add_row("screen installed", _status("FAIL"), "(not found)", "sudo apt-get install screen")
        fail += 1
    else:
        try:
            r = subprocess.run(["screen", "-version"], capture_output=True, text=True)
            ok = (r.returncode == 0)
            level = "PASS" if ok else "WARN"
            table.add_row("screen installed", _status(level), screen_path, "")
            if level == "WARN":
                warn += 1
        except Exception as e:
            table.add_row("screen installed", _status("WARN"), str(e), "ç¡®è®¤ screen å¯æ‰§è¡Œ")
            warn += 1

    # 6) Klei cluster paths
    if klei_home and cluster:
        klei_p = Path(klei_home)
        ok, level, details, fix = _check_path_exists(klei_p, "dir", "ç¡®ä¿ KLEI_HOME å­˜åœ¨ï¼ˆé€šå¸¸æ˜¯ ~/.klei/DoNotStarveTogetherï¼‰")
        table.add_row("KLEI_HOME exists", _status(level), details, fix if level != "PASS" else "")
        if not ok:
            warn += 1

        cluster_dir = klei_p / cluster
        ok, level, details, fix = _check_path_exists(cluster_dir, "dir", "ç¬¬ä¸€æ¬¡å¼€æœå‰ç›®å½•å¯èƒ½ä¸å­˜åœ¨ï¼›å¼€æœä¸€æ¬¡ååº”å‡ºç°")
        table.add_row("Cluster dir", _status("PASS" if ok else "WARN"), details, fix if not ok else "")
        if not ok:
            warn += 1

        master_log = cluster_dir / "Master" / "server_log.txt"
        caves_log = cluster_dir / "Caves" / "server_log.txt"
        # logs may not exist yet -> WARN
        table.add_row("Master log", _status("PASS" if master_log.exists() else "WARN"), str(master_log), "å¼€æœåç”Ÿæˆ" if not master_log.exists() else "")
        table.add_row("Caves log", _status("PASS" if caves_log.exists() else "WARN"), str(caves_log), "å¼€æœåç”Ÿæˆ" if not caves_log.exists() else "")

    # 7) backup dir (do not create; just check)
    if backup_dir:
        bdir = Path(backup_dir)
        if bdir.exists():
            table.add_row("BACKUP_DIR exists", _status("PASS"), str(bdir), "")
        else:
            table.add_row("BACKUP_DIR exists", _status("WARN"), str(bdir), "mkdir -p è¯¥ç›®å½•")
            warn += 1

    console.print(table)
    console.print(f"[dim]Summary: FAIL={fail}, WARN={warn}[/dim]")
    return 0 if fail == 0 else 1


if __name__ == "__main__":
    raise SystemExit(main())
```

### File: src/engine.py
> size=4409B, sha256=3b06776239e6
```python
#!/usr/bin/env python3
import os
import zipfile
from rich.console import Console
from utils import wagstaff_config
from analyzer import TuningResolver, RecipeAnalyzer, LuaAnalyzer

console = Console()

class WagstaffEngine:
    """
    Wagstaff Lab æ ¸å¿ƒå¼•æ“ (v1.0)
    èŒè´£: ç»Ÿä¸€ç®¡ç†æ•°æ®æº (Zip/Folder) å’Œ æ ¸å¿ƒçŸ¥è¯†åº“ (Tuning/Recipes)
    """
    def __init__(self, load_db=True, silent=False):
        self.base_dir = wagstaff_config.get('PATHS', 'DST_ROOT')
        self.zip_path = os.path.join(self.base_dir, "data", "databundles", "scripts.zip")
        self.fallback_dir = os.path.join(self.base_dir, "data", "scripts")
        
        self.mode = None
        self.source = None
        self.file_list = []
        
        self.tuning = None
        self.recipes = None
        
        self._init_source(silent)
        if load_db:
            self._init_databases(silent)

    def _init_source(self, silent):
        if os.path.exists(self.zip_path):
            self.mode = 'zip'
            self.source = zipfile.ZipFile(self.zip_path, 'r')
            self.file_list = self.source.namelist()
            if not silent: console.print(f"[dim]ğŸ“¦ å¼•æ“æŒ‚è½½ Zip æº: {self.zip_path}[/dim]")
        elif os.path.exists(self.fallback_dir):
            self.mode = 'folder'
            self.source = self.fallback_dir
            for root, _, files in os.walk(self.fallback_dir):
                for name in files:
                    rel = os.path.relpath(os.path.join(root, name), self.fallback_dir).replace("\\", "/")
                    self.file_list.append(rel)
            if not silent: console.print(f"[dim]ğŸ“‚ å¼•æ“æŒ‚è½½æ–‡ä»¶å¤¹æº: {self.fallback_dir}[/dim]")
        else:
            raise FileNotFoundError("æ— æ³•æ‰¾åˆ° scripts.zip æˆ– scripts/ ç›®å½•")

    def _init_databases(self, silent):
        if not silent: console.print("[dim]ğŸ”„ åŠ è½½ç¥ç»ä¸­æ¢ (Tuning & Recipes)...[/dim]")
        t_content = self.read_file("scripts/tuning.lua") or self.read_file("tuning.lua")
        self.tuning = TuningResolver(t_content if t_content else "")
        r_content = self.read_file("scripts/recipes.lua") or self.read_file("recipes.lua")
        self.recipes = RecipeAnalyzer(r_content if r_content else "")

    def read_file(self, path):
        """æ™ºèƒ½è¯»å–æ–‡ä»¶ï¼ˆè‡ªåŠ¨å¤„ç† scripts/ å‰ç¼€ï¼‰"""
        candidates = [path]
        if not path.startswith("scripts/"): candidates.append(f"scripts/{path}")
        else: candidates.append(path.replace("scripts/", ""))
        
        try:
            if self.mode == 'zip':
                for p in candidates:
                    if p in self.file_list:
                        return self.source.read(p).decode('utf-8', errors='replace')
            else:
                for p in candidates:
                    real_path = os.path.join(self.source, p.replace("scripts/", ""))
                    if os.path.exists(real_path):
                        with open(real_path, 'r', encoding='utf-8', errors='replace') as f: return f.read()
        except Exception:
            return None
        return None

    def find_file(self, name, fuzzy=True):
        """æ¨¡ç³ŠæŸ¥æ‰¾æ–‡ä»¶ (å¦‚ armorwood -> scripts/prefabs/armor_wood.lua)"""
        candidates = [f"scripts/prefabs/{name}.lua", f"prefabs/{name}.lua", f"scripts/{name}", name]
        for c in candidates:
            if c in self.file_list: return c
            
        if not fuzzy: return None

        target = name.replace("_", "").lower()
        for fname in self.file_list:
            if not fname.endswith(".lua"): continue
            base = os.path.basename(fname).replace(".lua", "")
            if base.replace("_", "").lower() == target:
                return fname
        return None

    def analyze_prefab(self, item_name):
        """ä¸€é”®åˆ†æ Prefab (æ•´åˆäº† wiki.py çš„é€»è¾‘)"""
        path = self.find_file(item_name)
        if not path: return None
        
        content = self.read_file(path)
        if not content: return None
        
        analyzer = LuaAnalyzer(content)
        data = analyzer.get_report()
        
        if self.tuning:
            for comp in data.get('components', []):
                comp['properties'] = [self.tuning.enrich(p) for p in comp['properties']]
                comp['methods'] = [self.tuning.enrich(m) for m in comp['methods']]
        
        return data
```

### File: src/explorer.py
> size=7609B, sha256=97e6d35c205e
```python
#!/usr/bin/env python3
import os
import sys
from rich.console import Console
from rich.table import Table
from rich.tree import Tree
from rich.panel import Panel
from rich.prompt import Prompt, IntPrompt
from rich.syntax import Syntax
from rich import box
from engine import WagstaffEngine

console = Console()

class DSTExplorer:
    def __init__(self):
        # ç›´æ¥ä½¿ç”¨å¼•æ“ï¼Œä¸å†è‡ªå·±å¤„ç† Zip å’Œ Tuning
        try:
            self.engine = WagstaffEngine(load_db=True)
        except Exception as e:
            console.print(f"[red]å¼•æ“å¯åŠ¨å¤±è´¥: {e}[/red]")
            sys.exit(1)
        
        console.print(Panel(f"[bold cyan]Wagstaff æºç é€è§†é•œ v3.0[/bold cyan]\næ ¸å¿ƒ: {self.engine.mode.upper()} æ¨¡å¼", border_style="blue"))
        if self.engine.tuning:
            console.print(f"[dim]âš¡ Tuning è§£æå™¨å°±ç»ª (åŒ…å« {len(self.engine.tuning.raw_map)} æ¡å¸¸æ•°)[/dim]")

    def get_structure_tree(self):
        tree = Tree(f"ğŸ“ [bold yellow]æºç ç»“æ„[/bold yellow]")
        dir_counts = {}
        for f in self.engine.file_list:
            clean_path = f.replace("scripts/", "", 1) if f.startswith("scripts/") else f
            top_dir = clean_path.split('/')[0] if '/' in clean_path else "[Root Files]"
            dir_counts[top_dir] = dir_counts.get(top_dir, 0) + 1

        for d, count in sorted(dir_counts.items(), key=lambda x: x[1], reverse=True):
            if d == "[Root Files]":
                tree.add(f"ğŸ“„ {d} ({count})")
            else:
                style = "bold cyan" if d in ["prefabs", "components", "tuning.lua"] else "white"
                tree.add(f"ğŸ“‚ [{style}]{d}[/{style}] ([dim]{count}[/dim])")
        return tree

    def search_files(self):
        keyword = Prompt.ask("[bold green]ğŸ” æœç´¢å…³é”®è¯[/bold green]")
        if not keyword: return
        matches = [f for f in self.engine.file_list if keyword.lower() in f.lower()]
        
        if not matches:
            console.print("[yellow]æ— ç»“æœ[/yellow]")
            return

        table = Table(title=f"Results: '{keyword}'", box=box.SIMPLE)
        table.add_column("è·¯å¾„", style="dim")
        table.add_column("æ–‡ä»¶", style="bold green")
        for m in matches[:15]:
            d, f = os.path.split(m)
            table.add_row(d, f)
        console.print(table)
        if len(matches) > 15: console.print(f"[dim]...å‰©ä½™ {len(matches)-15} é¡¹éšè—[/dim]")

    def analyze_content(self, filename, content):
        # ä½¿ç”¨å¼•æ“æä¾›çš„åˆ†ææ–¹æ³• (å·²åŒ…å«æ•°å€¼å¢å¼º)
        # æ³¨æ„ï¼šengine.analyze_prefab æ˜¯é’ˆå¯¹ prefab çš„ï¼Œè¿™é‡Œæˆ‘ä»¬å¯èƒ½éœ€è¦é€šç”¨çš„ analyzer
        # ä¸ºäº†å¤ç”¨ engine çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬æ‰‹åŠ¨è°ƒç”¨ analyzer ä½†ä½¿ç”¨ engine çš„ tuning
        from analyzer import LuaAnalyzer
        
        try:
            analyzer = LuaAnalyzer(content)
            data = analyzer.get_report()
        except Exception as e:
            console.print(f"[red]è§£æå¤±è´¥: {e}[/red]")
            return
        
        tree = Tree(f"ğŸ§¬ [bold green]æ·±åº¦è§£æ: {filename}[/bold green]")
        
        # 1. èµ„æº
        if data.get('assets'):
            asset_branch = tree.add(f"ğŸ“¦ èµ„æºå¼•ç”¨ ({len(data['assets'])})")
            for a in data['assets']:
                style = "magenta" if "Anim" in a['type'] else "blue"
                asset_branch.add(f"[{style}]{a['type']}[/{style}]: {a['path']}")

        # 2. é€»è¾‘ (Brain/StateGraph/Tags)
        logic_branch = tree.add("ğŸ§  æ ¸å¿ƒé€»è¾‘")
        has_logic = False
        if data.get('brain'): 
            logic_branch.add(f"AI: [magenta]{data['brain']}[/magenta]")
            has_logic = True
        if data.get('stategraph'): 
            logic_branch.add(f"SG: [magenta]{data['stategraph']}[/magenta]")
            has_logic = True
        if data.get('tags'): 
            tags = data['tags']
            tag_str = ", ".join([f"[dim]{t}[/dim]" for t in tags[:8]])
            if len(tags) > 8: tag_str += "..."
            logic_branch.add(f"Tags: {tag_str}")
            has_logic = True
        if not has_logic: logic_branch.label = "[dim]ğŸ§  æ ¸å¿ƒé€»è¾‘ (æ— )[/dim]"

        # 3. ç»„ä»¶ (ä½¿ç”¨ Engine çš„ Tuning è¿›è¡Œå¢å¼º)
        if data.get('components'):
            comp_branch = tree.add(f"âš™ï¸ åŠŸèƒ½ç»„ä»¶ ({len(data['components'])})")
            for comp in data['components']:
                node = comp_branch.add(f"[bold yellow]{comp['name']}[/bold yellow]")
                
                # å±æ€§
                if comp['properties']:
                    target = node if len(comp['properties']) <=3 else node.add("[dim]å±æ€§é…ç½®[/dim]")
                    for p in comp['properties']:
                        p = self.engine.tuning.enrich(p) if self.engine.tuning else p
                        if "=" in p:
                            k, v = p.split("=", 1)
                            target.add(f"[cyan]{k.strip()}[/cyan] = [white]{v.strip()}[/white]")
                        else:
                            target.add(f"[cyan]{p}[/cyan]")
                
                # æ–¹æ³•
                if comp['methods']:
                    target = node if len(comp['methods']) <=3 else node.add("[dim]å‡½æ•°è°ƒç”¨[/dim]")
                    for m in comp['methods']:
                        m = self.engine.tuning.enrich(m) if self.engine.tuning else m
                        target.add(f"[green]Æ’[/green] {m}")
        else:
            tree.add("[dim]âš™ï¸ åŠŸèƒ½ç»„ä»¶ (æ— )[/dim]")

        console.print(Panel(tree, border_style="green"))
        input("æŒ‰å›è½¦è¿”å›...")

    def preview_file(self):
        target = Prompt.ask("[bold green]ğŸ‘€ æ–‡ä»¶å[/bold green]")
        path = self.engine.find_file(target, fuzzy=True)
        if not path:
            console.print("[red]æœªæ‰¾åˆ°[/red]")
            return
        
        console.print(f"[yellow]æ‰“å¼€: {path}[/yellow]")
        content = self.engine.read_file(path)
        
        if content:
            syntax = Syntax("\n".join(content.splitlines()[:50]), "lua", theme="monokai", line_numbers=True)
            console.print(Panel(syntax, title=f"{path} (Top 50 lines)", border_style="blue"))
            
            action = Prompt.ask("[bold cyan]ä¸‹ä¸€æ­¥[/bold cyan]", choices=["q", "a"], default="q")
            if action == "a":
                self.analyze_content(path, content)

    def show_tuning(self):
        if not self.engine.tuning: 
            return console.print("[red]Tuning æœªåŠ è½½[/red]")
        
        console.print("[bold magenta]ğŸ”¢ Tuning æ•°å€¼é‡‡æ ·[/bold magenta]")
        # ç®€å•å±•ç¤ºå‰ 10 ä¸ª
        count = 0
        for k, v in list(self.engine.tuning.raw_map.items())[:10]:
             console.print(f"  [cyan]{k}[/cyan] = {v}")
             count += 1

def main():
    explorer = DSTExplorer()
    while True:
        console.print("\n[bold white on blue] ğŸ¦ Wagstaff æ¢ç´¢é¢æ¿ v3.0 [/bold white on blue]")
        console.print("1. [bold]ğŸ“ ç»“æ„[/]  2. [bold]ğŸ” æœç´¢[/]  3. [bold]ğŸ‘€ é¢„è§ˆ&åˆ†æ[/]  4. [bold]ğŸ”¢ æ•°å€¼[/]  0. [bold red]é€€å‡º[/]")
        choice = IntPrompt.ask("é€‰æ‹©", choices=["0","1","2","3","4"], default=1)
        if choice == 0: break
        elif choice == 1: console.print(explorer.get_structure_tree())
        elif choice == 2: explorer.search_files()
        elif choice == 3: explorer.preview_file()
        elif choice == 4: explorer.show_tuning()

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        console.print(f"[red]Error: {e}[/red]")
```

### File: src/guide.py
> size=1548B, sha256=b69213e54f5e
```python
#!/usr/bin/env python3
import os
import sys
import json
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from pathlib import Path

# å¼•å…¥é…ç½®å’Œæ³¨å†Œè¡¨
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from registry import get_tools

console = Console()
PROJECT_ROOT = Path(__file__).resolve().parent.parent

def load_status():
    status_path = PROJECT_ROOT / "PROJECT_STATUS.json"
    if status_path.exists():
        with open(status_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def main():
    data = load_status()
    
    console.print(Panel("[bold white on blue] ğŸ§ª Wagstaff-Lab (v2.2) æ§åˆ¶å° [/bold white on blue]", border_style="blue"))
    
    if "objective" in data:
        console.print(f"[bold green]ğŸ¯ å½“å‰ç›®æ ‡:[/bold green] {data['objective']}")
    
    # å¢åŠ  Usage åˆ—çš„å±•ç¤º
    console.print("\n[bold yellow]ğŸ› ï¸  å·¥å…·ç®±ä½¿ç”¨æŒ‡å—[/bold yellow]")
    table = Table(box=None, show_header=True, header_style="bold cyan")
    table.add_column("å·¥å…·", style="bold")
    table.add_column("æè¿°")
    table.add_column("æ ‡å‡†ç”¨æ³• (Usage)", style="green")
    
    for tool in get_tools():
        table.add_row(
            tool['file'], 
            tool['desc'], 
            tool.get('usage', 'N/A')
        )

    console.print(table)
    console.print("\n[dim]ğŸ’¡ è¾“å…¥ [bold]pm ui[/bold] ç®¡ç†ä»»åŠ¡ï¼Œè¾“å…¥ [bold]wagstaff snap[/bold] æ›´æ–°å¿«ç…§ã€‚[/dim]")

if __name__ == "__main__":
    main()
```

### File: src/registry.py
> size=1845B, sha256=99ac307d7629
```python
#!/usr/bin/env python3
"""
Wagstaff-Lab å·¥å…·æ³¨å†Œä¸­å¿ƒ (v2.3)
"""

TOOLS = [
    # --- æ ¸å¿ƒ/ä¸šåŠ¡å·¥å…· (src/) ---
    {
        "file": "guide.py",
        "alias": None,
        "desc": "Wagstaff-Lab æ§åˆ¶å°ä¸»é¢æ¿",
        "usage": "Wagstaff-Lab",
        "type": "Core"
    },
    {
        "file": "doctor.py",
        "alias": "doctor",
        "desc": "ç¯å¢ƒé…ç½®ä¸ä¾èµ–å¥åº·æ£€æŸ¥",
        "usage": "wagstaff doctor",
        "type": "Src"
    },
    {
        "file": "wiki.py",
        "alias": "wiki",
        "desc": "ç‰©å“/é…æ–¹/æ•°å€¼æŸ¥è¯¢ç™¾ç§‘",
        "usage": "wagstaff wiki <item_code>",
        "type": "Src"
    },
    {
        "file": "explorer.py",
        "alias": "exp",
        "desc": "æºç ç»“æ„æµè§ˆä¸æ·±åº¦åˆ†æ",
        "usage": "wagstaff exp",
        "type": "Src"
    },

    # --- å¼€å‘å·¥å…· (devtools/) ---
    {
        "file": "pm.py",
        "alias": "pm",
        "desc": "é¡¹ç›®è¿›åº¦ä¸ä»»åŠ¡ç®¡ç†",
        "usage": "pm [ui|obj|add|done|log]",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "reporter.py",
        "alias": "report",
        "desc": "ç”Ÿæˆå…¨æœèµ„äº§/é…æ–¹åˆ†å¸ƒæŠ¥å‘Š",
        "usage": "wagstaff report [assets|recipes|all]",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "snapshot.py",
        "alias": "snap",
        "desc": "ç”Ÿæˆé¡¹ç›®å…¨æ¯ä»£ç å¿«ç…§",
        "usage":  "wagstaff snap [--mode core|full|custom] [--config conf/snapshot_profile.json]",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "installer.py",
        "alias": "install",
        "desc": "ç¯å¢ƒæ³¨å†Œä¸å®‰è£…å‘å¯¼",
        "usage": "python3 devtools/installer.py",
        "type": "Dev",
        "folder": "devtools"
    },
]

def get_tools():
    return TOOLS
```

### File: src/utils.py
> size=1040B, sha256=ffc01cb3d8f3
```python
import configparser
import os
from pathlib import Path

class ConfigLoader:
    def __init__(self):
        # è‡ªåŠ¨å®šä½é¡¹ç›®æ ¹ç›®å½• (å‡è®¾ utils.py åœ¨ src/ ä¸‹)
        self.project_root = Path(__file__).resolve().parent.parent
        self.config_path = self.project_root / "conf" / "settings.ini"
        
        self.config = configparser.ConfigParser()
        if not self.config_path.exists():
            raise FileNotFoundError(f"âŒ é…ç½®æ–‡ä»¶ä¸¢å¤±: {self.config_path}")
        
        self.config.read(self.config_path)

    def get(self, section, key):
        """è·å–é…ç½®å€¼å¹¶è‡ªåŠ¨å±•å¼€ç”¨æˆ·è·¯å¾„ (~)"""
        val = self.config.get(section, key, fallback=None)
        if val and "~" in val:
            return os.path.expanduser(val)
        return val

# å•ä¾‹æ¨¡å¼ï¼šç›´æ¥å¯¼å‡ºçš„å®ä¾‹
wagstaff_config = ConfigLoader()

# === æµ‹è¯•ä»£ç  ===
if __name__ == "__main__":
    print(f"Project Root: {wagstaff_config.project_root}")
    print(f"DST Path: {wagstaff_config.get('PATHS', 'DST_ROOT')}")
```

### File: src/wiki.py
> size=3622B, sha256=6a16ed377544
```python
#!/usr/bin/env python3
import sys
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.text import Text
from rich import box
from engine import WagstaffEngine # ç›´æ¥è°ƒç”¨å¼•æ“

console = Console()

def main():
    if len(sys.argv) < 2:
        console.print("[yellow]ç”¨æ³•: python src/wiki.py <ç‰©å“ä»£ç >[/yellow]")
        return
    
    target = sys.argv[1].lower()
    
    # 1. å¯åŠ¨å¼•æ“
    try:
        engine = WagstaffEngine()
    except Exception as e:
        console.print(f"[red]å¼•æ“å¯åŠ¨å¤±è´¥: {e}[/red]")
        return

    # 2. æŸ¥é…æ–¹
    real_name, recipe_data = engine.recipes.get(target)
    if not real_name: real_name = target
    
    # 3. æŸ¥æ•°æ® (ä½¿ç”¨å¼•æ“å°è£…å¥½çš„æ–¹æ³•)
    prefab_data = engine.analyze_prefab(real_name)

    if not recipe_data and not prefab_data:
        console.print(f"[red]âŒ æœªæ‰¾åˆ° '{target}'[/red]")
        return

    # === æ¸²æŸ“å±‚ (ä¿æŒåŸæœ‰ç¾è§‚é€»è¾‘) ===
    console.print(Panel(f"[bold white on blue] ğŸ“š Wagstaff æ¡£æ¡ˆ: {real_name.upper()} [/bold white on blue]"))
    
    grid = Table.grid(expand=True, padding=(0, 2))
    grid.add_column(ratio=1)
    grid.add_column(ratio=2)

    # å·¦ï¼šé…æ–¹
    left_rows = []
    if recipe_data:
        t_name = recipe_data['tab'].replace("RECIPETABS.", "")
        rt = Table(title=f"ğŸ“œ åˆæˆ ({t_name})", border_style="green", box=box.SIMPLE)
        rt.add_column("ææ–™", style="cyan"); rt.add_column("æ•°é‡", style="magenta")
        for ing in recipe_data['ingredients']:
            rt.add_row(ing['item'], engine.tuning.enrich(ing['amount']))
        left_rows.append(rt)
        if recipe_data.get('tech'): 
            left_rows.append(f"\n[dim]ğŸ”¬ {recipe_data['tech'].replace('TECH.', '')}[/dim]")
    else:
        left_rows.append(Panel("[dim]ä¸å¯åˆæˆ[/dim]", border_style="dim"))

    # å³ï¼šç»„ä»¶
    right_rows = []
    if prefab_data:
        # Helpers
        if prefab_data.get('helpers'):
            tags = [f"[reverse cyan]{h.replace('Make','').replace('Inventory','')}[/reverse cyan]" for h in prefab_data['helpers']]
            right_rows.append(Text.from_markup(" ".join(tags) + "\n"))
        
        # Stats
        INTERESTING = ["weapon", "armor", "finiteuses", "edible", "tool", "fuel", "instrument"]
        st = Table(box=box.MINIMAL, show_header=False)
        st.add_column("C", style="dim"); st.add_column("V", style="white")
        
        has_stat = False
        for comp in prefab_data.get('components', []):
            if comp['name'] in INTERESTING:
                # æå–æ–¹æ³•è°ƒç”¨ä½œä¸ºå…³é”®æ•°æ®
                for m in comp['methods']:
                    if any(k in m for k in ["SetDamage", "SetAbsorption", "SetMaxUses", "GetHealth"]):
                        icon = "âš”ï¸" if comp['name']=="weapon" else "âš™ï¸"
                        st.add_row(f"{icon} {comp['name']}", m.split('(', 1)[1][:-1]) # ç®€ç•¥æ˜¾ç¤ºå‚æ•°
                        has_stat = True
                # æå–å±æ€§
                for p in comp['properties']:
                    if "fuelvalue" in p or "armor" in p:
                         st.add_row(f"âš™ï¸ {comp['name']}", p)
                         has_stat = True
        
        if has_stat: right_rows.append(st)
        else: right_rows.append("[dim]æ— æ ¸å¿ƒæˆ˜æ–—/ç”Ÿå­˜æ•°æ®[/dim]")
    else:
        right_rows.append("[red]âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶[/red]")

    from rich.console import Group
    grid.add_row(Group(*left_rows), Group(*right_rows))
    console.print(grid)

if __name__ == "__main__":
    main()
```

### File: tests/test_recipes.py
> size=1479B, sha256=89bad0a5e326
```python
#!/usr/bin/env python3
import sys
import time
from rich.console import Console
from rich.table import Table
from engine import WagstaffEngine

console = Console()

def main():
    console.print("[bold blue]ğŸ§ª é…æ–¹è§£æå™¨éªŒæ”¶æµ‹è¯• (åŸºäº Wagstaff Engine)[/bold blue]")
    
    # 1. å¯åŠ¨å¼•æ“
    try:
        start_t = time.time()
        engine = WagstaffEngine(load_db=True)
        duration = (time.time() - start_t) * 1000
    except Exception as e:
        console.print(f"[red]å¼•æ“å¯åŠ¨å¤±è´¥: {e}[/red]")
        return
    
    # 2. ç»Ÿè®¡
    count = len(engine.recipes.recipes)
    count_style = "green" if count > 500 else "red"
    
    console.print(f"åŠ è½½è€—æ—¶: [bold]{duration:.2f} ms[/bold]")
    console.print(f"å‘ç°é…æ–¹: [{count_style}]{count}[/{count_style}]")

    # 3. æŠ½æŸ¥
    check_list = ["spear", "armorwood", "hambat", "firestaff"]
    table = Table(title="å…³é”®ç‰©å“éªŒè¯", border_style="blue")
    table.add_column("Key", style="cyan")
    table.add_column("Name", style="dim")
    table.add_column("Ingredients", style="white")
    
    for item in check_list:
        real_name, data = engine.recipes.get(item)
        if data:
            ing_str = ", ".join([f"{i['item']}x{i['amount']}" for i in data['ingredients']])
            table.add_row(item, real_name, ing_str)
        else:
            table.add_row(item, "-", "[red]Not Found[/red]")
        
    console.print(table)

if __name__ == "__main__":
    main()
```

## Snapshot Summary
```yaml
full_included: 18/22
stub_included: 0/0
omitted: 0
skipped_binary: 4
skipped_budget: 0
files_truncated_or_stubbed: 0
embedded_bytes: 105426
```

## Token Estimate (rough)
```text
chars: 105953
estimated_tokens(~chars/4): 26488
```