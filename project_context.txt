# Wagstaff-Lab Project Snapshot

- Generated: 2026-01-17T10:51:59
- Mode: llm
- Template: core

## 1. Environment Diagnostics
```yaml
Time: 2026-01-17 10:51:59
User: steam
Host: VM-8-2-ubuntu (Linux 6.8.0-49-generic)
Python: 3.13.11 (/home/steam/miniconda3/bin/python)
Rich Ver: Installed (ver unknown)
--------------------
Branch: main [DIRTY]
Commit: e835fc3
Message: WebCraft i18n index + stats expansion
```

## 2. Project Overview
### Toolbox (apps/cli/registry.py)
```text
alias    | file                    | type | desc                            | usage                                           
---------+-------------------------+------+---------------------------------+-------------------------------------------------
dash     | dash.py                 | CLI  | Wagstaff-Lab 控制台主面板             | wagstaff dash                                   
doctor   | doctor.py               | CLI  | 环境配置与依赖健康检查                     | wagstaff doctor                                 
wiki     | wiki.py                 | CLI  | 物品/配方/数值查询百科                    | wagstaff wiki <item_code>                       
exp      | explorer.py             | CLI  | 源码结构浏览与深度分析                     | wagstaff exp                                    
mgmt     | mgmt.py                 | CLI  | 项目管理：状态展示与同步                    | wagstaff mgmt <status|sync|dump|check>          
server   | server.py               | CLI  | DST 服务器管理 (screen-based)        | wagstaff server <status|start|stop|restart|up...
report   | reporter.py             | Dev  | 生成全服资产/配方分布报告                   | wagstaff report [assets|recipes|all]            
catalog2 | build_catalog_v2.py     | Dev  | 生成 Catalog v2 (item-centric)    | wagstaff catalog2 [--tuning-mode value_only|f...
i18n     | build_i18n_index.py     | Dev  | 生成 i18n 索引 (names + UI strings) | wagstaff i18n [--lang zh] [--dst-root PATH]     
icons    | build_icons.py          | Dev  | 生成物品图标 PNG + icon index         | wagstaff icons [--dst-root PATH] [--all-eleme...
catindex | build_catalog_index.py  | Dev  | 生成 Catalog 紧凑索引（列表 + 多维倒排）      | wagstaff catindex [--catalog PATH] [--icon-in...
catqa    | catalog_quality.py      | Dev  | 生成 Catalog 覆盖率/质量报告             | wagstaff catqa [--catalog PATH] [--i18n PATH]...
quality  | quality_gate.py         | Dev  | 质量门禁自检（默认仅提示）                   | wagstaff quality [--enforce] [--strict]         
snap     | snapshot.py             | Dev  | 生成 LLM 友好代码快照                   | wagstaff snapshot [-h] [--mode {llm,core,arch...
samples  | sampler.py              | Dev  | 生成 DST Lua 样本包（用于扩展解析器）         | wagstaff samples [--categories ...] [--n N] [...
resindex | build_resource_index.py | Dev  | 生成 DST 资源索引（scripts + data）     | wagstaff resindex [--data-full] [--bundle-ful...
map      | codemap.py              | Dev  | 生成 DST scripts 宏观结构地图报告         | wagstaff map                                    
web      | serve_webcraft.py       | Dev  | 启动 WebCraft (FastAPI + Uvicorn) | wagstaff web [--host 0.0.0.0 --port 20000]      
```

### Project Context (PROJECT_STATUS.json)
```text
DEV MANIFESTO:
* 分层清晰：core 负责解析与索引，apps 负责交互与服务，devtools 提供流程工具
* 单向依赖：apps/devtools 可以依赖 core，core 不依赖上层
* 数据契约：对外数据统一落盘 data/，版本化命名并携带元信息
* 路径自适应：禁止硬编码绝对路径，统一通过 __file__ 推导
* 可追溯与可复用：产物记录来源 hash，核心能力被 CLI/Web 共享
* 稳健降级：优先 scripts.zip，缺失时降级 scripts/ 目录
* LLM 快照规范：snapshot.py 作为统一导出入口，模板与 sections 控制噪声
--------------------
OBJECTIVE: Wagstaff Lab v3.0 架构重构：core/apps 分层与 WebCraft 服务化

TASKS TODO:
- Catalog stats 解析继续扩展：优先补齐 equippable/rechargeable/heater 等仍有缺口的组件字段，并提升动态/条件赋值的覆盖率。
- i18n 覆盖率提升：扩充 names/desc/quotes 索引并完善 UI 词条。
- CatalogV2 索引与质量报告持续迭代：对比覆盖率与新增字段。
- Cooking ingredient tags 解析与 catalog 落盘（ingredients.lua / cooking.lua）。
- Cooking 探索/模拟重做：可做/接近可做 + 解释卡片 + 高密度切换。

TASKS DONE:
- 重构 Wiki 和 Explorer 使用 Engine
- 实现情报扫描结果保存到 data/reports/
- 创建 apps/cli/commands/dash.py 项目概况面板
- 文档化：在 README.md 中记录新工具接入 SOP
- 重构工具注册逻辑：引入 apps/cli/registry.py 实现单一数据源
- Hotfix(pm): 修复 STATUS_FILE 路径依赖并实现原子化写入 (.tmp -> rename)
- Wiki v2.3: 实现交互式搜索 (find) 与详细组件展示
- Analyzer: 支持内联掉落表解析 (Krampus) 与 Tuning 递归数值追踪
- PM Tool: 修复 JSON 数据结构并实现自动迁移 (v1->v2)
- WebCraft: Catalog UI 修复 i18n helper 缺失导致的空白与标签切换异常
- Refactor: core/apps 拆分，CLI 与 WebCraft 应用层分离
- CatalogV2: WebCraft 后端切换到 v2 items 索引，提供更完整的 item 元信息。
- CatalogV2: Catalog UI 支持 v2 元信息检索与详情展示。
- WebCraft: tuning trace API 与 UI 按需加载实现。
- CatalogV2: item stats 提取（weapon/armor/uses 等）并在 UI 展示。
- CLI: commands 子目录与 main dispatcher 重构完成。
- Tooling: 引入 pyproject.toml 与 Makefile 统一依赖与任务入口。
- Tooling: 移除 bin/ 包装器与 installer，CLI 仅通过 pyproject 入口提供。
- Server: 将 tempforcodex 服务器管理脚本重构为 wagstaff server 子命令。
- Mgmt: 退役 pm 工具，统一使用 PROJECT_MANAGEMENT + PROJECT_STATUS。
- Stats 缺口定位：清点 equippable/rechargeable/heater 缺失样本并抽查 prefab 动态/条件赋值。
- Stats 解析补齐：按 low_coverage_keys 优先补 recharge_max/recharge_time 与 carried_heat/heat_radius 的解析路径。
- Storage: 导出 SQLite catalog 并在 WebCraft 优先加载 SQLite、缺失时回退 JSON。
- WebCraft: catalog 分页 + 缓存头，UI 分页加载与搜索改造。
- WebCraft: tuning trace 前缀索引优化，i18n 切换为 index-only。
- WebCraft: 重构 Craft/Cooking/Catalog 前端布局与交互，统一页面结构与移动端体验。
- WebCraft: Craft/Cooking/Catalog 搜索改为后端 i18n index 驱动，移除前端中文回退逻辑。
- Icons: 修复 KTEX 图标方向翻转并同步 build_icons 导出流程。
- Tooling: 修复 build_icons 导入异常导致的 CLI 启动失败。

RECENT LOGS:
- [2026-01-17 08:52] WebCraft: Craft/Cooking/Catalog 前端重构，统一多页面结构与移动端交互。
- [2026-01-17 08:53] WebCraft: 搜索统一迁移后端，CJK 场景接入 i18n index。
- [2026-01-17 08:54] Icons: 修复 KTEX 图标方向翻转并同步导出逻辑。
- [2026-01-17 08:55] Tooling: 修复 build_icons 导入异常导致的启动失败。
- [2026-01-17 09:20] Mgmt: 归档 Cooking 探索/模拟方案并立项 ingredient tags 解析。
```

## 3. Project Structure
```text
├── .gitignore
├── apps
│   ├── __init__.py
│   ├── cli
│   │   ├── __init__.py
│   │   ├── cli_common.py
│   │   ├── commands
│   │   │   ├── __init__.py
│   │   │   ├── dash.py
│   │   │   ├── doctor.py
│   │   │   ├── explorer.py
│   │   │   ├── mgmt.py
│   │   │   ├── server.py
│   │   │   └── wiki.py
│   │   ├── main.py
│   │   └── registry.py
│   ├── server
│   │   ├── __init__.py
│   │   ├── cli.py
│   │   ├── config.py
│   │   ├── manager.py
│   │   └── ui.py
│   └── webcraft
│       ├── __init__.py
│       ├── api.py
│       ├── app.py
│       ├── catalog_store.py
│       ├── cooking_planner.py
│       ├── i18n_index.py
│       ├── i18n_service.py
│       ├── icon_service.py
│       ├── planner.py
│       ├── settings.py
│       ├── static
│       │   └── fonts
│       │       ├── BricolageGrotesque-normal-400.ttf
│       │       ├── BricolageGrotesque-normal-600.ttf
│       │       ├── BricolageGrotesque-normal-700.ttf
│       │       ├── IBMPlexSans-normal-400.ttf
│       │       ├── IBMPlexSans-normal-500.ttf
│       │       ├── IBMPlexSans-normal-600.ttf
│       │       ├── JetBrainsMono-normal-400.ttf
│       │       └── JetBrainsMono-normal-500.ttf
│       ├── tuning_trace.py
│       └── ui.py
├── conf
│   ├── i18n_ui.json
│   ├── samples
│   │   ├── parse_other_data.json
│   │   └── tag_overrides.example.json
│   ├── settings.ini
│   └── snapshot_templates.json
├── core
│   ├── __init__.py
│   ├── analyzer.py
│   ├── craft_recipes.py
│   ├── engine.py
│   ├── indexers
│   │   ├── __init__.py
│   │   ├── catalog_index.py
│   │   ├── catalog_v2.py
│   │   ├── i18n_index.py
│   │   ├── resource_index.py
│   │   └── shared.py
│   ├── klei_atlas_tex.py
│   ├── schemas
│   │   ├── __init__.py
│   │   ├── catalog_v2.py
│   │   └── meta.py
│   ├── tagging.py
│   └── utils.py
├── data
│   ├── index
│   │   ├── wagstaff_catalog_index_v1.json
│   │   ├── wagstaff_catalog_v1.json
│   │   ├── wagstaff_catalog_v2.json
│   │   ├── wagstaff_i18n_v1.json
│   │   ├── wagstaff_icon_index_v1.json
│   │   ├── wagstaff_resource_index_v1.json
│   │   └── wagstaff_tuning_trace_v1.json
│   ├── reports
│   │   ├── catalog_quality_report.json
│   │   ├── catalog_quality_report.md
│   │   ├── catalog_v2_summary.md
│   │   ├── stats_gap_inspect.json
│   │   └── stats_gap_inspect.md
│   └── static
│       ├── i18n
│       │   └── names_zh.json
│       └── icons
├── devtools
│   ├── __init__.py
│   ├── build_catalog_index.py
│   ├── build_catalog_sqlite.py
│   ├── build_catalog_v2.py
│   ├── build_i18n_index.py
│   ├── build_icons.py
│   ├── build_resource_index.py
│   ├── catalog_quality.py
│   ├── codemap.py
│   ├── quality_gate.py
│   ├── raw_scan.py
│   ├── reporter.py
│   ├── sampler.py
│   ├── serve_webcraft.py
│   ├── snapshot.py
│   ├── snapshot_gui.py
│   └── stats_gap_inspect.py
├── docs
│   ├── architecture
│   │   └── WEBCRAFT_NETWORK_STACK.md
│   ├── guides
│   │   ├── CLI_GUIDE.md
│   │   └── DEV_GUIDE.md
│   ├── management
│   │   ├── PROJECT_MANAGEMENT.md
│   │   └── ROADMAP.md
│   ├── README.md
│   └── specs
│       └── CATALOG_V2_SPEC.md
├── Makefile
├── PROJECT_STATUS.json
├── pyproject.toml
├── README.md
├── setup.sh
├── tempforcodex
│   ├── boot.sh
│   └── dst_tool.sh
├── tests
│   └── test_recipes.py
└── wagstaff_lab.egg-info
    ├── dependency_links.txt
    ├── entry_points.txt
    ├── PKG-INFO
    ├── requires.txt
    ├── SOURCES.txt
    └── top_level.txt
```

## 4. File Inventory
(mode: full/interface/head/skip; '*' means truncated when rendered)

```text
mode      | bytes  | sha256_12 | path                                       
----------+--------+-----------+--------------------------------------------
head      | 3799   | -         | README.md                                  
full      | 52     | -         | apps/__init__.py                           
full      | 43     | -         | apps/cli/__init__.py                       
full      | 1915   | -         | apps/cli/cli_common.py                     
full      | 51     | -         | apps/cli/commands/__init__.py              
full      | 6322   | -         | apps/cli/commands/dash.py                  
full      | 6232   | -         | apps/cli/commands/doctor.py                
full      | 9698   | -         | apps/cli/commands/explorer.py              
full      | 8668   | -         | apps/cli/commands/mgmt.py                  
full      | 209    | -         | apps/cli/commands/server.py                
full      | 22253  | -         | apps/cli/commands/wiki.py                  
full      | 1747   | -         | apps/cli/main.py                           
full      | 4880   | -         | apps/cli/registry.py                       
full      | 66     | -         | apps/server/__init__.py                    
full      | 4691   | -         | apps/server/cli.py                         
full      | 2974   | -         | apps/server/config.py                      
full      | 7508   | -         | apps/server/manager.py                     
full      | 39402  | -         | apps/server/ui.py                          
full      | 48     | -         | apps/webcraft/__init__.py                  
full      | 24167  | -         | apps/webcraft/api.py                       
full      | 7083   | -         | apps/webcraft/app.py                       
full      | 45241  | -         | apps/webcraft/catalog_store.py             
full      | 4276   | -         | apps/webcraft/cooking_planner.py           
full      | 3476   | -         | apps/webcraft/i18n_index.py                
full      | 26143  | -         | apps/webcraft/i18n_service.py              
full      | 10007  | -         | apps/webcraft/icon_service.py              
full      | 3808   | -         | apps/webcraft/planner.py                   
full      | 919    | -         | apps/webcraft/settings.py                  
full      | 2474   | -         | apps/webcraft/tuning_trace.py              
full      | 114320 | -         | apps/webcraft/ui.py                        
full      | 353    | -         | conf/settings.ini                          
full      | 61     | -         | core/__init__.py                           
full      | 53880  | -         | core/analyzer.py                           
full      | 28234  | -         | core/craft_recipes.py                      
full      | 15955  | -         | core/engine.py                             
full      | 48     | -         | core/indexers/__init__.py                  
full      | 7063   | -         | core/indexers/catalog_index.py             
full      | 25944  | -         | core/indexers/catalog_v2.py                
full      | 5194   | -         | core/indexers/i18n_index.py                
full      | 17170  | -         | core/indexers/resource_index.py            
full      | 2072   | -         | core/indexers/shared.py                    
full      | 17536  | -         | core/klei_atlas_tex.py                     
full      | 47     | -         | core/schemas/__init__.py                   
full      | 824    | -         | core/schemas/catalog_v2.py                 
full      | 697    | -         | core/schemas/meta.py                       
full      | 5775   | -         | core/tagging.py                            
full      | 1041   | -         | core/utils.py                              
head      | 3351   | -         | data/reports/catalog_quality_report.md     
head      | 339    | -         | data/reports/catalog_v2_summary.md         
head      | 1124   | -         | data/reports/stats_gap_inspect.md          
interface | 48     | -         | devtools/__init__.py                       
interface | 2031   | -         | devtools/build_catalog_index.py            
interface | 19031  | -         | devtools/build_catalog_sqlite.py           
interface | 4808   | -         | devtools/build_catalog_v2.py               
interface | 9149   | -         | devtools/build_i18n_index.py               
interface | 27213  | -         | devtools/build_icons.py                    
interface | 3236   | -         | devtools/build_resource_index.py           
interface | 14996  | -         | devtools/catalog_quality.py                
interface | 6312   | -         | devtools/codemap.py                        
interface | 9571   | -         | devtools/quality_gate.py                   
interface | 29218  | -         | devtools/raw_scan.py                       
interface | 4751   | -         | devtools/reporter.py                       
interface | 14606  | -         | devtools/sampler.py                        
interface | 5481   | -         | devtools/serve_webcraft.py                 
full      | 51404  | -         | devtools/snapshot.py                       
interface | 66096  | -         | devtools/snapshot_gui.py                   
interface | 13521  | -         | devtools/stats_gap_inspect.py              
head      | 466    | -         | docs/README.md                             
head      | 1594   | -         | docs/architecture/WEBCRAFT_NETWORK_STACK.md
head      | 2574   | -         | docs/guides/CLI_GUIDE.md                   
head      | 5751   | -         | docs/guides/DEV_GUIDE.md                   
head      | 4277   | -         | docs/management/PROJECT_MANAGEMENT.md      
head      | 1914   | -         | docs/management/ROADMAP.md                 
head      | 11133  | -         | docs/specs/CATALOG_V2_SPEC.md              
head      | 1653   | -         | tests/test_recipes.py                      
```

## 5. File Contents

### File: README.md
- mode: head
- size_bytes: 3799
- sha256_12: ad4890397a9c

```md
# Wagstaff-Lab (v3)

Wagstaff-Lab 是 DST（Don't Starve Together）数据实验室：负责索引、分析与 WebCraft UI，所有上层展示都基于稳定的索引产物。当前架构为 `core/` 解析与索引、`apps/` 应用层、`devtools/` 构建与报告工具。

## 必读

- `docs/guides/DEV_GUIDE.md`：开发规范与强制约束
- `docs/management/PROJECT_MANAGEMENT.md`：管理与进度执行入口

## 当前能力

- **Catalog v2**：以物品为中心的可标签化目录，含 stats 与 assets
- **Tuning trace**：可选输出 TUNING 解析链路
- **i18n index**：名称 + UI 词条（数据层与语言解耦）
- **Icon pipeline**：静态图标 + 动态回退
- **WebCraft**：FastAPI UI，严格使用索引产物

## 安装（pyproject 入口）

建议在 `dst_lab` 环境中执行：

```bash
python -m pip install -e ".[cli]"
```

全量依赖（web + icons + quality）：

```bash
python -m pip install -e ".[all]"
```

CLI 入口为 `wagstaff`。

## 配置 DST 路径

在 `conf/settings.ini` 中配置 `DST_ROOT`，或通过命令参数 `--dst-root` 覆盖。

示例：
```
[PATHS]
DST_ROOT=/path/to/dontstarvetogether_dedicated_server
```

## 构建流程

所有产物落盘在 `data/`，并带版本后缀。

一键构建：
```bash
make all
```

或分步构建：
```bash
wagstaff resindex   # resource index
wagstaff catalog2   # catalog v2 (+ tuning trace)
wagstaff catindex   # compact catalog index
wagstaff i18n       # i18n index
wagstaff icons      # icon export + icon index
wagstaff catqa      # coverage/quality report
wagstaff quality    # info-only quality gate
```

可选：生成 SQLite 版本 catalog：
```bash
make catalog-sqlite
```

## 启动 WebCraft

```bash
wagstaff web --host 0.0.0.0 --port 20000 --reload-catalog
```

WebCraft 优先读取 `data/index/wagstaff_catalog_v2.sqlite`（缺失时回退 JSON）。
i18n 仅使用 `data/index/wagstaff_i18n_v1.json`（运行时不解析 PO）。

默认本地启动：
```bash
wagstaff web
```

## CLI 总览

- `wagstaff` / `wagstaff dash`：项目概览面板
- `wagstaff doctor`：环境与产物检查（信息提示）
- `wagstaff wiki`：配方/烹饪/Prefab 查询
- `wagstaff exp`：源码与 Lua 解析探索
- `wagstaff mgmt`：管理状态展示与同步
- `wagstaff server`：DST 服务器管理（screen 会话）
- `wagstaff snap`：LLM 快照导出

## 服务器管理示例

```bash
wagstaff server status
wagstaff server ui
wagstaff server start
wagstaff server stop --timeout 40 --force
wagstaff server backup
wagstaff server restore --latest --yes --start
wagstaff server logs --shard master --follow
wagstaff server cmd "c_announce(\"hello\")"
```

## 关键产物

```
data/index/wagstaff_resource_index_v1.json
data/index/wagstaff_catalog_v2.json
data/index/wagstaff_catalog_v2.sqlite
data/index/wagstaff_catalog_index_v1.json
data/index/wagstaff_i18n_v1.json
data/index/wagstaff_icon_index_v1.json
data/index/wagstaff_tuning_trace_v1.json
data/reports/catalog_quality_report.md
```

## 项目结构

```
core/            解析 + 索引 + schemas
core/indexers/   索引构建逻辑
core/schemas/    数据契约 + meta 辅助
apps/cli/        CLI dispatcher + commands
apps/server/     DST server ops (isolated from data analysis)
apps/webcraft/   WebCraft API + UI
devtools/        构建/报告/快照工具
conf/            配置与快照模板
data/            产物与报告
docs/            guides/ specs/ management/ architecture
```

## 文档入口

- `docs/README.md`：文档索引
- `docs/guides/DEV_GUIDE.md`：开发规范
- `docs/guides/CLI_GUIDE.md`：CLI 角色与职责
- `docs/specs/CATALOG_V2_SPEC.md`：Catalog v2 规范
- `docs/management/ROADMAP.md`：项目路线图
- `docs/management/PROJECT_MANAGEMENT.md`：项目管理与进度
```

### File: docs/README.md
- mode: head
- size_bytes: 466
- sha256_12: 9088f3deea34

```md
# Docs Index

文档按用途分层，避免规划/规范/实现混杂。

## guides/

- `guides/DEV_GUIDE.md`：开发规范与强制约束
- `guides/CLI_GUIDE.md`：CLI 角色与职责

## management/

- `management/PROJECT_MANAGEMENT.md`：执行管理与进度
- `management/ROADMAP.md`：长期方向

## specs/

- `specs/CATALOG_V2_SPEC.md`：Catalog v2 + API 契约

## architecture/

- `architecture/WEBCRAFT_NETWORK_STACK.md`：WebCraft 网络与服务栈
```

### File: conf/settings.ini
- mode: full
- size_bytes: 353
- sha256_12: 15952c921af7

```toml
[PATHS]
# 游戏安装目录
DST_ROOT = ~/dontstarvetogether_dedicated_server
# SteamCMD 目录
STEAMCMD_DIR = ~/steamcmd
# 备份存放目录
BACKUP_DIR = ~/dst_backups

[SERVER]
# 你的存档文件夹名 (Cluster Name)
CLUSTER_NAME = MyDediServer
# Klei 存档根目录 (通常是 ~/.klei/DoNotStarveTogether)
KLEI_HOME = ~/.klei/DoNotStarveTogether
```

### File: docs/guides/DEV_GUIDE.md
- mode: head
- size_bytes: 5751
- sha256_12: e04dc09b8fd7

```md
# Wagstaff-Lab 开发规范 (v3.2)

本指南用于约束核心架构边界与开发协作方式，确保可维护与可扩展。

## 0. 快速必读（人/LLM）

- **本文件是强制入口**：任何架构/入口/产物变更都必须先对照并更新本文件。
- **执行顺序建议**：`README.md` → `DEV_GUIDE.md` → `PROJECT_MANAGEMENT.md` → `CATALOG_V2_SPEC.md`。
- **规范优先级**：若文档冲突，以 `DEV_GUIDE.md` 为准。

### DEV_GUIDE_META

```yaml
dev_guide:
  version: v3.2
  must_update_on:
    - 架构/目录调整
    - CLI/Web/Server 入口变更
    - 索引/产物结构变更
    - 依赖/构建流程变更
  entrypoints:
    - wagstaff
    - make
  management:
    - docs/management/PROJECT_MANAGEMENT.md
    - PROJECT_STATUS.json
```

## 1. 分层职责

- `core/`：解析、索引、算法与数据模型。不得依赖 `apps/` 或 `devtools/`。
- `core/schemas/`：核心数据结构与元信息规范（仅类型/结构，不含流程）。
- `core/indexers/`：索引构建逻辑（依赖 `core/` 但不触碰上层）。
- `apps/cli/`：CLI 交互层。调用 `core/`，仅做输入/输出组织。
- `apps/cli/commands/`：CLI 子命令实现（dashboard/doctor/wiki/explorer 等）。
- `apps/server/`：服务器运维（DST 运行/备份/恢复），与数据分析解耦。
- `apps/webcraft/`：WebCraft 服务层（API + UI）。只通过索引产物与 `core/` 暴露的能力。
- `devtools/`：构建、报表、快照等流程工具。
- `data/`：所有产物、报告、索引、静态资源的统一落盘目录。
- CLI 角色与职责见 `docs/guides/CLI_GUIDE.md`。

## 2. 依赖与导入约定

- 依赖方向：`apps/`、`devtools/` -> `core/`。
- 入口脚本只挂载项目根目录到 `sys.path`，通过 `core.*` / `apps.*` / `devtools.*` 进行导入。
- `core/` 不得自行修改 `sys.path`。
- 任何跨层访问，优先通过 `core` 的稳定 API，而非直接读文件或 copy 逻辑。

## 3. 包管理 (pyproject.toml)

- 依赖统一由 `pyproject.toml` 管理，禁止散落在脚本内。
- 采用可选依赖分组：`cli` / `web` / `icons` / `quality` / `all`。
- 入口注册统一通过：`python -m pip install -e ".[cli]"`（需要完整能力时用 `.[all]`）。

## 4. 数据产物与命名

- 统一落盘到 `data/`，并带版本号后缀，例如：
  - `data/index/wagstaff_catalog_v2.json`
  - `data/index/wagstaff_catalog_v2.sqlite`
  - `data/index/wagstaff_icon_index_v1.json`
- 产物需携带统一元信息（schema / generated / tool / sources / scripts hash）。
- WebCraft UI 不应直接读取原始脚本或 datastream，仅消费 `data/index` 等稳定产物。
- Catalog v2 产物新增 `cooking_ingredients` 字段用于料理食材 tags 索引。

## 5. WebCraft 约定

- API 统一在 `/api/v1` 下，UI 与 API 使用同一 `root_path`。
- UI 仅通过 API 访问数据；静态资源来自 `data/static/`。
- 新增字段须保证向后兼容或同步更新 `schema_version`。
- WebCraft 运行时优先使用 `data/index/wagstaff_catalog_v2.sqlite`，缺失时回退 JSON。
- i18n 仅使用 `data/index/wagstaff_i18n_v1.json`（运行时不解析 PO）。
- WebCraft 应用静态资源（CSS/字体等）放在 `apps/webcraft/static/`，对外挂载为 `/static/app`；数据产物静态资源（如图标）继续落盘 `data/static/` 并对外挂载 `/static/data`。

## 6. 变更与文档

- 重要重构必须同步更新：
  - `README.md`
  - `docs/guides/DEV_GUIDE.md`
  - `PROJECT_STATUS.json`
  - `docs/management/PROJECT_MANAGEMENT.md`
  - `docs/` 相关文档
- 所有结构调整需记录到 `RECENT_LOGS`。

## 6.1 变更检查清单（强制）

- [ ] DEV_GUIDE 是否需要更新（架构/入口/产物/依赖）
- [ ] PROJECT_MANAGEMENT 是否需要更新（里程碑/任务）
- [ ] PROJECT_STATUS 是否同步（RECENT_LOGS/任务）
- [ ] 文档入口是否一致（README / SPEC / ROADMAP）

## 7. Snapshot 友好开发规范 (面向后续开发)

- 公开接口集中在少数入口文件（例如 `core/engine.py`、`apps/*/app.py`），避免散落式 API。
- 模块顶部写清楚职责与输入/输出约束，复杂模块必须有模块级 docstring。
- 对外数据结构必须有字段说明（注释或类型定义），避免“隐式字段”。
- 重要函数保持稳定签名，新增参数必须给默认值并写清变更意图。
- 新增索引/产物必须落盘 `data/` 并记录 schema_version 与生成来源。
- 关键流程写最小示例（1-3 行 usage），便于快照直接引用。

## 8. LLM 快照与文档导出 (snapshot.py)

- `devtools/snapshot.py` 是统一的 LLM 友好导出工具；`wagstaff snap` 默认使用 llm 模板输出 `project_context.txt`。
- 模板集中在 `conf/snapshot_templates.json`，通过 `sections` 控制 env/tree/inventory/contents/stats 等模块输出。
- 聚焦导出使用 `--focus path|glob`（可多次传入），默认仍保留 `README.md`/`PROJECT_STATUS.json` 作为上下文。
- 若需更清爽输出，可用 `--no-tree`/`--no-inventory`/`--no-contents` 等开关精简。
- 重要重构必须同步更新 `PROJECT_STATUS.json`/`README.md`，确保快照上下文准确。

## 9. 任务入口 (Makefile)

- `make resindex` / `make catalog` / `make catalog-index`
- `make catalog-sqlite`
- `make i18n` / `make icons`
- `make quality` / `make gate`
- `make webcraft` / `make snap`

## 10. 最低自检清单

- `wagstaff dash` (主界面可运行)
- `python devtools/build_catalog_v2.py --silent`
- `python devtools/quality_gate.py` (信息提示，CI 可加 --enforce/--strict)
- `python devtools/snapshot.py --mode llm --plan` (快照计划可生成)
- `python devtools/serve_webcraft.py --help` (需要 uvicorn)
```

### File: docs/management/ROADMAP.md
- mode: head
- size_bytes: 1914
- sha256_12: f44e75296c14

```md
# Wagstaff-Lab 版本演进方向 (v3+)

本文件仅保留**长期方向**，执行计划与进度请统一查看：
- `docs/management/PROJECT_MANAGEMENT.md`

## 1. 架构与工程化

- 模块化与包化：逐步引入 `pyproject.toml`，形成可安装的内核与应用包。
- 入口统一：提供明确的 CLI/Web 启动入口与配置模板。
- 插件接口：定义解析器/索引器的扩展协议，降低新增功能成本。

## 2. 数据层演进

- Catalog schema v2：更多字段归一化（prefab、asset、tuning trace）。
- 增量构建：对比 scripts hash，支持局部重建与 cache reuse。
- 存储升级：从 JSON 过渡到 SQLite/Parquet（大规模检索性能）。

## 3. WebCraft 体验

- 多维检索：标签、来源、制作链路、组件属性联动检索。
- 探索/模拟：料理食材驱动探索、配方模拟与发现流。
- 食材索引：解析 ingredients/cooking 定义，提供 cooking_ingredients tags 数据契约。
- 信息密度：表格/列表切换，中英文/调试 ID 同屏，快捷复制。
- 结果解释：TUNING 解析链路可视化、配方链路图与条件展示。
- 体验与性能：统一页面结构、键盘/移动端优化、静态资源本地化与缓存。

## 4. CLI 与工具链

- CLI 统一输出规范（JSON/表格/纯文本）。
- devtools 统一日志与报告产出格式，便于对比与自动化。
- 建立脚手架：新工具生成器（模板 + 注册）。

## 5. 质量与可观测

- 核心功能最小测试集：解析器、索引器、Web API 合同测试。
- 产物验证：索引一致性检查（assets/recipes/cooking）。
- 运行指标：构建时间、产物规模、缺失率统计。

## 6. 生态与协作

- 明确贡献指南与代码风格约定。
- 对外文档与示例数据集（便于复现与扩展）。
- 分离实验区与稳定区（feature branch/experimental modules）。
```

### File: apps/cli/main.py
- mode: full
- size_bytes: 1747
- sha256_12: 1f13f3912194

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Unified CLI dispatcher for Wagstaff-Lab."""

from __future__ import annotations

import runpy
import sys
from pathlib import Path
from typing import List, Optional, Tuple

PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))


def _tool_path(tool: dict) -> Path:
    folder = tool.get("folder") or "apps/cli"
    if folder == "apps/cli":
        base = PROJECT_ROOT / "apps" / "cli"
    elif folder == "devtools":
        base = PROJECT_ROOT / "devtools"
    else:
        base = PROJECT_ROOT / folder
    return base / str(tool.get("file"))


def _resolve_tool(alias: Optional[str]) -> Tuple[Path, List[str]]:
    from apps.cli.registry import get_tools

    tools = get_tools()
    dash = next((t for t in tools if t.get("alias") == "dash"), None)
    default_path = _tool_path(dash) if dash else (PROJECT_ROOT / "apps" / "cli" / "commands" / "dash.py")

    if not alias:
        return default_path, []

    key = str(alias).strip()
    if not key:
        return default_path, []

    for tool in tools:
        if tool.get("alias") == key or tool.get("file") == key:
            return _tool_path(tool), []

    # fallback: show dashboard, pass through as arg to help locate typos
    return default_path, [key]


def main(argv: Optional[List[str]] = None) -> None:
    argv = list(argv) if argv is not None else list(sys.argv[1:])
    alias = argv[0] if argv else None
    path, injected = _resolve_tool(alias)

    if argv and alias:
        argv = argv[1:]
    argv = injected + argv

    sys.argv = [str(path)] + argv
    runpy.run_path(str(path), run_name="__main__")


if __name__ == "__main__":
    main()
```

### File: apps/cli/registry.py
- mode: full
- size_bytes: 4880
- sha256_12: fb4ace09edbb

```py
#!/usr/bin/env python3
"""
Wagstaff-Lab 工具注册中心 (v2.3)
"""

TOOLS = [
    # --- CLI 工具 (apps/cli) ---
    {
        "file": "dash.py",
        "alias": "dash",
        "desc": "Wagstaff-Lab 控制台主面板",
        "usage": "wagstaff dash",
        "type": "CLI",
        "folder": "apps/cli/commands"
    },
    {
        "file": "doctor.py",
        "alias": "doctor",
        "desc": "环境配置与依赖健康检查",
        "usage": "wagstaff doctor",
        "type": "CLI",
        "folder": "apps/cli/commands"
    },
    {
        "file": "wiki.py",
        "alias": "wiki",
        "desc": "物品/配方/数值查询百科",
        "usage": "wagstaff wiki <item_code>",
        "type": "CLI",
        "folder": "apps/cli/commands"
    },
    {
        "file": "explorer.py",
        "alias": "exp",
        "desc": "源码结构浏览与深度分析",
        "usage": "wagstaff exp",
        "type": "CLI",
        "folder": "apps/cli/commands"
    },
    {
        "file": "mgmt.py",
        "alias": "mgmt",
        "desc": "项目管理：状态展示与同步",
        "usage": "wagstaff mgmt <status|sync|dump|check>",
        "type": "CLI",
        "folder": "apps/cli/commands"
    },
    {
        "file": "server.py",
        "alias": "server",
        "desc": "DST 服务器管理 (screen-based)",
        "usage": "wagstaff server <status|start|stop|restart|update|backup|restore|logs|cmd|ui>",
        "type": "CLI",
        "folder": "apps/cli/commands"
    },

    # --- 开发工具 (devtools/) ---
    {
        "file": "reporter.py",
        "alias": "report",
        "desc": "生成全服资产/配方分布报告",
        "usage": "wagstaff report [assets|recipes|all]",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "build_catalog_v2.py",
        "alias": "catalog2",
        "desc": "生成 Catalog v2 (item-centric)",
        "usage": "wagstaff catalog2 [--tuning-mode value_only|full] [--tuning-trace-out PATH]",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "build_i18n_index.py",
        "alias": "i18n",
        "desc": "生成 i18n 索引 (names + UI strings)",
        "usage": "wagstaff i18n [--lang zh] [--dst-root PATH]",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "build_icons.py",
        "alias": "icons",
        "desc": "生成物品图标 PNG + icon index",
        "usage": "wagstaff icons [--dst-root PATH] [--all-elements]",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "build_catalog_index.py",
        "alias": "catindex",
        "desc": "生成 Catalog 紧凑索引（列表 + 多维倒排）",
        "usage": "wagstaff catindex [--catalog PATH] [--icon-index PATH]",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "catalog_quality.py",
        "alias": "catqa",
        "desc": "生成 Catalog 覆盖率/质量报告",
        "usage": "wagstaff catqa [--catalog PATH] [--i18n PATH] [--trace PATH]",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "quality_gate.py",
        "alias": "quality",
        "desc": "质量门禁自检（默认仅提示）",
        "usage": "wagstaff quality [--enforce] [--strict]",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "snapshot.py",
        "alias": "snap",
        "desc": "生成 LLM 友好代码快照",
        "usage":  "wagstaff snapshot [-h] [--mode {llm,core,archive,custom}] [--template TEMPLATE] [--config CONFIG] [--output OUTPUT] [--focus PATH|GLOB ...] [--list-templates] [--no-redact] [--zip] [--no-tree] [--no-inventory] [--no-contents] [--no-stats] [--verbose] [--plan]",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "sampler.py",
        "alias": "samples",
        "desc": "生成 DST Lua 样本包（用于扩展解析器）",
        "usage": "wagstaff samples [--categories ...] [--n N] [--head-lines N] ...",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "build_resource_index.py",
        "alias": "resindex",
        "desc": "生成 DST 资源索引（scripts + data）",
        "usage": "wagstaff resindex [--data-full] [--bundle-full] [--dst-root PATH]",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "codemap.py",
        "alias": "map",
        "desc": "生成 DST scripts 宏观结构地图报告",
        "usage": "wagstaff map",
        "type": "Dev",
        "folder": "devtools"
    },
    {
        "file": "serve_webcraft.py",
        "alias": "web",
        "desc": "启动 WebCraft (FastAPI + Uvicorn)",
        "usage": "wagstaff web [--host 0.0.0.0 --port 20000]",
        "type": "Dev",
        "folder": "devtools"
    },
]

def get_tools():
    return TOOLS
```

### File: apps/__init__.py
- mode: full
- size_bytes: 52
- sha256_12: 358b6db47998

```py
# -*- coding: utf-8 -*-
"""Applications package."""
```

### File: apps/cli/__init__.py
- mode: full
- size_bytes: 43
- sha256_12: f8d7e7942c05

```py
# -*- coding: utf-8 -*-
"""CLI package."""
```

### File: apps/cli/cli_common.py
- mode: full
- size_bytes: 1915
- sha256_12: 3ee63244bc5c

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Shared helpers for CLI tools."""

from __future__ import annotations

import json
import os
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

PROJECT_ROOT = Path(__file__).resolve().parents[2]
DATA_DIR = PROJECT_ROOT / "data"
INDEX_DIR = DATA_DIR / "index"
REPORT_DIR = DATA_DIR / "reports"
CONF_DIR = PROJECT_ROOT / "conf"


def read_json(path: Path) -> Optional[Dict[str, Any]]:
    if not path.exists():
        return None
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return None


def read_text(path: Path) -> Optional[str]:
    if not path.exists():
        return None
    try:
        return path.read_text(encoding="utf-8")
    except Exception:
        return None


def load_status() -> Dict[str, Any]:
    status_path = PROJECT_ROOT / "PROJECT_STATUS.json"
    doc = read_json(status_path)
    return doc if isinstance(doc, dict) else {}


def file_info(path: Path) -> Dict[str, Any]:
    if not path.exists():
        return {"exists": False, "size": 0, "mtime": None}
    st = path.stat()
    return {"exists": True, "size": int(st.st_size), "mtime": float(st.st_mtime)}


def human_size(num: int) -> str:
    if num <= 0:
        return "-"
    for unit in ("B", "KiB", "MiB", "GiB"):
        if num < 1024.0:
            return f"{num:.0f} {unit}" if unit == "B" else f"{num:.1f} {unit}"
        num /= 1024.0
    return f"{num:.1f} TiB"


def human_mtime(ts: Optional[float]) -> str:
    if not ts:
        return "-"
    return datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M")


def env_hint() -> Tuple[str, str]:
    env = os.environ.get("CONDA_DEFAULT_ENV", "").strip()
    if env:
        return env, "conda"
    venv = os.environ.get("VIRTUAL_ENV", "").strip()
    if venv:
        return venv, "venv"
    return "system", "system"
```

### File: apps/cli/commands/__init__.py
- mode: full
- size_bytes: 51
- sha256_12: 6ea567813f48

```py
# -*- coding: utf-8 -*-
"""CLI command modules."""
```

### File: apps/cli/commands/dash.py
- mode: full
- size_bytes: 6322
- sha256_12: 7ab0813dd13e

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, List, Tuple

from rich.console import Console
from rich.panel import Panel
from rich.table import Table

from apps.cli.cli_common import (
    DATA_DIR,
    INDEX_DIR,
    REPORT_DIR,
    PROJECT_ROOT,
    env_hint,
    file_info,
    human_mtime,
    human_size,
    load_status,
    read_json,
)
from apps.cli.registry import get_tools

console = Console()


def _artifact_rows() -> List[Tuple[str, Path]]:
    return [
        ("resource_index", INDEX_DIR / "wagstaff_resource_index_v1.json"),
        ("catalog_v2", INDEX_DIR / "wagstaff_catalog_v2.json"),
        ("catalog_index", INDEX_DIR / "wagstaff_catalog_index_v1.json"),
        ("icon_index", INDEX_DIR / "wagstaff_icon_index_v1.json"),
        ("i18n_index", INDEX_DIR / "wagstaff_i18n_v1.json"),
        ("tuning_trace", INDEX_DIR / "wagstaff_tuning_trace_v1.json"),
        ("catalog_quality", REPORT_DIR / "catalog_quality_report.md"),
        ("quality_gate", REPORT_DIR / "quality_gate_report.md"),
    ]


def _render_artifacts() -> None:
    table = Table(title="Artifacts", box=None, show_header=True, header_style="bold cyan")
    table.add_column("Name", style="bold")
    table.add_column("Status")
    table.add_column("Updated", style="dim")
    table.add_column("Size", style="green")
    table.add_column("Path", style="dim")

    for name, path in _artifact_rows():
        info = file_info(path)
        status = "[green]OK[/green]" if info["exists"] else "[red]MISSING[/red]"
        table.add_row(
            name,
            status,
            human_mtime(info["mtime"]),
            human_size(info["size"]),
            str(path.relative_to(PROJECT_ROOT)),
        )
    console.print(table)


def _render_quality() -> None:
    qpath = REPORT_DIR / "catalog_quality_report.json"
    doc = read_json(qpath) or {}

    counts = doc.get("counts") if isinstance(doc, dict) else None
    counts = counts if isinstance(counts, dict) else {}
    trace = doc.get("tuning_trace") if isinstance(doc, dict) else None
    trace = trace if isinstance(trace, dict) else {}
    i18n = doc.get("i18n") if isinstance(doc, dict) else None
    i18n = i18n if isinstance(i18n, dict) else {}

    items_total = int(counts.get("items_total") or 0)
    items_with_stats = int(counts.get("items_with_stats") or 0)
    stats_ratio = (items_with_stats / items_total) if items_total else 0.0
    t_items = (trace.get("items") or {}).get("with_trace", 0)
    t_cook = (trace.get("cooking") or {}).get("with_trace", 0)
    i18n_cov = i18n.get("coverage") or {}

    table = Table(title="Quality Snapshot", box=None, show_header=False)
    table.add_column("Key", style="bold")
    table.add_column("Value")
    table.add_row("items_total", str(items_total))
    table.add_row("items_with_stats", f"{items_with_stats} ({stats_ratio:.1%})")
    table.add_row("tuning_trace", f"items={t_items} cooking={t_cook}")
    if i18n_cov:
        for lang, row in i18n_cov.items():
            try:
                names = row.get("names", 0)
                covered = row.get("coverage_items", {}).get("covered", 0)
                total = row.get("coverage_items", {}).get("total", 0)
                ratio = (covered / total) if total else 0.0
                table.add_row(f"i18n:{lang}", f"{names} names ({ratio:.1%})")
            except Exception:
                continue
    console.print(table)


def _render_tasks(status: Dict[str, Any]) -> None:
    todo = status.get("TASKS_TODO") or []
    done = status.get("TASKS_DONE") or []
    logs = status.get("RECENT_LOGS") or []

    table = Table(title="Tasks", box=None, show_header=False)
    table.add_column("Key", style="bold")
    table.add_column("Value")
    table.add_row("todo", str(len(todo)))
    table.add_row("done", str(len(done)))
    console.print(table)

    if todo:
        console.print("[bold yellow]Todo (top 6)[/bold yellow]")
        for t in todo[:6]:
            console.print(f"- {t}")
    if logs:
        console.print("\n[bold cyan]Recent Logs[/bold cyan]")
        for line in logs[-6:]:
            console.print(f"- {line}")


def _render_docs() -> None:
    table = Table(title="Docs", box=None, show_header=True, header_style="bold cyan")
    table.add_column("Name", style="bold")
    table.add_column("Updated", style="dim")
    table.add_column("Path", style="dim")

    docs = [
        ("DEV_GUIDE", PROJECT_ROOT / "docs" / "guides" / "DEV_GUIDE.md"),
        ("PROJECT_MANAGEMENT", PROJECT_ROOT / "docs" / "management" / "PROJECT_MANAGEMENT.md"),
        ("CATALOG_V2_SPEC", PROJECT_ROOT / "docs" / "specs" / "CATALOG_V2_SPEC.md"),
        ("ROADMAP", PROJECT_ROOT / "docs" / "management" / "ROADMAP.md"),
    ]

    for name, path in docs:
        info = file_info(path)
        table.add_row(name, human_mtime(info["mtime"]), str(path.relative_to(PROJECT_ROOT)))
    console.print(table)


def _render_tools() -> None:
    table = Table(title="Toolbox", box=None, show_header=True, header_style="bold cyan")
    table.add_column("Command", style="bold")
    table.add_column("Desc")
    table.add_column("Usage", style="green")
    for tool in get_tools():
        name = tool.get("alias") or tool.get("file") or "-"
        cmd = f"wagstaff {name}" if tool.get("alias") else "wagstaff"
        table.add_row(cmd, tool.get("desc", "-"), tool.get("usage", "-"))
    console.print(table)


def main() -> None:
    status = load_status()
    objective = status.get("OBJECTIVE") or status.get("objective") or "-"
    env_name, env_kind = env_hint()

    header = f"[bold white on blue] Wagstaff-Lab Dashboard (v3) [/bold white on blue]"
    console.print(Panel(header, border_style="blue"))
    console.print(f"[bold green]Objective:[/bold green] {objective}")
    console.print(f"[dim]Root: {PROJECT_ROOT} | Env: {env_name} ({env_kind}) | Data: {DATA_DIR}[/dim]")

    console.print("")
    _render_tasks(status)
    console.print("")
    _render_docs()
    console.print("")
    _render_quality()
    console.print("")
    _render_artifacts()
    console.print("")
    _render_tools()
    console.print("\n[dim]Tips: wagstaff quality | wagstaff catqa | wagstaff catindex | wagstaff snap[/dim]")


if __name__ == "__main__":
    main()
```

### File: apps/cli/commands/doctor.py
- mode: full
- size_bytes: 6232
- sha256_12: 9f344e461317

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations

import argparse
import configparser
import os
import shutil
import subprocess
from pathlib import Path

from rich.console import Console
from rich.panel import Panel
from rich.table import Table

from apps.cli.cli_common import (
    CONF_DIR,
    INDEX_DIR,
    PROJECT_ROOT,
    env_hint,
    file_info,
    human_mtime,
    human_size,
)

console = Console()
CONFIG_PATH = CONF_DIR / "settings.ini"


def _expand(p: str) -> str:
    return os.path.expanduser(p.strip())


def _cfg_get(cfg: configparser.ConfigParser, section: str, key: str) -> str:
    try:
        v = cfg.get(section, key, fallback="").strip()
    except Exception:
        v = ""
    return _expand(v) if v else ""


def _status(level: str) -> str:
    if level == "PASS":
        return "[green]PASS[/green]"
    if level == "WARN":
        return "[yellow]WARN[/yellow]"
    return "[red]FAIL[/red]"


def _check_path_exists(path: Path, kind: str, fix: str = ""):
    if kind == "file":
        ok = path.is_file()
    elif kind == "dir":
        ok = path.is_dir()
    else:
        ok = path.exists()
    level = "PASS" if ok else "WARN"
    return ok, level, str(path), fix


def main() -> int:
    p = argparse.ArgumentParser(description="Wagstaff Doctor (environment + data health check)")
    p.add_argument("--enforce", action="store_true", help="exit non-zero on failures (CI)")
    p.add_argument("--strict", action="store_true", help="treat WARN as FAIL (only when --enforce)")
    args = p.parse_args()

    env_name, env_kind = env_hint()
    console.print(Panel(f"[bold cyan]Wagstaff Doctor[/bold cyan]\nEnv: {env_name} ({env_kind})", border_style="cyan"))

    table = Table(title="Health Checks", box=None, show_header=True, header_style="bold cyan")
    table.add_column("Check", style="bold")
    table.add_column("Status", justify="center")
    table.add_column("Details", style="dim")
    table.add_column("Fix Hint", style="green")

    fail = 0
    warn = 0

    # 1) config file (optional)
    ok, level, details, fix = _check_path_exists(CONFIG_PATH, "file", "Optional: configure conf/settings.ini to enable DST path checks")
    table.add_row("conf/settings.ini", _status(level), details, fix if not ok else "")
    if not ok:
        warn += 1

    cfg = configparser.ConfigParser()
    if ok:
        try:
            cfg.read(CONFIG_PATH)
        except Exception as e:
            table.add_row("parse settings.ini", _status("WARN"), str(e), "Check ini format")
            warn += 1

    dst_root = _cfg_get(cfg, "PATHS", "DST_ROOT") if ok else ""
    steamcmd_dir = _cfg_get(cfg, "PATHS", "STEAMCMD_DIR") if ok else ""
    backup_dir = _cfg_get(cfg, "PATHS", "BACKUP_DIR") if ok else ""

    # 2) data artifacts
    artifacts = [
        ("catalog_v2", INDEX_DIR / "wagstaff_catalog_v2.json"),
        ("catalog_index", INDEX_DIR / "wagstaff_catalog_index_v1.json"),
        ("icon_index", INDEX_DIR / "wagstaff_icon_index_v1.json"),
        ("i18n_index", INDEX_DIR / "wagstaff_i18n_v1.json"),
        ("tuning_trace", INDEX_DIR / "wagstaff_tuning_trace_v1.json"),
    ]
    for name, path in artifacts:
        info = file_info(path)
        level = "PASS" if info["exists"] else "WARN"
        details = f"{human_mtime(info['mtime'])} | {human_size(info['size'])}"
        table.add_row(
            f"data/{name}",
            _status(level),
            details if info["exists"] else "missing",
            "Run the matching build_* script" if not info["exists"] else "",
        )
        if not info["exists"]:
            warn += 1

    # 3) DST root + scripts source (optional)
    if dst_root:
        dst_root_p = Path(dst_root)
        ok, level, details, fix = _check_path_exists(dst_root_p, "dir", "Ensure DST is installed at this path")
        table.add_row("DST_ROOT exists", _status(level), details, fix if level != "PASS" else "")
        if not ok:
            warn += 1

        scripts_zip = dst_root_p / "data" / "databundles" / "scripts.zip"
        scripts_dir = dst_root_p / "data" / "scripts"
        ok_zip = scripts_zip.is_file()
        ok_dir = scripts_dir.is_dir()
        level = "PASS" if (ok_zip or ok_dir) else "WARN"
        details = f"zip={scripts_zip} ({'ok' if ok_zip else 'missing'}), dir={scripts_dir} ({'ok' if ok_dir else 'missing'})"
        table.add_row("scripts source", _status(level), details, "Ensure scripts.zip exists or data/scripts is available" if level != "PASS" else "")
        if level != "PASS":
            warn += 1

    # 4) steamcmd (optional)
    if steamcmd_dir:
        steamcmd = Path(steamcmd_dir) / "steamcmd.sh"
        ok, level, details, fix = _check_path_exists(steamcmd, "file", "Ensure SteamCMD is installed and steamcmd.sh exists")
        table.add_row("steamcmd.sh", _status(level), details, fix if level != "PASS" else "")
        if not ok:
            warn += 1

    # 5) screen (optional)
    screen_path = shutil.which("screen")
    if not screen_path:
        table.add_row("screen installed", _status("WARN"), "(not found)", "sudo apt-get install screen")
        warn += 1
    else:
        try:
            r = subprocess.run(["screen", "-version"], capture_output=True, text=True)
            level = "PASS" if (r.returncode == 0) else "WARN"
            table.add_row("screen installed", _status(level), screen_path, "")
            if level == "WARN":
                warn += 1
        except Exception as e:
            table.add_row("screen installed", _status("WARN"), str(e), "Verify screen is executable")
            warn += 1

    # 6) backup dir (optional)
    if backup_dir:
        bdir = Path(backup_dir)
        level = "PASS" if bdir.exists() else "WARN"
        table.add_row("BACKUP_DIR exists", _status(level), str(bdir), "mkdir -p this directory" if not bdir.exists() else "")
        if level != "PASS":
            warn += 1

    console.print(table)
    console.print(f"[dim]Root: {PROJECT_ROOT} | Summary: FAIL={fail}, WARN={warn}[/dim]")

    if not args.enforce:
        return 0
    if fail:
        return 2
    if args.strict and warn:
        return 1
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
```

### File: apps/cli/commands/explorer.py
- mode: full
- size_bytes: 9698
- sha256_12: fed2c31acc6b

```py
#!/usr/bin/env python3
import os
import sys
from pathlib import Path
from rich.console import Console
from rich.table import Table
from rich.tree import Tree
from rich.panel import Panel
from rich.prompt import Prompt, IntPrompt
from rich.syntax import Syntax
from rich import box
from apps.cli.cli_common import PROJECT_ROOT

from core.engine import WagstaffEngine

console = Console()

class DSTExplorer:
    def __init__(self):
        # 初始化引擎
        try:
            self.engine = WagstaffEngine(load_db=True)
        except Exception as e:
            console.print(f"[red]引擎启动失败: {e}[/red]")
            sys.exit(1)
        
        console.print(Panel(f"[bold cyan]Wagstaff 源码透视镜 v3.1[/bold cyan]\n模式: {self.engine.mode.upper()} | 解析核心: Multi-Parser", border_style="blue"))
        if self.engine.tuning:
            console.print(f"[dim]⚡ Tuning 数值库就绪 ({len(self.engine.tuning.raw_map)} 条目)[/dim]")

    def get_structure_tree(self):
        """展示源码目录结构"""
        tree = Tree(f"📁 [bold yellow]源码结构[/bold yellow]")
        dir_counts = {}
        for f in self.engine.file_list:
            clean_path = f.replace("scripts/", "", 1) if f.startswith("scripts/") else f
            top_dir = clean_path.split('/')[0] if '/' in clean_path else "[Root Files]"
            dir_counts[top_dir] = dir_counts.get(top_dir, 0) + 1

        for d, count in sorted(dir_counts.items(), key=lambda x: x[1], reverse=True):
            if d == "[Root Files]":
                tree.add(f"📄 {d} ({count})")
            else:
                style = "bold cyan" if d in ["prefabs", "components", "tuning.lua"] else "white"
                tree.add(f"📂 [{style}]{d}[/{style}] ([dim]{count}[/dim])")
        return tree

    def search_files(self):
        """文件名搜索"""
        keyword = Prompt.ask("[bold green]🔍 搜索关键词[/bold green]")
        if not keyword: return
        
        matches = [f for f in self.engine.file_list if keyword.lower() in f.lower()]
        
        if not matches:
            console.print("[yellow]无结果[/yellow]")
            return

        table = Table(title=f"Results: '{keyword}'", box=box.SIMPLE)
        table.add_column("路径", style="dim")
        table.add_column("文件", style="bold green")
        for m in matches[:15]:
            d, f = os.path.split(m)
            table.add_row(d, f)
        console.print(table)
        if len(matches) > 15: console.print(f"[dim]...剩余 {len(matches)-15} 项隐藏[/dim]")

    def analyze_content(self, filename, content):
        """核心分析逻辑：根据 analyzer 返回的类型进行多态渲染"""
        from core.analyzer import LuaAnalyzer
        
        try:
            # 1. 统一入口解析 (Facade)
            data = LuaAnalyzer(content).get_report()
        except Exception as e:
            console.print(f"[red]解析失败: {e}[/red]")
            return
        
        # 2. 根据数据类型分发渲染
        dtype = data.get("type", "prefab")
        tree = Tree(f"🧬 [bold green]深度解析: {dtype.upper()}[/bold green]")
        
        if dtype == "loot":
            self._render_loot(tree, data)
        elif dtype == "widget":
            self._render_widget(tree, data)
        elif dtype == "strings":
            self._render_strings(tree, data)
        else:
            self._render_prefab(tree, data)

        console.print(Panel(tree, border_style="green"))
        input("按回车返回...")

    # === 子渲染器 (Renderers) ===

    def _render_loot(self, tree, data):
        """渲染掉落表数据"""
        if data.get('table_name'):
            tree.add(f"📜 表名: [bold gold1]{data['table_name']}[/bold gold1]")
        
        entries = data.get('entries', [])
        if entries:
            branch = tree.add(f"💰 掉落项 ({len(entries)})")
            for item in entries:
                if item.get('method') == 'Random':
                    branch.add(f"[cyan]{item['item']}[/cyan]: 权重 [yellow]{item['weight']}[/yellow]")
                else:
                    chance = item.get('chance', 0)
                    branch.add(f"[cyan]{item['item']}[/cyan]: 几率 [magenta]{chance}[/magenta]")

    def _render_widget(self, tree, data):
        """渲染 UI Widget 数据"""
        if data.get('classes'):
            c_branch = tree.add("🧩 UI 类定义")
            for c in data['classes']:
                c_branch.add(f"[bold white]{c['name']}[/bold white] (extends [dim]{c['parent']}[/dim])")
        
        if data.get('dependencies'):
            d_branch = tree.add("🔗 依赖模块")
            for d in data['dependencies']:
                d_branch.add(f"[dim]{d}[/dim]")

    def _render_strings(self, tree, data):
        """渲染文本配置数据"""
        if data.get('includes'):
            tree.add(f"📥 引入文件: {', '.join(data['includes'])}")
        
        if data.get('roots'):
            r_branch = tree.add("🔤 文本根节点 (Roots)")
            for root in data['roots']:
                r_branch.add(f"STRINGS.[bold yellow]{root}[/bold yellow]")

    def _render_prefab(self, tree, data):
        """渲染实体 Prefab 数据 (包含 Tuning 增强)"""
        # 1. 资源
        if data.get('assets'):
            asset_branch = tree.add(f"📦 资源引用 ({len(data['assets'])})")
            for a in data['assets']:
                style = "magenta" if "Anim" in a['type'] else "blue"
                asset_branch.add(f"[{style}]{a['type']}[/{style}]: {a['path']}")

        # 2. 逻辑 (Brain/SG/Tags)
        logic_branch = tree.add("🧠 核心逻辑")
        has_logic = False
        if data.get('brain'): 
            logic_branch.add(f"AI: [magenta]{data['brain']}[/magenta]")
            has_logic = True
        if data.get('stategraph'): 
            logic_branch.add(f"SG: [magenta]{data['stategraph']}[/magenta]")
            has_logic = True
        if data.get('tags'): 
            tags = data['tags']
            tag_str = ", ".join([f"[dim]{t}[/dim]" for t in tags[:8]])
            if len(tags) > 8: tag_str += "..."
            logic_branch.add(f"Tags: {tag_str}")
            has_logic = True
        if not has_logic: logic_branch.label = "[dim]🧠 核心逻辑 (无)[/dim]"

        # 3. 组件 (使用 Engine 的 Tuning 进行增强)
        if data.get('components'):
            comp_branch = tree.add(f"⚙️ 功能组件 ({len(data['components'])})")
            for comp in data['components']:
                node = comp_branch.add(f"[bold yellow]{comp['name']}[/bold yellow]")
                
                # 属性
                if comp['properties']:
                    target = node if len(comp['properties']) <=3 else node.add("[dim]属性配置[/dim]")
                    for p in comp['properties']:
                        # 使用 Engine 传入的 Tuning 进行增强
                        p_text = self.engine.tuning.enrich(p) if self.engine.tuning else p
                        target.add(f"[cyan]{p_text}[/cyan]")
                
                # 方法
                if comp['methods']:
                    target = node if len(comp['methods']) <=3 else node.add("[dim]函数调用[/dim]")
                    for m in comp['methods']:
                        # 使用 Engine 传入的 Tuning 进行增强
                        m_text = self.engine.tuning.enrich(m) if self.engine.tuning else m
                        target.add(f"[green]ƒ[/green] {m_text}")
        else:
            tree.add("[dim]⚙️ 功能组件 (无)[/dim]")

    def preview_file(self):
        """文件预览入口"""
        target = Prompt.ask("[bold green]👀 文件名[/bold green]")
        path = self.engine.find_file(target, fuzzy=True)
        if not path:
            console.print("[red]未找到[/red]")
            return
        
        console.print(f"[yellow]打开: {path}[/yellow]")
        content = self.engine.read_file(path)
        
        if content:
            # 只显示前 50 行以供概览
            syntax = Syntax("\n".join(content.splitlines()[:50]), "lua", theme="monokai", line_numbers=True)
            console.print(Panel(syntax, title=f"{path} (Top 50 lines)", border_style="blue"))
            
            action = Prompt.ask("[bold cyan]操作[/bold cyan]", choices=["q", "a"], default="q")
            if action == "a":
                self.analyze_content(path, content)

    def show_tuning(self):
        """展示 Tuning 样本"""
        if not self.engine.tuning: 
            return console.print("[red]Tuning 未加载[/red]")
        
        console.print("[bold magenta]🔢 Tuning 数值采样[/bold magenta]")
        count = 0
        for k, v in list(self.engine.tuning.raw_map.items())[:10]:
             console.print(f"  [cyan]{k}[/cyan] = {v}")
             count += 1

def main():
    explorer = DSTExplorer()
    while True:
        console.print("\n[bold white on blue] 🦁 Wagstaff 探索面板 v3.1 [/bold white on blue]")
        console.print("1. [bold]📁 结构[/]  2. [bold]🔍 搜索[/]  3. [bold]👀 预览&分析[/]  4. [bold]🔢 数值[/]  0. [bold red]退出[/]")
        choice = IntPrompt.ask("选择", choices=["0","1","2","3","4"], default=1)
        if choice == 0: break
        elif choice == 1: console.print(explorer.get_structure_tree())
        elif choice == 2: explorer.search_files()
        elif choice == 3: explorer.preview_file()
        elif choice == 4: explorer.show_tuning()

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        console.print(f"[red]Error: {e}[/red]")
```

### File: apps/cli/commands/mgmt.py
- mode: full
- size_bytes: 8668
- sha256_12: 1037af5080dc

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Project management tools (docs + status sync)."""

from __future__ import annotations

import argparse
import json
import re
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from apps.cli.cli_common import PROJECT_ROOT, load_status

try:
    from rich.console import Console
    from rich.table import Table
except Exception:  # pragma: no cover
    Console = None
    Table = None


@dataclass
class Task:
    key: str
    desc: str


@dataclass
class Milestone:
    key: str
    title: str
    status: str


def _read_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8")
    except Exception:
        return ""


def _extract_section(text: str, heading_prefix: str) -> str:
    lines = text.splitlines()
    out: List[str] = []
    in_section = False
    for line in lines:
        if line.startswith(heading_prefix):
            if in_section:
                break
            in_section = True
            continue
        if in_section and line.startswith("## "):
            break
        if in_section:
            out.append(line)
    return "\n".join(out)


def _parse_tasks(text: str) -> List[Task]:
    section = _extract_section(text, "## 4.")
    tasks: List[Task] = []
    for line in section.splitlines():
        m = re.match(r"\s*-\s*\*\*(T-\d+)\*\*[：:]?\s*(.+)$", line.strip())
        if not m:
            continue
        key = m.group(1).strip()
        desc = m.group(2).strip()
        tasks.append(Task(key=key, desc=desc))
    return tasks


def _normalize_status(raw: str) -> str:
    r = (raw or "").strip().lower()
    if not r:
        return "unknown"
    if any(x in r for x in ("完成", "done", "complete")):
        return "done"
    if any(x in r for x in ("进行中", "in progress", "ongoing")):
        return "in_progress"
    if any(x in r for x in ("规划中", "planned", "plan")):
        return "planned"
    return r


def _parse_milestones(text: str) -> List[Milestone]:
    section = _extract_section(text, "## 2.")
    out: List[Milestone] = []
    for line in section.splitlines():
        m = re.match(r"\s*-\s*\*\*(M[0-9.]+)\s+([^*]+)\*\*（?([^）)]*)", line.strip())
        if not m:
            continue
        key = m.group(1).strip()
        title = m.group(2).strip()
        status = _normalize_status(m.group(3).strip())
        out.append(Milestone(key=key, title=title, status=status))
    return out


def _default_mgmt_path() -> Path:
    status = load_status()
    doc = status.get("MANAGEMENT_DOC")
    if isinstance(doc, str) and doc:
        return (PROJECT_ROOT / doc).resolve()
    return PROJECT_ROOT / "docs" / "management" / "PROJECT_MANAGEMENT.md"


def _render_status(tasks: List[Task], milestones: List[Milestone], doc_path: Path) -> None:
    if Console is None or Table is None:
        print(f"management: {doc_path}")
        print(f"milestones: {len(milestones)}")
        print(f"tasks: {len(tasks)}")
        for t in tasks:
            print(f"- {t.key} {t.desc}")
        return

    console = Console()
    console.print(f"[bold]Management Doc:[/bold] {doc_path}")

    counts = {"done": 0, "in_progress": 0, "planned": 0, "unknown": 0}
    for m in milestones:
        counts[m.status] = counts.get(m.status, 0) + 1

    table = Table(title="Milestones", box=None, show_header=True, header_style="bold cyan")
    table.add_column("Key", style="bold")
    table.add_column("Title")
    table.add_column("Status", style="green")
    for m in milestones:
        table.add_row(m.key, m.title, m.status)
    console.print(table)

    summary = f"done={counts.get('done',0)} in_progress={counts.get('in_progress',0)} planned={counts.get('planned',0)}"
    console.print(f"[dim]{summary}[/dim]")

    if tasks:
        console.print("[bold]Active Tasks[/bold]")
        for t in tasks:
            console.print(f"- {t.key}: {t.desc}")


def _sync_tasks(status_path: Path, tasks: List[Task], write: bool) -> int:
    status_doc = load_status()
    new_tasks = [f"{t.key}：{t.desc}" for t in tasks]

    old_tasks = status_doc.get("TASKS_TODO") if isinstance(status_doc, dict) else None
    old_tasks = list(old_tasks) if isinstance(old_tasks, list) else []

    if new_tasks == old_tasks:
        print("No changes.")
        return 0

    if not write:
        print("Pending TASKS_TODO update (dry-run):")
        print(json.dumps({"old": old_tasks, "new": new_tasks}, ensure_ascii=False, indent=2))
        return 0

    status_doc["TASKS_TODO"] = new_tasks
    logs = status_doc.get("RECENT_LOGS")
    if not isinstance(logs, list):
        logs = []
    stamp = datetime.now().strftime("%Y-%m-%d %H:%M")
    logs.append(f"[{stamp}] Mgmt: sync TASKS_TODO from PROJECT_MANAGEMENT.md")
    status_doc["RECENT_LOGS"] = logs

    status_path.write_text(json.dumps(status_doc, ensure_ascii=False, indent=2), encoding="utf-8")
    print("TASKS_TODO updated.")
    return 0


def _dump_json(tasks: List[Task], milestones: List[Milestone], doc_path: Path) -> None:
    payload = {
        "doc": str(doc_path),
        "milestones": [m.__dict__ for m in milestones],
        "tasks": [t.__dict__ for t in tasks],
    }
    print(json.dumps(payload, ensure_ascii=False, indent=2))


def _file_age_days(path: Path) -> Optional[int]:
    try:
        mtime = path.stat().st_mtime
    except Exception:
        return None
    delta = datetime.now() - datetime.fromtimestamp(mtime)
    return int(delta.total_seconds() // 86400)


def _check_dev_guide() -> int:
    guide_path = PROJECT_ROOT / "docs" / "guides" / "DEV_GUIDE.md"
    readme_path = PROJECT_ROOT / "README.md"
    mgmt_path = _default_mgmt_path()

    if not guide_path.exists():
        print(f"DEV_GUIDE missing: {guide_path}")
        return 2

    text = _read_text(guide_path)
    meta_ok = "DEV_GUIDE_META" in text
    age_days = _file_age_days(guide_path)
    age_note = f"{age_days}d" if age_days is not None else "unknown"
    age_ok = (age_days is None) or (age_days <= 30)

    readme_text = _read_text(readme_path)
    readme_ok = "DEV_GUIDE" in readme_text

    mgmt_ok = mgmt_path.exists()

    if Console is None or Table is None:
        print(f"DEV_GUIDE: {'OK' if meta_ok else 'WARN'} meta")
        print(f"DEV_GUIDE age: {age_note}")
        print(f"README mentions DEV_GUIDE: {readme_ok}")
        print(f"PROJECT_MANAGEMENT exists: {mgmt_ok}")
        return 0

    console = Console()
    table = Table(title="DEV_GUIDE Check", box=None, show_header=True, header_style="bold cyan")
    table.add_column("Check", style="bold")
    table.add_column("Status")
    table.add_column("Details", style="dim")
    table.add_row("dev_guide_meta", "[green]OK[/green]" if meta_ok else "[yellow]WARN[/yellow]", "DEV_GUIDE_META block")
    table.add_row("dev_guide_age", "[green]OK[/green]" if age_ok else "[yellow]WARN[/yellow]", f"mtime age {age_note}")
    table.add_row("readme_link", "[green]OK[/green]" if readme_ok else "[yellow]WARN[/yellow]", "README mentions DEV_GUIDE")
    table.add_row("mgmt_doc", "[green]OK[/green]" if mgmt_ok else "[yellow]WARN[/yellow]", str(mgmt_path))
    console.print(table)
    return 0


def main() -> int:
    p = argparse.ArgumentParser(description="Project management tools (docs + status sync)")
    p.add_argument("--doc", default=None, help="Override management doc path")

    sub = p.add_subparsers(dest="action", required=True)
    sub.add_parser("status", help="Show milestones + active tasks")
    p_sync = sub.add_parser("sync", help="Sync TASKS_TODO from management doc")
    p_sync.add_argument("--write", action="store_true", help="Write changes to PROJECT_STATUS.json")
    sub.add_parser("dump", help="Dump management doc as JSON")
    sub.add_parser("check", help="Check DEV_GUIDE emphasis + freshness")

    args = p.parse_args()

    doc_path = Path(args.doc).resolve() if args.doc else _default_mgmt_path()
    text = _read_text(doc_path)
    if not text:
        raise SystemExit(f"Management doc not found: {doc_path}")

    tasks = _parse_tasks(text)
    milestones = _parse_milestones(text)

    if args.action == "status":
        _render_status(tasks, milestones, doc_path)
        return 0
    if args.action == "sync":
        status_path = PROJECT_ROOT / "PROJECT_STATUS.json"
        return _sync_tasks(status_path, tasks, write=bool(args.write))
    if args.action == "dump":
        _dump_json(tasks, milestones, doc_path)
        return 0
    if args.action == "check":
        return _check_dev_guide()

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
```

### File: apps/cli/commands/server.py
- mode: full
- size_bytes: 209
- sha256_12: 6c94b0d9aa63

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""CLI entrypoint: server ops."""

from __future__ import annotations

from apps.server.cli import main


if __name__ == "__main__":
    raise SystemExit(main())
```

### File: apps/cli/commands/wiki.py
- mode: full
- size_bytes: 22253
- sha256_12: 7e3ee796673c

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""apps/cli/commands/wiki.py

CLI-oriented "wiki" front-end.

Notes
- This module is intentionally a thin UI layer.
- Core parsing/indexing lives in `engine.py`, `craft_recipes.py`, `analyzer.py`, etc.
"""

import math
import os
import re
import sys
from pathlib import Path
from typing import Dict

from rich.console import Console
from rich.panel import Panel
from rich.prompt import Prompt
from rich.table import Table
from rich.tree import Tree

from apps.cli.cli_common import PROJECT_ROOT
from core.engine import WagstaffEngine  # noqa: E402
from core.analyzer import LuaAnalyzer, LootParser  # noqa: E402

console = Console()


def _parse_inventory_spec(spec: str) -> Dict[str, float]:
    """Parse inventory spec into {item: count}.

    Accepted examples
    - "twigs=2,flint=1"
    - "twigs:2 flint:1"
    - "twigs flint" (defaults to 1)

    Non-numeric counts are ignored.
    """
    out: Dict[str, float] = {}
    if not spec:
        return out

    s = spec.strip()
    if not s:
        return out

    # Fast path: key=value / key:value pairs
    pairs = re.findall(r"([A-Za-z0-9_]+)\s*[:=]\s*([0-9]+(?:\.[0-9]+)?)", s)
    for k, v in pairs:
        try:
            out[k] = out.get(k, 0.0) + float(v)
        except Exception:
            pass

    if out:
        return out

    # Fallback: plain tokens => count=1
    tokens = re.split(r"[\s,]+", s)
    for t in tokens:
        t = (t or "").strip()
        if not t:
            continue
        out[t] = out.get(t, 0.0) + 1.0
    return out


class WagstaffWiki:
    def __init__(self):
        try:
            self.engine = WagstaffEngine(load_db=True)
        except Exception as e:
            console.print(f"[red]引擎初始化失败: {e}[/red]")
            sys.exit(1)

    def run(self, args):
        if not args:
            self._print_help()
            return

        command = args[0].lower()

        if command == "recipe":
            # Supported:
            #   wiki recipe <name>
            #   wiki recipe tab <TAB>
            #   wiki recipe filter <FILTER>
            #   wiki recipe who <BUILDER_TAG>
            #   wiki recipe tech <TECH>
            #   wiki recipe uses <ITEM>
            #   wiki recipe can <INV_SPEC>
            #   wiki recipe missing <RECIPE> <INV_SPEC>
            if len(args) >= 2 and args[1].lower() in ("tab", "filter", "who", "tech", "uses", "can", "missing", "tabs", "filters"):
                sub = args[1].lower()

                if sub == "tabs":
                    self._list_recipe_tabs()
                elif sub == "filters":
                    self._list_recipe_filters()
                elif sub == "missing":
                    if len(args) < 4:
                        return console.print("[red]用法: wiki recipe missing <recipe> <inv>[/red]")
                    recipe = args[2]
                    inv = _parse_inventory_spec(" ".join(args[3:]))
                    self._recipe_missing(recipe, inv)
                else:
                    if len(args) < 3:
                        return console.print("[red]缺少参数[/red]")
                    q = " ".join(args[2:])
                    if sub == "tab":
                        self._list_recipe_by_tab(q)
                    elif sub == "filter":
                        self._list_recipe_by_filter(q)
                    elif sub == "who":
                        self._list_recipe_by_builder_tag(q)
                    elif sub == "tech":
                        self._list_recipe_by_tech(q)
                    elif sub == "uses":
                        self._list_recipe_by_ingredient(q)
                    elif sub == "can":
                        inv = _parse_inventory_spec(q)
                        self._list_recipe_craftable(inv)
            else:
                q = args[1] if len(args) > 1 else None
                self._search_recipe(q)

        elif command in ("mob", "item"):
            q = args[1] if len(args) > 1 else None
            self._analyze_prefab(q)

        elif command == "loot":
            q = args[1] if len(args) > 1 else None
            self._find_loot_table(q)

        elif command == "food":
            # Minimal preparedfoods index
            #   wiki food <name>
            #   wiki food can <INV_SPEC>
            if len(args) >= 2 and args[1].lower() == "can":
                inv = _parse_inventory_spec(" ".join(args[2:]))
                self._list_food_cookable(inv)
            else:
                q = args[1] if len(args) > 1 else None
                self._show_food(q)

        elif command == "find":
            q = args[1] if len(args) > 1 else None
            self._global_search_interactive(q)

        else:
            self._print_help()

    def _print_help(self):
        console.print(
            Panel(
                """
[bold cyan]📖 Wagstaff Wiki v2.6 (Craft + Cooking)[/bold cyan]

[green]wagstaff wiki recipe <配方名/产物名>[/green]
[green]wagstaff wiki recipe tab <TAB>[/green]            按制作栏大类列出
[green]wagstaff wiki recipe filter <FILTER>[/green]      按筛选分类列出
[green]wagstaff wiki recipe who <TAG>[/green]            按角色专属列出 (builder_tag)
[green]wagstaff wiki recipe tech <TECH>[/green]          按科技需求列出
[green]wagstaff wiki recipe uses <ITEM>[/green]          反查：哪些配方需要该材料
[green]wagstaff wiki recipe can <INV>[/green]            给定材料，列出可制作配方
[green]wagstaff wiki recipe missing <R> <INV>[/green]    给定材料，查看缺少哪些
[green]wagstaff wiki recipe tabs[/green]                 查看 TAB 顺序
[green]wagstaff wiki recipe filters[/green]              查看 FILTER 定义(含icon字段)

[green]wagstaff wiki food <食谱名>[/green]                查询烹饪食谱(准备食物)
[green]wagstaff wiki food can <INV>[/green]              近似：按 card_ingredients 判断可做食谱

[green]wagstaff wiki mob <生物名>[/green]                查询生物/物品详情
[green]wagstaff wiki loot <表名>[/green]                 查询掉落表
[green]wagstaff wiki find <关键词>[/green]               交互式代码搜索

INV 格式例：twigs=2,flint=1  或  twigs:2 flint:1
""",
                title="Help",
                border_style="blue",
            )
        )

    # ---------- recipe detail ----------

    def _search_recipe(self, query):
        if not query:
            return console.print("[red]请输入配方名称[/red]")

        real_name, recipe_data = self.engine.recipes.get(query)  # type: ignore[union-attr]

        if not recipe_data:
            # fallback: 子串匹配
            db = self.engine.recipes  # type: ignore[assignment]
            candidates = [k for k in db.recipes.keys() if query in k]
            if not candidates:
                return console.print(f"[red]未找到配方: {query}[/red]")
            if len(candidates) > 1:
                console.print(f"[yellow]可能的匹配: {', '.join(candidates[:8])}...[/yellow]")
                return
            real_name, recipe_data = self.engine.recipes.get(candidates[0])  # type: ignore[union-attr]

        tab = str(recipe_data.get("tab", "UNKNOWN"))
        tech = str(recipe_data.get("tech", "UNKNOWN"))

        filters = recipe_data.get("filters") or []
        builder_tags = recipe_data.get("builder_tags") or ([] if recipe_data.get("builder_tag") is None else [recipe_data.get("builder_tag")])
        product = recipe_data.get("product") or None

        grid = Table.grid(expand=True)
        grid.add_column()
        grid.add_column(justify="right")

        grid.add_row(f"[bold gold1]{real_name.upper()}[/bold gold1]", f"[dim]{tab}[/dim]")
        grid.add_row(f"[bold]科技:[/bold] {tech}", "")

        if filters:
            grid.add_row(f"[bold]Filters:[/bold] {', '.join(filters)}", "")
        if builder_tags:
            grid.add_row(f"[bold]角色专属:[/bold] {', '.join([str(x) for x in builder_tags])}", "")
        if product:
            grid.add_row(f"[bold]产物:[/bold] {product}", "")

        grid.add_row("\n[bold]所需材料:[/bold]")
        for ing in recipe_data.get("ingredients", []):
            amt = ing.get("amount")
            grid.add_row(f"  • [cyan]{ing.get('item')}[/cyan]", f"[yellow]x{amt}[/yellow]")

        console.print(Panel(grid, title="🛠️  配方详情", border_style="gold1"))

    # ---------- recipe list ----------

    def _render_recipe_list(self, title: str, names):
        names = list(names or [])
        if not names:
            console.print(f"[yellow]无结果: {title}[/yellow]")
            return

        table = Table(title=f"{title} (共 {len(names)})", box=None, show_header=True, header_style="bold dim")
        table.add_column("No.", justify="right", style="dim", width=4)
        table.add_column("Recipe", style="cyan")
        table.add_column("Tab", style="dim")
        table.add_column("Tech", style="dim")

        # 只展示前 80 条，避免刷屏（后续可做交互分页）
        show = names[:80]
        for i, nm in enumerate(show, start=1):
            _, r = self.engine.recipes.get(nm)  # type: ignore[union-attr]
            tab = str((r or {}).get("tab", "UNKNOWN"))
            tech = str((r or {}).get("tech", "UNKNOWN"))
            table.add_row(str(i), nm, tab, tech)

        console.print(Panel(table, border_style="blue"))
        if len(names) > 80:
            console.print(f"[dim]... 其余 {len(names) - 80} 条未显示[/dim]")

    def _list_recipe_by_tab(self, tab):
        names = self.engine.recipes.list_by_tab(tab)  # type: ignore[union-attr]
        self._render_recipe_list(f"🧭 Tab = {tab}", names)

    def _list_recipe_by_filter(self, flt):
        names = self.engine.recipes.list_by_filter(flt)  # type: ignore[union-attr]
        self._render_recipe_list(f"🔎 Filter = {flt}", names)

    def _list_recipe_by_builder_tag(self, tag):
        names = self.engine.recipes.list_by_builder_tag(tag)  # type: ignore[union-attr]
        self._render_recipe_list(f"👤 builder_tag = {tag}", names)

    def _list_recipe_by_tech(self, tech):
        names = self.engine.recipes.list_by_tech(tech)  # type: ignore[union-attr]
        self._render_recipe_list(f"🧪 Tech = {tech}", names)

    def _list_recipe_tabs(self):
        db = self.engine.recipes  # type: ignore[assignment]
        if not db:
            return console.print("[red]recipes DB not loaded[/red]")

        rows = db.tab_order or sorted(db.by_tab.keys())
        table = Table(title=f"Craft Tabs ({len(rows)})", box=None, show_header=True, header_style="bold dim")
        table.add_column("No.", justify="right", style="dim", width=4)
        table.add_column("TAB", style="cyan")
        for i, t in enumerate(rows, start=1):
            table.add_row(str(i), str(t))
        console.print(Panel(table, border_style="blue"))

    def _list_recipe_filters(self):
        db = self.engine.recipes  # type: ignore[assignment]
        if not db:
            return console.print("[red]recipes DB not loaded[/red]")

        defs = db.filter_defs or []
        table = Table(title=f"Craft Filters ({len(defs)})", box=None, show_header=True, header_style="bold dim")
        table.add_column("No.", justify="right", style="dim", width=4)
        table.add_column("Name", style="cyan")
        table.add_column("Image", style="dim")
        table.add_column("Atlas", style="dim")

        for i, d in enumerate(defs, start=1):
            table.add_row(str(i), str(d.get("name")), str(d.get("image")), str(d.get("atlas")))

        console.print(Panel(table, border_style="blue"))

    def _list_recipe_by_ingredient(self, item: str):
        db = self.engine.recipes  # type: ignore[assignment]
        if not db:
            return console.print("[red]recipes DB not loaded[/red]")
        names = db.list_by_ingredient(item)
        self._render_recipe_list(f"🧱 Uses ingredient = {item}", names)

    def _list_recipe_craftable(self, inv: Dict[str, float]):
        db = self.engine.recipes  # type: ignore[assignment]
        if not db:
            return console.print("[red]recipes DB not loaded[/red]")

        names = db.craftable(inv)
        self._render_recipe_list("✅ Craftable recipes", names)

    def _recipe_missing(self, recipe: str, inv: Dict[str, float]):
        db = self.engine.recipes  # type: ignore[assignment]
        if not db:
            return console.print("[red]recipes DB not loaded[/red]")

        missing = db.missing_for(recipe, inv)
        if not missing:
            return console.print("[green]✅ 材料充足（或配方不存在/无材料）[/green]")

        table = Table(title=f"Missing for: {recipe}", box=None, show_header=True, header_style="bold dim")
        table.add_column("Item", style="cyan")
        table.add_column("Need", justify="right")
        table.add_column("Have", justify="right", style="dim")

        for row in missing:
            table.add_row(row["item"], str(row["need"]), str(row["have"]))

        console.print(Panel(table, border_style="red"))

    # ---------- cooking recipes ----------

    def _show_food(self, query: str):
        if not query:
            return console.print("[red]请输入食谱名[/red]")

        db = self.engine.cooking_recipes or {}
        if query not in db:
            # fuzzy contains
            cands = [k for k in db.keys() if query in k]
            if not cands:
                return console.print(f"[red]未找到食谱: {query}[/red]")
            if len(cands) > 1:
                console.print(f"[yellow]可能的匹配: {', '.join(cands[:10])}...[/yellow]")
                return
            query = cands[0]

        r = db.get(query, {})

        grid = Table.grid(expand=True)
        grid.add_column()
        grid.add_column(justify="right")

        grid.add_row(f"[bold gold1]{query.upper()}[/bold gold1]", str(r.get("foodtype", "")))

        for k in ("hunger", "health", "sanity", "perishtime", "cooktime", "priority", "weight"):
            if k in r:
                grid.add_row(f"[bold]{k}:[/bold] {r.get(k)}", "")

        tags = r.get("tags")
        if tags:
            grid.add_row(f"[bold]tags:[/bold] {tags}", "")

        card = r.get("card_ingredients") or []
        if card:
            grid.add_row("\n[bold]card_ingredients (近似用):[/bold]")
            for it, cnt in card:
                grid.add_row(f"  • [cyan]{it}[/cyan]", f"[yellow]x{cnt}[/yellow]")

        console.print(Panel(grid, title="🍲 食谱详情", border_style="gold1"))

    def _list_food_cookable(self, inv: Dict[str, float]):
        # NOTE: This is an approximation: uses card_ingredients as requirements.
        db = self.engine.cooking_recipes or {}
        if not db:
            return console.print("[yellow]未加载 cooking recipes[/yellow]")

        ok: List[str] = []
        for name, rec in db.items():
            req = rec.get("card_ingredients")
            if not req:
                continue
            good = True
            for it, cnt in req:
                try:
                    need = float(cnt)
                except Exception:
                    good = False
                    break
                have = float(inv.get(str(it), 0.0))
                if have + 1e-9 < need:
                    good = False
                    break
            if good:
                ok.append(name)

        ok = sorted(ok)
        table = Table(title=f"Cookable (approx) ({len(ok)})", box=None, show_header=True, header_style="bold dim")
        table.add_column("No.", justify="right", style="dim", width=4)
        table.add_column("Food", style="cyan")
        for i, nm in enumerate(ok[:120], start=1):
            table.add_row(str(i), nm)
        console.print(Panel(table, border_style="blue"))
        if len(ok) > 120:
            console.print(f"[dim]... 其余 {len(ok) - 120} 条未显示[/dim]")

    # ---------- prefab / loot / find (kept) ----------

    def _analyze_prefab(self, query):
        if not query:
            return console.print("[red]请输入名称[/red]")

        filepath = self.engine.find_file(query, fuzzy=True)
        if not filepath:
            return console.print(f"[red]未找到文件: {query}[/red]")

        content = self.engine.read_file(filepath)
        report = LuaAnalyzer(content).get_report()

        tree = Tree(f"🧬 [bold green]实体情报: {os.path.basename(filepath)}[/bold green]")
        tuning = self.engine.tuning

        if report.get("components"):
            comp_branch = tree.add("⚙️ 关键组件")
            for comp in report["components"]:
                c_name = comp["name"]
                has_content = comp.get("properties") or comp.get("methods")

                style = "bold yellow"
                if c_name in ["weapon", "health", "hunger", "sanity", "armor", "lootdropper"]:
                    style = "bold magenta"

                node_text = f"[{style}]{c_name}[/{style}]"

                if not has_content:
                    comp_branch.add(node_text)
                    continue

                comp_node = comp_branch.add(node_text)

                for prop in comp.get("properties", []):
                    val_text = tuning.enrich(prop) if tuning else prop
                    comp_node.add(f"[dim]•[/dim] {val_text}")

                for method in comp.get("methods", []):
                    val_text = tuning.enrich(method) if tuning else method
                    if any(k in method for k in ["SetDamage", "SetMaxHealth", "SetArmor"]):
                        comp_node.add(f"[bold green]ƒ {val_text}[/bold green]")
                    elif "SetChanceLootTable" in method or "SetSharedLootTable" in method:
                        comp_node.add(f"[bold red]ƒ {val_text}[/bold red]")
                    else:
                        comp_node.add(f"[dim]ƒ[/dim] {val_text}")

        console.print(Panel(tree, border_style="green"))
        console.print(
            "\n💡 提示: 若发现 [red]SetChanceLootTable('NAME')[/red]，\n"
            "请运行: [bold cyan]wagstaff wiki loot NAME[/bold cyan] 查看掉落率"
        )

    def _find_loot_table(self, query):
        if not query:
            return console.print("[red]请输入掉落表名称 (例如: krampus)[/red]")

        console.print(f"[dim]正在全库搜索掉落表: '{query}' ...[/dim]")
        pattern = re.compile(r"SetSharedLootTable\s*\(\s*[\'\"]" + re.escape(query) + r"[\'\"]")

        found = False
        for filepath in self.engine.file_list:
            if not filepath.endswith(".lua"):
                continue
            content = self.engine.read_file(filepath)
            if not content:
                continue

            if pattern.search(content):
                self._render_loot_table(filepath, query, content)
                found = True
                break

        if not found:
            console.print(f"[red]未找到掉落表定义: '{query}'[/red]")

    def _render_loot_table(self, filepath, table_name, content):
        console.print(f"[bold green]✅ 找到定义文件: {filepath}[/bold green]")
        parser = LootParser(content)
        data = parser.parse()

        if not data["entries"]:
            console.print("[yellow]解析器未能提取到具体物品项。[/yellow]")
            return

        table = Table(title=f"💰 掉落表: {table_name}", box=None)
        table.add_column("物品 (Prefab)", style="cyan")
        table.add_column("几率 / 权重", style="magenta")
        table.add_column("类型", style="dim")

        for entry in data["entries"]:
            val_str = ""
            if "chance" in entry:
                pct = entry["chance"] * 100
                val_str = f"{pct:.2f}%" if pct < 1 else f"{pct:.0f}%"
            elif "weight" in entry:
                val_str = f"权重 {entry['weight']}"

            table.add_row(entry["item"], val_str, entry["method"])

        console.print(Panel(table, border_style="gold1"))

    def _global_search_interactive(self, query):
        if not query:
            return console.print("[red]请输入搜索关键词[/red]")

        console.print(f"[bold cyan]🔍 正在扫描全库: '{query}' ...[/bold cyan]")

        matches = []
        for f in self.engine.file_list:
            content = self.engine.read_file(f)
            if content and query in content:
                matches.append(f)

        total_count = len(matches)
        if total_count == 0:
            return console.print("[yellow]❌ 无结果[/yellow]")

        page = 1
        per_page = 15
        total_pages = math.ceil(total_count / per_page)

        while True:
            console.clear()
            start_idx = (page - 1) * per_page
            end_idx = start_idx + per_page
            current_batch = matches[start_idx:end_idx]

            console.print(Panel(f"🔍 关键词: [bold green]{query}[/bold green] | 命中: {total_count} 文件", style="blue"))

            table = Table(box=None, show_header=True, header_style="bold dim")
            table.add_column("No.", justify="right", style="dim", width=4)
            table.add_column("文件路径", style="cyan")

            for i, f in enumerate(current_batch):
                idx = start_idx + i + 1
                dir_path, fname = os.path.split(f)
                display_path = f"{dir_path}/[bold white]{fname}[/bold white]"
                table.add_row(str(idx), display_path)

            console.print(table)
            status_color = "green" if page == total_pages else "yellow"
            console.print(f"\n[dim]📄 页码: [{status_color}]{page}/{total_pages}[/{status_color}][/dim]")
            console.print("[dim]操作: n 下一页 | p 上一页 | q 退出[/dim]")

            cmd = input("\n> ").strip().lower()
            if cmd == "q":
                break
            elif cmd == "n" and page < total_pages:
                page += 1
            elif cmd == "p" and page > 1:
                page -= 1


def main(argv=None):
    argv = argv or sys.argv[1:]
    WagstaffWiki().run(argv)


if __name__ == "__main__":
    main()
```

### File: apps/server/__init__.py
- mode: full
- size_bytes: 66
- sha256_12: 00130d1d4140

```py
# -*- coding: utf-8 -*-
"""Server management module (DST ops)."""
```

### File: apps/server/cli.py
- mode: full
- size_bytes: 4691
- sha256_12: 8e414946c537

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Server CLI entrypoint (no data analysis dependency)."""

from __future__ import annotations

import argparse
from pathlib import Path
from typing import Iterable, Optional

from apps.server.config import DEFAULT_CONFIG_PATH, resolve_config
from apps.server import manager
from apps.server.ui import run_ui


def _add_common_flags(p: argparse.ArgumentParser) -> None:
    p.add_argument("--config", default=str(DEFAULT_CONFIG_PATH), help="Path to conf/settings.ini")
    p.add_argument("--dst-root", default=None)
    p.add_argument("--steamcmd-dir", default=None)
    p.add_argument("--backup-dir", default=None)
    p.add_argument("--cluster-name", default=None)
    p.add_argument("--klei-home", default=None)


def main(argv: Optional[Iterable[str]] = None) -> int:
    parser = argparse.ArgumentParser(description="DST server management (screen-based)")
    sub = parser.add_subparsers(dest="action", required=True)

    p_status = sub.add_parser("status", help="Show server status")
    _add_common_flags(p_status)

    p_start = sub.add_parser("start", help="Start server")
    _add_common_flags(p_start)
    p_start.add_argument("--no-caves", action="store_true", help="Start Master only")

    p_stop = sub.add_parser("stop", help="Stop server")
    _add_common_flags(p_stop)
    p_stop.add_argument("--timeout", type=float, default=40.0)
    p_stop.add_argument("--force", action="store_true", help="Kill screen sessions if graceful stop times out")

    p_restart = sub.add_parser("restart", help="Restart server")
    _add_common_flags(p_restart)
    p_restart.add_argument("--no-caves", action="store_true")
    p_restart.add_argument("--update", action="store_true")

    p_update = sub.add_parser("update", help="Update DST via SteamCMD")
    _add_common_flags(p_update)

    p_backup = sub.add_parser("backup", help="Create backup tar.gz")
    _add_common_flags(p_backup)
    p_backup.add_argument("--out", default=None, help="Output tar.gz path")

    p_restore = sub.add_parser("restore", help="Restore from backup")
    _add_common_flags(p_restore)
    p_restore.add_argument("--file", default=None, help="Backup tar.gz path")
    p_restore.add_argument("--index", type=int, default=None, help="Backup index (newest=0)")
    p_restore.add_argument("--latest", action="store_true")
    p_restore.add_argument("--yes", action="store_true", help="Confirm destructive overwrite")
    p_restore.add_argument("--start", action="store_true", help="Start after restore")

    p_logs = sub.add_parser("logs", help="Tail server logs")
    _add_common_flags(p_logs)
    p_logs.add_argument("--shard", choices=["master", "caves"], default="master")
    p_logs.add_argument("--follow", action="store_true")
    p_logs.add_argument("--lines", type=int, default=120)

    p_cmd = sub.add_parser("cmd", help="Send console command")
    _add_common_flags(p_cmd)
    p_cmd.add_argument("--shard", choices=["master", "caves"], default="master")
    p_cmd.add_argument("cmd", help="Console command to send")

    p_ui = sub.add_parser("ui", help="Interactive server menu")
    _add_common_flags(p_ui)

    args = parser.parse_args(list(argv) if argv is not None else None)
    cfg = resolve_config(
        config_path=Path(args.config),
        dst_root=args.dst_root,
        steamcmd_dir=args.steamcmd_dir,
        backup_dir=args.backup_dir,
        cluster_name=args.cluster_name,
        klei_home=args.klei_home,
    )

    if args.action == "status":
        return manager.status(cfg)
    if args.action == "start":
        return manager.start(cfg, start_caves=not args.no_caves)
    if args.action == "stop":
        return manager.stop(cfg, timeout=args.timeout, force=args.force)
    if args.action == "restart":
        return manager.restart(cfg, start_caves=not args.no_caves, update=args.update)
    if args.action == "update":
        return manager.update_game(cfg)
    if args.action == "backup":
        out = Path(args.out) if args.out else None
        return manager.backup(cfg, out_path=out)
    if args.action == "restore":
        return manager.restore(
            cfg,
            file_path=Path(args.file) if args.file else None,
            index=args.index,
            latest=args.latest,
            yes=args.yes,
            start_after=args.start,
        )
    if args.action == "logs":
        return manager.logs(cfg, shard=args.shard, follow=args.follow, lines=args.lines)
    if args.action == "cmd":
        return manager.send_cmd(cfg, shard=args.shard, command=args.cmd)
    if args.action == "ui":
        return run_ui(cfg)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
```

### File: apps/server/config.py
- mode: full
- size_bytes: 2974
- sha256_12: 9ef01d91607b

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Server config loader (isolated from data analysis)."""

from __future__ import annotations

import configparser
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Optional


PROJECT_ROOT = Path(__file__).resolve().parents[2]
DEFAULT_CONFIG_PATH = PROJECT_ROOT / "conf" / "settings.ini"


@dataclass(frozen=True)
class ServerConfig:
    dst_root: Path
    steamcmd_dir: Optional[Path]
    backup_dir: Path
    cluster_name: str
    klei_home: Path

    @property
    def bin_dir(self) -> Path:
        return self.dst_root / "bin"

    @property
    def cluster_dir(self) -> Path:
        return self.klei_home / self.cluster_name

    @property
    def master_log(self) -> Path:
        return self.cluster_dir / "Master" / "server_log.txt"

    @property
    def caves_log(self) -> Path:
        return self.cluster_dir / "Caves" / "server_log.txt"


def _expand(val: Optional[str]) -> Optional[str]:
    if not val:
        return None
    return os.path.expanduser(val.strip())


def _cfg_get(cfg: configparser.ConfigParser, section: str, key: str) -> Optional[str]:
    try:
        val = cfg.get(section, key, fallback="").strip()
    except Exception:
        val = ""
    return _expand(val) if val else None


def load_ini(path: Path) -> configparser.ConfigParser:
    cfg = configparser.ConfigParser()
    if not path.exists():
        raise SystemExit(f"Missing config: {path}")
    cfg.read(path)
    return cfg


def resolve_config(
    *,
    config_path: Path = DEFAULT_CONFIG_PATH,
    dst_root: Optional[str] = None,
    steamcmd_dir: Optional[str] = None,
    backup_dir: Optional[str] = None,
    cluster_name: Optional[str] = None,
    klei_home: Optional[str] = None,
) -> ServerConfig:
    cfg = load_ini(config_path)

    dst_root = dst_root or os.environ.get("DST_ROOT") or _cfg_get(cfg, "PATHS", "DST_ROOT")
    steamcmd_dir = steamcmd_dir or os.environ.get("STEAMCMD_DIR") or _cfg_get(cfg, "PATHS", "STEAMCMD_DIR")
    backup_dir = backup_dir or os.environ.get("BACKUP_DIR") or _cfg_get(cfg, "PATHS", "BACKUP_DIR")
    cluster_name = cluster_name or os.environ.get("CLUSTER_NAME") or _cfg_get(cfg, "SERVER", "CLUSTER_NAME")
    klei_home = klei_home or os.environ.get("KLEI_HOME") or _cfg_get(cfg, "SERVER", "KLEI_HOME")

    if not dst_root:
        raise SystemExit("DST_ROOT missing (conf/settings.ini or --dst-root).")
    if not cluster_name:
        raise SystemExit("CLUSTER_NAME missing (conf/settings.ini or --cluster-name).")
    if not klei_home:
        raise SystemExit("KLEI_HOME missing (conf/settings.ini or --klei-home).")

    if not backup_dir:
        backup_dir = str(Path.home() / "dst_backups")

    return ServerConfig(
        dst_root=Path(dst_root),
        steamcmd_dir=Path(steamcmd_dir) if steamcmd_dir else None,
        backup_dir=Path(backup_dir),
        cluster_name=str(cluster_name),
        klei_home=Path(klei_home),
    )
```

### File: apps/server/manager.py
- mode: full
- size_bytes: 7508
- sha256_12: c7fa4e1b4e45

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Server operations (screen-based)."""

from __future__ import annotations

import os
import shutil
import subprocess
import tarfile
import time
from datetime import datetime
from pathlib import Path
from typing import Optional

from apps.server.config import ServerConfig


def _require_screen() -> None:
    if not shutil.which("screen"):
        raise SystemExit("screen not found (install screen to manage DST sessions).")


def _screen_list() -> str:
    r = subprocess.run(["screen", "-ls"], capture_output=True, text=True)
    return r.stdout or ""


def _screen_has(name: str) -> bool:
    return name in _screen_list()


def _send_screen_cmd(name: str, cmd: str) -> None:
    subprocess.run(["screen", "-S", name, "-p", "0", "-X", "stuff", f"{cmd}\015"], check=False)


def _quit_screen(name: str) -> None:
    subprocess.run(["screen", "-S", name, "-X", "quit"], check=False)


def _dst_env(cfg: ServerConfig) -> dict:
    env = os.environ.copy()
    bin_dir = cfg.bin_dir
    ld = env.get("LD_LIBRARY_PATH", "")
    env["LD_LIBRARY_PATH"] = f"{bin_dir}/lib32:{bin_dir}:{ld}"
    return env


def status(cfg: ServerConfig) -> int:
    master, caves = get_status(cfg)
    print(f"master: {'running' if master else 'stopped'}")
    print(f"caves:  {'running' if caves else 'stopped'}")
    return 0


def get_status(cfg: ServerConfig) -> tuple[bool, bool]:
    _require_screen()
    master = _screen_has("DST_Master")
    caves = _screen_has("DST_Caves")
    return master, caves


def start(cfg: ServerConfig, *, start_caves: bool = True) -> int:
    _require_screen()
    if _screen_has("DST_Master") or _screen_has("DST_Caves"):
        print("Server already running.")
        return 1

    bin_dir = cfg.bin_dir
    exe = bin_dir / "dontstarve_dedicated_server_nullrenderer"
    if not exe.exists():
        raise SystemExit(f"Missing server binary: {exe}")

    env = _dst_env(cfg)
    subprocess.run(
        ["screen", "-dmS", "DST_Master", "./dontstarve_dedicated_server_nullrenderer", "-console", "-cluster", cfg.cluster_name, "-shard", "Master"],
        cwd=bin_dir,
        env=env,
        check=False,
    )
    print("Master started.")

    if start_caves:
        subprocess.run(
            ["screen", "-dmS", "DST_Caves", "./dontstarve_dedicated_server_nullrenderer", "-console", "-cluster", cfg.cluster_name, "-shard", "Caves"],
            cwd=bin_dir,
            env=env,
            check=False,
        )
        print("Caves started.")
    return 0


def stop(cfg: ServerConfig, *, timeout: float = 40.0, force: bool = False) -> int:
    _require_screen()
    if not (_screen_has("DST_Master") or _screen_has("DST_Caves")):
        print("Server not running.")
        return 1

    for shard in ("DST_Master", "DST_Caves"):
        if _screen_has(shard):
            _send_screen_cmd(shard, "c_shutdown(true)")

    end_at = time.time() + timeout
    while time.time() < end_at:
        if not (_screen_has("DST_Master") or _screen_has("DST_Caves")):
            print("Server stopped.")
            return 0
        time.sleep(0.5)

    if force:
        for shard in ("DST_Master", "DST_Caves"):
            if _screen_has(shard):
                _quit_screen(shard)
        print("Server force-stopped.")
        return 0

    print("Timeout waiting for shutdown. Use --force to kill sessions.")
    return 2


def restart(cfg: ServerConfig, *, start_caves: bool = True, update: bool = False) -> int:
    stop(cfg, timeout=40.0, force=True)
    if update:
        update_game(cfg)
    return start(cfg, start_caves=start_caves)


def update_game(cfg: ServerConfig) -> int:
    if not cfg.steamcmd_dir:
        raise SystemExit("STEAMCMD_DIR missing (conf/settings.ini or --steamcmd-dir).")
    steamcmd = cfg.steamcmd_dir / "steamcmd.sh"
    if not steamcmd.exists():
        raise SystemExit(f"steamcmd.sh not found: {steamcmd}")

    subprocess.run(
        [
            str(steamcmd),
            "+force_install_dir",
            str(cfg.dst_root),
            "+login",
            "anonymous",
            "+app_update",
            "343050",
            "validate",
            "+quit",
        ],
        check=False,
    )
    print("Update completed.")
    return 0


def backup(cfg: ServerConfig, *, out_path: Optional[Path] = None) -> int:
    cfg.backup_dir.mkdir(parents=True, exist_ok=True)
    if not cfg.cluster_dir.exists():
        raise SystemExit(f"Cluster dir missing: {cfg.cluster_dir}")

    if out_path is None:
        stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        out_path = cfg.backup_dir / f"backup_{stamp}.tar.gz"

    with tarfile.open(out_path, "w:gz") as tar:
        tar.add(cfg.cluster_dir, arcname=cfg.cluster_name)
    print(f"Backup created: {out_path}")
    return 0


def _safe_delete_cluster(cfg: ServerConfig) -> None:
    target = cfg.cluster_dir.resolve()
    base = cfg.klei_home.resolve()

    if str(target) in ("/", str(Path.home()), str(base)):
        raise SystemExit(f"Refuse to delete unsafe path: {target}")
    if not str(target).startswith(str(base)):
        raise SystemExit("Cluster path is outside KLEI_HOME.")

    shutil.rmtree(target)


def _list_backups(cfg: ServerConfig) -> list[Path]:
    if not cfg.backup_dir.exists():
        return []
    backups = sorted(cfg.backup_dir.glob("*.tar.gz"), key=lambda p: p.stat().st_mtime, reverse=True)
    return backups


def list_backups(cfg: ServerConfig) -> list[Path]:
    return _list_backups(cfg)


def restore(
    cfg: ServerConfig,
    *,
    file_path: Optional[Path] = None,
    index: Optional[int] = None,
    latest: bool = False,
    yes: bool = False,
    start_after: bool = False,
) -> int:
    backups = _list_backups(cfg)
    if not backups:
        raise SystemExit(f"No backups found in {cfg.backup_dir}")

    chosen: Optional[Path] = None
    if file_path:
        chosen = Path(file_path)
    elif index is not None:
        if index < 0 or index >= len(backups):
            raise SystemExit("Backup index out of range.")
        chosen = backups[index]
    elif latest:
        chosen = backups[0]
    else:
        chosen = backups[0]

    if not chosen.exists():
        raise SystemExit(f"Backup not found: {chosen}")
    if not yes:
        raise SystemExit("Restore requires --yes to confirm destructive overwrite.")

    if _screen_has("DST_Master") or _screen_has("DST_Caves"):
        stop(cfg, timeout=40.0, force=True)

    if cfg.cluster_dir.exists():
        _safe_delete_cluster(cfg)

    with tarfile.open(chosen, "r:gz") as tar:
        tar.extractall(cfg.klei_home)
    print(f"Restore completed: {chosen}")

    if start_after:
        return start(cfg, start_caves=True)
    return 0


def logs(cfg: ServerConfig, *, shard: str = "master", follow: bool = False, lines: int = 120) -> int:
    log_path = cfg.master_log if shard == "master" else cfg.caves_log
    if not log_path.exists():
        raise SystemExit(f"Log not found: {log_path}")
    cmd = ["tail", "-n", str(lines), str(log_path)]
    if follow:
        cmd = ["tail", "-f", "-n", str(lines), str(log_path)]
    subprocess.run(cmd, check=False)
    return 0


def send_cmd(cfg: ServerConfig, *, shard: str = "master", command: str = "") -> int:
    _require_screen()
    target = "DST_Master" if shard == "master" else "DST_Caves"
    if not _screen_has(target):
        raise SystemExit(f"{target} is not running.")
    _send_screen_cmd(target, command)
    print("Command sent.")
    return 0
```

### File: apps/server/ui.py
- mode: full
- size_bytes: 39402
- sha256_12: 6786f4b8ce07

```py
# -*- coding: utf-8 -*-
"""Interactive server UI (menu-based)."""

from __future__ import annotations

import os
import re
import shutil
import sys
import unicodedata
from datetime import datetime
from pathlib import Path
from typing import Callable, Optional

from apps.server import manager
from apps.server.config import ServerConfig


LANG_DEFAULT = "zh"


def _supports_color() -> bool:
    if not sys.stdout.isatty():
        return False
    if os.environ.get("NO_COLOR"):
        return False
    term = os.environ.get("TERM", "")
    if term in ("", "dumb"):
        return False
    return True


class _Palette:
    def __init__(self, enabled: bool) -> None:
        if not enabled:
            self.reset = ""
            self.bold = ""
            self.dim = ""
            self.red = ""
            self.green = ""
            self.yellow = ""
            self.blue = ""
            self.cyan = ""
            self.white = ""
            self.black = ""
            self.bg_red = ""
            self.bg_green = ""
            self.bg_yellow = ""
            self.bg_blue = ""
            self.bg_cyan = ""
            return
        self.reset = "\033[0m"
        self.bold = "\033[1m"
        self.dim = "\033[2m"
        self.red = "\033[31m"
        self.green = "\033[32m"
        self.yellow = "\033[33m"
        self.blue = "\033[34m"
        self.cyan = "\033[36m"
        self.white = "\033[97m"
        self.black = "\033[30m"
        self.bg_red = "\033[41m"
        self.bg_green = "\033[42m"
        self.bg_yellow = "\033[43m"
        self.bg_blue = "\033[44m"
        self.bg_cyan = "\033[46m"


PALETTE = _Palette(_supports_color())


TEXT = {
    "title": {"zh": "Wagstaff-Lab 控制台", "en": "Wagstaff-Lab Control Center"},
    "box_status": {"zh": "状态监控", "en": "Status Monitor"},
    "box_paths": {"zh": "路径配置", "en": "Paths & Config"},
    "box_menu": {"zh": "功能菜单", "en": "Menu"},
    "status": {"zh": "状态", "en": "Status"},
    "master": {"zh": "地面", "en": "Master"},
    "caves": {"zh": "洞穴", "en": "Caves"},
    "running": {"zh": "运行中", "en": "RUNNING"},
    "stopped": {"zh": "未运行", "en": "STOPPED"},
    "unknown": {"zh": "未知", "en": "UNKNOWN"},
    "checks": {"zh": "检查", "en": "Checks"},
    "logs": {"zh": "日志", "en": "Logs"},
    "backups": {"zh": "备份", "en": "Backups"},
    "cluster_label": {"zh": "存档簇", "en": "Cluster"},
    "dst_label": {"zh": "DST目录", "en": "DST"},
    "klei_label": {"zh": "Klei目录", "en": "Klei"},
    "steam_label": {"zh": "Steam目录", "en": "Steam"},
    "backup_label": {"zh": "备份目录", "en": "Backup Dir"},
    "section_ops": {"zh": "运维管理", "en": "Server Ops"},
    "section_data": {"zh": "数据与工具", "en": "Data & Tools"},
    "menu_start": {"zh": "🚀 启动服务器", "en": "🚀 Start server"},
    "menu_stop": {"zh": "🛑 停止服务器", "en": "🛑 Stop server"},
    "menu_restart": {"zh": "🔄 重启服务器", "en": "🔄 Restart server"},
    "menu_update": {"zh": "⬇️ 更新版本", "en": "⬇️ Update game"},
    "menu_backup": {"zh": "💾 创建备份", "en": "💾 Backup"},
    "menu_restore": {"zh": "⏪ 恢复存档", "en": "⏪ Restore"},
    "menu_logs": {"zh": "📜 查看日志", "en": "📜 View logs"},
    "menu_console": {"zh": "🎮 控制台指令", "en": "🎮 Console shortcuts"},
    "menu_cmd": {"zh": "📡 发送指令", "en": "📡 Send command"},
    "menu_lang": {"zh": "🌐 切换语言", "en": "🌐 Language"},
    "menu_quit": {"zh": "🚪 退出", "en": "🚪 Quit"},
    "tip": {"zh": "回车刷新，或输入关键字/数字。", "en": "Press Enter to refresh; type keyword or number."},
    "prompt_select": {"zh": "选项", "en": "Select"},
    "prompt_shard": {"zh": "分片 (地面/洞穴)", "en": "Shard (master/caves)"},
    "prompt_timeout": {"zh": "超时时间 (秒)", "en": "Timeout (seconds)"},
    "prompt_force": {"zh": "超时后强制退出", "en": "Force kill if timeout"},
    "prompt_update_continue": {"zh": "服务器似乎在运行，继续更新？", "en": "Server appears running. Continue update"},
    "prompt_update_restart": {"zh": "重启前更新", "en": "Update before restart"},
    "prompt_start_caves": {"zh": "启动洞穴分片", "en": "Start caves shard"},
    "prompt_follow": {"zh": "持续跟随", "en": "Follow"},
    "prompt_lines": {"zh": "行数", "en": "Lines"},
    "prompt_backup_out": {"zh": "备份输出路径 (留空自动)", "en": "Backup output path (blank for auto)"},
    "prompt_restore_choose": {"zh": "选择备份序号/路径 (空取消, L=最新)", "en": "Choose backup index/path (blank to cancel, L=latest)"},
    "prompt_restore_start": {"zh": "恢复后启动服务器", "en": "Start server after restore"},
    "prompt_send_cmd": {"zh": "控制台指令", "en": "Console command"},
    "prompt_announce": {"zh": "公告内容", "en": "Announcement"},
    "prompt_regen_confirm": {"zh": "输入 YES 确认", "en": "Type YES to confirm"},
    "prompt_rollback_days": {"zh": "回滚天数", "en": "Rollback days"},
    "console_title": {"zh": "控制台指令中心", "en": "Console Command Center"},
    "console_save": {"zh": "💾 立即保存 (c_save)", "en": "💾 Save now (c_save)"},
    "console_rollback": {"zh": "⏪ 回滚 (c_rollback)", "en": "⏪ Rollback (c_rollback)"},
    "console_announce": {"zh": "📢 发送公告 (c_announce)", "en": "📢 Announce (c_announce)"},
    "console_regen": {"zh": "☠️  重置世界 (c_regenerateworld)", "en": "☠️  Regenerate world (c_regenerateworld)"},
    "console_players": {"zh": "👥 列出玩家 (c_listallplayers)", "en": "👥 List players (c_listallplayers)"},
    "console_back": {"zh": "🔙 返回", "en": "🔙 Back"},
    "msg_screen_missing": {"zh": "未找到 screen，请先安装。", "en": "screen not found. Install screen to manage DST sessions."},
    "msg_server_running": {"zh": "服务器已在运行。", "en": "Server already running."},
    "msg_server_not_running": {"zh": "服务器未运行。", "en": "Server not running."},
    "msg_steam_missing": {"zh": "未配置 SteamCMD (设置 STEAMCMD_DIR)。", "en": "SteamCMD not configured (set STEAMCMD_DIR)."},
    "msg_cluster_missing": {"zh": "存档目录不存在", "en": "Cluster dir missing"},
    "msg_backup_none": {"zh": "暂无备份。", "en": "No backups found."},
    "msg_backup_index_oob": {"zh": "备份序号超出范围。", "en": "Backup index out of range."},
    "msg_backup_not_found": {"zh": "备份不存在", "en": "Backup not found"},
    "msg_log_not_found": {"zh": "日志不存在", "en": "Log not found"},
    "msg_unknown": {"zh": "无效选项。", "en": "Unknown option."},
    "msg_enter_continue": {"zh": "按回车继续...", "en": "Press Enter to continue..."},
    "msg_enter_number": {"zh": "请输入数字。", "en": "Please enter a number."},
    "msg_enter_yn": {"zh": "请输入 y 或 n。", "en": "Please enter y or n."},
    "msg_restore_overwrite": {"zh": "恢复将覆盖以下目录：", "en": "Restore will overwrite:"},
    "msg_restore_confirm": {"zh": "输入 DELETE <path> 确认", "en": "Type DELETE <path> to confirm"},
    "backups_header": {"zh": "备份列表 (最新在前):", "en": "Backups (newest first):"},
    "backups_more": {"zh": "还有 {count} 个未显示", "en": "{count} more not shown"},
    "backup_latest": {"zh": "最新", "en": "latest"},
    "flag_ok": {"zh": "OK", "en": "OK"},
    "flag_missing": {"zh": "缺失", "en": "MISSING"},
    "flag_na": {"zh": "N/A", "en": "N/A"},
    "file_missing": {"zh": "缺失", "en": "missing"},
    "file_unknown": {"zh": "未知", "en": "unknown"},
    "result_ok": {"zh": "结果: 成功", "en": "Result: OK"},
    "result_exit": {"zh": "结果: exit={code}", "en": "Result: exit={code}"},
    "msg_interrupted": {"zh": "已中断。", "en": "Interrupted."},
}


def _t(key: str, lang: str) -> str:
    entry = TEXT.get(key) or {}
    if lang in entry:
        return entry[lang]
    if "en" in entry:
        return entry["en"]
    return key


_ANSI_RE = re.compile(r"\x1b\[[0-9;]*m")


def _strip_ansi(text: str) -> str:
    return _ANSI_RE.sub("", text or "")


def _display_width(text: str) -> int:
    width = 0
    for ch in _strip_ansi(text):
        if unicodedata.combining(ch):
            continue
        if unicodedata.east_asian_width(ch) in ("W", "F"):
            width += 2
        else:
            width += 1
    return width


def _pad(text: str, width: int) -> str:
    padding = width - _display_width(text)
    if padding <= 0:
        return text
    return text + (" " * padding)


def _two_col(
    items: list[str],
    width: int,
    *,
    sep_text: str = "  │  ",
    min_col_width: int = 18,
) -> list[str]:
    sep = _paint(sep_text, PALETTE.dim)
    col_width = max(min_col_width, (width - _display_width(sep_text)) // 2)
    lines: list[str] = []
    for i in range(0, len(items), 2):
        left = items[i]
        right = items[i + 1] if i + 1 < len(items) else ""
        if right:
            line = _pad(left, col_width) + sep + right
        else:
            line = left
        lines.append(line.rstrip())
    return lines


def _lang_label(lang: str) -> str:
    return "中文" if lang == "zh" else "EN"


def _compose_title_line(width: int, lang: str, *, context: str = "") -> str:
    left = f"🦅 {_t('title', lang)}"
    ctx = str(context or "").strip()
    if ctx:
        left = f"{left} {_paint('·', PALETTE.dim)} {_paint(ctx, PALETTE.dim)}"
    right = f"🌐 {_lang_label(lang)}"
    gap = width - _display_width(left) - _display_width(right)
    if gap < 2:
        return left
    return left + (" " * gap) + right


def _kv_line(label: str, value: str, label_width: int) -> str:
    return f"{_pad(label, label_width)}: {value}"


def _truncate(text: str, max_width: int) -> str:
    if max_width <= 0:
        return ""
    if _display_width(text) <= max_width:
        return text
    if max_width == 1:
        return "…"

    limit = max_width - 1
    out: list[str] = []
    w = 0
    i = 0
    n = len(text)
    while i < n and w < limit:
        if text[i] == "\x1b" and i + 1 < n and text[i + 1] == "[":
            end = text.find("m", i)
            if end == -1:
                break
            out.append(text[i : end + 1])
            i = end + 1
            continue

        ch = text[i]
        i += 1
        if unicodedata.combining(ch):
            out.append(ch)
            continue
        cw = 2 if unicodedata.east_asian_width(ch) in ("W", "F") else 1
        if w + cw > limit:
            break
        out.append(ch)
        w += cw

    out.append("…")
    if PALETTE.reset:
        out.append(PALETTE.reset)
    return "".join(out)


def _divider_line(inner_width: int) -> str:
    return "─" * max(0, inner_width)


def _shorten_path(text: str, max_width: int) -> str:
    if max_width <= 0:
        return ""
    if _display_width(text) <= max_width:
        return text
    if max_width == 1:
        return "…"

    home = str(Path.home())
    if home and text.startswith(home):
        suffix = text[len(home) :]
        if not suffix or suffix.startswith(("/", "\\")):
            text = "~" + suffix

    sep = "/" if "/" in text else ("\\" if "\\" in text else os.sep)
    parts = [part for part in re.split(r"[\\/]+", text) if part]
    if not parts:
        return _truncate(text, max_width)

    has_tilde = text.startswith("~")
    tail = parts[-1]
    idx = len(parts) - 2
    while idx >= 0:
        candidate = parts[idx] + sep + tail
        if _display_width(f"…{sep}{candidate}") > max_width:
            break
        tail = candidate
        idx -= 1

    out = f"…{sep}{tail}"
    if has_tilde and not tail.startswith("~"):
        prefixed = f"~{sep}{out}"
        if _display_width(prefixed) <= max_width:
            out = prefixed
    if _display_width(out) > max_width:
        return _truncate(out, max_width)
    return out


def _fit_value(value: str, max_width: int) -> str:
    if max_width <= 0:
        return ""
    raw = str(value or "")
    if "/" in raw or "\\" in raw:
        return _shorten_path(raw, max_width)
    return _truncate(raw, max_width)


def _box_lines(title: str, lines: list[str], width: int, *, dim_body: bool = False) -> list[str]:
    width = max(40, width)
    inner = width - 2

    title_text = f" {title} "
    title_text = _truncate(title_text, inner)
    title_w = _display_width(title_text)
    top = "┌" + title_text + ("─" * max(0, inner - title_w)) + "┐"
    bottom = "└" + ("─" * inner) + "┘"

    border_style = (PALETTE.cyan + PALETTE.dim) if PALETTE.cyan else ""
    title_style = PALETTE.bold
    body_style = PALETTE.dim if dim_body else ""

    out: list[str] = []
    out.append(_paint(top, border_style, title_style))
    for raw in lines:
        line = _truncate(raw, inner)
        line = _pad(line, inner)
        if body_style:
            line = _paint(line, body_style)
        out.append(_paint("│", border_style) + line + _paint("│", border_style))
    out.append(_paint(bottom, border_style))
    return out


def _box(title: str, lines: list[str], width: int, *, dim_body: bool = False) -> None:
    for line in _box_lines(title, lines, width, dim_body=dim_body):
        print(line)


def _pill(text: str, *, fg: str, bg: str, fallback: str) -> str:
    if not PALETTE.reset:
        return fallback
    return _paint(f" {text} ", PALETTE.bold, fg, bg)


def _paint(text: str, *styles: str) -> str:
    if not any(styles):
        return text
    return "".join(styles) + text + PALETTE.reset


def _term_width(default: int = 80) -> int:
    try:
        width = shutil.get_terminal_size((default, 20)).columns
    except Exception:
        return default
    return max(60, min(120, width))


def _vstack(blocks: list[list[str]], *, gap: int = 1) -> list[str]:
    out: list[str] = []
    for idx, block in enumerate(blocks):
        if idx and gap:
            out.extend([""] * gap)
        out.extend(block)
    return out


def _hstack(
    left: list[str],
    right: list[str],
    *,
    left_width: int,
    right_width: int,
    gap: int = 2,
) -> list[str]:
    gap_text = " " * max(0, int(gap))
    blank_left = " " * max(0, left_width)
    blank_right = " " * max(0, right_width)
    height = max(len(left), len(right))
    out: list[str] = []
    for i in range(height):
        l = left[i] if i < len(left) else blank_left
        r = right[i] if i < len(right) else blank_right
        out.append(_pad(l, left_width) + gap_text + r)
    return out


def _sidebar_layout(width: int) -> Optional[tuple[int, int, int]]:
    gap = 2
    min_sidebar = 32
    max_sidebar = 48
    sidebar = min(max_sidebar, max(min_sidebar, width // 3))
    main_min = 58
    if width >= (main_min + gap + sidebar):
        return (width - gap - sidebar, sidebar, gap)
    return None


def _clear() -> None:
    if not sys.stdout.isatty():
        return
    try:
        os.system("cls" if os.name == "nt" else "clear")
    except Exception:
        pass


def _prompt(text: str, *, default: Optional[str] = None) -> str:
    suffix = f" [{default}]" if default else ""
    try:
        raw = input(f"{text}{suffix}: ").strip()
    except (KeyboardInterrupt, EOFError):
        print("")
        return default or ""
    return raw if raw else (default or "")


def _prompt_bool(text: str, *, default: bool = False, lang: str = LANG_DEFAULT) -> bool:
    hint = "Y/n" if default else "y/N"
    while True:
        raw = input(f"{text} [{hint}]: ").strip().lower()
        if not raw:
            return default
        if raw in ("y", "yes"):
            return True
        if raw in ("n", "no"):
            return False
        print(_t("msg_enter_yn", lang))


def _prompt_int(text: str, *, default: int, lang: str = LANG_DEFAULT) -> int:
    while True:
        raw = _prompt(text, default=str(default))
        try:
            return int(raw)
        except ValueError:
            print(_t("msg_enter_number", lang))


def _prompt_float(text: str, *, default: float, lang: str = LANG_DEFAULT) -> float:
    while True:
        raw = _prompt(text, default=str(default))
        try:
            return float(raw)
        except ValueError:
            print(_t("msg_enter_number", lang))


def _prompt_path(text: str, *, default: Optional[str] = None) -> Optional[Path]:
    raw = _prompt(text, default=default)
    if not raw:
        return None
    return Path(raw).expanduser()


def _pause(lang: str = LANG_DEFAULT) -> None:
    try:
        input(f"\n{_t('msg_enter_continue', lang)}")
    except (KeyboardInterrupt, EOFError):
        print("")


def _format_bytes(size: int) -> str:
    value = float(size)
    for unit in ("B", "KB", "MB", "GB", "TB"):
        if value < 1024.0 or unit == "TB":
            if unit == "B":
                return f"{int(value)}{unit}"
            return f"{value:.1f}{unit}"
        value /= 1024.0
    return f"{value:.1f}PB"


def _format_time(ts: float) -> str:
    return datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M")


def _path_exists(path: Optional[Path]) -> Optional[bool]:
    if path is None:
        return None
    try:
        return path.exists()
    except Exception:
        return None


def _flag(ok: Optional[bool], lang: str) -> str:
    if ok is True:
        return _paint(_t("flag_ok", lang), PALETTE.dim)
    if ok is False:
        return _paint(_t("flag_missing", lang), PALETTE.red)
    return _paint(_t("flag_na", lang), PALETTE.dim)


def _check_item(label: str, ok: Optional[bool], lang: str) -> str:
    return f"{_paint(label, PALETTE.dim)} {_flag(ok, lang)}"


def _file_brief(path: Path, lang: str) -> str:
    try:
        if not path.exists():
            return _paint(_t("file_missing", lang), PALETTE.red)
        stat = path.stat()
        return f"{_format_bytes(stat.st_size)} @ {_format_time(stat.st_mtime)}"
    except Exception:
        return _paint(_t("file_unknown", lang), PALETTE.dim)


def _backup_brief(cfg: ServerConfig, lang: str) -> str:
    backups = manager.list_backups(cfg)
    if not backups:
        return _t("msg_backup_none", lang)
    latest = backups[0]
    size = "-"
    stamp = "-"
    try:
        stat = latest.stat()
        size = _format_bytes(stat.st_size)
        stamp = _format_time(stat.st_mtime)
    except Exception:
        pass
    return f"{len(backups)} ({_t('backup_latest', lang)} {latest.name} {size} {stamp})"


def _ensure_screen(lang: str) -> bool:
    if shutil.which("screen"):
        return True
    print(_paint(_t("msg_screen_missing", lang), PALETTE.red))
    return False


def _run_action(label: str, fn: Callable[[], int], lang: str) -> None:
    print(f"\n[{label}]")
    try:
        code = fn()
    except KeyboardInterrupt:
        print(f"\n{_t('msg_interrupted', lang)}")
        return
    except SystemExit as exc:
        msg = str(exc)
        if msg:
            print(msg)
        return
    except Exception as exc:
        print(f"Error: {exc}")
        return
    if isinstance(code, int):
        if code == 0:
            print(_paint(_t("result_ok", lang), PALETTE.green))
        else:
            msg = _t("result_exit", lang).format(code=code)
            print(_paint(msg, PALETTE.yellow))


def _choose_shard(lang: str) -> str:
    default = "地面" if lang == "zh" else "master"
    raw = _prompt(_t("prompt_shard", lang), default=default).strip().lower()
    if raw in ("c", "cave", "caves", "洞", "洞穴"):
        return "caves"
    if raw in ("m", "master", "地面", "主"):
        return "master"
    return "caves" if raw.startswith("c") or "洞" in raw else "master"


def _get_status(cfg: ServerConfig) -> tuple[Optional[bool], Optional[bool], Optional[str]]:
    try:
        master, caves = manager.get_status(cfg)
        return master, caves, None
    except SystemExit as exc:
        msg = str(exc) or "screen not available"
        return None, None, msg
    except Exception as exc:
        return None, None, f"status error: {exc}"


def _status_label(running: Optional[bool], lang: str) -> str:
    if running is True:
        label = _t("running", lang)
        return _pill(label, fg=PALETTE.black, bg=PALETTE.bg_green, fallback=f"🟢 {label}")
    if running is False:
        label = _t("stopped", lang)
        return _pill(label, fg=PALETTE.white, bg=PALETTE.bg_red, fallback=f"🔴 {label}")
    label = _t("unknown", lang)
    return _pill(label, fg=PALETTE.black, bg=PALETTE.bg_yellow, fallback=f"🟡 {label}")


def _status_line(cfg: ServerConfig, lang: str) -> str:
    master, caves, err = _get_status(cfg)
    if err:
        return _paint(err, PALETTE.yellow)
    return (
        f"{_t('master', lang)}: {_status_label(master, lang)} | "
        f"{_t('caves', lang)}: {_status_label(caves, lang)}"
    )


def _is_running(cfg: ServerConfig) -> Optional[bool]:
    master, caves, err = _get_status(cfg)
    if err:
        return None
    return bool(master or caves)


def _build_status_box(cfg: ServerConfig, lang: str, width: int) -> list[str]:
    screen_ok = shutil.which("screen") is not None
    bin_ok = _path_exists(cfg.bin_dir / "dontstarve_dedicated_server_nullrenderer")
    cluster_ok = _path_exists(cfg.cluster_dir)
    steam_path = cfg.steamcmd_dir / "steamcmd.sh" if cfg.steamcmd_dir else None
    steam_ok = _path_exists(steam_path) if steam_path else None

    master, caves, err = _get_status(cfg)

    inner = max(40, width) - 2
    check_items = [
        _check_item("Screen", screen_ok, lang),
        _check_item("Binary", bin_ok, lang),
        _check_item("Cluster", cluster_ok, lang),
        _check_item("SteamCMD", steam_ok, lang),
    ]
    checks = _two_col(check_items, inner, sep_text="  ·  ", min_col_width=16)

    status_rows = [
        (_t("master", lang), _status_label(master, lang)),
        (_t("caves", lang), _status_label(caves, lang)),
        (f"📜 {_t('logs', lang)}", f"master={_file_brief(cfg.master_log, lang)} · caves={_file_brief(cfg.caves_log, lang)}"),
        (f"💾 {_t('backups', lang)}", _backup_brief(cfg, lang)),
    ]
    s_label_w = max(_display_width(label) for label, _ in status_rows)
    status_lines = [
        _kv_line(status_rows[0][0], status_rows[0][1], s_label_w),
        _kv_line(status_rows[1][0], status_rows[1][1], s_label_w),
        _paint(_divider_line(inner), PALETTE.dim),
        _paint(f"🔎 {_t('checks', lang)}", PALETTE.bold),
        *checks,
        _paint(_divider_line(inner), PALETTE.dim),
        _kv_line(status_rows[2][0], status_rows[2][1], s_label_w),
        _kv_line(status_rows[3][0], status_rows[3][1], s_label_w),
    ]
    if err:
        status_lines.append(_paint(f"! {err}", PALETTE.red))

    return _box_lines(f"📡 {_t('box_status', lang)}", status_lines, width)


def _build_paths_box(cfg: ServerConfig, lang: str, width: int) -> list[str]:
    path_rows = [
        (_t("cluster_label", lang), str(cfg.cluster_name)),
        (_t("dst_label", lang), str(cfg.dst_root)),
        (_t("klei_label", lang), str(cfg.klei_home)),
        (_t("steam_label", lang), str(cfg.steamcmd_dir or "(not set)")),
        (_t("backup_label", lang), str(cfg.backup_dir)),
    ]
    inner = max(40, width) - 2
    p_label_w = max(_display_width(label) for label, _ in path_rows)
    value_max = inner - p_label_w - 2
    path_lines = [
        _kv_line(label, _fit_value(value, value_max), p_label_w)
        for label, value in path_rows
    ]
    return _box_lines(f"🧭 {_t('box_paths', lang)}", path_lines, width, dim_body=True)


def _format_entry(key: str, label: str) -> str:
    k = str(key or "").strip()
    if not k:
        return str(label)
    if not k.startswith("["):
        k = f"[{k}]"
    return f"{k} {label}"


def _build_main_menu_box(lang: str, width: int) -> list[str]:
    inner = max(10, width - 2)
    ops = [
        _format_entry("1", _t("menu_start", lang)),
        _format_entry("2", _t("menu_stop", lang)),
        _format_entry("3", _t("menu_restart", lang)),
        _format_entry("4", _t("menu_update", lang)),
    ]
    data = [
        _format_entry("5", _t("menu_backup", lang)),
        _format_entry("6", _t("menu_restore", lang)),
        _format_entry("7", _t("menu_logs", lang)),
        _format_entry("8", _t("menu_console", lang)),
        _format_entry("9", _t("menu_cmd", lang)),
        _format_entry("L", _t("menu_lang", lang)),
        _format_entry("0", _t("menu_quit", lang)),
    ]

    lines: list[str] = []
    lines.append(_paint(_t("section_ops", lang), PALETTE.bold))
    lines.append(_paint(_divider_line(inner), PALETTE.dim))
    lines.extend(_two_col(ops, inner))
    lines.append("")
    lines.append(_paint(_t("section_data", lang), PALETTE.bold))
    lines.append(_paint(_divider_line(inner), PALETTE.dim))
    lines.extend(_two_col(data, inner))
    lines.append(_paint(_divider_line(inner), PALETTE.dim))
    lines.append(_paint(_t("tip", lang), PALETTE.dim))
    return _box_lines(f"🧰 {_t('box_menu', lang)}", lines, width)


def _render_main_screen(cfg: ServerConfig, lang: str) -> None:
    _clear()
    width = _term_width()
    print(_paint(_compose_title_line(width, lang), PALETTE.bold))
    print("")

    layout = _sidebar_layout(width)
    if layout:
        main_w, side_w, gap = layout
        status_box = _build_status_box(cfg, lang, main_w)
        menu_box = _build_main_menu_box(lang, main_w)
        paths_box = _build_paths_box(cfg, lang, side_w)
        left_col = _vstack([status_box, menu_box], gap=1)
        for line in _hstack(left_col, paths_box, left_width=main_w, right_width=side_w, gap=gap):
            print(line)
        return

    status_box = _build_status_box(cfg, lang, width)
    menu_box = _build_main_menu_box(lang, width)
    paths_box = _build_paths_box(cfg, lang, width)
    for line in _vstack([status_box, menu_box, paths_box], gap=1):
        print(line)


def _build_console_menu_box(lang: str, width: int) -> list[str]:
    inner = max(10, width - 2)
    options = [
        _format_entry("1", _t("console_save", lang)),
        _format_entry("2", _t("console_rollback", lang)),
        _format_entry("3", _t("console_announce", lang)),
        _format_entry("4", _t("console_regen", lang)),
        _format_entry("5", _t("console_players", lang)),
        _format_entry("L", _t("menu_lang", lang)),
        _format_entry("0", _t("console_back", lang)),
    ]
    lines: list[str] = []
    lines.extend(_two_col(options, inner))
    lines.append(_paint(_divider_line(inner), PALETTE.dim))
    lines.append(_paint(_t("tip", lang), PALETTE.dim))
    return _box_lines(f"🎮 {_t('console_title', lang)}", lines, width)


def _render_console_screen(cfg: ServerConfig, lang: str) -> None:
    _clear()
    width = _term_width()
    print(_paint(_compose_title_line(width, lang, context=_t("menu_console", lang)), PALETTE.bold))
    print("")

    layout = _sidebar_layout(width)
    if layout:
        main_w, side_w, gap = layout
        status_box = _build_status_box(cfg, lang, main_w)
        menu_box = _build_console_menu_box(lang, main_w)
        paths_box = _build_paths_box(cfg, lang, side_w)
        left_col = _vstack([status_box, menu_box], gap=1)
        for line in _hstack(left_col, paths_box, left_width=main_w, right_width=side_w, gap=gap):
            print(line)
        return

    status_box = _build_status_box(cfg, lang, width)
    menu_box = _build_console_menu_box(lang, width)
    paths_box = _build_paths_box(cfg, lang, width)
    for line in _vstack([status_box, menu_box, paths_box], gap=1):
        print(line)


def _console_menu(cfg: ServerConfig, lang: str) -> str:
    cur = lang
    while True:
        if not _ensure_screen(cur):
            _pause(cur)
            return cur
        _render_console_screen(cfg, cur)

        choice = _prompt(_t("prompt_select", cur), default="").strip().lower()
        if not choice:
            continue

        if choice in ("0", "back", "b", "返回"):
            return cur
        if choice in ("l", "lang", "language", "语言", "切换"):
            cur = "en" if cur == "zh" else "zh"
            continue

        if choice == "1":
            _run_action("Save", lambda: manager.send_cmd(cfg, shard="master", command="c_save()"), cur)
            _pause(cur)
            continue
        if choice == "2":
            days = _prompt_int(_t("prompt_rollback_days", cur), default=1, lang=cur)
            _run_action("Rollback", lambda: manager.send_cmd(cfg, shard="master", command=f"c_rollback({days})"), cur)
            _pause(cur)
            continue
        if choice == "3":
            msg = _prompt(_t("prompt_announce", cur), default="")
            if not msg:
                continue
            msg = msg.replace('"', '\\"')
            _run_action("Announce", lambda: manager.send_cmd(cfg, shard="master", command=f'c_announce("{msg}")'), cur)
            _pause(cur)
            continue
        if choice == "4":
            confirm = _prompt(_t("prompt_regen_confirm", cur), default="")
            if confirm != "YES":
                continue
            _run_action("Regenerate", lambda: manager.send_cmd(cfg, shard="master", command="c_regenerateworld()"), cur)
            _pause(cur)
            continue
        if choice == "5":
            _run_action("Players", lambda: manager.send_cmd(cfg, shard="master", command="c_listallplayers()"), cur)
            _pause(cur)
            continue

        print(_t("msg_unknown", cur))
        _pause(cur)


def _build_restore_box(backups: list[Path], lang: str, width: int, *, limit: int = 10) -> list[str]:
    inner = max(40, width) - 2
    lines: list[str] = []
    lines.append(_paint(_t("backups_header", lang), PALETTE.bold))
    lines.append(_paint(_divider_line(inner), PALETTE.dim))
    for idx, path in enumerate(backups[:limit]):
        size = "-"
        stamp = "-"
        try:
            stat = path.stat()
            size = _format_bytes(stat.st_size)
            stamp = _format_time(stat.st_mtime)
        except Exception:
            pass
        lines.append(f"[{idx}] {path.name}  {size}  {stamp}")
    if len(backups) > limit:
        msg = _t("backups_more", lang).format(count=len(backups) - limit)
        lines.append(_paint(f"... {msg}", PALETTE.dim))
    lines.append(_paint(_divider_line(inner), PALETTE.dim))
    lines.append(_paint(_t("prompt_restore_choose", lang), PALETTE.dim))
    return _box_lines(_t("menu_restore", lang), lines, width)


def _render_restore_screen(cfg: ServerConfig, lang: str, backups: list[Path]) -> None:
    _clear()
    width = _term_width()
    print(_paint(_compose_title_line(width, lang, context=_t("menu_restore", lang)), PALETTE.bold))
    print("")

    layout = _sidebar_layout(width)
    if layout:
        main_w, side_w, gap = layout
        main_box = _build_restore_box(backups, lang, main_w)
        side_col = _vstack([_build_status_box(cfg, lang, side_w), _build_paths_box(cfg, lang, side_w)], gap=1)
        for line in _hstack(main_box, side_col, left_width=main_w, right_width=side_w, gap=gap):
            print(line)
        return

    status_box = _build_status_box(cfg, lang, width)
    restore_box = _build_restore_box(backups, lang, width)
    paths_box = _build_paths_box(cfg, lang, width)
    for line in _vstack([status_box, restore_box, paths_box], gap=1):
        print(line)


def _confirm_restore_target(cfg: ServerConfig, lang: str, *, selected_backup: Optional[Path] = None) -> bool:
    try:
        target = cfg.cluster_dir.resolve()
    except Exception:
        target = cfg.cluster_dir

    lines: list[str] = []
    lines.append(_paint(_t("msg_restore_overwrite", lang), PALETTE.bold))
    lines.append(f"  {target}")
    if selected_backup is not None:
        lines.append("")
        lines.append(_paint(f"Backup: {selected_backup.name}", PALETTE.dim))
    lines.append("")
    lines.append(_paint(_t("msg_restore_confirm", lang), PALETTE.dim))

    _clear()
    width = _term_width()
    print(_paint(_compose_title_line(width, lang, context=_t("menu_restore", lang)), PALETTE.bold))
    print("")

    layout = _sidebar_layout(width)
    if layout:
        main_w, side_w, gap = layout
        confirm_box = _box_lines("⚠️ Confirm", lines, main_w)
        side_col = _vstack([_build_status_box(cfg, lang, side_w), _build_paths_box(cfg, lang, side_w)], gap=1)
        for line in _hstack(confirm_box, side_col, left_width=main_w, right_width=side_w, gap=gap):
            print(line)
    else:
        status_box = _build_status_box(cfg, lang, width)
        confirm_box = _box_lines("⚠️ Confirm", lines, width)
        paths_box = _build_paths_box(cfg, lang, width)
        for line in _vstack([status_box, confirm_box, paths_box], gap=1):
            print(line)

    confirm = _prompt(_t("msg_restore_confirm", lang), default="")
    return confirm == f"DELETE {target}"


def run_ui(cfg: ServerConfig) -> int:
    lang = LANG_DEFAULT
    while True:
        _render_main_screen(cfg, lang)
        choice = _prompt(_t("prompt_select", lang), default="").strip().lower()
        if not choice:
            continue

        if choice in ("r", "refresh", "刷新"):
            continue

        if choice in ("0", "q", "quit", "exit", "退出"):
            return 0

        if choice in ("l", "lang", "language", "语言", "切换"):
            lang = "en" if lang == "zh" else "zh"
            continue

        if choice in ("1", "start", "启动", "开服"):
            if not _ensure_screen(lang):
                _pause(lang)
                continue
            if _is_running(cfg) is True:
                print(_t("msg_server_running", lang))
                _pause(lang)
                continue
            start_caves = _prompt_bool(_t("prompt_start_caves", lang), default=True, lang=lang)
            _run_action("Start", lambda: manager.start(cfg, start_caves=start_caves), lang)
            _pause(lang)
            continue

        if choice in ("2", "stop", "停止", "停服"):
            if not _ensure_screen(lang):
                _pause(lang)
                continue
            if _is_running(cfg) is False:
                print(_t("msg_server_not_running", lang))
                _pause(lang)
                continue
            timeout = _prompt_float(_t("prompt_timeout", lang), default=40.0, lang=lang)
            force = _prompt_bool(_t("prompt_force", lang), default=True, lang=lang)
            _run_action("Stop", lambda: manager.stop(cfg, timeout=timeout, force=force), lang)
            _pause(lang)
            continue

        if choice in ("3", "restart", "重启"):
            if not _ensure_screen(lang):
                _pause(lang)
                continue
            update = _prompt_bool(_t("prompt_update_restart", lang), default=False, lang=lang)
            start_caves = _prompt_bool(_t("prompt_start_caves", lang), default=True, lang=lang)
            _run_action("Restart", lambda: manager.restart(cfg, start_caves=start_caves, update=update), lang)
            _pause(lang)
            continue

        if choice in ("4", "update", "更新"):
            steam_path = cfg.steamcmd_dir / "steamcmd.sh" if cfg.steamcmd_dir else None
            if steam_path is None or not steam_path.exists():
                print(_t("msg_steam_missing", lang))
                _pause(lang)
                continue
            running = _is_running(cfg)
            if running:
                proceed = _prompt_bool(_t("prompt_update_continue", lang), default=False, lang=lang)
                if not proceed:
                    continue
            _run_action("Update", lambda: manager.update_game(cfg), lang)
            _pause(lang)
            continue

        if choice in ("5", "backup", "备份"):
            if not cfg.cluster_dir.exists():
                print(f"{_t('msg_cluster_missing', lang)}: {cfg.cluster_dir}")
                _pause(lang)
                continue
            out_path = _prompt_path(_t("prompt_backup_out", lang), default="")
            _run_action("Backup", lambda: manager.backup(cfg, out_path=out_path), lang)
            _pause(lang)
            continue

        if choice in ("6", "restore", "恢复"):
            backups = manager.list_backups(cfg)
            if not backups:
                print(_t("msg_backup_none", lang))
                _pause(lang)
                continue
            _render_restore_screen(cfg, lang, backups)
            raw = _prompt(_t("prompt_restore_choose", lang), default="")
            if not raw:
                continue
            file_path = None
            index = None
            latest = False
            selected_backup = None
            raw_lower = raw.lower()
            if raw_lower in ("l", "latest", "最新"):
                latest = True
                selected_backup = backups[0]
            elif raw.isdigit():
                index = int(raw)
                if index < 0 or index >= len(backups):
                    print(_t("msg_backup_index_oob", lang))
                    _pause(lang)
                    continue
                selected_backup = backups[index]
            else:
                file_path = Path(raw).expanduser()
                if not file_path.exists():
                    print(f"{_t('msg_backup_not_found', lang)}: {file_path}")
                    _pause(lang)
                    continue
                selected_backup = file_path

            if not _confirm_restore_target(cfg, lang, selected_backup=selected_backup):
                continue
            start_after = _prompt_bool(_t("prompt_restore_start", lang), default=True, lang=lang)
            _run_action(
                "Restore",
                lambda: manager.restore(
                    cfg,
                    file_path=file_path,
                    index=index,
                    latest=latest,
                    yes=True,
                    start_after=start_after,
                ),
                lang,
            )
            _pause(lang)
            continue

        if choice in ("7", "logs", "日志"):
            shard = _choose_shard(lang)
            log_path = cfg.master_log if shard == "master" else cfg.caves_log
            if not log_path.exists():
                print(f"{_t('msg_log_not_found', lang)}: {log_path}")
                _pause(lang)
                continue
            lines = _prompt_int(_t("prompt_lines", lang), default=120, lang=lang)
            follow = _prompt_bool(_t("prompt_follow", lang), default=True, lang=lang)
            _run_action("Logs", lambda: manager.logs(cfg, shard=shard, follow=follow, lines=lines), lang)
            _pause(lang)
            continue

        if choice in ("8", "console", "控制台"):
            lang = _console_menu(cfg, lang)
            continue

        if choice in ("9", "cmd", "command", "指令"):
            if not _ensure_screen(lang):
                _pause(lang)
                continue
            shard = _choose_shard(lang)
            cmd = _prompt(_t("prompt_send_cmd", lang), default="")
            if not cmd:
                continue
            _run_action("Send command", lambda: manager.send_cmd(cfg, shard=shard, command=cmd), lang)
            _pause(lang)
            continue

        print(_t("msg_unknown", lang))
        _pause(lang)
```

### File: apps/webcraft/__init__.py
- mode: full
- size_bytes: 48
- sha256_12: 43210b35acae

```py
# -*- coding: utf-8 -*-
"""WebCraft package."""
```

### File: apps/webcraft/api.py
- mode: full
- size_bytes: 24167
- sha256_12: 10c6ae4105c9

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

from typing import Any, Dict, List, Optional

import hashlib

from fastapi import APIRouter, Request, Depends, HTTPException, Query
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel, Field

from .catalog_store import CatalogStore, CraftRecipe, CookingRecipe
from .planner import craftable_recipes, missing_for, normalize_inventory
from .cooking_planner import find_cookable, simulate_cookpot, normalize_counts


def get_store(request: Request) -> CatalogStore:
    """Resolve the catalog store from app state (with optional auto-reload)."""

    store: CatalogStore = request.app.state.store  # type: ignore[attr-defined]
    auto = bool(getattr(request.app.state, "auto_reload_catalog", False))
    if auto:
        try:
            store.load(force=False)
        except Exception:
            # do not break requests on reload errors
            pass
    return store


def _cache_headers(request: Request, *, max_age: int, etag: Optional[str] = None) -> Dict[str, str]:
    if max_age <= 0:
        return {}
    if bool(getattr(request.app.state, "auto_reload_catalog", False)):
        return {}
    headers = {"Cache-Control": f"public, max-age={int(max_age)}"}
    if etag:
        headers["ETag"] = str(etag)
    return headers


def _json(data: Dict[str, Any], *, headers: Optional[Dict[str, str]] = None) -> JSONResponse:
    return JSONResponse(content=data, headers=headers or {})


router = APIRouter(prefix="/api/v1")


def _has_cjk(text: str) -> bool:
    return any("\u4e00" <= ch <= "\u9fff" for ch in str(text or ""))


# ----------------- optional tuning traces (requires analyzer engine) -----------------


def _get_engine(request: Request):
    return getattr(request.app.state, "engine", None)


def _get_tuning_trace_store(request: Request):
    store = getattr(request.app.state, "tuning_trace_store", None)
    if store is None:
        path = getattr(request.app.state, "tuning_trace_path", None)
        if path:
            try:
                from pathlib import Path
                from .tuning_trace import TuningTraceStore

                p = Path(path)
                if p.exists():
                    store = TuningTraceStore(p)
                    request.app.state.tuning_trace_store = store
            except Exception:
                store = None
    auto = bool(getattr(request.app.state, "auto_reload_tuning_trace", False))
    if store is not None and auto:
        try:
            store.load(force=False)
        except Exception:
            pass
    return store


def _get_i18n_index_store(request: Request):
    store = getattr(request.app.state, "i18n_index_store", None)
    if store is None:
        path = getattr(request.app.state, "i18n_index_path", None)
        if path:
            try:
                from pathlib import Path
                from .i18n_index import I18nIndexStore

                p = Path(path)
                if p.exists():
                    store = I18nIndexStore(p)
                    request.app.state.i18n_index_store = store
            except Exception:
                store = None
    auto = bool(getattr(request.app.state, "auto_reload_i18n_index", False))
    if store is not None and auto:
        try:
            store.load(force=False)
        except Exception:
            pass
    return store


def _ensure_tuning(engine, store_meta: Optional[Dict[str, Any]] = None) -> Any:
    """Best-effort: ensure tuning.lua is parsed (even without analyzer engine)."""

    tuning = getattr(engine, "tuning", None) if engine is not None else None
    if tuning is not None:
        return tuning

    try:
        from core.analyzer import TuningResolver  # type: ignore
        content = ""
        if engine is not None:
            content = engine.read_file("scripts/tuning.lua") or engine.read_file("tuning.lua") or ""
        if (not content) and store_meta:
            hint = str(store_meta.get("scripts_zip") or "").strip()
            if hint:
                try:
                    import zipfile
                    with zipfile.ZipFile(hint, "r") as z:
                        content = z.read("scripts/tuning.lua").decode("utf-8", errors="replace")
                except Exception:
                    content = ""
        if not content:
            return None
        tuning = TuningResolver(content)
        if engine is not None:
            try:
                engine.tuning = tuning
            except Exception:
                pass
        return tuning
    except Exception:
        return None


def _enrich_cooking_recipe(raw: Dict[str, Any], *, name: Optional[str] = None, tuning: Any = None) -> Dict[str, Any]:
    """Return a safe copy of cooking recipe dict with optional tuning traces.

    Adds:
      - name (if missing)
      - _tuning: { field -> tuning.trace_expr(raw_string) } for any string that contains "TUNING"
    """
    out: Dict[str, Any] = dict(raw or {})
    if name and not out.get("name"):
        out["name"] = name

    if tuning is None:
        return out

    traces: Dict[str, Any] = {}
    for k, v in list(out.items()):
        if isinstance(v, str) and ("TUNING" in v):
            try:
                tr = tuning.trace_expr(v)
                traces[str(k)] = tr
                # If resolvable, inline final value so UI can show both value + expr.
                if isinstance(tr.get("value"), (int, float)):
                    out[k] = tr.get("value")
            except Exception:
                traces[str(k)] = {"expr": v, "value": None, "expr_resolved": v, "refs": {}}

    if traces:
        out["_tuning"] = traces
    return out



class PlanRequest(BaseModel):
    inventory: Dict[str, float] = Field(default_factory=dict)
    builder_tag: Optional[str] = None
    strict: bool = False
    limit: int = 200


class MissingRequest(BaseModel):
    name: str
    inventory: Dict[str, float] = Field(default_factory=dict)


class CookingFindRequest(BaseModel):
    inventory: Dict[str, float] = Field(default_factory=dict)
    limit: int = 200


class CookingSimulateRequest(BaseModel):
    slots: Dict[str, float] = Field(default_factory=dict)
    return_top: int = 25


@router.get("/meta")
def meta(request: Request, store: CatalogStore = Depends(get_store)):
    m = store.meta()
    m.update({"schema_version": store.schema_version()})

    # icon config (public)
    svc = getattr(request.app.state, "icon_service", None)
    if svc is not None:
        try:
            m.update({"icon": svc.cfg.to_public_dict()})
        except Exception:
            pass


    # runtime analyzer availability (optional)
    eng = _get_engine(request)
    m.update({"analyzer_enabled": bool(eng)})
    if eng is not None:
        try:
            m.update(
                {
                    "engine_mode": str(getattr(eng, "mode", "") or ""),
                    "scripts_file_count": len(getattr(eng, "file_list", []) or []),
                }
            )
        except Exception:
            pass

    # tuning traces for UI (optional; requires scripts mounted)
    tuning = _ensure_tuning(eng, store.meta())
    if tuning is not None:
        try:
            m.update({"tuning_enabled": True, "tuning_count": len(getattr(tuning, "raw_map", {}) or {})})
        except Exception:
            m.update({"tuning_enabled": True})
    else:
        m.update({"tuning_enabled": False})

    # tuning trace index (optional; built offline)
    tstore = _get_tuning_trace_store(request)
    if tstore is not None:
        try:
            m.update({"tuning_trace_enabled": True, "tuning_trace_count": tstore.count()})
        except Exception:
            m.update({"tuning_trace_enabled": True})
    else:
        m.update({"tuning_trace_enabled": False})

    # i18n (optional)
    iindex = _get_i18n_index_store(request)
    if iindex is not None:
        try:
            m.update({"i18n": iindex.public_meta()})
        except Exception:
            pass
    else:
        isvc = getattr(request.app.state, "i18n_service", None)
        if isvc is not None:
            try:
                scripts_zip_hint = str((m or {}).get("scripts_zip") or "").strip() or None
                m.update({"i18n": isvc.public_meta(engine=eng, scripts_zip_hint=scripts_zip_hint)})
            except Exception:
                pass

    etag = f'W/"meta-{int(store.mtime())}"'
    headers = _cache_headers(request, max_age=60, etag=etag)
    return _json(m, headers=headers)


@router.get("/tuning/trace")
def tuning_trace(
    request: Request,
    key: Optional[str] = None,
    prefix: Optional[str] = None,
    limit: int = Query(2000, ge=1, le=10000),
):
    """Return tuning trace entries by key or prefix (from tuning trace index)."""
    store = _get_tuning_trace_store(request)
    if store is None:
        return {"enabled": False, "trace": None, "traces": {}, "count": 0}

    if key:
        trace = store.get(str(key))
        return {"enabled": True, "key": str(key), "trace": trace}

    pref = str(prefix or "").strip()
    traces = store.get_prefix(pref, limit=int(limit))
    return {"enabled": True, "prefix": pref, "traces": traces, "count": len(traces)}


@router.get("/assets")
def assets(request: Request, store: CatalogStore = Depends(get_store)):
    mp = store.assets(include_icon_only=True)

    svc = getattr(request.app.state, "icon_service", None)
    icon_cfg = None
    if svc is not None:
        try:
            icon_cfg = svc.cfg.to_public_dict()
        except Exception:
            icon_cfg = None

    etag = f'W/"assets-{int(store.mtime())}-{len(mp)}"'
    headers = _cache_headers(request, max_age=300, etag=etag)
    return _json(
        {"assets": mp, "count": len(mp), "icon": icon_cfg or {"mode": "off", "static_base": "/static/data/icons", "api_base": "/api/v1/icon"}},
        headers=headers,
    )


@router.get("/catalog/index")
def catalog_index(
    request: Request,
    store: CatalogStore = Depends(get_store),
    offset: int = Query(0, ge=0),
    limit: int = Query(200, ge=1, le=2000),
):
    items, total = store.catalog_index_page(offset=int(offset), limit=int(limit))

    svc = getattr(request.app.state, "icon_service", None)
    icon_cfg = None
    if svc is not None:
        try:
            icon_cfg = svc.cfg.to_public_dict()
        except Exception:
            icon_cfg = None

    etag = f'W/"catalog-{int(store.mtime())}-{total}"'
    headers = _cache_headers(request, max_age=300, etag=etag)
    return _json(
        {
            "items": items,
            "count": len(items),
            "total": total,
            "offset": int(offset),
            "limit": int(limit),
            "icon": icon_cfg or {"mode": "off", "static_base": "/static/data/icons", "api_base": "/api/v1/icon"},
        },
        headers=headers,
    )


@router.get("/catalog/search")
def catalog_search(
    request: Request,
    q: str = Query(..., min_length=1),
    store: CatalogStore = Depends(get_store),
    offset: int = Query(0, ge=0),
    limit: int = Query(200, ge=1, le=2000),
):
    name_lookup: Optional[Dict[str, str]] = None
    iindex = _get_i18n_index_store(request)
    i18n_stamp = ""
    if iindex is not None and _has_cjk(q):
        try:
            name_lookup = iindex.names("zh")
            i18n_stamp = f"-i18n{int(getattr(iindex, 'mtime', lambda: 0)())}"
        except Exception:
            name_lookup = None
    items, total = store.catalog_search(q, offset=int(offset), limit=int(limit), name_lookup=name_lookup)
    q_sig = hashlib.sha1(str(q).encode("utf-8")).hexdigest()[:8]
    etag = f'W/"catalog-search-{int(store.mtime())}-{q_sig}-{total}{i18n_stamp}"'
    headers = _cache_headers(request, max_age=60, etag=etag)
    return _json({"q": q, "items": items, "count": len(items), "total": total, "offset": int(offset), "limit": int(limit)}, headers=headers)

@router.get("/i18n")
def i18n_meta(request: Request, store: CatalogStore = Depends(get_store)):
    """Return i18n capability + available languages."""
    iindex = _get_i18n_index_store(request)
    if iindex is not None:
        try:
            meta = iindex.public_meta()
            etag = f'W/"i18n-meta-{int(getattr(iindex, "mtime", lambda: 0)())}-{meta.get("langs")}"'
            headers = _cache_headers(request, max_age=300, etag=etag)
            return _json(meta, headers=headers)
        except Exception:
            return _json({"enabled": False, "langs": [], "ui_langs": [], "modes": ["en", "zh", "id"], "default_mode": "en"})
    return _json({"enabled": False, "langs": [], "ui_langs": [], "modes": ["en", "zh", "id"], "default_mode": "en"})


@router.get("/i18n/ui/{lang}")
def i18n_ui(lang: str, request: Request):
    """Return UI strings for the given language."""
    store = _get_i18n_index_store(request)
    if store is None:
        return _json({"lang": str(lang), "strings": {}, "count": 0, "enabled": False})
    try:
        mp = store.ui_strings(str(lang))
    except Exception:
        mp = {}
    etag = f'W/"i18n-ui-{int(getattr(store, "mtime", lambda: 0)())}-{lang}-{len(mp)}"'
    headers = _cache_headers(request, max_age=600, etag=etag)
    return _json({"lang": str(lang), "strings": mp, "count": len(mp or {}), "enabled": bool(mp)}, headers=headers)


@router.get("/i18n/names/{lang}")
def i18n_names(lang: str, request: Request, store: CatalogStore = Depends(get_store)):
    """Return id->localized name mapping for items in the current catalog."""
    iindex = _get_i18n_index_store(request)
    if iindex is not None:
        try:
            mp = iindex.names(str(lang))
        except Exception:
            mp = {}
        if mp:
            etag = f'W/"i18n-names-{int(getattr(iindex, "mtime", lambda: 0)())}-{lang}-{len(mp)}"'
            headers = _cache_headers(request, max_age=600, etag=etag)
            return _json({"lang": str(lang), "names": mp, "count": len(mp or {})}, headers=headers)
    return _json({"lang": str(lang), "names": {}, "count": 0})


@router.get("/items/{item_id}")
def item_detail(item_id: str, request: Request, store: CatalogStore = Depends(get_store)):
    """Return best-effort item-centric view.

    This endpoint is used by the /catalog UI.
    """
    q = (item_id or "").strip()
    if not q:
        raise HTTPException(status_code=400, detail="empty item_id")

    # presentation asset + item metadata (if any)
    asset = store.get_asset(q) or store.get_asset(q.lower())
    item = store.get_item(q) or store.get_item(q.lower())

    # craft references
    craft_used_in = store.list_by_ingredient(q) or store.list_by_ingredient(q.lower())
    craft_produced_by = store.list_by_product(q) or store.list_by_product(q.lower())

    # cooking references
    cook_used_in = store.list_cooking_by_ingredient(q) or store.list_cooking_by_ingredient(q.lower())
    cook_rec = store.get_cooking_recipe(q) or store.get_cooking_recipe(q.lower())

    return {
        "item_id": q,
        "item": item,
        "asset": asset,
        "craft": {"used_in": craft_used_in, "produced_by": craft_produced_by},
        "cooking": {
            "as_recipe": (
                _enrich_cooking_recipe(
                    cook_rec.raw,
                    name=cook_rec.name,
                    tuning=_ensure_tuning(_get_engine(request), store.meta()),
                )
                if cook_rec else None
            ),
            "used_in": cook_used_in,
        },
    }



@router.get("/icon/{item_id}.png")
def icon_png(item_id: str, request: Request, store: CatalogStore = Depends(get_store)):
    """Return an item icon as PNG.

    This endpoint supports dynamic generation (atlas+xml + tex) when enabled.
    In all modes, it caches to the static icons directory as <id>.png.
    """

    svc = getattr(request.app.state, "icon_service", None)
    if svc is None:
        raise HTTPException(status_code=503, detail="Icon service not configured")

    asset = store.get_asset(item_id)
    p = svc.ensure_icon(item_id, asset)
    if not p:
        raise HTTPException(status_code=404, detail=f"Icon not found: {item_id}")

    return FileResponse(path=str(p), media_type="image/png")


# ----------------- craft browse -----------------


@router.get("/craft/filters")
def craft_filters(store: CatalogStore = Depends(get_store)):
    order, defs = store.list_filters()
    return {"order": order, "defs": defs}


@router.get("/craft/tabs")
def craft_tabs(store: CatalogStore = Depends(get_store)):
    return {"tabs": store.list_tabs()}


@router.get("/craft/tags")
def craft_tags(store: CatalogStore = Depends(get_store)):
    return {"tags": store.list_tags()}


@router.get("/craft/filters/{filter_name}/recipes")
def craft_filter_recipes(filter_name: str, store: CatalogStore = Depends(get_store)):
    names = store.list_by_filter(filter_name)
    return {"filter": filter_name, "recipes": names}


@router.get("/craft/tabs/{tab}/recipes")
def craft_tab_recipes(tab: str, store: CatalogStore = Depends(get_store)):
    names = store.list_by_tab(tab)
    return {"tab": tab, "recipes": names}


@router.get("/craft/tags/{tag}/recipes")
def craft_tag_recipes(tag: str, store: CatalogStore = Depends(get_store)):
    names = store.list_by_tag(tag)
    return {"tag": tag, "recipes": names}


@router.get("/craft/ingredients/{item}/recipes")
def craft_ingredient_recipes(item: str, store: CatalogStore = Depends(get_store)):
    names = store.list_by_ingredient(item)
    return {"ingredient": item, "recipes": names}


# ----------------- craft recipe -----------------

@router.get("/craft/products/{item}/recipes")
def craft_product_recipes(item: str, store: CatalogStore = Depends(get_store)):
    names = store.list_by_product(item)
    return {"product": item, "recipes": names}



@router.get("/craft/recipes/search")
def craft_search(
    request: Request,
    q: str = Query(..., min_length=1),
    limit: int = Query(50, ge=1, le=500),
    store: CatalogStore = Depends(get_store),
):
    name_lookup: Optional[Dict[str, str]] = None
    iindex = _get_i18n_index_store(request)
    if iindex is not None and _has_cjk(q):
        try:
            name_lookup = iindex.names("zh")
        except Exception:
            name_lookup = None
    return {"q": q, "results": store.search(q, limit=limit, name_lookup=name_lookup)}


@router.get("/craft/recipes/{name}")
def craft_recipe(name: str, store: CatalogStore = Depends(get_store)):
    rec = store.get_recipe(name)
    if not rec:
        raise HTTPException(status_code=404, detail=f"Recipe not found: {name}")
    return {"recipe": rec.raw}


# ----------------- craft planning -----------------


@router.post("/craft/plan")
def craft_plan(req: PlanRequest, store: CatalogStore = Depends(get_store)):
    inv = normalize_inventory(req.inventory)
    limit = int(req.limit or 200)
    limit = max(1, min(limit, 2000))

    recipes: List[CraftRecipe] = store.iter_recipes()
    recipes.sort(key=lambda x: x.name)

    ok, blocked = craftable_recipes(recipes, inv, builder_tag=req.builder_tag, strict=bool(req.strict))
    ok_names = [r.name for r in ok[:limit]]
    return {"craftable": ok_names, "blocked": blocked[:limit], "count": len(ok_names)}


@router.post("/craft/missing")
def craft_missing(req: MissingRequest, store: CatalogStore = Depends(get_store)):
    rec = store.get_recipe(req.name)
    if not rec:
        raise HTTPException(status_code=404, detail=f"Recipe not found: {req.name}")
    inv = normalize_inventory(req.inventory)
    miss = missing_for(rec, inv)
    return {"name": rec.name, "missing": [m.__dict__ for m in miss]}


# ----------------- cooking browse -----------------


@router.get("/cooking/recipes")
def cooking_all(store: CatalogStore = Depends(get_store)):
    recipes: List[CookingRecipe] = store.iter_cooking_recipes()
    names = sorted([r.name for r in recipes])
    return {"recipes": names, "count": len(names)}


@router.get("/cooking/foodtypes")
def cooking_foodtypes(store: CatalogStore = Depends(get_store)):
    return {"foodtypes": store.list_cooking_foodtypes()}


@router.get("/cooking/tags")
def cooking_tags(store: CatalogStore = Depends(get_store)):
    return {"tags": store.list_cooking_tags()}


@router.get("/cooking/foodtypes/{foodtype}/recipes")
def cooking_foodtype_recipes(foodtype: str, store: CatalogStore = Depends(get_store)):
    return {"foodtype": foodtype, "recipes": store.list_cooking_by_foodtype(foodtype)}


@router.get("/cooking/tags/{tag}/recipes")
def cooking_tag_recipes(tag: str, store: CatalogStore = Depends(get_store)):
    return {"tag": tag, "recipes": store.list_cooking_by_tag(tag)}


@router.get("/cooking/ingredients/{item}/recipes")
def cooking_ingredient_recipes(item: str, store: CatalogStore = Depends(get_store)):
    return {"ingredient": item, "recipes": store.list_cooking_by_ingredient(item)}


# ----------------- cooking recipe -----------------


@router.get("/cooking/recipes/search")
def cooking_search(
    request: Request,
    q: str = Query(..., min_length=1),
    limit: int = Query(50, ge=1, le=500),
    store: CatalogStore = Depends(get_store),
):
    name_lookup: Optional[Dict[str, str]] = None
    iindex = _get_i18n_index_store(request)
    if iindex is not None and _has_cjk(q):
        try:
            name_lookup = iindex.names("zh")
        except Exception:
            name_lookup = None
    return {"q": q, "results": store.search_cooking(q, limit=limit, name_lookup=name_lookup)}


@router.get("/cooking/recipes/{name}")
def cooking_recipe(name: str, request: Request, store: CatalogStore = Depends(get_store)):
    rec = store.get_cooking_recipe(name)
    if not rec:
        raise HTTPException(status_code=404, detail=f"Cooking recipe not found: {name}")
    eng = _get_engine(request)
    tuning = _ensure_tuning(eng, store.meta())
    return {"recipe": _enrich_cooking_recipe(rec.raw, name=rec.name, tuning=tuning)}


# ----------------- cooking helpers -----------------


@router.post("/cooking/find")
def cooking_find(req: CookingFindRequest, store: CatalogStore = Depends(get_store)):
    inv = normalize_counts(req.inventory)
    limit = max(1, min(int(req.limit or 200), 2000))

    recipes = store.iter_cooking_recipes()
    cookable = find_cookable(recipes, inv, limit=limit)
    names = [r.name for r in cookable]

    return {
        "cookable": names,
        "count": len(names),
        "note": "only recipes with card_ingredients are searchable/simulatable",
    }


@router.post("/cooking/simulate")
def cooking_simulate(req: CookingSimulateRequest, request: Request, store: CatalogStore = Depends(get_store)):
    recipes = store.iter_cooking_recipes()
    out = simulate_cookpot(recipes, req.slots, return_top=int(req.return_top or 25))

    # Attach result recipe details if available.
    if out.get("ok") and out.get("result"):
        rec = store.get_cooking_recipe(str(out.get("result")))
        if rec:
            eng = _get_engine(request)
            tuning = _ensure_tuning(eng, store.meta())
            out["recipe"] = _enrich_cooking_recipe(rec.raw, name=rec.name, tuning=tuning)

    return out


@router.get("/analyze/prefab/{name}")
def analyze_prefab(name: str, request: Request):
    """Parse a prefab lua file and return a structured report.

    Requires the server to be started with analyzer enabled (scripts mounted).
    """
    eng = getattr(request.app.state, "engine", None)
    if eng is None:
        raise HTTPException(status_code=400, detail="analyzer disabled (no scripts source mounted)")

    q = (name or "").strip()
    if not q:
        raise HTTPException(status_code=400, detail="empty name")

    try:
        path = eng.find_file(q, fuzzy=True)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    if not path:
        raise HTTPException(status_code=404, detail=f"file not found for: {q}")

    content = eng.read_file(path)
    if content is None:
        raise HTTPException(status_code=404, detail=f"cannot read: {path}")

    from core.analyzer import LuaAnalyzer
    rep = LuaAnalyzer(content, path=path).get_report()
    return {"query": q, "path": path, "report": rep}
```

### File: apps/webcraft/app.py
- mode: full
- size_bytes: 7083
- sha256_12: 778a0e07ed89

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

from pathlib import Path
from typing import Optional, Sequence

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles

from .api import router as api_router
from .catalog_store import CatalogStore
from .icon_service import IconConfig, IconService
from .i18n_index import I18nIndexStore
from .settings import WebCraftSettings
from .tuning_trace import TuningTraceStore
from .ui import render_index_html, render_cooking_html, render_catalog_html


def create_app(
    catalog_path: Path,
    *,
    root_path: str = "",
    cors_allow_origins: Optional[Sequence[str]] = None,
    gzip_minimum_size: int = 800,
    auto_reload_catalog: bool = False,
    # icons
    icons_mode: str = "auto",
    game_data_dir: Optional[Path] = None,
    icons_unpremultiply: bool = True,
    static_root_dir: Optional[Path] = None,
    # analyzer (optional)
    enable_analyzer: bool = False,
    analyzer_load_db: bool = False,
    dst_root: Optional[Path] = None,
    scripts_zip: Optional[Path] = None,
    scripts_dir: Optional[Path] = None,
    # tuning trace (optional)
    tuning_trace_path: Optional[Path] = None,
    auto_reload_tuning_trace: bool = False,
    # i18n index (optional)
    i18n_index_path: Optional[Path] = None,
    auto_reload_i18n_index: bool = False,
) -> FastAPI:
    """FastAPI app factory."""

    rp = WebCraftSettings.normalize_root_path(root_path)

    app = FastAPI(
        title="Wagstaff WebCraft API",
        version="1.0",
        root_path=rp,
        docs_url="/docs",
        redoc_url=None,
    )

    # static: app assets vs data outputs
    project_root = Path(__file__).resolve().parents[2]
    app_static_root = project_root / "apps" / "webcraft" / "static"
    data_static_root = Path(static_root_dir) if static_root_dir else (project_root / "data" / "static")
    try:
        app_static_root.mkdir(parents=True, exist_ok=True)
        data_static_root.mkdir(parents=True, exist_ok=True)
    except Exception:
        pass
    app.mount("/static/app", StaticFiles(directory=str(app_static_root), check_dir=False), name="static-app")
    app.mount("/static/data", StaticFiles(directory=str(data_static_root), check_dir=False), name="static-data")

    # state
    app.state.store = CatalogStore(Path(catalog_path))

    # tuning trace (separate from catalog)
    ttp = Path(tuning_trace_path) if tuning_trace_path else (Path(catalog_path).parent / "wagstaff_tuning_trace_v1.json")
    app.state.tuning_trace_path = ttp
    if ttp.exists():
        app.state.tuning_trace_store = TuningTraceStore(ttp)
    else:
        app.state.tuning_trace_store = None
    app.state.auto_reload_tuning_trace = bool(auto_reload_tuning_trace or auto_reload_catalog)

    # i18n index (separate from catalog)
    iip = Path(i18n_index_path) if i18n_index_path else (Path(catalog_path).parent / "wagstaff_i18n_v1.json")
    app.state.i18n_index_path = iip
    if iip.exists():
        app.state.i18n_index_store = I18nIndexStore(iip)
    else:
        app.state.i18n_index_store = None
    app.state.auto_reload_i18n_index = bool(auto_reload_i18n_index or auto_reload_catalog)

    # analyzer (auto-on if scripts_zip hint is available)
    scripts_zip_hint = None
    scripts_dir_hint = None
    try:
        scripts_zip_hint = str((app.state.store.meta() or {}).get("scripts_zip") or "").strip() or None
    except Exception:
        scripts_zip_hint = None
    try:
        scripts_dir_hint = str((app.state.store.meta() or {}).get("scripts_dir") or "").strip() or None
    except Exception:
        scripts_dir_hint = None

    scripts_zip_arg = scripts_zip
    scripts_dir_arg = scripts_dir
    dst_root_arg = dst_root
    enable_analyzer_arg = bool(enable_analyzer)

    if (not enable_analyzer_arg) and (not dst_root_arg) and (not scripts_zip_arg) and (not scripts_dir_arg):
        if scripts_zip_hint and Path(scripts_zip_hint).exists():
            scripts_zip_arg = Path(scripts_zip_hint)
            enable_analyzer_arg = True
        elif scripts_dir_hint and Path(scripts_dir_hint).exists():
            scripts_dir_arg = Path(scripts_dir_hint)
            enable_analyzer_arg = True

    # optional live analyzer (mount scripts source for on-demand parsing)
    app.state.engine = None
    if enable_analyzer_arg or dst_root_arg or scripts_zip_arg or scripts_dir_arg:
        try:
            from core.engine import WagstaffEngine
            app.state.engine = WagstaffEngine(
                load_db=bool(analyzer_load_db),
                silent=True,
                dst_root=str(dst_root_arg) if dst_root_arg else None,
                scripts_zip=str(scripts_zip_arg) if scripts_zip_arg else None,
                scripts_dir=str(scripts_dir_arg) if scripts_dir_arg else None,
            )
        except Exception:
            app.state.engine = None
    app.state.auto_reload_catalog = bool(auto_reload_catalog)

    # i18n index only (runtime PO parsing disabled)
    app.state.i18n_service = None

    icons_dir = data_static_root / "icons"
    try:
        icons_dir.mkdir(parents=True, exist_ok=True)
    except Exception:
        pass

    cfg = IconConfig(
        mode=str(icons_mode or "auto"),
        static_dir=icons_dir,
        game_data_dir=(Path(game_data_dir).expanduser().resolve() if game_data_dir else None),
        unpremultiply=bool(icons_unpremultiply),
    )
    app.state.icon_service = IconService(cfg)

    # middleware
    if gzip_minimum_size and gzip_minimum_size > 0:
        app.add_middleware(GZipMiddleware, minimum_size=int(gzip_minimum_size))

    if cors_allow_origins:
        app.add_middleware(
            CORSMiddleware,
            allow_origins=list(cors_allow_origins),
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )

    # routes
    app.include_router(api_router)

    @app.on_event("shutdown")
    def _shutdown() -> None:
        eng = getattr(app.state, "engine", None)
        if eng is not None:
            try:
                eng.close()
            except Exception:
                pass

    @app.get("/healthz")
    def healthz():
        return {"ok": True}

    @app.get("/", response_class=HTMLResponse)
    def index(request: Request):
        # root_path is already applied by FastAPI; still need it for frontend URL prefixing
        root = request.scope.get("root_path") or ""
        return HTMLResponse(render_index_html(app_root=str(root)))

    @app.get("/cooking", response_class=HTMLResponse)
    def cooking(request: Request):
        root = request.scope.get("root_path") or ""
        return HTMLResponse(render_cooking_html(app_root=str(root)))


    @app.get("/catalog", response_class=HTMLResponse)
    def catalog(request: Request):
        root = request.scope.get("root_path") or ""
        return HTMLResponse(render_catalog_html(app_root=str(root)))

    return app
```

### File: apps/webcraft/catalog_store.py
- mode: full
- size_bytes: 45241
- sha256_12: 6f658886004f

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

import json
import sqlite3
import threading
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple


def _dedup_preserve_order(items: Iterable[str]) -> List[str]:
    out: List[str] = []
    seen = set()
    for x in items:
        if not x:
            continue
        if x in seen:
            continue
        out.append(x)
        seen.add(x)
    return out


_SQLITE_SUFFIXES = (".sqlite", ".sqlite3", ".db")


def _is_sqlite_path(path: Path) -> bool:
    return path.suffix.lower() in _SQLITE_SUFFIXES


def _find_sqlite_peer(path: Path) -> Optional[Path]:
    if path.suffix.lower() != ".json":
        return None
    for ext in _SQLITE_SUFFIXES:
        candidate = path.with_suffix(ext)
        if candidate.exists():
            return candidate
    return None


@dataclass
class CraftRecipe:
    name: str
    product: Optional[str]
    tab: str
    tech: str
    filters: List[str]
    builder_tags: List[str]
    builder_skill: Optional[str]
    station_tag: Optional[str]
    ingredients: List[Dict[str, Any]]
    ingredients_unresolved: List[str]
    raw: Dict[str, Any]


@dataclass
class CookingRecipe:
    """Cookpot cooking recipe (preparedfoods).

    Notes
    - Currently backed by catalog['cooking'] entries.
    - `card_ingredients` may be missing for many recipes (legacy limitation).
    """

    name: str
    priority: float
    weight: float
    foodtype: Optional[str]
    hunger: Any
    health: Any
    sanity: Any
    perishtime: Any
    cooktime: Any
    tags: List[str]
    card_ingredients: List[Tuple[str, float]]
    raw: Dict[str, Any]


class CatalogError(RuntimeError):
    pass


class CatalogStore:
    """Load + index wagstaff catalog for fast queries (thread-safe).

    Data source:
      - data/index/wagstaff_catalog_v2.json
      - data/index/wagstaff_catalog_v2.sqlite

    This layer is intentionally independent from wiki/cli layers. It should be safe
    to reuse from:
      - CLI (wiki)
      - Web (webcraft)
      - future GUI (desktop)
    """

    def __init__(self, catalog_path: Path):
        resolved = self._resolve_catalog_path(Path(catalog_path))
        self._path = resolved
        self._use_sqlite = _is_sqlite_path(self._path)
        self._lock = threading.RLock()
        self._mtime: float = -1.0
        self._icon_index_mtime: float = -1.0
        self._icon_index: Dict[str, str] = {}
        self._icon_index_path: Path = self._path.parent / "wagstaff_icon_index_v1.json"
        self._catalog_index_path: Path = self._path.parent / "wagstaff_catalog_index_v1.json"
        self._catalog_index_mtime: float = -1.0
        self._catalog_index_items: List[Dict[str, Any]] = []
        self._catalog_index_total: int = 0

        self._doc: Dict[str, Any] = {}
        self._meta: Dict[str, Any] = {}

        # presentation mapping (id -> {name, atlas, image, ...})
        self._assets: Dict[str, Any] = {}
        self._items: Dict[str, Dict[str, Any]] = {}
        self._item_ids: List[str] = []
        self._by_kind: Dict[str, List[str]] = {}
        self._by_category: Dict[str, List[str]] = {}
        self._by_behavior: Dict[str, List[str]] = {}
        self._by_source: Dict[str, List[str]] = {}
        self._by_component: Dict[str, List[str]] = {}
        self._by_tag_item: Dict[str, List[str]] = {}
        self._by_slot: Dict[str, List[str]] = {}

        # craft
        self._recipes: Dict[str, CraftRecipe] = {}
        self._aliases: Dict[str, str] = {}
        self._filter_defs: List[Dict[str, Any]] = []
        self._filter_order: List[str] = []

        # indexes (craft)
        self._by_filter: Dict[str, List[str]] = {}
        self._by_tab: Dict[str, List[str]] = {}
        self._by_tag: Dict[str, List[str]] = {}
        self._by_ingredient: Dict[str, List[str]] = {}
        self._by_product: Dict[str, List[str]] = {}

        # cooking
        self._cooking: Dict[str, CookingRecipe] = {}
        self._cook_by_tag: Dict[str, List[str]] = {}
        self._cook_by_foodtype: Dict[str, List[str]] = {}
        self._cook_by_ingredient: Dict[str, List[str]] = {}

        self.load(force=True)

    @staticmethod
    def _resolve_catalog_path(catalog_path: Path) -> Path:
        if _is_sqlite_path(catalog_path):
            return catalog_path
        peer = _find_sqlite_peer(catalog_path)
        return peer if peer else catalog_path

    @property
    def path(self) -> Path:
        return self._path

    def meta(self) -> Dict[str, Any]:
        with self._lock:
            return dict(self._meta)

    def schema_version(self) -> int:
        with self._lock:
            return int(self._doc.get("schema_version") or (self._meta or {}).get("schema") or 0)

    def mtime(self) -> float:
        with self._lock:
            return float(self._mtime or 0)

    def item_ids(self, include_icon_only: bool = False) -> List[str]:
        """Return known item ids (optionally including icon-only ids)."""
        with self._lock:
            ids = list(self._item_ids)
            if include_icon_only:
                self._ensure_icon_index()
                ids = _dedup_preserve_order(ids + list((self._icon_index or {}).keys()))
            return ids

    def get_item(self, item_id: str) -> Optional[Dict[str, Any]]:
        if not item_id:
            return None
        with self._lock:
            v = (self._items or {}).get(str(item_id))
            return dict(v) if isinstance(v, dict) else None

    # ----------------- presentation assets -----------------

    def assets(self, include_icon_only: bool = False) -> Dict[str, Any]:
        """Return presentation assets mapping (shallow copy).

        If include_icon_only=True, merge in icon-index-only entries (name=id) so the
        catalog page can list/search more ids even when catalog assets are sparse.
        """
        with self._lock:
            base = dict(self._assets or {})
            if include_icon_only:
                self._ensure_icon_index()
                for k, png in (self._icon_index or {}).items():
                    if k in base:
                        if png and isinstance(base.get(k), dict):
                            base[k].setdefault("icon", png)
                            base[k].setdefault("image", png)
                        continue
                    base[k] = {"name": k, "icon": png, "image": png, "icon_only": True}
            return base

    def get_asset(self, item_id: str) -> Optional[Dict[str, Any]]:
        if not item_id:
            return None
        with self._lock:
            v = (self._assets or {}).get(str(item_id))
            if not v:
                v = (self._items or {}).get(str(item_id), {}).get("assets")
            return dict(v) if isinstance(v, dict) else None

    # ----------------- load / reload -----------------

    def load(self, force: bool = False) -> bool:
        """Load catalog if changed.

        Returns True if reload occurred.
        """
        with self._lock:
            try:
                mtime = self._path.stat().st_mtime
            except FileNotFoundError as e:
                raise CatalogError(f"Catalog file not found: {self._path}") from e

            if (not force) and self._doc and self._mtime == mtime:
                return False

            doc = self._load_doc()
            self._validate(doc)

            self._doc = doc
            self._meta = doc.get("meta") or {}
            self._mtime = mtime

            self._build_indexes(doc)
            self._load_icon_index_if_stale(force=force)
            self._load_catalog_index_if_stale(force=force)
            return True

    def _load_doc(self) -> Dict[str, Any]:
        if self._use_sqlite:
            return self._load_doc_from_sqlite(self._path)
        return json.loads(self._path.read_text(encoding="utf-8"))

    def _load_doc_from_sqlite(self, path: Path) -> Dict[str, Any]:
        try:
            conn = sqlite3.connect(str(path))
            conn.row_factory = sqlite3.Row
        except Exception as exc:
            raise CatalogError(f"Failed to open SQLite catalog: {path}") from exc
        try:
            cur = conn.cursor()
            meta_rows = {row["key"]: row["value"] for row in cur.execute("SELECT key, value FROM meta")}
            items_rows = cur.execute("SELECT id, data FROM items").fetchall()
            assets_rows = cur.execute("SELECT id, data FROM assets").fetchall()
            craft_rows = cur.execute("SELECT key, data FROM craft").fetchall()
            cooking_rows = cur.execute("SELECT name, data FROM cooking").fetchall()
            tables = {row["name"] for row in cur.execute("SELECT name FROM sqlite_master WHERE type='table'")}
            if "cooking_ingredients" in tables:
                cooking_ingredient_rows = cur.execute("SELECT item_id, data FROM cooking_ingredients").fetchall()
            else:
                cooking_ingredient_rows = []
        except Exception as exc:
            raise CatalogError(f"SQLite catalog missing tables: {path}") from exc
        finally:
            conn.close()

        def _load_json(value: Any) -> Any:
            if value is None:
                return None
            try:
                return json.loads(value)
            except Exception:
                return value

        meta_obj = _load_json(meta_rows.get("meta")) or {}
        stats_obj = _load_json(meta_rows.get("stats")) or {}
        schema_version = _load_json(meta_rows.get("schema_version"))
        if schema_version is None:
            schema_version = (meta_obj or {}).get("schema") or 0

        items = {str(row["id"]): _load_json(row["data"]) for row in items_rows}
        assets = {str(row["id"]): _load_json(row["data"]) for row in assets_rows}
        craft = {str(row["key"]): _load_json(row["data"]) for row in craft_rows}
        cooking = {str(row["name"]): _load_json(row["data"]) for row in cooking_rows}
        cooking_ingredients = {str(row["item_id"]): _load_json(row["data"]) for row in cooking_ingredient_rows}

        return {
            "schema_version": schema_version,
            "meta": meta_obj,
            "items": items,
            "assets": assets,
            "craft": craft,
            "cooking": cooking,
            "cooking_ingredients": cooking_ingredients,
            "stats": stats_obj,
        }

    def _validate(self, doc: Dict[str, Any]) -> None:
        if not isinstance(doc, dict):
            raise CatalogError("Catalog root must be a JSON object")
        if "meta" not in doc:
            raise CatalogError("Catalog missing key: meta")

        if "assets" in doc and not isinstance(doc.get("assets"), dict):
            raise CatalogError("Catalog assets must be an object")

        schema = int(doc.get("schema_version") or (doc.get("meta") or {}).get("schema") or 0)
        if schema < 2:
            raise CatalogError("Catalog schema must be >=2")
        if "items" not in doc or not isinstance(doc.get("items"), dict):
            raise CatalogError("Catalog items must be an object")

        if "craft" not in doc:
            raise CatalogError("Catalog missing key: craft")
        craft = doc.get("craft") or {}
        if "recipes" not in craft or not isinstance(craft.get("recipes"), dict):
            raise CatalogError("Catalog craft.recipes must be an object")

        # cooking is optional, but if present it must be an object.
        if "cooking" in doc and not isinstance(doc.get("cooking"), dict):
            raise CatalogError("Catalog cooking must be an object")
        if "cooking_ingredients" in doc and not isinstance(doc.get("cooking_ingredients"), dict):
            raise CatalogError("Catalog cooking_ingredients must be an object")

    def _build_indexes(self, doc: Dict[str, Any]) -> None:
        assets_obj = doc.get("assets") or {}
        items_obj = doc.get("items") or {}

        items_out: Dict[str, Dict[str, Any]] = {}
        assets_out: Dict[str, Dict[str, Any]] = {}

        if isinstance(items_obj, dict) and items_obj:
            for iid, raw in items_obj.items():
                if not iid:
                    continue
                if isinstance(raw, dict):
                    item = dict(raw)
                else:
                    item = {"id": iid}
                item_id = str(item.get("id") or iid).strip()
                if not item_id:
                    continue
                item["id"] = item_id
                items_out[item_id] = item

        if isinstance(assets_obj, dict):
            for iid, raw in assets_obj.items():
                if not iid or not isinstance(raw, dict):
                    continue
                assets_out[str(iid)] = dict(raw)

        # merge per-item assets into assets_out
        for iid, item in items_out.items():
            a = item.get("assets")
            if not isinstance(a, dict):
                continue
            merged = dict(assets_out.get(iid) or {})
            for k, v in a.items():
                if k not in merged or merged.get(k) in (None, "", []):
                    merged[k] = v
            if merged:
                assets_out[iid] = merged

        self._items = items_out
        self._assets = assets_out

        # ---- item indexes ----
        by_kind: Dict[str, List[str]] = {}
        by_category: Dict[str, List[str]] = {}
        by_behavior: Dict[str, List[str]] = {}
        by_source: Dict[str, List[str]] = {}
        by_component: Dict[str, List[str]] = {}
        by_tag: Dict[str, List[str]] = {}
        by_slot: Dict[str, List[str]] = {}

        def _as_list(val: Any) -> List[str]:
            if isinstance(val, str):
                return [val]
            if isinstance(val, (list, tuple, set)):
                return [str(x) for x in val if x]
            return []

        def _push(bucket: Dict[str, List[str]], key: Optional[str], iid: str) -> None:
            if not key:
                return
            bucket.setdefault(str(key), []).append(iid)

        for iid, item in items_out.items():
            kind = item.get("kind")
            if kind:
                _push(by_kind, str(kind), iid)
            for cat in _as_list(item.get("categories")):
                _push(by_category, cat, iid)
            for beh in _as_list(item.get("behaviors")):
                _push(by_behavior, beh, iid)
            for src in _as_list(item.get("sources")):
                _push(by_source, src, iid)
            for comp in _as_list(item.get("components")):
                _push(by_component, comp, iid)
            for tag in _as_list(item.get("tags")):
                _push(by_tag, tag, iid)
            for slot in _as_list(item.get("slots")):
                _push(by_slot, slot, iid)

        for bucket in (by_kind, by_category, by_behavior, by_source, by_component, by_tag, by_slot):
            for k in list(bucket.keys()):
                bucket[k] = sorted(_dedup_preserve_order(bucket[k]))

        self._item_ids = sorted(items_out.keys())
        self._by_kind = by_kind
        self._by_category = by_category
        self._by_behavior = by_behavior
        self._by_source = by_source
        self._by_component = by_component
        self._by_tag_item = by_tag
        self._by_slot = by_slot

        # ---- craft ----
        craft = doc.get("craft") or {}
        recipes_obj: Dict[str, Any] = craft.get("recipes") or {}
        aliases: Dict[str, str] = craft.get("aliases") or {}
        filter_defs: List[Dict[str, Any]] = craft.get("filter_defs") or []
        filter_order: List[str] = craft.get("filter_order") or []

        recipes: Dict[str, CraftRecipe] = {}
        for name, raw in recipes_obj.items():
            if not isinstance(raw, dict):
                continue

            btags = raw.get("builder_tags") or []
            if isinstance(btags, str):
                btags = [btags]
            btags = [str(x) for x in btags if x]

            rec = CraftRecipe(
                name=str(raw.get("name") or name),
                product=(raw.get("product") or None),
                tab=str(raw.get("tab") or "UNKNOWN"),
                tech=str(raw.get("tech") or "UNKNOWN"),
                filters=[str(x) for x in (raw.get("filters") or []) if x],
                builder_tags=btags,
                builder_skill=(raw.get("builder_skill") or None),
                station_tag=(raw.get("station_tag") or None),
                ingredients=list(raw.get("ingredients") or []),
                ingredients_unresolved=list(raw.get("ingredients_unresolved") or []),
                raw=raw,
            )
            recipes[rec.name] = rec

        # indexes
        by_filter: Dict[str, List[str]] = {}
        by_tab: Dict[str, List[str]] = {}
        by_tag: Dict[str, List[str]] = {}
        by_ing: Dict[str, List[str]] = {}
        by_product: Dict[str, List[str]] = {}

        for rec in recipes.values():
            if rec.product:
                by_product.setdefault(str(rec.product), []).append(rec.name)

            for f in rec.filters:
                by_filter.setdefault(f, []).append(rec.name)

            if rec.tab:
                by_tab.setdefault(rec.tab, []).append(rec.name)

            for t in rec.builder_tags:
                by_tag.setdefault(t, []).append(rec.name)

            for ing in rec.ingredients:
                item = str(ing.get("item") or "").strip()
                if not item:
                    continue
                by_ing.setdefault(item, []).append(rec.name)

        for bucket in (by_filter, by_tab, by_tag, by_ing, by_product):
            for k in list(bucket.keys()):
                bucket[k] = sorted(_dedup_preserve_order(bucket[k]))

        self._recipes = recipes
        self._aliases = {str(k): str(v) for k, v in aliases.items() if k and v}
        self._filter_defs = list(filter_defs)
        self._filter_order = list(filter_order)

        self._by_filter = by_filter
        self._by_tab = by_tab
        self._by_tag = by_tag
        self._by_ingredient = by_ing
        self._by_product = by_product

        # ---- cooking ----
        self._build_cooking_indexes(doc.get("cooking") or {})

    def _build_cooking_indexes(self, cooking_obj: Dict[str, Any]) -> None:
        recipes: Dict[str, CookingRecipe] = {}
        by_tag: Dict[str, List[str]] = {}
        by_ft: Dict[str, List[str]] = {}
        by_ing: Dict[str, List[str]] = {}

        if not isinstance(cooking_obj, dict):
            cooking_obj = {}

        for name, raw in cooking_obj.items():
            if not isinstance(raw, dict):
                continue

            tags = raw.get("tags") or []
            if isinstance(tags, str):
                tags = [tags]
            tags = [str(x) for x in tags if x]

            ci_raw = raw.get("card_ingredients") or []
            card_ings: List[Tuple[str, float]] = []
            if isinstance(ci_raw, list):
                for row in ci_raw:
                    if not isinstance(row, (list, tuple)) or len(row) < 2:
                        continue
                    item = str(row[0]).strip()
                    if not item:
                        continue
                    try:
                        cnt = float(row[1])
                    except Exception:
                        continue
                    if cnt <= 0:
                        continue
                    card_ings.append((item, cnt))

            try:
                priority = float(raw.get("priority", 0))
            except Exception:
                priority = 0.0
            try:
                weight = float(raw.get("weight", 1))
            except Exception:
                weight = 1.0

            ft = raw.get("foodtype")
            foodtype = str(ft).strip() if ft else None

            rec = CookingRecipe(
                name=str(name),
                priority=priority,
                weight=weight,
                foodtype=foodtype,
                hunger=raw.get("hunger"),
                health=raw.get("health"),
                sanity=raw.get("sanity"),
                perishtime=raw.get("perishtime"),
                cooktime=raw.get("cooktime"),
                tags=tags,
                card_ingredients=card_ings,
                raw=raw,
            )
            recipes[rec.name] = rec

            if rec.foodtype:
                by_ft.setdefault(rec.foodtype, []).append(rec.name)

            for t in rec.tags:
                by_tag.setdefault(t, []).append(rec.name)

            for item, _ in rec.card_ingredients:
                by_ing.setdefault(item, []).append(rec.name)

        for bucket in (by_tag, by_ft, by_ing):
            for k in list(bucket.keys()):
                bucket[k] = sorted(_dedup_preserve_order(bucket[k]))

        self._cooking = recipes
        self._cook_by_tag = by_tag
        self._cook_by_foodtype = by_ft
        self._cook_by_ingredient = by_ing

    # ----------------- helpers -----------------

    def _load_icon_index_if_stale(self, force: bool = False) -> None:
        path = self._icon_index_path
        try:
            mtime = path.stat().st_mtime
        except Exception:
            return
        if (not force) and self._icon_index and self._icon_index_mtime == mtime:
            return
        try:
            data = json.loads(path.read_text(encoding="utf-8"))
            icons = data.get("icons") or {}
            mp: Dict[str, str] = {}
            for k, v in icons.items():
                if not k or not isinstance(k, str):
                    continue
                if isinstance(v, dict) and v.get("png"):
                    mp[k] = str(v.get("png"))
            self._icon_index = mp
            self._icon_index_mtime = mtime
        except Exception:
            return

    def _load_catalog_index_if_stale(self, force: bool = False) -> None:
        if self._use_sqlite:
            self._load_catalog_index_from_sqlite(force=force)
            return

        path = self._catalog_index_path
        try:
            mtime = path.stat().st_mtime
        except Exception:
            self._catalog_index_items = []
            self._catalog_index_total = 0
            self._catalog_index_mtime = -1.0
            return
        if (not force) and self._catalog_index_items and self._catalog_index_mtime == mtime:
            return
        try:
            data = json.loads(path.read_text(encoding="utf-8"))
            items = data.get("items") if isinstance(data, dict) else None
            if isinstance(items, list):
                out: List[Dict[str, Any]] = []
                for row in items:
                    if not isinstance(row, dict):
                        continue
                    iid = str(row.get("id") or "").strip()
                    if not iid:
                        continue
                    out.append(dict(row))
                out.sort(key=lambda x: x.get("id") or "")
                self._catalog_index_items = out
                self._catalog_index_total = len(out)
            else:
                self._catalog_index_items = []
                self._catalog_index_total = 0
            self._catalog_index_mtime = mtime
        except Exception:
            return

    def _load_catalog_index_from_sqlite(self, force: bool = False) -> None:
        try:
            mtime = self._path.stat().st_mtime
        except Exception:
            self._catalog_index_items = []
            self._catalog_index_total = 0
            self._catalog_index_mtime = -1.0
            return
        if (not force) and self._catalog_index_items and self._catalog_index_mtime == mtime:
            return
        try:
            conn = sqlite3.connect(str(self._path))
            conn.row_factory = sqlite3.Row
        except Exception:
            return
        try:
            cur = conn.cursor()
            rows = cur.execute(
                """
                SELECT id, name, icon, image, has_icon, icon_only, kind, categories, behaviors, sources, tags, components, slots
                FROM catalog_index
                ORDER BY id
                """
            ).fetchall()
        except Exception:
            self._catalog_index_items = []
            self._catalog_index_total = 0
            self._catalog_index_mtime = mtime
            conn.close()
            return
        finally:
            conn.close()

        def _load_list(value: Any) -> List[str]:
            if value is None:
                return []
            if isinstance(value, list):
                return [str(x) for x in value if x]
            try:
                out = json.loads(value)
                if isinstance(out, list):
                    return [str(x) for x in out if x]
            except Exception:
                pass
            return []

        out: List[Dict[str, Any]] = []
        for row in rows:
            iid = str(row["id"] or "").strip()
            if not iid:
                continue
            out.append(
                {
                    "id": iid,
                    "name": row["name"],
                    "icon": row["icon"],
                    "image": row["image"],
                    "has_icon": bool(row["has_icon"]),
                    "icon_only": bool(row["icon_only"]),
                    "kind": row["kind"],
                    "categories": _load_list(row["categories"]),
                    "behaviors": _load_list(row["behaviors"]),
                    "sources": _load_list(row["sources"]),
                    "tags": _load_list(row["tags"]),
                    "components": _load_list(row["components"]),
                    "slots": _load_list(row["slots"]),
                }
            )
        self._catalog_index_items = out
        self._catalog_index_total = len(out)
        self._catalog_index_mtime = mtime

    def _ensure_icon_index(self) -> None:
        self._load_icon_index_if_stale()

    def catalog_index(self) -> List[Dict[str, Any]]:
        """Compact catalog index for search/listing."""
        items: List[Dict[str, Any]] = []
        with self._lock:
            self._load_catalog_index_if_stale()
            if self._catalog_index_items:
                return list(self._catalog_index_items)
            self._ensure_icon_index()
            ids = list(self._item_ids)
            if not ids and self._assets:
                ids = list(self._assets.keys())
            if self._icon_index:
                ids = _dedup_preserve_order(ids + list(self._icon_index.keys()))

            for iid in ids:
                if not iid:
                    continue
                item = self._items.get(iid) or {}
                asset = (self._assets or {}).get(iid) or item.get("assets") or {}
                name = asset.get("name") or item.get("name") or iid
                icon = asset.get("icon") or asset.get("image") or (self._icon_index or {}).get(iid)
                items.append(
                    {
                        "id": iid,
                        "name": name,
                        "image": asset.get("image") or icon,
                        "icon": icon,
                        "has_icon": bool(icon),
                        "icon_only": bool(iid not in self._items),
                        "kind": item.get("kind"),
                        "categories": item.get("categories") or [],
                        "behaviors": item.get("behaviors") or [],
                        "sources": item.get("sources") or [],
                        "tags": item.get("tags") or [],
                        "components": item.get("components") or [],
                        "slots": item.get("slots") or [],
                    }
                )
        items.sort(key=lambda x: x["id"])
        with self._lock:
            self._catalog_index_items = items
            self._catalog_index_total = len(items)
        return list(items)

    def catalog_index_page(self, *, offset: int = 0, limit: int = 200) -> Tuple[List[Dict[str, Any]], int]:
        """Return a page of catalog index entries and total count."""
        off = max(0, int(offset or 0))
        lim = max(1, min(int(limit or 200), 2000))
        with self._lock:
            self._load_catalog_index_if_stale()
            items = list(self._catalog_index_items) if self._catalog_index_items else self.catalog_index()
            total = self._catalog_index_total or len(items)
        return items[off : off + lim], total

    def catalog_search(
        self,
        q: str,
        *,
        offset: int = 0,
        limit: int = 200,
        name_lookup: Optional[Dict[str, str]] = None,
    ) -> Tuple[List[Dict[str, Any]], int]:
        """Search catalog index entries (id/name/tags/etc).

        name_lookup:
          Optional external name mapping (id -> name) used for extra matching.
        """
        query = str(q or "").strip().lower()
        if not query:
            return [], 0

        def _split_query(text: str) -> Tuple[List[Tuple[str, str]], List[str]]:
            tokens = [t for t in text.split() if t]
            filters: List[Tuple[str, str]] = []
            words: List[str] = []
            for tok in tokens:
                if ":" in tok:
                    k, v = tok.split(":", 1)
                    k = k.strip()
                    v = v.strip()
                    if k and v:
                        filters.append((k, v))
                        continue
                words.append(tok)
            return filters, words

        filters, words = _split_query(query)

        def _as_list(val: Any) -> List[str]:
            if isinstance(val, str):
                return [val]
            if isinstance(val, (list, tuple, set)):
                return [str(x) for x in val if x]
            return []

        def _match_filters(item: Dict[str, Any]) -> bool:
            if not filters:
                return True
            kind = str(item.get("kind") or "").lower()
            cats = [v.lower() for v in _as_list(item.get("categories"))]
            behs = [v.lower() for v in _as_list(item.get("behaviors"))]
            srcs = [v.lower() for v in _as_list(item.get("sources"))]
            tags = [v.lower() for v in _as_list(item.get("tags"))]
            comps = [v.lower() for v in _as_list(item.get("components"))]
            slots = [v.lower() for v in _as_list(item.get("slots"))]

            def _hit(arr: List[str], vals: List[str]) -> bool:
                return any(v in arr for v in vals)

            for key_raw, val_raw in filters:
                key = key_raw.lower()
                vals = [v.strip().lower() for v in val_raw.split(",") if v.strip()]
                if not vals:
                    continue
                if key in ("kind", "type"):
                    if kind not in vals:
                        return False
                elif key in ("cat", "category"):
                    if not _hit(cats, vals):
                        return False
                elif key in ("beh", "behavior"):
                    if not _hit(behs, vals):
                        return False
                elif key in ("src", "source"):
                    if not _hit(srcs, vals):
                        return False
                elif key == "tag":
                    if not _hit(tags, vals):
                        return False
                elif key in ("comp", "component"):
                    if not _hit(comps, vals):
                        return False
                elif key == "slot":
                    if not _hit(slots, vals):
                        return False
            return True

        with self._lock:
            self._load_catalog_index_if_stale()
            items = list(self._catalog_index_items) if self._catalog_index_items else self.catalog_index()

        extra_names: Dict[str, str] = {}
        if name_lookup:
            extra_names = {
                str(k).lower(): str(v).lower()
                for k, v in name_lookup.items()
                if k and v
            }

        scored: List[Tuple[int, str, Dict[str, Any]]] = []
        for item in items:
            if not isinstance(item, dict):
                continue
            if not _match_filters(item):
                continue
            iid_raw = str(item.get("id") or "")
            iid = iid_raw.lower()
            name = str(item.get("name") or "").lower()
            alt = extra_names.get(iid) or extra_names.get(iid_raw.lower(), "")
            score = 0
            if not words:
                score = 1
            else:
                for w in words:
                    if not w:
                        continue
                    if iid == w:
                        score += 1000
                    if iid.startswith(w):
                        score += 200
                    if w in iid:
                        score += 80
                    if w in name:
                        score += 40
                    if alt and w in alt:
                        score += 60
            if score > 0:
                scored.append((score, iid, item))

        scored.sort(key=lambda x: (-x[0], x[1]))
        total = len(scored)
        off = max(0, int(offset or 0))
        lim = max(1, min(int(limit or 200), 2000))
        sliced = [row[2] for row in scored[off : off + lim]]
        return sliced, total

    # ----------------- craft queries -----------------

    def resolve_recipe_name(self, q: str) -> Optional[str]:
        """Resolve query -> canonical recipe name via aliases & exact match (case-insensitive)."""
        if not q:
            return None
        q0 = str(q).strip()
        if not q0:
            return None

        with self._lock:
            if q0 in self._recipes:
                return q0

            if q0 in self._aliases:
                return self._aliases[q0]

            ql = q0.lower()
            for nm in self._recipes.keys():
                if nm.lower() == ql:
                    return nm
            for a, nm in self._aliases.items():
                if a.lower() == ql:
                    return nm

        return None

    def get_recipe(self, q: str) -> Optional[CraftRecipe]:
        name = self.resolve_recipe_name(q)
        if not name:
            return None
        with self._lock:
            return self._recipes.get(name)

    def iter_recipes(self) -> List[CraftRecipe]:
        """Return a snapshot list of all recipes."""
        with self._lock:
            return list(self._recipes.values())

    def list_filters(self) -> Tuple[List[str], List[Dict[str, Any]]]:
        with self._lock:
            return list(self._filter_order), list(self._filter_defs)

    def list_tabs(self) -> List[Dict[str, Any]]:
        """Return ordered tabs with counts.

        Order heuristic:
          - follow filter_order for any matching tab name
          - then append remaining tabs alphabetically
        """
        with self._lock:
            tab_names = set(self._by_tab.keys())
            ordered: List[str] = []
            for f in self._filter_order:
                if f in tab_names and f not in ordered:
                    ordered.append(f)
            ordered += sorted([t for t in tab_names if t not in ordered])
            return [{"name": t, "count": len(self._by_tab.get(t, []))} for t in ordered]

    def list_tags(self) -> List[Dict[str, Any]]:
        with self._lock:
            tags = [{"name": t, "count": len(v)} for t, v in self._by_tag.items()]
        tags.sort(key=lambda x: (-x["count"], x["name"]))
        return tags

    def list_by_filter(self, filter_name: str) -> List[str]:
        with self._lock:
            return list(self._by_filter.get(filter_name, []))

    def list_by_tab(self, tab: str) -> List[str]:
        with self._lock:
            return list(self._by_tab.get(tab, []))

    def list_by_tag(self, tag: str) -> List[str]:
        with self._lock:
            return list(self._by_tag.get(tag, []))

    def list_by_ingredient(self, item: str) -> List[str]:
        with self._lock:
            return list(self._by_ingredient.get(item, []))

    def list_by_product(self, item: str) -> List[str]:
        """List craft recipes whose product equals `item`."""
        key = (item or "").strip()
        if not key:
            return []
        with self._lock:
            return list(self._by_product.get(key, []))

    def search(
        self,
        q: str,
        limit: int = 50,
        name_lookup: Optional[Dict[str, str]] = None,
    ) -> List[Dict[str, Any]]:
        """Search craft recipes.

        Supported prefixes:
          - ing:<item>
          - tag:<builder_tag>
          - filter:<FILTER>
          - tab:<TAB>

        Otherwise:
          - substring match on recipe name or product
        """
        q = (q or "").strip()
        if not q:
            return []

        limit = max(1, min(int(limit or 50), 500))
        ql = q.lower()

        extra_names: Dict[str, str] = {}
        if name_lookup:
            extra_names = {
                str(k).lower(): str(v).lower()
                for k, v in name_lookup.items()
                if k and v
            }

        with self._lock:
            for prefix in ("ing:", "tag:", "filter:", "tab:"):
                if ql.startswith(prefix):
                    val = q[len(prefix) :].strip()
                    if not val:
                        return []
                    if prefix == "ing:":
                        names = self._by_ingredient.get(val, [])
                    elif prefix == "tag:":
                        names = self._by_tag.get(val, [])
                    elif prefix == "filter:":
                        names = self._by_filter.get(val, [])
                    else:
                        names = self._by_tab.get(val, [])
                    return [self._recipe_brief(nm) for nm in names[:limit]]

            nm = self.resolve_recipe_name(q)
            if nm:
                return [self._recipe_brief(nm)]

            if not extra_names:
                hits: List[str] = []
                for nm2, rec in self._recipes.items():
                    if ql in nm2.lower() or (rec.product and ql in str(rec.product).lower()):
                        hits.append(nm2)
                        if len(hits) >= limit:
                            break
                return [self._recipe_brief(nm2) for nm2 in hits]

            scored: List[Tuple[int, str]] = []
            for nm2, rec in self._recipes.items():
                nm2l = nm2.lower()
                prod = str(rec.product or "").lower()
                alt_nm = extra_names.get(nm2l) or ""
                alt_prod = extra_names.get(prod) if prod else ""
                score = 0
                if nm2l == ql:
                    score += 400
                elif nm2l.startswith(ql):
                    score += 200
                elif ql in nm2l:
                    score += 80
                if prod:
                    if prod == ql:
                        score += 120
                    elif prod.startswith(ql):
                        score += 60
                    elif ql in prod:
                        score += 20
                if alt_nm:
                    idx = alt_nm.find(ql)
                    if idx >= 0:
                        score += 120
                        if idx == 0:
                            score += 60
                        if len(alt_nm) == len(ql):
                            score += 40
                if alt_prod:
                    idx = alt_prod.find(ql)
                    if idx >= 0:
                        score += 60
                        if idx == 0:
                            score += 30
                        if len(alt_prod) == len(ql):
                            score += 20
                if score > 0:
                    scored.append((score, nm2))

            scored.sort(key=lambda x: (-x[0], x[1]))
            return [self._recipe_brief(nm2) for _, nm2 in scored[:limit]]

    def _recipe_brief(self, name: str) -> Dict[str, Any]:
        rec = self._recipes.get(name)
        if not rec:
            return {"name": name}
        return {
            "name": rec.name,
            "product": rec.product,
            "tab": rec.tab,
            "tech": rec.tech,
            "filters": rec.filters,
            "builder_tags": rec.builder_tags,
            "builder_skill": rec.builder_skill,
            "station_tag": rec.station_tag,
        }

    # ----------------- cooking queries -----------------

    def resolve_cooking_name(self, q: str) -> Optional[str]:
        if not q:
            return None
        q0 = str(q).strip()
        if not q0:
            return None

        with self._lock:
            if q0 in self._cooking:
                return q0

            ql = q0.lower()
            for nm in self._cooking.keys():
                if nm.lower() == ql:
                    return nm

        return None

    def get_cooking_recipe(self, q: str) -> Optional[CookingRecipe]:
        nm = self.resolve_cooking_name(q)
        if not nm:
            return None
        with self._lock:
            return self._cooking.get(nm)

    def iter_cooking_recipes(self) -> List[CookingRecipe]:
        with self._lock:
            return list(self._cooking.values())

    def list_cooking_foodtypes(self) -> List[Dict[str, Any]]:
        with self._lock:
            items = [{"name": ft, "count": len(v)} for ft, v in self._cook_by_foodtype.items()]
        items.sort(key=lambda x: (-x["count"], x["name"]))
        return items

    def list_cooking_tags(self) -> List[Dict[str, Any]]:
        with self._lock:
            items = [{"name": t, "count": len(v)} for t, v in self._cook_by_tag.items()]
        items.sort(key=lambda x: (-x["count"], x["name"]))
        return items

    def list_cooking_by_foodtype(self, foodtype: str) -> List[str]:
        with self._lock:
            return list(self._cook_by_foodtype.get(foodtype, []))

    def list_cooking_by_tag(self, tag: str) -> List[str]:
        with self._lock:
            return list(self._cook_by_tag.get(tag, []))

    def list_cooking_by_ingredient(self, item: str) -> List[str]:
        with self._lock:
            return list(self._cook_by_ingredient.get(item, []))

    def search_cooking(
        self,
        q: str,
        limit: int = 50,
        name_lookup: Optional[Dict[str, str]] = None,
    ) -> List[Dict[str, Any]]:
        """Search cooking recipes.

        Supported prefixes:
          - ing:<item>      (uses card_ingredients index; may be incomplete)
          - tag:<tag>      (food tags)
          - type:<FOODTYPE.*> or foodtype:<FOODTYPE.*>

        Otherwise: substring match on recipe name.
        """
        q = (q or "").strip()
        if not q:
            return []

        limit = max(1, min(int(limit or 50), 500))
        ql = q.lower()

        extra_names: Dict[str, str] = {}
        if name_lookup:
            extra_names = {
                str(k).lower(): str(v).lower()
                for k, v in name_lookup.items()
                if k and v
            }

        with self._lock:
            for prefix in ("ing:", "tag:", "type:", "foodtype:"):
                if ql.startswith(prefix):
                    val = q[len(prefix) :].strip()
                    if not val:
                        return []
                    if prefix == "ing:":
                        names = self._cook_by_ingredient.get(val, [])
                    elif prefix == "tag:":
                        names = self._cook_by_tag.get(val, [])
                    else:
                        names = self._cook_by_foodtype.get(val, [])
                    return [{"name": nm} for nm in names[:limit]]

            nm = self.resolve_cooking_name(q)
            if nm:
                return [{"name": nm}]

            if not extra_names:
                hits: List[str] = []
                for nm2 in self._cooking.keys():
                    if ql in nm2.lower():
                        hits.append(nm2)
                        if len(hits) >= limit:
                            break
                return [{"name": nm2} for nm2 in hits]

            scored: List[Tuple[int, str]] = []
            for nm2 in self._cooking.keys():
                nm2l = nm2.lower()
                alt = extra_names.get(nm2l) or ""
                score = 0
                if nm2l == ql:
                    score += 200
                elif nm2l.startswith(ql):
                    score += 120
                elif ql in nm2l:
                    score += 60
                if alt:
                    idx = alt.find(ql)
                    if idx >= 0:
                        score += 120
                        if idx == 0:
                            score += 60
                        if len(alt) == len(ql):
                            score += 40
                if score > 0:
                    scored.append((score, nm2))

            scored.sort(key=lambda x: (-x[0], x[1]))
            return [{"name": nm2} for _, nm2 in scored[:limit]]
```

### File: apps/webcraft/cooking_planner.py
- mode: full
- size_bytes: 4276
- sha256_12: bd00afb78bbe

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

from .catalog_store import CookingRecipe


def normalize_counts(inv: Dict[str, Any]) -> Dict[str, float]:
    """Normalize item->count mapping.

    - Keys are stripped strings.
    - Values must be numeric and > 0.

    This helper is shared by:
      - cookable query (inventory)
      - simulator (cookpot slots)
    """

    out: Dict[str, float] = {}
    for k, v in (inv or {}).items():
        key = str(k).strip()
        if not key:
            continue
        try:
            num = float(v)
        except Exception:
            continue
        if num <= 0:
            continue
        out[key] = num
    return out


def _requirements_satisfied(req: List[Tuple[str, float]], available: Dict[str, float]) -> bool:
    """Check if `available` contains all `req` items with required counts."""
    for item, need in (req or []):
        if not item:
            continue
        have = float(available.get(item, 0.0))
        if have + 1e-9 < float(need):
            return False
    return True


def find_cookable(
    recipes: List[CookingRecipe],
    inventory: Dict[str, Any],
    *,
    limit: int = 200,
) -> List[CookingRecipe]:
    """Find cookable recipes based on catalog `card_ingredients`.

    Current limitation
    - Only recipes with `card_ingredients` can be evaluated.
    """

    inv = normalize_counts(inventory)
    limit = max(1, min(int(limit or 200), 2000))

    out: List[CookingRecipe] = []
    for r in recipes:
        if not r.card_ingredients:
            continue
        if _requirements_satisfied(r.card_ingredients, inv):
            out.append(r)

    # Stable order: higher priority first, then name.
    out.sort(key=lambda x: (-float(x.priority), x.name))
    return out[:limit]


@dataclass(frozen=True)
class SimCandidate:
    name: str
    priority: float
    weight: float


def simulate_cookpot(
    recipes: List[CookingRecipe],
    slots: Dict[str, Any],
    *,
    return_top: int = 25,
) -> Dict[str, Any]:
    """Simulate cookpot output using catalog `card_ingredients`.

    Input
    - slots: mapping of item -> count placed into the pot.

    Behavior
    - Requires total slot count == 4 (cookpot rule).
    - Only evaluates recipes that have `card_ingredients`.
    - If multiple match, choose the highest priority; tie-break by weight then name.
    - If none match, fall back to 'wetgoop' if present in recipe list.

    Returns a dict suitable for JSON response.
    """

    counts = normalize_counts(slots)
    total = sum(int(round(v)) for v in counts.values())
    if total != 4:
        return {
            "ok": False,
            "error": "cookpot_requires_4_items",
            "total": total,
            "slots": {k: int(round(v)) for k, v in counts.items()},
        }

    # int-normalize (cookpot is discrete)
    slots_i: Dict[str, int] = {}
    for k, v in counts.items():
        n = int(round(v))
        if n <= 0:
            continue
        slots_i[k] = slots_i.get(k, 0) + n

    candidates: List[CookingRecipe] = []
    for r in recipes:
        if not r.card_ingredients:
            continue
        if _requirements_satisfied(r.card_ingredients, {k: float(v) for k, v in slots_i.items()}):
            candidates.append(r)

    if candidates:
        candidates.sort(key=lambda x: (-float(x.priority), -float(x.weight), x.name))
        best = candidates[0]
        top = [SimCandidate(name=r.name, priority=float(r.priority), weight=float(r.weight)) for r in candidates[:return_top]]
        return {
            "ok": True,
            "result": best.name,
            "reason": "matched_card_ingredients",
            "candidates": [c.__dict__ for c in top],
            "slots": slots_i,
        }

    # fallback
    wet = next((r for r in recipes if r.name == "wetgoop"), None)
    if wet is not None:
        return {
            "ok": True,
            "result": "wetgoop",
            "reason": "fallback_wetgoop",
            "candidates": [],
            "slots": slots_i,
        }

    return {
        "ok": False,
        "error": "no_match_and_no_wetgoop",
        "candidates": [],
        "slots": slots_i,
    }
```

### File: apps/webcraft/i18n_index.py
- mode: full
- size_bytes: 3476
- sha256_12: 98b97123f865

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

import json
import threading
from pathlib import Path
from typing import Any, Dict, List, Optional


class I18nIndexStore:
    """Load + query i18n index JSON (thread-safe)."""

    def __init__(self, path: Path):
        self._path = Path(path)
        self._lock = threading.RLock()
        self._mtime: float = -1.0
        self._doc: Dict[str, Any] = {}
        self.load(force=True)

    @property
    def path(self) -> Path:
        return self._path

    def mtime(self) -> float:
        with self._lock:
            return float(self._mtime or 0)

    def load(self, force: bool = False) -> bool:
        """Load index file if changed. Returns True if reload occurred."""
        with self._lock:
            if not self._path.exists():
                self._doc = {}
                self._mtime = -1.0
                return False
            try:
                mtime = self._path.stat().st_mtime
            except Exception:
                return False
            if (not force) and self._doc and self._mtime == mtime:
                return False
            try:
                doc = json.loads(self._path.read_text(encoding="utf-8"))
            except Exception:
                doc = {}
            self._doc = doc if isinstance(doc, dict) else {}
            self._mtime = mtime
            return True

    def meta(self) -> Dict[str, Any]:
        with self._lock:
            return dict(self._doc.get("meta") or {})

    def langs(self) -> List[str]:
        with self._lock:
            langs = self._doc.get("langs")
            if isinstance(langs, list) and langs:
                return sorted({str(x) for x in langs if x})
            names = self._doc.get("names") or {}
            if isinstance(names, dict):
                return sorted({str(k) for k, v in names.items() if k and isinstance(v, dict) and v})
            return []

    def ui_langs(self) -> List[str]:
        with self._lock:
            ui = self._doc.get("ui") or {}
            if isinstance(ui, dict):
                return sorted({str(k) for k, v in ui.items() if k and isinstance(v, dict) and v})
            return []

    def names(self, lang: str) -> Dict[str, str]:
        l = str(lang or "").strip().lower()
        if not l:
            return {}
        with self._lock:
            names = (self._doc.get("names") or {}).get(l) if isinstance(self._doc.get("names"), dict) else None
            if not isinstance(names, dict):
                return {}
            return {str(k): str(v) for k, v in names.items() if k and v}

    def ui_strings(self, lang: str) -> Dict[str, str]:
        l = str(lang or "").strip().lower()
        if not l:
            return {}
        with self._lock:
            ui = (self._doc.get("ui") or {}).get(l) if isinstance(self._doc.get("ui"), dict) else None
            if not isinstance(ui, dict):
                return {}
            return {str(k): str(v) for k, v in ui.items() if k and v}

    def public_meta(self) -> Dict[str, Any]:
        name_langs = self.langs()
        return {
            "enabled": bool(name_langs),
            "langs": name_langs,
            "ui_langs": self.ui_langs(),
            "modes": ["en", "zh", "id"],
            "default_mode": "en",
        }

    def count_names(self, lang: str) -> int:
        return len(self.names(lang))

    def count_ui(self, lang: str) -> int:
        return len(self.ui_strings(lang))
```

### File: apps/webcraft/i18n_service.py
- mode: full
- size_bytes: 26143
- sha256_12: 28951d7fce69

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

import hashlib
import json
import os
import threading
import zipfile
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, Optional, Tuple, List


# ----------------------------
# Minimal PO parser (DST)
# ----------------------------


def _po_unquote(s: str) -> str:
    """Unquote a PO string literal line segment.

    PO strings use C-like escapes. We implement a small, predictable subset.
    """

    s = (s or "").strip()
    if not (s.startswith('"') and s.endswith('"')):
        return ""
    inner = s[1:-1]
    out: List[str] = []
    i = 0
    while i < len(inner):
        ch = inner[i]
        if ch == "\\" and i + 1 < len(inner):
            nxt = inner[i + 1]
            if nxt == "n":
                out.append("\n")
            elif nxt == "t":
                out.append("\t")
            elif nxt == "r":
                out.append("\r")
            elif nxt == '"':
                out.append('"')
            elif nxt == "\\":
                out.append("\\")
            else:
                # Best-effort: keep the escaped char
                out.append(nxt)
            i += 2
            continue
        out.append(ch)
        i += 1
    return "".join(out)


def parse_po(text: str) -> Dict[str, str]:
    """Parse a PO file and return mapping: msgctxt -> msgstr.

    Notes
    - We only keep entries with non-empty msgctxt and msgstr.
    - For plural forms, we only take msgstr[0].
    """

    lines = (text or "").splitlines()
    cur: Dict[str, Any] = {}
    last_key: Optional[str] = None
    out: Dict[str, str] = {}

    def commit() -> None:
        nonlocal cur, last_key
        ctx = cur.get("msgctxt")
        msgstr = cur.get("msgstr")
        if isinstance(ctx, str) and ctx and isinstance(msgstr, str) and msgstr:
            out[ctx] = msgstr
        cur = {}
        last_key = None

    for raw in lines:
        line = raw.rstrip("\n")
        s = line.strip()
        if not s:
            commit()
            continue
        if s.startswith("#"):
            continue

        if s.startswith("msgctxt "):
            cur["msgctxt"] = _po_unquote(s[len("msgctxt ") :].strip())
            last_key = "msgctxt"
            continue

        if s.startswith("msgid "):
            # keep for state tracking (and multiline), though we don't use it in output
            cur["msgid"] = _po_unquote(s[len("msgid ") :].strip())
            last_key = "msgid"
            continue

        if s.startswith("msgid_plural "):
            cur["msgid_plural"] = _po_unquote(s[len("msgid_plural ") :].strip())
            last_key = "msgid_plural"
            continue

        if s.startswith("msgstr["):
            # msgstr[0] "..."
            rb = s.find("]")
            idx_s = s[len("msgstr[") : rb].strip() if rb != -1 else ""
            try:
                idx = int(idx_s)
            except Exception:
                idx = -1
            if idx == 0:
                # only take msgstr[0]
                rest = s[rb + 1 :].strip() if rb != -1 else ""
                cur["msgstr"] = _po_unquote(rest)
                last_key = "msgstr"
            else:
                last_key = None
            continue

        if s.startswith("msgstr "):
            cur["msgstr"] = _po_unquote(s[len("msgstr ") :].strip())
            last_key = "msgstr"
            continue

        if s.startswith('"') and last_key:
            # multiline continuation
            cur[last_key] = str(cur.get(last_key) or "") + _po_unquote(s)
            continue

    commit()
    return out


# ----------------------------
# I18n service
# ----------------------------

_NAMES_PREFIX = "STRINGS.NAMES."

# Optional override via environment variable:
# - If set, it takes precedence over engine-mounted scripts source.
_ENV_LANG_PO = {
    "zh": ("WAGSTAFF_PO_ZH", "WAGSTAFF_ZH_PO"),
}

# Default DST language pack locations inside scripts source (zip/folder).
# NOTE: When mounted via WagstaffEngine, both "scripts/..." and "..." may be accepted,
# but we keep explicit candidates to avoid relying on internal normalization.
_ENGINE_PO_CANDIDATES: Dict[str, List[str]] = {
    "zh": [
        "scripts/languages/chinese_s.po",
        "languages/chinese_s.po",
    ],
}


def _norm_lang(lang: str) -> str:
    return str(lang or "").strip().lower()


def _items_sig(item_ids: Iterable[str]) -> str:
    """Stable signature for item ids."""

    keys = sorted([str(k) for k in (item_ids or []) if k])
    h = hashlib.sha1()
    for k in keys:
        h.update(k.encode("utf-8", errors="ignore"))
        h.update(b"\n")
    return f"items:{len(keys)}:{h.hexdigest()}"


def _atomic_write_text(path: Path, text: str) -> bool:
    try:
        path.parent.mkdir(parents=True, exist_ok=True)
    except Exception:
        pass

    tmp = path.with_suffix(path.suffix + ".tmp")
    try:
        tmp.write_text(text, encoding="utf-8")
        tmp.replace(path)
        return True
    except Exception:
        try:
            if tmp.exists():
                tmp.unlink()
        except Exception:
            pass
        return False


@dataclass(frozen=True)
class I18nConfig:
    """Runtime i18n configuration.

    lang_to_po:
      - {lang: path_to_po} for external overrides (optional).

    The PO file is expected to contain msgctxt entries like:
      STRINGS.NAMES.AXE
    """

    lang_to_po: Dict[str, Path] = field(default_factory=dict)

    @staticmethod
    def from_env(*, extra: Optional[Dict[str, Path]] = None) -> "I18nConfig":
        mp: Dict[str, Path] = {}

        for lang, keys in _ENV_LANG_PO.items():
            for k in keys:
                v = os.environ.get(k)
                if not v:
                    continue
                p = Path(v).expanduser()
                if p.exists() and p.is_file():
                    mp[_norm_lang(lang)] = p
                    break

        for k, v in (extra or {}).items():
            kk = _norm_lang(str(k))
            if not kk or not v:
                continue
            p2 = Path(v).expanduser()
            if p2.exists() and p2.is_file():
                mp[kk] = p2

        return I18nConfig(lang_to_po=mp)


@dataclass(frozen=True)
class _PoSource:
    kind: str  # 'file' | 'engine' | 'zip'
    file_path: Optional[Path] = None
    engine: Any = None
    zip_path: Optional[Path] = None
    inner_path: Optional[str] = None


class I18nService:
    """Load PO translations and expose item-name translation maps.

    Key behavior
    - Prefer explicit external PO path (env/config)
    - Else try analyzer engine (mounted scripts source)
    - Else try catalog's scripts.zip hint (store.meta['scripts_zip'])
    - Optionally cache compiled id->name mapping to static_dir (served under /static)

    Design goals
    - Keep i18n concerns isolated from CatalogStore.
    - Work even when analyzer engine mounts a "no language" scripts bundle.
    - Keep runtime fast by compiling once and reusing a static JSON.
    """

    def __init__(
        self,
        cfg: I18nConfig,
        *,
        engine: Any = None,
        static_dir: Optional[Path] = None,
        scripts_zip_hint: Optional[str] = None,
        encoding: str = "utf-8",
    ):
        self.cfg = cfg
        self.engine = engine
        self.scripts_zip_hint = str(scripts_zip_hint) if scripts_zip_hint else None
        self.encoding = str(encoding or "utf-8")

        self.static_dir: Optional[Path] = None
        if static_dir is not None:
            try:
                sd = Path(static_dir).expanduser().resolve()
                sd.mkdir(parents=True, exist_ok=True)
                self.static_dir = sd
            except Exception:
                self.static_dir = None

        self._lock = threading.RLock()

        # Raw name cache: lang -> (po_sig, {normalized_key -> zh_name})
        self._raw_cache: Dict[str, Tuple[str, Dict[str, str]]] = {}

        # Item mapping cache: lang -> (assets_sig, po_sig_or_none, {item_id -> name})
        self._item_cache: Dict[str, Tuple[str, Optional[str], Dict[str, str]]] = {}

    # ----------------------------
    # Engine helpers
    # ----------------------------

    def _engine_has(self, eng: Any, inner_path: str) -> bool:
        """Check whether an inner path exists in the mounted scripts source."""

        if eng is None or not inner_path:
            return False

        mode = str(getattr(eng, "mode", "") or "").lower()
        src = getattr(eng, "source", None)

        if mode == "zip" and src is not None and hasattr(src, "getinfo"):
            try:
                src.getinfo(inner_path)
                return True
            except Exception:
                return False

        if mode == "folder":
            base = getattr(eng, "source", None)
            if isinstance(base, str) and base:
                rel = inner_path
                if rel.startswith("scripts/"):
                    rel = rel.replace("scripts/", "", 1)
                p = Path(base) / rel
                return p.exists() and p.is_file()

        # Fallback: best-effort by trying to read.
        try:
            rf = getattr(eng, "read_file", None)
            if callable(rf):
                return rf(inner_path) is not None
        except Exception:
            return False

        return False

    def _resolve_engine_po_path(self, eng: Any, lang: str) -> Optional[str]:
        cand = _ENGINE_PO_CANDIDATES.get(lang) or []
        for p in cand:
            if self._engine_has(eng, p):
                return p
        return None

    def _engine_source_sig(self, eng: Any, inner_path: str) -> str:
        """Compute a cache signature for a PO file loaded from engine."""

        mode = str(getattr(eng, "mode", "") or "").lower()
        src = getattr(eng, "source", None)

        if mode == "zip" and src is not None:
            zip_path = str(getattr(src, "filename", "") or "")
            zip_mtime = 0.0
            zip_size = 0
            try:
                st = Path(zip_path).stat()
                zip_mtime = float(st.st_mtime)
                zip_size = int(st.st_size)
            except Exception:
                pass

            crc = -1
            fsz = -1
            dt = None
            try:
                info = src.getinfo(inner_path) if hasattr(src, "getinfo") else None
                if info is not None:
                    crc = int(getattr(info, "CRC", -1))
                    fsz = int(getattr(info, "file_size", -1))
                    dt = getattr(info, "date_time", None)
            except Exception:
                pass

            return f"enginezip:{zip_path}:{zip_mtime}:{zip_size}:{inner_path}:{crc}:{fsz}:{dt}"

        if mode == "folder":
            base = getattr(eng, "source", None)
            rel = inner_path
            if rel.startswith("scripts/"):
                rel = rel.replace("scripts/", "", 1)
            try:
                p = Path(str(base)) / rel
                st = p.stat()
                return f"enginefolder:{p}:{float(st.st_mtime)}:{int(st.st_size)}"
            except Exception:
                return f"enginefolder:{base}:{inner_path}"

        return f"engine:{id(eng)}:{inner_path}"

    # ----------------------------
    # scripts.zip (hint) helpers
    # ----------------------------

    @staticmethod
    def _zip_has(z: zipfile.ZipFile, inner: str) -> bool:
        try:
            z.getinfo(inner)
            return True
        except Exception:
            return False

    def _resolve_zip_po_path(self, zip_path: Path, lang: str) -> Optional[str]:
        cand = _ENGINE_PO_CANDIDATES.get(lang) or []
        if not cand:
            return None
        try:
            with zipfile.ZipFile(str(zip_path), "r") as z:
                for p in cand:
                    if self._zip_has(z, p):
                        return p
        except Exception:
            return None
        return None

    def _zip_source_sig(self, zip_path: Path, inner_path: str) -> str:
        zip_mtime = 0.0
        zip_size = 0
        try:
            st = Path(zip_path).stat()
            zip_mtime = float(st.st_mtime)
            zip_size = int(st.st_size)
        except Exception:
            pass

        crc = -1
        fsz = -1
        dt = None
        try:
            with zipfile.ZipFile(str(zip_path), "r") as z:
                info = z.getinfo(inner_path)
                crc = int(getattr(info, "CRC", -1))
                fsz = int(getattr(info, "file_size", -1))
                dt = getattr(info, "date_time", None)
        except Exception:
            pass

        return f"zipfile:{zip_path}:{zip_mtime}:{zip_size}:{inner_path}:{crc}:{fsz}:{dt}"

    # ----------------------------
    # Compiled static mapping helpers
    # ----------------------------

    def _compiled_path(self, lang: str) -> Optional[Path]:
        if self.static_dir is None:
            return None
        l = _norm_lang(lang)
        if not l:
            return None
        return self.static_dir / f"names_{l}.json"

    def _read_compiled(self, lang: str) -> Tuple[Optional[str], Optional[str], Dict[str, str]]:
        """Return (po_sig, assets_sig, names) from compiled file."""

        p = self._compiled_path(lang)
        if p is None or not p.exists() or not p.is_file():
            return (None, None, {})

        try:
            doc = json.loads(p.read_text(encoding="utf-8", errors="replace"))
        except Exception:
            return (None, None, {})

        # Backward-compatible: allow file to be just a dict of names.
        if isinstance(doc, dict) and "names" in doc:
            names = doc.get("names")
            if not isinstance(names, dict):
                names = {}
            return (
                str(doc.get("po_sig") or "") or None,
                str(doc.get("assets_sig") or "") or None,
                {str(k): str(v) for k, v in (names or {}).items() if k and v},
            )

        if isinstance(doc, dict):
            return (None, None, {str(k): str(v) for k, v in doc.items() if k and v})

        return (None, None, {})

    def _write_compiled(self, *, lang: str, po_sig: Optional[str], assets_sig: str, names: Dict[str, str]) -> None:
        p = self._compiled_path(lang)
        if p is None:
            return

        doc = {
            "lang": _norm_lang(lang),
            "po_sig": str(po_sig or "") or None,
            "assets_sig": str(assets_sig or ""),
            "count": int(len(names or {})),
            "names": dict(names or {}),
        }
        txt = json.dumps(doc, ensure_ascii=False, separators=(",", ":"))
        _atomic_write_text(p, txt)

    # ----------------------------
    # PO source resolving
    # ----------------------------

    def _resolve_po_source(
        self,
        *,
        lang: str,
        engine: Any = None,
        scripts_zip_hint: Optional[str] = None,
    ) -> Optional[_PoSource]:
        l = _norm_lang(lang)
        if not l:
            return None

        # 1) External override: explicit path.
        p = (self.cfg.lang_to_po or {}).get(l)
        if p:
            try:
                if p.exists() and p.is_file():
                    return _PoSource(kind="file", file_path=p)
            except Exception:
                pass

        # 2) Engine-mounted scripts source.
        eng = engine if engine is not None else self.engine
        if eng is not None:
            inner = self._resolve_engine_po_path(eng, l)
            if inner:
                return _PoSource(kind="engine", engine=eng, inner_path=inner)

        # 3) Catalog-provided scripts.zip hint (usually DST's scripts.zip with languages).
        hint = str(scripts_zip_hint or self.scripts_zip_hint or "").strip()
        if hint:
            zp = Path(hint).expanduser()
            try:
                if zp.exists() and zp.is_file():
                    inner2 = self._resolve_zip_po_path(zp, l)
                    if inner2:
                        return _PoSource(kind="zip", zip_path=zp, inner_path=inner2)
            except Exception:
                pass

        return None

    def _po_sig(self, *, lang: str, engine: Any = None, scripts_zip_hint: Optional[str] = None) -> Optional[str]:
        src = self._resolve_po_source(lang=lang, engine=engine, scripts_zip_hint=scripts_zip_hint)
        if src is None:
            return None

        if src.kind == "file" and src.file_path is not None:
            try:
                st = src.file_path.stat()
                return f"file:{src.file_path}:{float(st.st_mtime)}:{int(st.st_size)}"
            except Exception:
                return None

        if src.kind == "engine" and src.engine is not None and src.inner_path:
            try:
                return self._engine_source_sig(src.engine, src.inner_path)
            except Exception:
                return None

        if src.kind == "zip" and src.zip_path is not None and src.inner_path:
            try:
                return self._zip_source_sig(src.zip_path, src.inner_path)
            except Exception:
                return None

        return None

    def _read_po_text(
        self,
        *,
        lang: str,
        engine: Any = None,
        scripts_zip_hint: Optional[str] = None,
    ) -> Tuple[Optional[str], Optional[str]]:
        """Return (po_sig, po_text)."""

        src = self._resolve_po_source(lang=lang, engine=engine, scripts_zip_hint=scripts_zip_hint)
        if src is None:
            return (None, None)

        sig = self._po_sig(lang=lang, engine=engine, scripts_zip_hint=scripts_zip_hint)

        if src.kind == "file" and src.file_path is not None:
            try:
                txt = src.file_path.read_text(encoding=self.encoding, errors="replace")
                return (sig, txt)
            except Exception:
                return (None, None)

        if src.kind == "engine" and src.engine is not None and src.inner_path:
            try:
                rf = getattr(src.engine, "read_file", None)
                txt = rf(src.inner_path) if callable(rf) else None
                if isinstance(txt, bytes):
                    try:
                        txt = txt.decode(self.encoding, errors="replace")
                    except Exception:
                        txt = txt.decode("utf-8", errors="replace")
                if not txt:
                    return (None, None)
                return (sig, str(txt))
            except Exception:
                return (None, None)

        if src.kind == "zip" and src.zip_path is not None and src.inner_path:
            try:
                with zipfile.ZipFile(str(src.zip_path), "r") as z:
                    data = z.read(src.inner_path)
                try:
                    txt2 = data.decode(self.encoding, errors="replace")
                except Exception:
                    txt2 = data.decode("utf-8", errors="replace")
                return (sig, txt2)
            except Exception:
                return (None, None)

        return (None, None)

    # ----------------------------
    # Public API
    # ----------------------------

    def available_langs(self, *, engine: Any = None, scripts_zip_hint: Optional[str] = None) -> List[str]:
        eng = engine if engine is not None else self.engine
        langs: List[str] = []

        # 1) Config-provided overrides
        for k in (self.cfg.lang_to_po or {}).keys():
            kk = _norm_lang(str(k))
            if kk and kk not in langs:
                langs.append(kk)

        # 2) Compiled static files
        for k in _ENGINE_PO_CANDIDATES.keys():
            kk = _norm_lang(str(k))
            if not kk or kk in langs:
                continue
            p = self._compiled_path(kk)
            if p is not None and p.exists():
                # only enable if it has some names
                _, _, mp = self._read_compiled(kk)
                if mp:
                    langs.append(kk)

        # 3) Engine-provided defaults
        for k in _ENGINE_PO_CANDIDATES.keys():
            kk = _norm_lang(str(k))
            if not kk or kk in langs:
                continue
            if eng is not None and self._resolve_engine_po_path(eng, kk):
                langs.append(kk)

        # 4) scripts.zip hint
        hint = str(scripts_zip_hint or self.scripts_zip_hint or "").strip()
        if hint:
            zp = Path(hint).expanduser()
            for k in _ENGINE_PO_CANDIDATES.keys():
                kk = _norm_lang(str(k))
                if not kk or kk in langs:
                    continue
                try:
                    if zp.exists() and zp.is_file() and self._resolve_zip_po_path(zp, kk):
                        langs.append(kk)
                except Exception:
                    continue

        langs.sort()
        return langs

    def public_meta(self, *, engine: Any = None, scripts_zip_hint: Optional[str] = None) -> Dict[str, Any]:
        langs = self.available_langs(engine=engine, scripts_zip_hint=scripts_zip_hint)
        return {
            "enabled": bool(langs),
            "langs": langs,
            "modes": ["en", "zh", "id"],
            "default_mode": "en",
        }

    def _load_names_raw(self, lang: str, *, engine: Any = None, scripts_zip_hint: Optional[str] = None) -> Tuple[Optional[str], Dict[str, str]]:
        """Return (po_sig, {normalized_key -> localized_name})."""

        l = _norm_lang(lang)
        if not l:
            return (None, {})

        sig, txt = self._read_po_text(lang=l, engine=engine, scripts_zip_hint=scripts_zip_hint)
        if not sig or not txt:
            return (None, {})

        with self._lock:
            cached = self._raw_cache.get(l)
            if cached and str(cached[0]) == str(sig):
                return (str(sig), dict(cached[1]))

        ctx_map = parse_po(txt)
        names: Dict[str, str] = {}
        for ctx, val in ctx_map.items():
            if not isinstance(ctx, str) or not ctx.startswith(_NAMES_PREFIX):
                continue
            key = ctx[len(_NAMES_PREFIX) :].strip()
            if not key:
                continue
            kid = key.strip().lower()
            if not kid:
                continue
            v = str(val).strip()
            if not v:
                continue
            names[kid] = v
            # Common alt-id: strip underscores
            if "_" in kid:
                names.setdefault(kid.replace("_", ""), v)

        with self._lock:
            self._raw_cache[l] = (str(sig), dict(names))

        return (str(sig), dict(names))

    def item_name_map(
        self,
        *,
        lang: str,
        assets: Dict[str, Any],
        item_ids: Optional[Iterable[str]] = None,
        engine: Any = None,
        scripts_zip_hint: Optional[str] = None,
    ) -> Dict[str, str]:
        """Build {item_id: localized_name} for item ids.

        If static_dir is configured, it will also compile/cache the mapping as:
          <static_dir>/names_<lang>.json
        """

        l = _norm_lang(lang)
        if not l or l in ("en", "id"):
            return {}

        ids = list(item_ids) if item_ids is not None else list((assets or {}).keys())
        aset_sig = _items_sig(ids)

        with self._lock:
            ic = self._item_cache.get(l)
            if ic and str(ic[0]) == str(aset_sig):
                return dict(ic[2] or {})

        # 1) If we have a compiled file, use it (and verify freshness when possible).
        po_sig_file, aset_sig_file, compiled = self._read_compiled(l)
        if compiled:
            if not aset_sig_file or str(aset_sig_file) == str(aset_sig):
                # If we can compute current po sig, ensure it matches; otherwise trust compiled.
                cur_po_sig = self._po_sig(lang=l, engine=engine, scripts_zip_hint=scripts_zip_hint)
                if (not cur_po_sig) or (po_sig_file and str(po_sig_file) == str(cur_po_sig)):
                    with self._lock:
                        self._item_cache[l] = (str(aset_sig), po_sig_file or cur_po_sig, dict(compiled))
                    return dict(compiled)

        # 2) Rebuild from PO (engine or scripts.zip hint or explicit file).
        po_sig, raw = self._load_names_raw(l, engine=engine, scripts_zip_hint=scripts_zip_hint)
        if not raw:
            # No source now; fall back to compiled content if any (filter to current assets if possible).
            if compiled:
                out2 = {iid: compiled[iid] for iid in ids if iid in compiled}
                with self._lock:
                    self._item_cache[l] = (str(aset_sig), po_sig_file, dict(out2))
                return out2
            return {}

        out: Dict[str, str] = {}
        for iid in ids:
            if not iid:
                continue
            k1 = str(iid).strip().lower()
            if not k1:
                continue
            k2 = k1.replace("_", "")
            v = raw.get(k1) or raw.get(k2)
            if v:
                out[str(iid)] = v

        # 3) Persist compiled mapping (best-effort).
        try:
            self._write_compiled(lang=l, po_sig=po_sig, assets_sig=aset_sig, names=out)
        except Exception:
            pass

        with self._lock:
            self._item_cache[l] = (str(aset_sig), po_sig, dict(out))

        return out

    def warmup(
        self,
        *,
        assets: Dict[str, Any],
        item_ids: Optional[Iterable[str]] = None,
        engine: Any = None,
        scripts_zip_hint: Optional[str] = None,
        langs: Optional[List[str]] = None,
    ) -> None:
        """Best-effort precompile.

        This is safe to call at server startup.
        """

        ls = langs or ["zh"]
        for l in ls:
            try:
                self.item_name_map(
                    lang=str(l),
                    assets=assets,
                    item_ids=item_ids,
                    engine=engine,
                    scripts_zip_hint=scripts_zip_hint,
                )
            except Exception:
                continue
```

### File: apps/webcraft/icon_service.py
- mode: full
- size_bytes: 10007
- sha256_12: 26a4f75bb2a2

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

import re
import threading
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

from core.klei_atlas_tex import (
    Atlas,
    decode_ktex_to_image,
    parse_atlas_xml,
    pick_first_existing,
    resolve_tex_path_from_atlas,
    extract_atlas_element,
)


_SAFE_ID_RE = re.compile(r"^[A-Za-z0-9_]+$")


@dataclass(frozen=True)
class IconConfig:
    """Runtime icon configuration.

    mode:
      - off      : UI shows no icons (always fallback to text)
      - static   : serve only prebuilt PNG icons from static_dir
      - dynamic  : generate icons from (atlas xml + tex) on demand (cached as png)
      - auto     : static first, if missing then dynamic

    static_dir:
      - directory that contains <id>.png files (served via /static/data/icons/...)

    game_data_dir:
      - directory root where atlas/xml/tex can be resolved, e.g. DST data folder that contains "images/..."
        Example: /path/to/Don't Starve Together/data

    unpremultiply:
      - whether to unpremultiply alpha for cropped icons (usually True for DST inventory icons)
    """

    mode: str = "auto"
    static_dir: Path = Path("data/static/icons")
    game_data_dir: Optional[Path] = None
    unpremultiply: bool = True

    def normalized_mode(self) -> str:
        m = (self.mode or "").strip().lower()
        if m in ("off", "0", "false", "none"):
            return "off"
        if m in ("static", "png"):
            return "static"
        if m in ("dynamic", "tex"):
            return "dynamic"
        return "auto"

    def to_public_dict(self) -> Dict[str, Any]:
        # URL bases are fixed by server routing.
        return {
            "mode": self.normalized_mode(),
            "static_base": "/static/data/icons",
            "api_base": "/api/v1/icon",
        }


class IconService:
    """Icon build/serve helper.

    The service is safe for concurrent requests.
    """

    def __init__(self, cfg: IconConfig):
        self.cfg = cfg
        self._lock = threading.RLock()
        self._atlas_cache: Dict[Path, Tuple[float, Atlas]] = {}
        self._tex_cache: Dict[Path, Tuple[float, Any]] = {}  # PIL.Image.Image, but keep Any to avoid import
        self._tex_cache_order: list[Path] = []
        self._tex_cache_max = 4

        # Ensure static directory exists (even in off mode).
        try:
            self.cfg.static_dir.mkdir(parents=True, exist_ok=True)
        except Exception:
            pass

    @staticmethod
    def is_safe_id(item_id: str) -> bool:
        return bool(item_id) and bool(_SAFE_ID_RE.match(item_id))

    def icon_path(self, item_id: str) -> Path:
        return self.cfg.static_dir / f"{item_id}.png"

    def resolve_existing(self, item_id: str) -> Optional[Path]:
        if not self.is_safe_id(item_id):
            return None
        p = self.icon_path(item_id)
        return p if p.exists() else None

    def ensure_icon(self, item_id: str, asset: Optional[Dict[str, Any]] = None) -> Optional[Path]:
        """Ensure icon PNG exists and return its path.

        Behavior depends on cfg.mode.
        """

        if not self.is_safe_id(item_id):
            return None

        mode = self.cfg.normalized_mode()
        if mode == "off":
            return None

        # 1) static
        p = self.icon_path(item_id)
        if p.exists():
            return p

        alias = self._resolve_existing_alias(item_id, asset=asset)
        if alias is not None:
            return alias

        if mode == "static":
            return None

        # 2) dynamic
        if mode in ("dynamic", "auto"):
            gd = self.cfg.game_data_dir
            if gd is None:
                return None
            if not asset:
                return None
            ok = self._build_from_asset(item_id, asset, out_path=p)
            return p if ok and p.exists() else None

        return None

    # ----------------- internals -----------------
    def _resolve_existing_alias(self, item_id: str, asset: Optional[Dict[str, Any]] = None) -> Optional[Path]:
        for cand in self._alias_candidates(item_id, asset=asset):
            if not self.is_safe_id(cand):
                continue
            p = self.icon_path(cand)
            if p.exists():
                return p
        return None

    def _alias_candidates(self, item_id: str, asset: Optional[Dict[str, Any]] = None) -> list[str]:
        if not item_id:
            return []

        out: list[str] = []

        def _push(v: Optional[str]) -> None:
            if not v:
                return
            if v == item_id:
                return
            if v not in out:
                out.append(v)

        # explicit known aliases
        explicit = {
            "waterpump": ["waterpump_item"],
            "hermit_bundle_shells": ["hermit_bundle"],
            "dragonboat_kit": ["dragonboat_pack"],
        }
        for v in explicit.get(item_id, []):
            _push(v)

        if item_id.startswith("wintercooking_"):
            _push(item_id[len("wintercooking_") :])

        if item_id.endswith("_builder"):
            base = item_id[: -len("_builder")]
            _push(f"{base}_sketch")
            _push(base)

        if item_id.endswith("_kit"):
            base = item_id[: -len("_kit")]
            _push(f"{base}_item")
            _push(f"{base}_pack")
            _push(base)

        if item_id.endswith("_item"):
            _push(item_id[: -len("_item")])

        if item_id.endswith("_blueprint"):
            _push(item_id[: -len("_blueprint")])

        if item_id.endswith("_recipe"):
            _push(item_id[: -len("_recipe")])

        if asset:
            image_rel = str(asset.get("image") or "").strip()
            if image_rel:
                base = Path(image_rel).name
                if base.lower().endswith(".tex"):
                    base = base[: -len(".tex")]
                _push(base)

        return out

    def _read_atlas(self, xml_path: Path) -> Optional[Atlas]:
        try:
            mtime = xml_path.stat().st_mtime
        except Exception:
            return None

        with self._lock:
            cached = self._atlas_cache.get(xml_path)
            if cached and cached[0] == mtime:
                return cached[1]

        try:
            xml_text = xml_path.read_text(encoding="utf-8", errors="ignore")
            atlas = parse_atlas_xml(xml_text)
        except Exception:
            return None

        with self._lock:
            self._atlas_cache[xml_path] = (mtime, atlas)
        return atlas

    def _read_tex_image(self, tex_path: Path):
        """Decode and cache tex image (mipmap0)."""
        try:
            mtime = tex_path.stat().st_mtime
        except Exception:
            return None

        with self._lock:
            cached = self._tex_cache.get(tex_path)
            if cached and cached[0] == mtime:
                return cached[1]

        try:
            tex_bytes = tex_path.read_bytes()
            img = decode_ktex_to_image(tex_bytes)
        except Exception:
            return None

        with self._lock:
            self._tex_cache[tex_path] = (mtime, img)
            # LRU bookkeeping
            if tex_path in self._tex_cache_order:
                self._tex_cache_order.remove(tex_path)
            self._tex_cache_order.append(tex_path)
            while len(self._tex_cache_order) > self._tex_cache_max:
                old = self._tex_cache_order.pop(0)
                self._tex_cache.pop(old, None)

        return img

    def _build_from_asset(self, item_id: str, asset: Dict[str, Any], *, out_path: Path) -> bool:
        """Build <item_id>.png from one catalog assets entry."""

        gd = self.cfg.game_data_dir
        if gd is None:
            return False

        atlas_rel = str(asset.get("atlas") or "").strip()
        if not atlas_rel:
            return False

        # normalize leading slashes
        while atlas_rel.startswith("/"):
            atlas_rel = atlas_rel[1:]

        xml_path = (gd / atlas_rel).resolve()
        if not xml_path.exists():
            return False

        atlas = self._read_atlas(xml_path)
        if not atlas:
            return False

        tex_path = resolve_tex_path_from_atlas(xml_path, atlas)
        if not tex_path or not tex_path.exists():
            # fallback: swap suffix
            alt = xml_path.with_suffix(".tex")
            if alt.exists():
                tex_path = alt
            else:
                return False

        tex_img = self._read_tex_image(tex_path)
        if tex_img is None:
            return False

        # Pick element name candidates
        image_rel = str(asset.get("image") or "").strip()
        candidates = []
        if image_rel:
            base = Path(image_rel).name
            if base and not base.lower().endswith(".tex"):
                base = base + ".tex"
            if base:
                candidates.append(base)
        candidates.append(f"{item_id}.tex")
        if "_" in item_id:
            candidates.append(f"{item_id.replace('_','')}.tex")

        element_name = pick_first_existing(candidates, atlas.elements)
        if not element_name:
            return False

        invert_v = self._invert_v_for_atlas(atlas_rel)
        cropped = extract_atlas_element(
            atlas,
            tex_img,
            element_name,
            unpremultiply=bool(self.cfg.unpremultiply),
            invert_v=invert_v,
        )
        if cropped is None:
            return False

        try:
            out_path.parent.mkdir(parents=True, exist_ok=True)
            cropped.save(out_path, format="PNG")
            return True
        except Exception:
            return False

    @staticmethod
    def _invert_v_for_atlas(atlas_rel: str) -> bool:
        p = str(atlas_rel or "").lower()
        if "inventoryimages" in p:
            return False
        return True
```

### File: apps/webcraft/planner.py
- mode: full
- size_bytes: 3808
- sha256_12: a9ac339eaf54

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

from .catalog_store import CraftRecipe


def normalize_inventory(inv: Dict[str, Any]) -> Dict[str, float]:
    out: Dict[str, float] = {}
    for k, v in (inv or {}).items():
        key = str(k).strip()
        if not key:
            continue
        try:
            num = float(v)
        except Exception:
            continue
        if num <= 0:
            continue
        out[key] = num
    return out


def _recipe_requires_builder_tag(recipe: CraftRecipe) -> Optional[str]:
    # builder_tags preferred
    if recipe.builder_tags:
        # a recipe can accept multiple tags; treat as "any-of"
        return ",".join(recipe.builder_tags)
    return None


def is_builder_allowed(recipe: CraftRecipe, builder_tag: Optional[str], strict: bool = False) -> Tuple[bool, str]:
    """Check if builder can craft this recipe.

    strict:
      - if True: treat builder_skill as locked (unknown to us), require builder_tag for builder_tags
      - if False: only enforce builder_tags; ignore builder_skill
    """
    bt_required = recipe.builder_tags or []
    if bt_required:
        if not builder_tag:
            return False, "missing_builder_tag"
        if builder_tag not in bt_required:
            return False, "builder_tag_mismatch"

    if strict and recipe.builder_skill:
        # we don't model skill tree yet; mark as blocked
        return False, "builder_skill_locked"

    return True, ""


@dataclass
class MissingItem:
    item: str
    need: float
    have: float
    reason: str = ""


def missing_for(recipe: CraftRecipe, inventory: Dict[str, float]) -> List[MissingItem]:
    """Compute missing materials for a recipe based on numeric amounts.

    If amount_num is missing/unresolvable => treated as missing with reason 'unresolved_amount'.
    """
    inv = inventory or {}
    missing: List[MissingItem] = []

    # unresolved list from catalog (e.g. CHARACTER_INGREDIENT.HEALTH)
    for unresolved in (recipe.ingredients_unresolved or []):
        missing.append(MissingItem(item=str(unresolved), need=1.0, have=0.0, reason="unresolved_ingredient"))

    for ing in (recipe.ingredients or []):
        item = str(ing.get("item") or "").strip()
        if not item:
            continue
        amt_num = ing.get("amount_num", None)
        if amt_num is None:
            # fallback: try parse amount string
            try:
                amt_num = float(ing.get("amount"))
            except Exception:
                amt_num = None
        if amt_num is None:
            missing.append(MissingItem(item=item, need=1.0, have=float(inv.get(item, 0.0)), reason="unresolved_amount"))
            continue

        have = float(inv.get(item, 0.0))
        need = float(amt_num)
        if have + 1e-9 < need:
            missing.append(MissingItem(item=item, need=need, have=have, reason="insufficient"))

    return missing


def craftable_recipes(
    recipes: List[CraftRecipe],
    inventory: Dict[str, float],
    builder_tag: Optional[str] = None,
    strict: bool = False,
) -> Tuple[List[CraftRecipe], List[Dict[str, Any]]]:
    """Return craftable recipes + blocked details."""
    inv = inventory or {}
    ok: List[CraftRecipe] = []
    blocked: List[Dict[str, Any]] = []

    for r in recipes:
        allowed, reason = is_builder_allowed(r, builder_tag, strict=strict)
        if not allowed:
            blocked.append({"name": r.name, "reason": reason})
            continue

        miss = missing_for(r, inv)
        if miss:
            blocked.append({"name": r.name, "reason": "missing_material", "missing": [m.__dict__ for m in miss]})
            continue

        ok.append(r)

    return ok, blocked
```

### File: apps/webcraft/settings.py
- mode: full
- size_bytes: 919
- sha256_12: 57f5a4c92b56

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional


@dataclass(frozen=True)
class WebCraftSettings:
    """Runtime settings for WebCraft server.

    Notes
    - catalog_path can point to wagstaff_catalog_v2.json or wagstaff_catalog_v2.sqlite
      (SQLite is preferred when both exist).
    - i18n requires wagstaff_i18n_v1.json (no runtime PO fallback).
    - root_path is for reverse-proxy mount (e.g. '/webcraft')
    """

    catalog_path: Path
    root_path: str = ""
    cors_allow_origins: Optional[List[str]] = None
    gzip_minimum_size: int = 800

    @staticmethod
    def normalize_root_path(root_path: str) -> str:
        rp = (root_path or "").strip()
        if not rp:
            return ""
        if not rp.startswith("/"):
            rp = "/" + rp
        rp = rp.rstrip("/")
        return rp
```

### File: apps/webcraft/tuning_trace.py
- mode: full
- size_bytes: 2474
- sha256_12: ff14604df156

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

import json
import threading
from pathlib import Path
from typing import Any, Dict, List, Optional

import bisect


class TuningTraceStore:
    """Load + index tuning trace JSON for on-demand queries (thread-safe)."""

    def __init__(self, path: Path):
        self._path = Path(path)
        self._lock = threading.RLock()
        self._mtime: float = -1.0
        self._doc: Dict[str, Any] = {}
        self._keys: List[str] = []
        self.load(force=True)

    @property
    def path(self) -> Path:
        return self._path

    def mtime(self) -> float:
        with self._lock:
            return float(self._mtime or 0)

    def load(self, force: bool = False) -> bool:
        """Load trace file if changed. Returns True if reload occurred."""
        with self._lock:
            if not self._path.exists():
                self._doc = {}
                self._keys = []
                self._mtime = -1.0
                return False
            try:
                mtime = self._path.stat().st_mtime
            except Exception:
                return False
            if (not force) and self._doc and self._mtime == mtime:
                return False
            try:
                doc = json.loads(self._path.read_text(encoding="utf-8"))
            except Exception:
                doc = {}
            self._doc = doc if isinstance(doc, dict) else {}
            self._keys = sorted(k for k in self._doc.keys() if isinstance(k, str))
            self._mtime = mtime
            return True

    def count(self) -> int:
        with self._lock:
            return len(self._doc)

    def get(self, key: str) -> Optional[Any]:
        if not key:
            return None
        with self._lock:
            v = self._doc.get(str(key))
            if isinstance(v, dict):
                return dict(v)
            return v

    def get_prefix(self, prefix: str, *, limit: int = 2000) -> Dict[str, Any]:
        p = str(prefix or "")
        if not p:
            return {}
        out: Dict[str, Any] = {}
        with self._lock:
            keys = self._keys
            start = bisect.bisect_left(keys, p)
            end = bisect.bisect_right(keys, p + "\uffff")
            for k in keys[start:end]:
                v = self._doc.get(k)
                out[k] = dict(v) if isinstance(v, dict) else v
                if len(out) >= limit:
                    break
        return out
```

### File: apps/webcraft/ui.py
- mode: full
- size_bytes: 114320
- sha256_12: 1b3873f46225

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

from html import escape

# NOTE:
# - Keep HTML/JS as a normal triple-quoted string.
# - Do NOT use Python f-strings here: the template contains many `{}` (CSS/JS/template literals).

_SHARED_CSS = r"""
@font-face {
  font-family: 'Bricolage Grotesque';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: url('__WAGSTAFF_APP_ROOT__/static/app/fonts/BricolageGrotesque-normal-400.ttf') format('truetype');
}
@font-face {
  font-family: 'Bricolage Grotesque';
  font-style: normal;
  font-weight: 600;
  font-display: swap;
  src: url('__WAGSTAFF_APP_ROOT__/static/app/fonts/BricolageGrotesque-normal-600.ttf') format('truetype');
}
@font-face {
  font-family: 'Bricolage Grotesque';
  font-style: normal;
  font-weight: 700;
  font-display: swap;
  src: url('__WAGSTAFF_APP_ROOT__/static/app/fonts/BricolageGrotesque-normal-700.ttf') format('truetype');
}
@font-face {
  font-family: 'IBM Plex Sans';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: url('__WAGSTAFF_APP_ROOT__/static/app/fonts/IBMPlexSans-normal-400.ttf') format('truetype');
}
@font-face {
  font-family: 'IBM Plex Sans';
  font-style: normal;
  font-weight: 500;
  font-display: swap;
  src: url('__WAGSTAFF_APP_ROOT__/static/app/fonts/IBMPlexSans-normal-500.ttf') format('truetype');
}
@font-face {
  font-family: 'IBM Plex Sans';
  font-style: normal;
  font-weight: 600;
  font-display: swap;
  src: url('__WAGSTAFF_APP_ROOT__/static/app/fonts/IBMPlexSans-normal-600.ttf') format('truetype');
}
@font-face {
  font-family: 'JetBrains Mono';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: url('__WAGSTAFF_APP_ROOT__/static/app/fonts/JetBrainsMono-normal-400.ttf') format('truetype');
}
@font-face {
  font-family: 'JetBrains Mono';
  font-style: normal;
  font-weight: 500;
  font-display: swap;
  src: url('__WAGSTAFF_APP_ROOT__/static/app/fonts/JetBrainsMono-normal-500.ttf') format('truetype');
}

:root {
  --paper: #f8f2e6;
  --paper-2: #efe4d2;
  --ink: #1b1c1f;
  --muted: #6f6a61;
  --line: rgba(27, 28, 31, 0.16);
  --accent: #0f7b6c;
  --accent-2: #d07b3a;
  --accent-soft: rgba(15, 123, 108, 0.16);
  --panel: rgba(255, 255, 255, 0.86);
  --panel-strong: #ffffff;
  --shadow: 0 24px 56px rgba(22, 23, 24, 0.12);
  --shadow-soft: 0 12px 24px rgba(22, 23, 24, 0.08);
  --radius: 18px;
}
* { box-sizing: border-box; }
html, body { margin: 0; padding: 0; }
body {
  min-height: 100vh;
  color: var(--ink);
  font-family: "IBM Plex Sans", "Noto Sans", sans-serif;
  background:
    radial-gradient(900px 560px at 12% -10%, rgba(15, 123, 108, 0.2), transparent 60%),
    radial-gradient(860px 520px at 95% 0%, rgba(208, 123, 58, 0.16), transparent 60%),
    linear-gradient(180deg, var(--paper), var(--paper-2));
}
body::before {
  content: "";
  position: fixed;
  inset: 0;
  z-index: -1;
  pointer-events: none;
  background-image:
    radial-gradient(rgba(27, 28, 31, 0.08) 0.6px, transparent 0.6px),
    repeating-linear-gradient(115deg, rgba(27, 28, 31, 0.04) 0, rgba(27, 28, 31, 0.04) 1px, transparent 1px, transparent 24px);
  background-size: 28px 28px, 220px 220px;
  opacity: 0.45;
}
a { color: var(--accent); text-decoration: none; }
a:hover { color: #0a5d51; }

.header {
  position: sticky;
  top: 0;
  z-index: 20;
  background: rgba(248, 242, 230, 0.92);
  backdrop-filter: blur(14px);
  border-bottom: 1px solid var(--line);
}
.topbar,
.subbar {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
  gap: 12px 18px;
  padding: 14px 20px;
}
.topbar { justify-content: space-between; }
.subbar {
  border-top: 1px solid rgba(27, 28, 31, 0.08);
  background: rgba(255, 255, 255, 0.4);
  justify-content: space-between;
}
.topbar-left,
.topbar-right,
.subbar-left,
.subbar-right {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
  gap: 10px 12px;
}
.topbar-right { margin-left: auto; }
.subbar-right { flex: 1 1 360px; justify-content: flex-end; }
.subbar-left { flex-direction: column; align-items: flex-start; gap: 4px; }
.brand {
  display: flex;
  align-items: baseline;
  gap: 6px;
  font-family: "Bricolage Grotesque", "IBM Plex Sans", sans-serif;
  font-weight: 700;
  font-size: 12px;
  letter-spacing: 0.34em;
  text-transform: uppercase;
}
.brand-sub {
  font-size: 10px;
  letter-spacing: 0.22em;
  color: var(--muted);
  font-weight: 600;
}
.page-title {
  font-family: "Bricolage Grotesque", "IBM Plex Sans", sans-serif;
  font-size: 20px;
  font-weight: 700;
}
.page-sub {
  font-size: 12px;
  color: var(--muted);
}
.nav-links {
  display: flex;
  flex-wrap: wrap;
  gap: 8px;
}
.nav-link {
  font-size: 12px;
  font-weight: 600;
  color: var(--muted);
  padding: 6px 12px;
  border: 1px solid var(--line);
  border-radius: 999px;
  background: var(--panel);
  transition: transform 0.2s ease, border-color 0.2s ease, color 0.2s ease;
}
.nav-link:hover {
  color: var(--ink);
  border-color: rgba(15, 123, 108, 0.45);
  transform: translateY(-1px);
}
.nav-link.active {
  color: #fff;
  border-color: var(--ink);
  background: var(--ink);
}
.label-toggle {
  display: flex;
  align-items: center;
  gap: 6px;
  font-size: 12px;
  color: var(--muted);
}

.search {
  flex: 1 1 300px;
  display: flex;
  align-items: center;
  gap: 8px;
  max-width: 560px;
}
input[type="text"],
textarea {
  width: 100%;
  background: var(--panel-strong);
  color: var(--ink);
  border: 1px solid var(--line);
  border-radius: 12px;
  padding: 10px 12px;
  outline: none;
  box-shadow: var(--shadow-soft);
  transition: border-color 0.2s ease, box-shadow 0.2s ease;
}
input[type="text"]:focus,
textarea:focus {
  border-color: var(--accent);
  box-shadow: 0 0 0 3px var(--accent-soft);
}
textarea {
  min-height: 84px;
  resize: vertical;
  font-family: "JetBrains Mono", "SFMono-Regular", monospace;
}
select {
  background: var(--panel-strong);
  color: var(--ink);
  border: 1px solid var(--line);
  border-radius: 999px;
  padding: 6px 10px;
  font-size: 12px;
  outline: none;
  cursor: pointer;
}
button,
.btn {
  background: var(--panel-strong);
  border: 1px solid var(--line);
  color: var(--ink);
  border-radius: 999px;
  padding: 9px 12px;
  cursor: pointer;
  font-weight: 600;
  box-shadow: var(--shadow-soft);
  transition: transform 0.2s ease, border-color 0.2s ease, background 0.2s ease;
}
button:hover,
.btn:hover {
  border-color: rgba(15, 123, 108, 0.45);
  transform: translateY(-1px);
}
button.primary,
.btn.primary {
  background: var(--accent);
  border-color: var(--accent);
  color: #fff;
  box-shadow: none;
}
button.primary:hover,
.btn.primary:hover {
  background: #0a5d51;
}
.btn.ghost {
  background: transparent;
  border-color: transparent;
  box-shadow: none;
  color: var(--muted);
}
.btn.ghost:hover { color: var(--ink); transform: none; }
.btn.back { display: none; }

button:focus-visible,
.nav-link:focus-visible,
input[type="text"]:focus-visible,
textarea:focus-visible,
select:focus-visible {
  outline: 2px solid var(--accent);
  outline-offset: 2px;
}
.meta,
#meta {
  padding: 4px 10px;
  border-radius: 999px;
  border: 1px dashed var(--line);
  background: rgba(255, 255, 255, 0.6);
  color: var(--muted);
  font-size: 12px;
  max-width: 42vw;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.layout {
  display: grid;
  grid-template-columns: minmax(200px, 250px) minmax(320px, 420px) minmax(420px, 1fr);
  grid-template-areas: "filters recipes detail";
  gap: 20px;
  padding: 20px;
}
.layout > .panel:nth-child(1) { grid-area: filters; }
.layout > .panel:nth-child(2) { grid-area: recipes; }
.layout > .panel:nth-child(3) { grid-area: detail; }

.wrap {
  display: grid;
  grid-template-columns: minmax(360px, 460px) minmax(0, 1fr);
  grid-template-areas: "list detail";
  gap: 20px;
  padding: 20px;
}

.panel {
  background: var(--panel);
  border: 1px solid var(--line);
  border-radius: var(--radius);
  overflow: hidden;
  box-shadow: var(--shadow);
  min-height: 0;
  display: flex;
  flex-direction: column;
  animation: panelRise 0.5s ease both;
}
.panel--primary {
  border-color: rgba(15, 123, 108, 0.45);
  box-shadow: 0 30px 60px rgba(20, 30, 30, 0.16);
}
.panel-head,
.phead,
.panel h2 {
  margin: 0;
  padding: 12px 16px;
  border-bottom: 1px solid var(--line);
  background: rgba(255, 255, 255, 0.7);
  display: flex;
  align-items: center;
  justify-content: space-between;
  gap: 10px;
}
.panel-title {
  font-size: 11px;
  letter-spacing: 0.22em;
  text-transform: uppercase;
  color: var(--muted);
  font-weight: 600;
}
.panel-actions {
  display: flex;
  align-items: center;
  gap: 8px;
}
.panel h2 button {
  padding: 4px 10px;
  border-radius: 999px;
  font-size: 11px;
  box-shadow: none;
}
.panel-body,
.pbody,
.detail-body,
.detail {
  padding: 18px;
}
.panel-body--meta {
  border-bottom: 1px solid var(--line);
  background: rgba(255, 255, 255, 0.6);
}
.detail {
  display: flex;
  flex-direction: column;
  gap: 16px;
  font-size: 14px;
  line-height: 1.6;
}

.list {
  max-height: min(60vh, 680px);
  overflow: auto;
}
.list::-webkit-scrollbar { width: 10px; }
.list::-webkit-scrollbar-thumb {
  background: rgba(27, 28, 31, 0.16);
  border-radius: 999px;
}
.list::-webkit-scrollbar-track { background: transparent; }

.item {
  display: inline-flex;
  align-items: center;
  gap: 8px;
}
.list .item,
.li {
  padding: 12px 16px;
  border-bottom: 1px solid rgba(27, 28, 31, 0.08);
  cursor: pointer;
  display: grid;
  grid-template-columns: 1fr auto;
  align-items: center;
  gap: 12px;
  animation: itemIn 0.25s ease;
}
.li { grid-template-columns: auto 1fr; }
.list .item:hover,
.li:hover { background: rgba(15, 123, 108, 0.08); }
.list .item.active,
.li.active {
  background: rgba(15, 123, 108, 0.18);
  box-shadow: inset 3px 0 0 var(--accent);
}
.li > div { display: flex; flex-direction: column; gap: 4px; }
.item .name { font-weight: 600; }
.item .meta { color: var(--muted); font-size: 12px; }

.detail-hero {
  display: flex;
  flex-wrap: wrap;
  align-items: center;
  justify-content: space-between;
  gap: 10px 16px;
}
.hero-title {
  font-family: "Bricolage Grotesque", "IBM Plex Sans", sans-serif;
  font-size: 20px;
  font-weight: 700;
}
.hero-sub {
  font-size: 12px;
  color: var(--muted);
}
.hero-meta {
  display: flex;
  flex-wrap: wrap;
  gap: 6px;
}
.pill,
.chip {
  font-size: 11px;
  padding: 4px 10px;
  border: 1px solid rgba(27, 28, 31, 0.2);
  border-radius: 999px;
  background: rgba(255, 255, 255, 0.6);
}
.chip {
  color: var(--ink);
  background: rgba(15, 123, 108, 0.08);
  border-color: rgba(15, 123, 108, 0.25);
}

.stat-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(170px, 1fr));
  gap: 12px;
}
.stat-card {
  background: rgba(255, 255, 255, 0.75);
  border: 1px solid var(--line);
  border-radius: 14px;
  padding: 10px 12px;
  box-shadow: var(--shadow-soft);
}
.stat-label {
  font-size: 11px;
  letter-spacing: 0.16em;
  text-transform: uppercase;
  color: var(--muted);
}
.stat-value { margin-top: 6px; }
.stat-row {
  display: flex;
  align-items: center;
  justify-content: space-between;
  gap: 8px;
}
.stat-row .mono {
  flex: 1 1 auto;
  min-width: 0;
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}
.stat-actions { flex: 0 0 auto; }

.section { border-top: 1px dashed rgba(27, 28, 31, 0.16); padding-top: 12px; }
.section-title {
  font-size: 11px;
  letter-spacing: 0.2em;
  text-transform: uppercase;
  color: var(--muted);
  margin-bottom: 8px;
}
.list-lines { display: flex; flex-direction: column; gap: 6px; }
.line { display: flex; gap: 8px; align-items: baseline; }

.tool-card {
  background: rgba(255, 255, 255, 0.75);
  border: 1px solid var(--line);
  border-radius: 14px;
  padding: 12px;
  display: flex;
  flex-direction: column;
  gap: 8px;
}

.kv {
  display: grid;
  grid-template-columns: 140px 1fr;
  gap: 6px 12px;
  font-size: 13px;
}
.kv .k { color: var(--muted); }

.chips { display: flex; flex-wrap: wrap; gap: 6px; }
.grid2 { display: grid; grid-template-columns: 1fr 1fr; gap: 10px; }
.row { display: flex; gap: 8px; align-items: center; flex-wrap: wrap; }

.err {
  color: #7f1d1d;
  font-size: 12px;
  white-space: pre-wrap;
  padding: 10px 12px;
  border-radius: 12px;
  border: 1px solid rgba(185, 28, 28, 0.2);
  background: rgba(254, 242, 242, 0.9);
}
.err:empty { display: none; }
.ok { color: #059669; font-size: 12px; }
.muted { color: var(--muted); }
.small { font-size: 12px; }
.mono { font-family: "JetBrains Mono", "SFMono-Regular", monospace; }
#listCount {
  font-size: 11px;
  padding: 2px 8px;
  border-radius: 999px;
  border: 1px dashed var(--line);
  color: var(--muted);
}
#stats { color: var(--muted); font-size: 12px; }

.itemRef { display: inline-flex; align-items: center; gap: 8px; }
.itemIcon {
  width: 24px;
  height: 24px;
  border-radius: 6px;
  border: 1px solid rgba(27, 28, 31, 0.2);
  background: rgba(15, 123, 108, 0.08);
  display: inline-flex;
  align-items: center;
  justify-content: center;
  overflow: hidden;
  flex: 0 0 auto;
}
.itemIconImg {
  width: 100%;
  height: 100%;
  object-fit: contain;
  image-rendering: pixelated;
  display: block;
}
.itemIconFallback {
  width: 100%;
  height: 100%;
  display: none;
  align-items: center;
  justify-content: center;
  font-size: 13px;
  color: var(--muted);
}
.itemLabel { color: var(--ink); }

.icon {
  width: 32px;
  height: 32px;
  border-radius: 8px;
  border: 1px solid rgba(27, 28, 31, 0.2);
  background: rgba(15, 123, 108, 0.08);
  object-fit: contain;
}
.icon.placeholder { display: inline-block; }

pre {
  margin: 0;
  padding: 10px 12px;
  border-radius: 12px;
  border: 1px solid var(--line);
  background: rgba(255, 255, 255, 0.7);
  box-shadow: var(--shadow-soft);
  overflow: auto;
  max-height: 520px;
  font-size: 12px;
  line-height: 1.35;
  font-family: "JetBrains Mono", "SFMono-Regular", monospace;
}
details summary { cursor: pointer; color: var(--muted); }
.err.fixed {
  position: fixed;
  bottom: 12px;
  left: 12px;
  right: 12px;
  z-index: 50;
}

#detailPanel,
#listPanel { scroll-margin-top: 150px; }

@keyframes panelRise {
  from { opacity: 0; transform: translateY(8px); }
  to { opacity: 1; transform: translateY(0); }
}
@keyframes itemIn {
  from { opacity: 0; transform: translateY(4px); }
  to { opacity: 1; transform: translateY(0); }
}

@media (max-width: 1280px) {
  .layout {
    grid-template-columns: minmax(0, 1fr) minmax(0, 1fr);
    grid-template-areas:
      "filters recipes"
      "detail detail";
  }
}
@media (max-width: 980px) {
  .subbar-right {
    width: 100%;
    justify-content: flex-start;
  }
  .search { max-width: none; }
  .meta,
  #meta { max-width: 100%; }
}
@media (max-width: 860px) {
  .header { position: static; }
  .topbar, .subbar { padding: 10px 14px; }
  .brand { font-size: 11px; letter-spacing: 0.28em; }
  .nav-link { padding: 4px 10px; }
  .page-title { font-size: 18px; }
  .page-sub { display: none; }
  .subbar-left { flex-direction: row; align-items: baseline; gap: 8px; }
  #detailPanel,
  #listPanel { scroll-margin-top: 12px; }
  .layout {
    grid-template-columns: 1fr;
    grid-template-areas:
      "filters"
      "recipes"
      "detail";
    padding: 14px;
  }
  .wrap {
    grid-template-columns: 1fr;
    grid-template-areas:
      "list"
      "detail";
    padding: 14px;
  }
  .grid2 { grid-template-columns: 1fr; }
  .kv { grid-template-columns: 1fr; }
  .list { max-height: 42vh; }
  .btn.back { display: inline-flex; }
}
@media (prefers-reduced-motion: reduce) {
  * { animation: none !important; transition: none !important; }
}
"""

_INDEX_TEMPLATE = r"""<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="app-root" content="__WAGSTAFF_APP_ROOT__" />
  <title>Wagstaff WebCraft</title>
  <style>
__SHARED_CSS__
  </style>
</head>
<body>
  <header class="header">
    <div class="topbar">
      <div class="topbar-left">
        <div class="brand">Wagstaff <span class="brand-sub">Field Manual</span></div>
        <div class="nav-links">
          <a id="navCraft" class="nav-link active" href="#">Craft</a>
          <a id="navCooking" class="nav-link" href="#">Cooking</a>
          <a id="navCatalog" class="nav-link" href="#">Catalog</a>
        </div>
      </div>
      <div class="topbar-right">
        <div class="label-toggle">
          <span class="muted" id="labelModeLabel">Label</span>
          <select id="labelMode">
            <option value="en">EN</option>
            <option value="zh">中文</option>
            <option value="id">ID</option>
          </select>
        </div>
        <div class="meta" id="meta"></div>
      </div>
    </div>
    <div class="subbar">
      <div class="subbar-left">
        <div class="page-title">Craft Atlas</div>
        <div class="page-sub">Recipes and planning tools</div>
      </div>
      <div class="subbar-right">
        <div class="search">
          <input id="q" type="text" placeholder="Search: axe | ing:twigs | tag:bookbuilder | filter:TOOLS | tab:LIGHT" />
          <button id="btnSearch" class="primary">Search</button>
        </div>
      </div>
    </div>
  </header>

  <div class="layout">
    <div class="panel panel--filters">
      <div class="panel-head">
        <div class="panel-title" id="groupTitle">Filters</div>
        <div class="panel-actions">
          <button id="btnToggle" class="btn ghost">Toggle</button>
        </div>
      </div>
      <div class="list" id="groupList"></div>
    </div>

    <div class="panel panel--list" id="listPanel">
      <div class="panel-head">
        <div class="panel-title" id="listTitle">Recipes</div>
        <span class="small muted" id="listCount"></span>
      </div>
      <div class="list" id="recipeList"></div>
    </div>

    <div class="panel panel--primary" id="detailPanel">
      <div class="panel-head">
        <div class="panel-title"><span id="detailTitle">Details</span></div>
        <button class="btn ghost back" id="btnBackList">Back to list</button>
      </div>
      <div class="detail">
        <div id="detail"></div>

        <div class="tool-card">
          <div class="small muted" id="inventoryHelp">Inventory (for missing/planning)</div>
          <textarea id="inv" placeholder="twigs=2, flint=1
rocks=10"></textarea>
          <div class="grid2" style="margin-top:8px;">
            <div>
              <div class="small muted" id="builderTagLabel">builder_tag (optional)</div>
              <input id="builderTag" type="text" placeholder="bookbuilder / handyperson / ..." />
            </div>
            <div style="display:flex; gap:8px; align-items:flex-end;">
              <button id="btnPlan" class="primary" style="flex:1;">Plan</button>
              <button id="btnMissing" style="flex:1;">Missing</button>
            </div>
          </div>
          <div id="planOut" class="small" style="margin-top:8px;"></div>
        </div>

        <div class="err" id="err"></div>
      </div>
    </div>
  </div>

  <script>
    const APP_ROOT = (document.querySelector('meta[name="app-root"]')?.content || '').replace(/\/+$/,'');
    const api = (path) => APP_ROOT + path;

    const navCraft = document.getElementById('navCraft');
    if (navCraft) navCraft.href = APP_ROOT + '/';

    const navCooking = document.getElementById('navCooking');
    if (navCooking) navCooking.href = APP_ROOT + '/cooking';

    const navCatalog = document.getElementById('navCatalog');
    if (navCatalog) navCatalog.href = APP_ROOT + '/catalog';

    const el = (id) => document.getElementById(id);
    const isNarrow = () => window.matchMedia('(max-width: 860px)').matches;
    const focusPanel = (id) => {
      if (!isNarrow()) return;
      const node = el(id);
      if (node) node.scrollIntoView({ behavior: 'smooth', block: 'start' });
    };
    const focusDetail = () => focusPanel('detailPanel');
    const focusList = () => focusPanel('listPanel');
    const backBtn = el('btnBackList');
    if (backBtn) backBtn.onclick = () => focusList();
    const state = {
      mode: 'filters', // filters | tabs | tags
      groups: [],
      activeGroup: null,
      recipes: [],
      activeRecipe: null,
      activeRecipeData: null,
      assets: {},
      icon: null, // {mode, static_base, api_base}

      // label mode: en | zh | id (persisted in localStorage)
      labelMode: localStorage.getItem('ws_label_mode') || 'en',
      i18n: null,         // meta from /api/v1/meta (set in loadMeta)
      i18nNames: {},      // {lang: {id: name}}
      i18nLoaded: {},     // {lang: true}
      uiStrings: {},      // {lang: {key: text}}
      uiLoaded: {},       // {lang: true}
    };

    function setError(msg) {
      el('err').textContent = msg || '';
    }

    function parseInventory(text) {
      const out = {};
      const raw = (text || '').trim();
      if (!raw) return out;

      const parts = raw
        .split(/[,\n]/g)
        .map(s => s.trim())
        .filter(Boolean);

      for (const p of parts) {
        const m = p.match(/^([^=\s]+)\s*(?:=|\s)\s*([0-9]+(?:\.[0-9]+)?)$/);
        if (!m) continue;
        const k = m[1].trim();
        const v = parseFloat(m[2]);
        if (!k || !Number.isFinite(v) || v <= 0) continue;
        out[k] = v;
      }
      return out;
    }

    async function fetchJson(url, opts) {
      const r = await fetch(url, opts || {});
      if (!r.ok) {
        const t = await r.text();
        throw new Error(`HTTP ${r.status} ${r.statusText}\n${t}`);
      }
      return await r.json();
    }

    function escHtml(s) {
      return String(s ?? '').replace(/[&<>"']/g, (c) => ({
        '&': '&amp;',
        '<': '&lt;',
        '>': '&gt;',
        '"': '&quot;',
        "'": '&#39;',
      }[c]));
    }

    async function loadAssets() {
      try {
        const res = await fetchJson(api('/api/v1/assets'));
        state.assets = res.assets || {};
        state.icon = res.icon || null;
      } catch (e) {
        state.assets = {};
        state.icon = null;
      }
    }

    function _iconUrls(iid) {
      const cfg = state.icon || {};
      const mode = String(cfg.mode || 'off');
      const enc = encodeURIComponent(iid);
      const staticBaseRaw = String(cfg.static_base || '/static/data/icons');
      const staticBase = (APP_ROOT && staticBaseRaw.startsWith('/') && !staticBaseRaw.startsWith(APP_ROOT + '/'))
        ? (APP_ROOT + staticBaseRaw)
        : staticBaseRaw;
      const apiBase = String(cfg.api_base || '/api/v1/icon');
      const staticUrl = api(`${staticBase}/${enc}.png`);
      const apiUrl = api(`${apiBase}/${enc}.png`);

      if (mode === 'dynamic') return { src: apiUrl, fallback: '' };
      if (mode === 'static') return { src: staticUrl, fallback: apiUrl };
      if (mode === 'auto') return { src: staticUrl, fallback: apiUrl };
      return { src: '', fallback: '' };
    }

    function iconError(img) {
      try {
        const fb = img?.dataset?.fallback || '';
        const tried = img?.dataset?.fallbackTried || '';
        if (fb && !tried) {
          img.dataset.fallbackTried = '1';
          img.src = fb;
          return;
        }
        img.style.display = 'none';
        const nxt = img.nextElementSibling;
        if (nxt) nxt.style.display = 'flex';
      } catch (e) {
        // ignore
      }
    }

    function _altId(iid) {
      if (!iid) return '';
      const s = String(iid);
      if (s.includes('_')) return s.replace(/_/g,'');
      return '';
    }

    function getI18nName(iid) {
      const mp = (state.i18nNames && state.i18nNames.zh) ? state.i18nNames.zh : null;
      if (!mp) return '';
      const k = String(iid || '').trim();
      if (!k) return '';
      const lo = k.toLowerCase();
      const a1 = _altId(k);
      const a2 = _altId(lo);
      return mp[k] || mp[lo] || (a1 ? mp[a1] : '') || (a2 ? mp[a2] : '') || '';
    }

    async function ensureI18nNames(mode) {
      if (String(mode || '') !== 'zh') return;
      if (state.i18nLoaded && state.i18nLoaded.zh) return;
      try {
        const res = await fetchJson(api('/api/v1/i18n/names/zh'));
        state.i18nNames.zh = res.names || {};
        state.i18nLoaded.zh = true;
      } catch (e) {
        state.i18nLoaded.zh = false;
      }
    }

    function uiLang() {
      return (state.labelMode === 'zh') ? 'zh' : 'en';
    }

    async function ensureUiStrings(lang) {
      const l = String(lang || '').trim();
      if (!l) return;
      if (state.uiLoaded && state.uiLoaded[l]) return;
      try {
        const res = await fetchJson(api(`/api/v1/i18n/ui/${encodeURIComponent(l)}`));
        state.uiStrings[l] = res.strings || {};
        state.uiLoaded[l] = true;
      } catch (e) {
        state.uiStrings[l] = {};
        state.uiLoaded[l] = false;
      }
    }

    function t(key, fallback) {
      const l = uiLang();
      const mp = (state.uiStrings && state.uiStrings[l]) ? state.uiStrings[l] : {};
      return (mp && mp[key]) ? mp[key] : (fallback || key || '');
    }

    function applyUiStrings() {
      const navCraft = el('navCraft');
      if (navCraft) navCraft.textContent = t('nav.craft', 'Craft');
      const navCooking = el('navCooking');
      if (navCooking) navCooking.textContent = t('nav.cooking', 'Cooking');
      const navCatalog = el('navCatalog');
      if (navCatalog) navCatalog.textContent = t('nav.catalog', 'Catalog');
      const label = el('labelModeLabel');
      if (label) label.textContent = t('label.mode', 'Label');
      const btnSearch = el('btnSearch');
      if (btnSearch) btnSearch.textContent = t('btn.search', 'Search');
      const btnPlan = el('btnPlan');
      if (btnPlan) btnPlan.textContent = t('btn.plan', 'Plan');
      const btnMissing = el('btnMissing');
      if (btnMissing) btnMissing.textContent = t('btn.missing', 'Missing');
      const btnToggle = el('btnToggle');
      if (btnToggle) btnToggle.textContent = t('btn.toggle', 'Toggle');
      const listTitle = el('listTitle');
      if (listTitle) {
        const txt = listTitle.textContent || '';
        if (!txt.includes(':') && !txt.includes('(')) {
          listTitle.textContent = t('craft.list.recipes', txt || 'Recipes');
        }
      }
      const groupTitle = el('groupTitle');
      if (groupTitle) {
        if (state.mode === 'filters') groupTitle.textContent = t('craft.group.filters', 'Filters');
        else if (state.mode === 'tabs') groupTitle.textContent = t('craft.group.tabs', 'Tabs');
        else groupTitle.textContent = t('craft.group.tags', 'Tags');
      }
      const detailTitle = el('detailTitle');
      if (detailTitle) detailTitle.textContent = t('craft.detail.title', 'Details');
      const invHelp = el('inventoryHelp');
      if (invHelp) invHelp.textContent = t('craft.inventory.help', 'Inventory (for missing/planning)');
      const builderLabel = el('builderTagLabel');
      if (builderLabel) builderLabel.textContent = t('craft.builder_tag.label', 'builder_tag (optional)');
      const input = el('q');
      if (input) input.placeholder = t('craft.search.placeholder', input.placeholder || '');
      const inv = el('inv');
      if (inv) inv.placeholder = t('craft.inventory.placeholder', inv.placeholder || '');
      const builderTag = el('builderTag');
      if (builderTag) builderTag.placeholder = t('craft.builder_tag.placeholder', builderTag.placeholder || '');
    }

    async function fetchTuningTrace(prefix) {
      if (!state.tuningTraceEnabled) return {};
      const pfx = String(prefix || '').trim();
      if (!pfx) return {};
      const res = await fetchJson(api(`/api/v1/tuning/trace?prefix=${encodeURIComponent(pfx)}`));
      const traces = res.traces || {};
      for (const k in traces) {
        if (!Object.prototype.hasOwnProperty.call(traces, k)) continue;
        state.tuningTrace[k] = traces[k];
      }
      return traces;
    }

    function applyLabelModeUI() {
      const sel = el('labelMode');
      if (!sel) return;
      const enabled = Boolean(state.i18n && state.i18n.enabled);
      const optZh = sel.querySelector('option[value="zh"]');
      if (optZh) optZh.disabled = !enabled;
      if (!enabled && state.labelMode === 'zh') {
        state.labelMode = 'en';
        try { localStorage.setItem('ws_label_mode', state.labelMode); } catch (e) {}
      }
      sel.value = state.labelMode || 'en';
    }

    function resolveLabel(iid, enName, zhName) {
      const mode = String(state.labelMode || 'en');
      if (mode === 'id') return iid;
      if (mode === 'zh' && zhName) return zhName;
      return enName || iid;
    }

    async function setLabelMode(mode) {
      state.labelMode = String(mode || 'en');
      try { localStorage.setItem('ws_label_mode', state.labelMode); } catch (e) {}
      applyLabelModeUI();
      await ensureI18nNames(state.labelMode);
      await ensureUiStrings(uiLang());
      applyUiStrings();
      renderRecipeList();
      renderRecipeDetail(state.activeRecipeData);
    }

    function renderItem(id) {
      const iid = String(id || '').trim();
      if (!iid) return '';
      const m = (state.assets && state.assets[iid]) ? state.assets[iid] : null;
      const enName = (m && m.name) ? m.name : iid;
      const zhName = getI18nName(iid);
      const name = resolveLabel(iid, enName, zhName);

      const tipParts = [`id:${iid}`];
      if (enName && enName !== iid) tipParts.push(`en:${enName}`);
      if (zhName && zhName !== enName && zhName !== iid) tipParts.push(`zh:${zhName}`);
      if (m && m.image) tipParts.push(`img:${m.image}`);
      if (m && m.atlas) tipParts.push(`atlas:${m.atlas}`);
      const tip = escHtml(tipParts.join(' | '));

      const { src, fallback } = _iconUrls(iid);
      const iconChar = (m && (m.image || m.atlas)) ? '🖼️' : '📦';

      if (!src) {
        return `<span class="itemRef" title="${tip}">` +
          `<span class="itemIcon"><span class="itemIconFallback" style="display:flex;">${iconChar}</span></span>` +
          `<span class="itemLabel">${escHtml(name)}</span></span>`;
      }

      const fbAttr = fallback ? ` data-fallback="${escHtml(fallback)}"` : '';
      return `<span class="itemRef" title="${tip}">` +
        `<span class="itemIcon">` +
          `<img class="itemIconImg" src="${escHtml(src)}"${fbAttr} onerror="iconError(this)" alt="" />` +
          `<span class="itemIconFallback">${iconChar}</span>` +
        `</span>` +
        `<span class="itemLabel">${escHtml(name)}</span>` +
      `</span>`;
    }


    function renderGroupList() {
      const box = el('groupList');
      box.innerHTML = '';
      for (const g of state.groups) {
        const div = document.createElement('div');
        div.className = 'item' + (state.activeGroup === g.name ? ' active' : '');
        div.innerHTML = `<span class="name">${g.name}</span><span class="meta">${g.count ?? ''}</span>`;
        div.onclick = () => selectGroup(g.name);
        box.appendChild(div);
      }
    }

    function renderRecipeList() {
      const box = el('recipeList');
      box.innerHTML = '';
      el('listCount').textContent = state.recipes.length ? `${state.recipes.length}` : '';
      for (const nm of state.recipes) {
        const div = document.createElement('div');
        div.className = 'item' + (state.activeRecipe === nm ? ' active' : '');
        div.innerHTML = `<span class="name">${renderItem(nm)}</span><span class="meta"></span>`;
        div.onclick = () => selectRecipe(nm);
        box.appendChild(div);
      }
    }

    function renderRecipeDetail(rec) {
      if (!rec) {
        el('detail').innerHTML = `<div class="muted">${escHtml(t('craft.detail.empty', 'Select a recipe.'))}</div>`;
        return;
      }
      const filters = (rec.filters || []).map(x => `<span class="chip">${x}</span>`).join('');
      const tags = (rec.builder_tags || []).map(x => `<span class="chip">${x}</span>`).join('');
      const ings = (rec.ingredients || []).map(i => {
        const item = i.item;
        const amt = i.amount ?? '';
        const num = i.amount_num;
        const extra = (num === null || num === undefined) ? ' <span class="muted">(?)</span>' : '';
        return `<div class="line"><span>•</span><span>${renderItem(item)} <span class="mono">x${escHtml(amt)}</span>${extra}</span></div>`;
      }).join('');
      const tabLabel = String(rec.tab || '').replace('RECIPETABS.','');
      const techLabel = String(rec.tech || '').replace('TECH.','');
      const heroSubParts = [];
      if (tabLabel) heroSubParts.push(`Tab: ${tabLabel}`);
      if (techLabel) heroSubParts.push(`Tech: ${techLabel}`);
      const heroSub = heroSubParts.length ? heroSubParts.join(' | ') : '-';
      const heroMeta = [tabLabel, techLabel].filter(Boolean).map(v => `<span class="pill">${escHtml(v)}</span>`).join('');
      const heroMetaHtml = heroMeta || '<span class="muted">-</span>';
      const statRows = [
        {
          label: t('craft.detail.product', 'Product'),
          value: rec.product ? renderItem(rec.product) : '<span class="muted">-</span>',
        },
        {
          label: t('craft.detail.tech', 'Tech'),
          value: techLabel ? `<span class="mono">${escHtml(techLabel)}</span>` : '<span class="muted">-</span>',
        },
        {
          label: t('craft.detail.station', 'Station'),
          value: rec.station_tag ? `<span class="mono">${escHtml(rec.station_tag)}</span>` : '<span class="muted">-</span>',
        },
        {
          label: t('craft.detail.builder_skill', 'Builder skill'),
          value: rec.builder_skill ? `<span class="mono">${escHtml(rec.builder_skill)}</span>` : '<span class="muted">-</span>',
        },
      ];
      const statCards = statRows.map(row => `
        <div class="stat-card">
          <div class="stat-label">${escHtml(row.label)}</div>
          <div class="stat-value">${row.value}</div>
        </div>
      `).join('');

      el('detail').innerHTML = `
        <div class="detail-hero">
          <div>
            <div class="hero-title">${renderItem(rec.name)}</div>
            <div class="hero-sub">${escHtml(heroSub)}</div>
          </div>
          <div class="hero-meta">${heroMetaHtml}</div>
        </div>
        <div class="stat-grid">
          ${statCards}
        </div>
        <div class="section">
          <div class="section-title">${escHtml(t('craft.detail.filters', 'Filters'))}</div>
          <div class="chips">${filters || '<span class="muted">-</span>'}</div>
        </div>
        <div class="section">
          <div class="section-title">${escHtml(t('craft.detail.builder_tags', 'Builder tags'))}</div>
          <div class="chips">${tags || '<span class="muted">-</span>'}</div>
        </div>
        <div class="section">
          <div class="section-title">${escHtml(t('craft.detail.ingredients', 'Ingredients'))}</div>
          <div class="list-lines">${ings || '<span class="muted">-</span>'}</div>
          ${(rec.ingredients_unresolved && rec.ingredients_unresolved.length)
            ? `<div class="muted small">${escHtml(t('craft.detail.unresolved', 'Unresolved'))}: ${rec.ingredients_unresolved.join(', ')}</div>`
            : ''}
        </div>
      `;
    }

    async function loadMeta() {
      const m = await fetchJson(api('/api/v1/meta'));
      state.i18n = (m && m.i18n) ? m.i18n : { enabled: false };
      state.tuningTraceEnabled = Boolean(m && m.tuning_trace_enabled);
      applyLabelModeUI();
      await ensureUiStrings(uiLang());
      applyUiStrings();
      const sha = m.scripts_sha256_12 ? `sha:${m.scripts_sha256_12}` : '';
      const ae = m.analyzer_enabled ? 'analyzer:on' : 'analyzer:off';
      const te = m.tuning_enabled ? 'tuning:on' : 'tuning:off';
      el('meta').textContent = `${sha} | mode:${m.engine_mode || ''} | files:${m.scripts_file_count || ''} | ${ae} | ${te}`;
    }

    async function loadGroups() {
      setError('');
      if (state.mode === 'filters') {
        el('groupTitle').textContent = t('craft.group.filters', 'Filters');
        const res = await fetchJson(api('/api/v1/craft/filters'));
        const order = res.order || [];
        state.groups = order.map(n => ({ name: n, count: '' }));
      } else if (state.mode === 'tabs') {
        el('groupTitle').textContent = t('craft.group.tabs', 'Tabs');
        const res = await fetchJson(api('/api/v1/craft/tabs'));
        state.groups = (res.tabs || []).map(t => ({ name: t.name, count: t.count }));
      } else {
        el('groupTitle').textContent = t('craft.group.tags', 'Tags');
        const res = await fetchJson(api('/api/v1/craft/tags'));
        state.groups = (res.tags || []).map(t => ({ name: t.name, count: t.count }));
      }

      state.activeGroup = null;
      state.recipes = [];
      state.activeRecipe = null;
      state.activeRecipeData = null;
      renderGroupList();
      renderRecipeList();
      renderRecipeDetail(null);
    }

    async function selectGroup(name) {
      setError('');
      state.activeGroup = name;
      renderGroupList();

      let url = '';
      if (state.mode === 'filters') url = api(`/api/v1/craft/filters/${encodeURIComponent(name)}/recipes`);
      else if (state.mode === 'tabs') url = api(`/api/v1/craft/tabs/${encodeURIComponent(name)}/recipes`);
      else url = api(`/api/v1/craft/tags/${encodeURIComponent(name)}/recipes`);

      const res = await fetchJson(url);
      state.recipes = (res.recipes || []);
      state.activeRecipe = null;
      state.activeRecipeData = null;

      el('listTitle').textContent = t('craft.list.recipes', 'Recipes');
      renderRecipeList();
      renderRecipeDetail(null);
    }

    async function selectRecipe(name) {
      setError('');
      state.activeRecipe = name;
      renderRecipeList();
      const res = await fetchJson(api(`/api/v1/craft/recipes/${encodeURIComponent(name)}`));
      state.activeRecipeData = res.recipe || null;
      renderRecipeDetail(state.activeRecipeData);
      focusDetail();
    }

    async function doSearch() {
      setError('');
      const q = el('q').value.trim();
      if (!q) return;
      const res = await fetchJson(api(`/api/v1/craft/recipes/search?q=${encodeURIComponent(q)}&limit=200`));
      const results = (res.results || []).map(r => r.name).filter(Boolean);
      state.recipes = results;
      state.activeGroup = null;
      state.activeRecipe = null;
      state.activeRecipeData = null;
      renderGroupList();
      renderRecipeList();
      renderRecipeDetail(null);
      el('listTitle').textContent = `${t('label.search', 'Search')}: ${q}`;
    }

    async function doPlan() {
      setError('');
      const inv = parseInventory(el('inv').value);
      const builderTag = el('builderTag').value.trim() || null;
      const payload = { inventory: inv, builder_tag: builderTag, strict: false, limit: 200 };
      const res = await fetchJson(api('/api/v1/craft/plan'), {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload),
      });
      const craftable = res.craftable || [];
      el('planOut').innerHTML = craftable.length
        ? `<div class="ok">${escHtml(t('craft.plan.craftable', 'Craftable'))} (${craftable.length})</div><div>${craftable.slice(0,120).map(n => renderItem(n)).join(', ')}</div>`
        : `<div class="muted">${escHtml(t('craft.plan.none', 'No craftable recipes with current inventory.'))}</div>`;
    }

    async function doMissing() {
      setError('');
      const nm = state.activeRecipe;
      if (!nm) {
        setError(t('craft.error.select_recipe', 'Select a recipe first.'));
        return;
      }
      const inv = parseInventory(el('inv').value);
      const res = await fetchJson(api('/api/v1/craft/missing'), {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ name: nm, inventory: inv }),
      });
      const miss = res.missing || [];
      if (!miss.length) {
        el('planOut').innerHTML = `<div class="ok">${escHtml(t('craft.missing.none', 'No missing materials.'))}</div>`;
        return;
      }
      const needLabel = t('label.need', 'need');
      const haveLabel = t('label.have', 'have');
      const reasonLabel = t('label.reason', 'reason');
      const lines = miss.map(m => `• ${renderItem(m.item)} ${escHtml(needLabel)}:${escHtml(m.need)} ${escHtml(haveLabel)}:${escHtml(m.have)} (${escHtml(reasonLabel)}:${escHtml(m.reason)})`).join('<br/>');
      el('planOut').innerHTML = `<div class="muted">${escHtml(t('craft.missing.title', 'Missing'))} (${miss.length})</div><div class="mono">${lines}</div>`;
    }

    function toggleMode() {
      if (state.mode === 'filters') state.mode = 'tabs';
      else if (state.mode === 'tabs') state.mode = 'tags';
      else state.mode = 'filters';
      loadGroups().catch(e => setError(String(e)));
    }

    // wire
    el('btnToggle').onclick = toggleMode;
    el('btnSearch').onclick = () => doSearch().catch(e => setError(String(e)));
    el('q').addEventListener('keydown', (e) => { if (e.key === 'Enter') doSearch().catch(err => setError(String(err))); });
    el('btnPlan').onclick = () => doPlan().catch(e => setError(String(e)));
    el('btnMissing').onclick = () => doMissing().catch(e => setError(String(e)));

    const labelSel = el('labelMode');
    if (labelSel) {
      try { labelSel.value = state.labelMode || 'en'; } catch (e) {}
      labelSel.onchange = () => setLabelMode(labelSel.value).catch(e => setError(String(e)));
    }

    function initFromUrl() {
      const params = new URLSearchParams(window.location.search || '');
      const recipe = params.get('recipe');
      const q = params.get('q');
      if (recipe) {
        selectRecipe(recipe).catch(e => setError(String(e)));
        return;
      }
      if (q) {
        el('q').value = q;
        doSearch().catch(e => setError(String(e)));
      }
    }

    // init
    (async () => {
      try {
        await loadMeta();
        await ensureI18nNames(state.labelMode);
        await loadAssets();
        await loadGroups();
        initFromUrl();
      } catch (e) {
        setError(String(e));
      }
    })();
  </script>
</body>
</html>
"""


_CATALOG_TEMPLATE = """<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <meta name="app-root" content="__WAGSTAFF_APP_ROOT__" />
  <title>Wagstaff Catalog</title>
  <style>
__SHARED_CSS__
  </style>
</head>
<body>
  <header class="header">
    <div class="topbar">
      <div class="topbar-left">
        <div class="brand">Wagstaff <span class="brand-sub">Field Manual</span></div>
        <div class="nav-links">
          <a class="nav-link" id="navCraft" href="__WAGSTAFF_APP_ROOT__/">Craft</a>
          <a class="nav-link" id="navCooking" href="__WAGSTAFF_APP_ROOT__/cooking">Cooking</a>
          <a class="nav-link active" id="navCatalog" href="__WAGSTAFF_APP_ROOT__/catalog">Catalog</a>
        </div>
      </div>
      <div class="topbar-right">
        <div class="label-toggle">
          <span class="muted" id="labelModeLabel">Label</span>
          <select id="labelMode">
            <option value="en">EN</option>
            <option value="zh">中文</option>
            <option value="id">ID</option>
          </select>
        </div>
        <div class="meta" id="meta">...</div>
      </div>
    </div>
    <div class="subbar">
      <div class="subbar-left">
        <div class="page-title">Catalog Index</div>
        <div class="page-sub">Items, stats, and prefab links</div>
      </div>
      <div class="subbar-right">
        <div class="search">
          <input id="q" type="text" placeholder="Search item id / name. Examples: beefalo, axe, spear, monstermeat" />
          <button class="btn primary" id="btnSearch">Search</button>
        </div>
        <button class="btn ghost" id="btnAll">All</button>
      </div>
    </div>
  </header>

  <div class="wrap">
    <div class="panel panel--list" id="listPanel">
      <div class="panel-head">
        <div class="panel-title" id="listTitle">Catalog</div>
        <span class="small muted" id="stats"></span>
      </div>
      <div class="panel-body panel-body--meta">
        <div class="small muted" id="searchHelp">Hints: kind:structure cat:weapon src:craft tag:monster comp:equippable slot:head</div>
      </div>
      <div class="list" id="list"></div>
    </div>

    <div class="panel panel--primary" id="detailPanel">
      <div class="panel-head">
        <div class="panel-title" id="detailTitle">Item Detail</div>
        <button class="btn ghost back" id="btnBackList">Back to list</button>
      </div>
      <div class="detail" id="detail">
        <div class="muted" id="detailEmpty">Select an item.</div>
      </div>
    </div>
  </div>

  <div class="err fixed" id="err"></div>

  <script>
    const APP_ROOT = (document.querySelector('meta[name="app-root"]')?.content || '').replace(/\/+$/,'');
    const api = (path) => APP_ROOT + path;

    const el = (id) => document.getElementById(id);
    const isNarrow = () => window.matchMedia('(max-width: 860px)').matches;
    const focusPanel = (id) => {
      if (!isNarrow()) return;
      const node = el(id);
      if (node) node.scrollIntoView({ behavior: 'smooth', block: 'start' });
    };
    const focusDetail = () => focusPanel('detailPanel');
    const focusList = () => focusPanel('listPanel');
    const backBtn = el('btnBackList');
    if (backBtn) backBtn.onclick = () => focusList();

    function setError(msg) {
      const box = el('err');
      if (!msg) { box.style.display = 'none'; box.textContent = ''; return; }
      box.style.display = 'block';
      box.textContent = String(msg);
    }

    async function fetchJson(url, opts) {
      const r = await fetch(url, opts || {});
      if (!r.ok) {
        const t = await r.text();
        throw new Error(`HTTP ${r.status} ${r.statusText}\n${t}`);
      }
      return await r.json();
    }

    function escHtml(s) {
      return String(s ?? '').replace(/[&<>"']/g, (c) => ({
        '&': '&amp;',
        '<': '&lt;',
        '>': '&gt;',
        '"': '&quot;',
        "'": '&#39;',
      }[c]));
    }

    function hasCjk(text) {
      return /[\u4e00-\u9fff]/.test(String(text || ''));
    }

    let meta = {};
    let assets = {};
    let icon = null; // {mode, static_base, api_base}
    let activeId = null;

    const state = {
      labelMode: localStorage.getItem('ws_label_mode') || 'en',
      i18n: null,         // meta from /api/v1/meta (set in loadMeta)
      i18nNames: {},      // {lang: {id: name}}
      i18nLoaded: {},     // {lang: true}
      tuningTrace: {},    // {trace_key: trace}
      tuningTraceEnabled: false,
      uiStrings: {},      // {lang: {key: text}}
      uiLoaded: {},       // {lang: true}
    };

    // list render state (supports full catalog without freezing)
    let allKeys = [];
    let viewKeys = [];
    let renderPos = 0;
    const CHUNK = 240;
    const PAGE_SIZE = 400;
    let catalogTotal = 0;
    let searchTotal = 0;
    let listMode = 'all';
    let loadingPage = false;
    let loadedKeys = new Set();

    function _iconUrls(iid) {
      const cfg = icon || {};
      const mode = String(cfg.mode || 'off');
      const enc = encodeURIComponent(iid);
      const staticBaseRaw = String(cfg.static_base || '/static/data/icons');
      const staticBase = (APP_ROOT && staticBaseRaw.startsWith('/') && !staticBaseRaw.startsWith(APP_ROOT + '/'))
        ? (APP_ROOT + staticBaseRaw)
        : staticBaseRaw;
      const apiBase = String(cfg.api_base || '/api/v1/icon');
      const staticUrl = api(`${staticBase}/${enc}.png`);
      const apiUrl = api(`${apiBase}/${enc}.png`);

      if (mode === 'dynamic') return { src: apiUrl, fallback: '' };
      if (mode === 'static') return { src: staticUrl, fallback: apiUrl };
      if (mode === 'auto') return { src: staticUrl, fallback: apiUrl };
      return { src: '', fallback: '' };
    }

    function iconError(img) {
      try {
        const fb = img?.dataset?.fallback || '';
        const tried = img?.dataset?.fallbackTried || '';
        if (fb && !tried) {
          img.dataset.fallbackTried = '1';
          img.src = fb;
          return;
        }
        img.style.display = 'none';
        const nxt = img.nextElementSibling;
        if (nxt) nxt.style.display = 'inline-block';
      } catch (e) {
        // ignore
      }
    }

    function _altId(iid) {
      if (!iid) return '';
      const s = String(iid);
      if (s.includes('_')) return s.replace(/_/g,'');
      return '';
    }

    function getI18nName(iid) {
      const mp = (state.i18nNames && state.i18nNames.zh) ? state.i18nNames.zh : null;
      if (!mp) return '';
      const k = String(iid || '').trim();
      if (!k) return '';
      const lo = k.toLowerCase();
      const a1 = _altId(k);
      const a2 = _altId(lo);
      return mp[k] || mp[lo] || (a1 ? mp[a1] : '') || (a2 ? mp[a2] : '') || '';
    }

    async function ensureI18nNames(mode) {
      if (String(mode || '') !== 'zh') return;
      if (state.i18nLoaded && state.i18nLoaded.zh) return;
      const enabled = Boolean(state.i18n && state.i18n.enabled);
      if (!enabled) return;
      try {
        const res = await fetchJson(api('/api/v1/i18n/names/zh'));
        state.i18nNames.zh = res.names || {};
        state.i18nLoaded.zh = true;
      } catch (e) {
        state.i18nLoaded.zh = false;
      }
    }
    // ui i18n (catalog)
    function uiLang() {
      return (state.labelMode === 'zh') ? 'zh' : 'en';
    }

    async function ensureUiStrings(lang) {
      const l = String(lang || '').trim();
      if (!l) return;
      if (state.uiLoaded && state.uiLoaded[l]) return;
      try {
        const res = await fetchJson(api(`/api/v1/i18n/ui/${encodeURIComponent(l)}`));
        state.uiStrings[l] = res.strings || {};
        state.uiLoaded[l] = true;
      } catch (e) {
        state.uiStrings[l] = {};
        state.uiLoaded[l] = false;
      }
    }

    function t(key, fallback) {
      const l = uiLang();
      const mp = (state.uiStrings && state.uiStrings[l]) ? state.uiStrings[l] : {};
      return (mp && mp[key]) ? mp[key] : (fallback || key || '');
    }

    function applyUiStrings() {
      const navCraft = el('navCraft');
      if (navCraft) navCraft.textContent = t('nav.craft', 'Craft');
      const navCooking = el('navCooking');
      if (navCooking) navCooking.textContent = t('nav.cooking', 'Cooking');
      const navCatalog = el('navCatalog');
      if (navCatalog) navCatalog.textContent = t('nav.catalog', 'Catalog');
      const label = el('labelModeLabel');
      if (label) label.textContent = t('label.mode', 'Label');
      const btnSearch = el('btnSearch');
      if (btnSearch) btnSearch.textContent = t('btn.search', 'Search');
      const btnAll = el('btnAll');
      if (btnAll) btnAll.textContent = t('btn.all', 'All');
      const input = el('q');
      if (input) input.placeholder = t('catalog.search.placeholder', input.placeholder || '');
      const hint = el('searchHelp');
      if (hint) hint.textContent = t('catalog.search.hint', hint.textContent || '');
      const detailEmpty = el('detailEmpty');
      if (detailEmpty) detailEmpty.textContent = t('catalog.detail.empty', 'Select an item.');
    }

    async function fetchTuningTrace(prefix) {
      if (!state.tuningTraceEnabled) return {};
      const pfx = String(prefix || '').trim();
      if (!pfx) return {};
      const res = await fetchJson(api(`/api/v1/tuning/trace?prefix=${encodeURIComponent(pfx)}`));
      const traces = res.traces || {};
      for (const k in traces) {
        if (!Object.prototype.hasOwnProperty.call(traces, k)) continue;
        state.tuningTrace[k] = traces[k];
      }
      return traces;
    }

    function applyLabelModeUI() {
      const sel = el('labelMode');
      if (!sel) return;
      const enabled = Boolean(state.i18n && state.i18n.enabled);
      const optZh = sel.querySelector('option[value="zh"]');
      if (optZh) optZh.disabled = !enabled;
      if (!enabled && state.labelMode === 'zh') {
        state.labelMode = 'en';
        try { localStorage.setItem('ws_label_mode', state.labelMode); } catch (e) {}
      }
      sel.value = state.labelMode || 'en';
    }

    function resolveLabel(iid, enName, zhName) {
      const mode = String(state.labelMode || 'en');
      if (mode === 'id') return iid;
      if (mode === 'zh' && zhName) return zhName;
      return enName || iid;
    }

    async function setLabelMode(mode) {
      state.labelMode = String(mode || 'en');
      try { localStorage.setItem('ws_label_mode', state.labelMode); } catch (e) {}
      applyLabelModeUI();
      await ensureI18nNames(state.labelMode);
      await ensureUiStrings(uiLang());
      applyUiStrings();
      const q = el('q').value;
      await runSearch(q);
    }

    function iconHtmlFor(id, sizePx) {
      const iid = String(id || '').trim();
      const sz = Number(sizePx || 28);
      const { src, fallback } = _iconUrls(iid);
      if (!src) {
        return `<span class="icon placeholder" style="width:${sz}px;height:${sz}px;"></span>`;
      }
      const fbAttr = fallback ? ` data-fallback="${escHtml(fallback)}"` : '';
      return `<span style="display:inline-flex; align-items:center; justify-content:center;">` +
        `<img class="icon" style="width:${sz}px;height:${sz}px;" src="${escHtml(src)}" loading="lazy" onerror="iconError(this)"${fbAttr} />` +
        `<span class="icon placeholder" style="width:${sz}px;height:${sz}px; display:none;"></span>` +
        `</span>`;
    }

    function renderItem(id) {
      const iid = String(id || '').trim();
      const a = assets[iid] || assets[iid.toLowerCase()] || null;
      const zh = getI18nName(iid);
      const label = resolveLabel(iid, a?.name || iid, zh);
      const iconHtml = iconHtmlFor(iid, 30);
      return `<span class="item">${iconHtml}<span>${escHtml(label)}</span></span>`;
    }

    function listKeys() {
      return allKeys;
    }

    async function runSearch(q) {
      const query = String(q || '').trim();
      if (!query) {
        listMode = 'all';
        searchTotal = 0;
        renderList(listKeys());
        return;
      }
      listMode = 'search';
      try {
        const res = await fetchJson(api(`/api/v1/catalog/search?q=${encodeURIComponent(query)}&limit=800`));
        const items = res.items || [];
        searchTotal = Number(res.total || res.count || items.length);
        applyCatalogItems(items, false);
        const keys = [];
        items.forEach((it) => {
          const iid = String(it.id || '').trim();
          if (iid) keys.push(iid);
        });
        renderList(keys);
      } catch (e) {
        setError(String(e));
      }
    }

    function appendListChunk() {
      const box = el('list');
      if (renderPos >= viewKeys.length) return;

      const end = Math.min(renderPos + CHUNK, viewKeys.length);
      const frag = document.createDocumentFragment();

      for (let i = renderPos; i < end; i++) {
        const k = viewKeys[i];
        const a = assets[k] || {};
        const zh = getI18nName(k);
        const label = resolveLabel(k, a.name || k, zh);
        const div = document.createElement('div');
        div.className = 'li' + (k === activeId ? ' active' : '');
        div.dataset.id = k;

        const iconHtml = iconHtmlFor(k, 34);
        const metaBits = [];
        if (a.kind) metaBits.push(a.kind);
        if (a.categories && a.categories.length) metaBits.push(a.categories.slice(0, 2).join(','));
        if (a.sources && a.sources.length) metaBits.push(a.sources.slice(0, 2).join(','));
        const metaLine = metaBits.length ? `<div class="small muted">${escHtml(metaBits.join(' · '))}</div>` : '';
        div.innerHTML = `${iconHtml}<div><div>${escHtml(label)}</div><div class="small mono">${escHtml(k)}</div>${metaLine}</div>`;
        div.onclick = () => openItem(k).catch(e => setError(String(e)));
        frag.appendChild(div);
      }

      box.appendChild(frag);
      renderPos = end;

      // stats line
      const shown = Math.min(renderPos, viewKeys.length);
      const total = (listMode === 'search')
        ? (searchTotal || viewKeys.length)
        : (catalogTotal || allKeys.length);
      el('stats').textContent = `${total} items. Showing ${shown}/${viewKeys.length}.`;
    }

    function renderList(keys) {
      viewKeys = (keys || []).slice();
      renderPos = 0;
      const box = el('list');
      box.innerHTML = '';
      if (!viewKeys.length) {
        box.innerHTML = '<div class="pbody muted">No results.</div>';
        const total = (listMode === 'search')
          ? (searchTotal || 0)
          : (catalogTotal || allKeys.length);
        el('stats').textContent = `${total} items. Showing 0/0.`;
        return;
      }
      appendListChunk();
    }

    async function maybeLoadMore() {
      if (listMode !== 'all') return;
      if (loadingPage) return;
      if (catalogTotal && allKeys.length >= catalogTotal) return;
      const before = allKeys.length;
      await loadCatalogPage(allKeys.length);
      if (allKeys.length > before) {
        viewKeys = listKeys();
      }
    }

    function installInfiniteScroll() {
      const box = el('list');
      box.addEventListener('scroll', () => {
        if (box.scrollTop + box.clientHeight >= box.scrollHeight - 200) {
          appendListChunk();
          maybeLoadMore().then(() => appendListChunk());
        }
      });
    }

    function setActiveInList(id) {
      activeId = String(id || '').trim();
      for (const node of el('list').querySelectorAll('.li')) {
        if (node.dataset.id === activeId) node.classList.add('active');
        else node.classList.remove('active');
      }
    }


    function recipeLinkCraft(name) {

      return `${APP_ROOT}/?recipe=${encodeURIComponent(name)}`;
    }
    function recipeLinkCooking(name) {
      return `${APP_ROOT}/cooking?recipe=${encodeURIComponent(name)}`;
    }

    function renderRecipeList(names, hrefFn) {
      const arr = names || [];
      if (!arr.length) return '<span class="muted">-</span>';
      const lines = arr.slice(0, 80).map(n => `<div class="line"><span>•</span><span><a class="mono" href="${hrefFn(n)}">${escHtml(n)}</a></span></div>`).join('');
      const more = arr.length > 80 ? `<div class="muted">… +${arr.length-80} more</div>` : '';
      return `<div class="list-lines">${lines}${more}</div>`;
    }

    function renderChips(list, extraClass) {
      const arr = (list || []).filter(Boolean);
      if (!arr.length) return '<span class="muted">-</span>';
      const cls = extraClass ? ` ${extraClass}` : '';
      return arr.slice(0, 80).map(v => `<span class="chip${cls}">${escHtml(v)}</span>`).join('');
    }

    function renderMonoLines(list, limit) {
      const arr = (list || []).filter(Boolean);
      if (!arr.length) return '<span class="muted">-</span>';
      const cap = Math.max(1, Number(limit || 8));
      const lines = arr.slice(0, cap).map(v => `<div class="mono">${escHtml(v)}</div>`).join('');
      const more = arr.length > cap ? `<div class="muted small">… +${arr.length - cap} more</div>` : '';
      return `<div class="list-lines">${lines}${more}</div>`;
    }

    function renderAnalysis(rep) {
      if (!rep) return '<span class="muted">-</span>';
      const brain = rep.brain ? `<span class="chip mono">${escHtml(rep.brain)}</span>` : '<span class="muted">-</span>';
      const sg = rep.stategraph ? `<span class="chip mono">${escHtml(rep.stategraph)}</span>` : '<span class="muted">-</span>';
      const tags = (rep.tags || []).slice(0, 60).map(t => `<span class="chip mono">${escHtml(t)}</span>`).join('') || '<span class="muted">-</span>';
      const comps = (rep.components || []).slice(0, 80).map(c => `<span class="chip mono">${escHtml(c)}</span>`).join('') || '<span class="muted">-</span>';
      const evs = (rep.events || []).slice(0, 80).map(e => `<span class="chip mono">${escHtml(e)}</span>`).join('') || '<span class="muted">-</span>';

      return `
        <div class="section">
          <div class="small muted">${escHtml(t('catalog.analysis.brain', 'Brain'))}</div>
          <div class="chips">${brain}</div>
        </div>
        <div class="section">
          <div class="small muted">${escHtml(t('catalog.analysis.stategraph', 'Stategraph'))}</div>
          <div class="chips">${sg}</div>
        </div>
        <div class="section">
          <div class="small muted">${escHtml(t('catalog.analysis.components', 'Components'))}</div>
          <div class="chips">${comps}</div>
        </div>
        <div class="section">
          <div class="small muted">${escHtml(t('catalog.analysis.tags', 'Tags'))}</div>
          <div class="chips">${tags}</div>
        </div>
        <div class="section">
          <div class="small muted">${escHtml(t('catalog.analysis.events', 'Events'))}</div>
          <div class="chips">${evs}</div>
        </div>
        <div class="section">
          <details>
            <summary>${escHtml(t('catalog.analysis.raw_report', 'Raw report (JSON)'))}</summary>
            <pre>${escHtml(JSON.stringify(rep, null, 2))}</pre>
          </details>
        </div>
      `;
    }

    async function openItem(id) {
      setError('');
      const q = String(id || '').trim();
      if (!q) return;
      setActiveInList(q);

      const data = await fetchJson(api(`/api/v1/items/${encodeURIComponent(q)}`));
      const item = data.item || {};
      const asset = data.asset || {};
      const craft = data.craft || {};
      const cooking = data.cooking || {};
      const iconHtml = iconHtmlFor(q, 64);

      const zh = getI18nName(q);
      const label = resolveLabel(q, item?.name || asset?.name || q, zh);
      const atlas = asset?.atlas || '';
      const image = asset?.image || '';
      const iconPath = asset?.icon || '';

      const kind = item?.kind || '';
      const categories = item?.categories || [];
      const behaviors = item?.behaviors || [];
      const sources = item?.sources || [];
      const slots = item?.slots || [];
      const components = item?.components || [];
      const tags = item?.tags || [];
      const prefabFiles = item?.prefab_files || [];
      const brains = item?.brains || [];
      const stategraphs = item?.stategraphs || [];
      const helpers = item?.helpers || [];
      const prefabAssets = item?.prefab_assets || [];
      const stats = item?.stats || {};

      const kindRow = [];
      if (kind) kindRow.push(kind);
      (sources || []).forEach((s) => kindRow.push(`src:${s}`));
      (slots || []).forEach((s) => kindRow.push(`slot:${s}`));

      const cookRec = cooking.as_recipe;

      function cookTraceForField(field) {
        if (!cookRec) return null;
        const v = cookRec[field];
        if (v && typeof v === 'object' && (v.trace || v.expr || v.value !== undefined)) return v;
        if (cookRec._tuning && cookRec._tuning[field]) return cookRec._tuning[field];
        const key = `cooking:${cookRec.name || q}:${field}`;
        return state.tuningTrace[key] || null;
      }

      function cookStat(field) {
        if (!cookRec) return '';
        const tr = cookTraceForField(field);
        if (tr && tr.value !== null && tr.value !== undefined) return tr.value;
        const val = cookRec[field];
        if (val && typeof val === 'object') {
          if (val.value !== undefined && val.value !== null) return val.value;
          if (val.expr !== undefined) return val.expr;
        }
        return val ?? '';
      }

      function renderCookStatRow(field) {
        if (!cookRec) return '<span class="muted">-</span>';
        const tr = cookTraceForField(field);
        const val = cookStat(field);
        const expr = tr ? (tr.expr ?? '') : '';
        const showExpr = expr && String(expr) !== String(val);
        const titleAttr = showExpr ? ` title="${escHtml(expr)}"` : '';
        const key = `cooking:${cookRec.name || q}:${field}`;
        const canTrace = Boolean(key);
        const enabled = Boolean(state.tuningTraceEnabled);
        const btn = canTrace
          ? `<button class="btn" data-cook-trace="${escHtml(field)}" ${enabled ? '' : 'disabled'} style="margin-left:6px; padding:2px 6px; font-size:11px;">${escHtml(t('btn.trace', 'Trace'))}</button>`
          : '';
        const details = tr
          ? `<details style="margin-top:4px;"><summary class="small muted">${escHtml(t('label.trace', 'Trace'))}</summary><pre>${escHtml(JSON.stringify(tr, null, 2))}</pre></details>`
          : '';
        const main = (val !== null && val !== undefined && val !== '')
          ? `<span class="mono"${titleAttr}>${escHtml(val ?? '')}</span>`
          : `<span class="mono">${escHtml(expr ?? '')}</span>`;
        const actions = btn ? `<span class="stat-actions">${btn}</span>` : '';
        return `<div class="stat-row">${main}${actions}</div>${details}`;
      }

      const STAT_LABELS = {
        weapon_damage: 'Weapon Damage',
        weapon_range: 'Weapon Range',
        weapon_range_min: 'Weapon Range (min)',
        weapon_range_max: 'Weapon Range (max)',
        combat_damage: 'Combat Damage',
        attack_period: 'Attack Period',
        attack_range: 'Attack Range',
        attack_range_max: 'Attack Range (max)',
        area_damage: 'Area Damage',
        uses_max: 'Max Uses',
        uses: 'Uses',
        armor_condition: 'Armor Condition',
        armor_absorption: 'Armor Absorption',
        edible_health: 'Edible Health',
        edible_hunger: 'Edible Hunger',
        edible_sanity: 'Edible Sanity',
        perish_time: 'Perish Time',
        fuel_level: 'Fuel Level',
        fuel_max: 'Max Fuel',
        dapperness: 'Dapperness',
        insulation: 'Insulation',
        insulation_winter: 'Insulation (Winter)',
        insulation_summer: 'Insulation (Summer)',
        waterproof: 'Waterproof',
        light_radius: 'Light Radius',
        light_intensity: 'Light Intensity',
        light_falloff: 'Light Falloff',
        stack_size: 'Stack Size',
        health_max: 'Max Health',
        sanity_max: 'Max Sanity',
        sanity_rate: 'Sanity Rate',
        sanity_aura: 'Sanity Aura',
        hunger_max: 'Max Hunger',
        hunger_rate: 'Hunger Rate',
        walk_speed: 'Walk Speed',
        run_speed: 'Run Speed',
        speed_multiplier: 'Speed Multiplier',
        recharge_time: 'Recharge Time',
        recharge_percent: 'Recharge Percent',
        recharge_charge: 'Recharge Charge',
        equip_slot: 'Equip Slot',
        equip_walk_speed_mult: 'Equip Walk Speed Mult',
        equip_run_speed_mult: 'Equip Run Speed Mult',
        equip_restricted_tag: 'Equip Restricted Tag',
        equip_stack: 'Equip Stack',
        equip_insulated: 'Equip Insulated',
        equip_moisture: 'Equip Moisture',
        equip_moisture_max: 'Equip Moisture Max',
        equip_magic_dapperness: 'Equip Magic Dapperness',
        heat: 'Heat',
        heat_radius: 'Heat Radius',
        heat_radius_cutoff: 'Heat Radius Cutoff',
        heat_falloff: 'Heat Falloff',
        heater_exothermic: 'Heater Exothermic',
        heater_endothermic: 'Heater Endothermic',
        equipped_heat: 'Equipped Heat',
        carried_heat_multiplier: 'Carried Heat Mult',
        heat_rate: 'Heat Rate',
        planar_damage_base: 'Planar Damage (base)',
        planar_damage_bonus: 'Planar Damage (bonus)',
        planar_damage: 'Planar Damage',
        planar_absorption: 'Planar Absorption',
        planar_absorption_base: 'Planar Absorption (base)',
        work_left: 'Work Left',
      };

      function renderStatRow(statKey, entry) {
        const key = String(statKey || '');
        const label = t(`stat.${key}`, STAT_LABELS[key] || key);
        const val = entry?.value ?? entry?.expr ?? '';
        const expr = entry?.expr ?? '';
        const showExpr = expr && String(expr) !== String(val);
        const traceKey = entry?.trace_key || `item:${q}:stat:${key}`;
        const trace = entry?.trace || state.tuningTrace[traceKey];
        const enabled = Boolean(state.tuningTraceEnabled);
        const btn = traceKey
          ? `<button class="btn" data-item-trace="${escHtml(traceKey)}" ${enabled ? '' : 'disabled'} style="margin-left:6px; padding:2px 6px; font-size:11px;">${escHtml(t('btn.trace', 'Trace'))}</button>`
          : '';
        const details = trace
          ? `<details style="margin-top:4px;"><summary class="small muted">${escHtml(t('label.trace', 'Trace'))}</summary><pre>${escHtml(JSON.stringify(trace, null, 2))}</pre></details>`
          : '';
        const value = `<span class="mono">${escHtml(val ?? '')}</span>${showExpr ? ` <span class="small muted mono">${escHtml(expr)}</span>` : ''}${btn}${details}`;
        return `
          <div class="stat-card">
            <div class="stat-label">${escHtml(label)}</div>
            <div class="stat-value">${value}</div>
          </div>
        `;
      }

      function renderStats(statsObj) {
        const entries = Object.entries(statsObj || {});
        if (!entries.length) return '<span class="muted">-</span>';
        return `<div class="stat-grid">${entries.map(([k, v]) => renderStatRow(k, v)).join('')}</div>`;
      }

      const cookBrief = cookRec ? `
        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.cooking_recipe', 'Cooking recipe'))}</div>
          <div class="list-lines">
            <div class="line"><span>•</span><span><a class="mono" href="${recipeLinkCooking(cookRec.name || q)}">${escHtml(cookRec.name || q)}</a></span></div>
          </div>
          <div class="stat-grid" style="margin-top:8px;">
            <div class="stat-card"><div class="stat-label">${escHtml(t('label.hunger', 'Hunger'))}</div><div class="stat-value">${renderCookStatRow('hunger')}</div></div>
            <div class="stat-card"><div class="stat-label">${escHtml(t('label.health', 'Health'))}</div><div class="stat-value">${renderCookStatRow('health')}</div></div>
            <div class="stat-card"><div class="stat-label">${escHtml(t('label.sanity', 'Sanity'))}</div><div class="stat-value">${renderCookStatRow('sanity')}</div></div>
            <div class="stat-card"><div class="stat-label">${escHtml(t('label.perish', 'Perish'))}</div><div class="stat-value">${renderCookStatRow('perishtime')}</div></div>
            <div class="stat-card"><div class="stat-label">${escHtml(t('label.cooktime', 'Cooktime'))}</div><div class="stat-value">${renderCookStatRow('cooktime')}</div></div>
          </div>
        </div>
      ` : `
        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.cooking_recipe', 'Cooking recipe'))}</div>
          <span class="muted">-</span>
        </div>
      `;

      const analyzerEnabled = Boolean(meta.analyzer_enabled);
      const analyzerBox = analyzerEnabled ? `
        <div class="section">
          <div class="row" style="justify-content:space-between;">
            <div class="section-title">${escHtml(t('catalog.section.prefab_analysis', 'Prefab analysis'))}</div>
            <button class="btn" id="btnAnalyze">${escHtml(t('btn.analyze', 'Analyze'))}</button>
          </div>
          <div class="muted small">${escHtml(t('catalog.prefab_analysis_help', 'Uses server-side LuaAnalyzer (prefab parser). Availability depends on how the server was started.'))}</div>
          <div id="analysis"></div>
        </div>
      ` : `
        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.prefab_analysis', 'Prefab analysis'))}</div>
          <div class="muted">${escHtml(t('catalog.prefab_analysis_disabled', 'Analyzer disabled. Start server with enable_analyzer=true and provide scripts_dir / scripts_zip (or dst_root).'))}</div>
        </div>
      `;

      el('detail').innerHTML = `
        <div class="detail-hero">
          <div class="row" style="align-items:center; gap:12px;">
            ${iconHtml}
            <div>
              <div class="hero-title">${escHtml(label)}</div>
              <div class="hero-sub mono">${escHtml(q)}</div>
            </div>
          </div>
          <div class="hero-meta">${renderChips(kindRow, 'mono')}</div>
        </div>

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.stats', 'Stats'))}</div>
          ${renderStats(stats)}
        </div>

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.categories', 'Categories'))}</div>
          <div class="chips">${renderChips(categories, '')}</div>
        </div>

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.behaviors', 'Behaviors'))}</div>
          <div class="chips">${renderChips(behaviors, '')}</div>
        </div>

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.components', 'Components'))}</div>
          <div class="chips">${renderChips(components, 'mono')}</div>
        </div>

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.tags', 'Tags'))}</div>
          <div class="chips">${renderChips(tags, 'mono')}</div>
        </div>

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.brains', 'Brains'))}</div>
          <div class="chips">${renderChips(brains, 'mono')}</div>
        </div>

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.stategraphs', 'Stategraphs'))}</div>
          <div class="chips">${renderChips(stategraphs, 'mono')}</div>
        </div>

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.helpers', 'Helpers'))}</div>
          <div class="chips">${renderChips(helpers, 'mono')}</div>
        </div>

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.prefab_files', 'Prefab files'))}</div>
          ${renderMonoLines(prefabFiles, 6)}
        </div>

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.assets', 'Assets'))}</div>
          <div class="list-lines">
            <div class="mono">${escHtml(t('label.icon', 'icon'))}: ${escHtml(iconPath || '-')}</div>
            <div class="mono">${escHtml(t('label.atlas', 'atlas'))}: ${escHtml(atlas || '-')}</div>
            <div class="mono">${escHtml(t('label.image', 'image'))}: ${escHtml(image || '-')}</div>
          </div>
        </div>

        ${prefabAssets && prefabAssets.length ? `<div class="section"><details><summary class="section-title">${escHtml(t('catalog.section.prefab_assets', 'Prefab assets (raw)'))}</summary><pre>${escHtml(JSON.stringify(prefabAssets, null, 2))}</pre></details></div>` : ''}

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.craft_produced', 'Craft: produced by'))}</div>
          ${renderRecipeList(craft.produced_by, recipeLinkCraft)}
        </div>

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.craft_used', 'Craft: used as ingredient'))}</div>
          ${renderRecipeList(craft.used_in, recipeLinkCraft)}
        </div>

        ${cookBrief}

        <div class="section">
          <div class="section-title">${escHtml(t('catalog.section.cooking_used', 'Cooking: used as card ingredient'))}</div>
          ${renderRecipeList(cooking.used_in, recipeLinkCooking)}
        </div>

        ${analyzerBox}
      `;

      if (analyzerEnabled) {
        el('btnAnalyze').onclick = async () => {
          try {
            setError('');
            el('analysis').innerHTML = `<div class="muted">${escHtml(t('label.loading', 'Loading...'))}</div>`;
            const res = await fetchJson(api(`/api/v1/analyze/prefab/${encodeURIComponent(q)}`));
            const rep = res.report || {};
            el('analysis').innerHTML = renderAnalysis(rep);
          } catch (e) {
            el('analysis').innerHTML = '';
            setError(String(e));
          }
        };
      }
      if (cookRec) {
        for (const btn of el('detail').querySelectorAll('button[data-cook-trace]')) {
          const field = btn.getAttribute('data-cook-trace');
          if (!field) continue;
          btn.onclick = async () => {
            try {
              setError('');
              await fetchTuningTrace(`cooking:${cookRec.name || q}:${field}`);
              await openItem(q);
            } catch (e) {
              setError(String(e));
            }
          };
        }
      }

      for (const btn of el('detail').querySelectorAll('button[data-item-trace]')) {
        const key = btn.getAttribute('data-item-trace');
        if (!key) continue;
        btn.onclick = async () => {
          try {
            setError('');
            await fetchTuningTrace(key);
            await openItem(q);
          } catch (e) {
            setError(String(e));
          }
        };
      }
      focusDetail();
    }

    async function loadMeta() {
      meta = await fetchJson(api('/api/v1/meta'));
      state.i18n = (meta && meta.i18n) ? meta.i18n : { enabled: false };
      state.tuningTraceEnabled = Boolean(meta && meta.tuning_trace_enabled);
      applyLabelModeUI();
      await ensureUiStrings(uiLang());
      applyUiStrings();
      const sha = meta.scripts_sha256_12 ? `sha:${meta.scripts_sha256_12}` : '';
      const ver = meta.schema_version ? `v${meta.schema_version}` : '';
      const ae = meta.analyzer_enabled ? 'analyzer:on' : 'analyzer:off';
      const te = meta.tuning_enabled ? 'tuning:on' : 'tuning:off';
      el('meta').textContent = [ver, sha, ae, te].filter(Boolean).join(' · ');

      el('navCraft').href = APP_ROOT + '/';
      el('navCooking').href = APP_ROOT + '/cooking';
      el('navCatalog').href = APP_ROOT + '/catalog';
    }

    function applyCatalogItems(items, updateList) {
      const trackList = (updateList !== false);
      (items || []).forEach((it) => {
        const iid = String(it.id || '').trim();
        if (!iid) return;
        if (trackList) {
          if (loadedKeys.has(iid)) return;
          loadedKeys.add(iid);
        }
        assets[iid] = {
          name: it.name || iid,
          image: it.image || null,
          icon: it.icon || it.image || null,
          kind: it.kind || '',
          categories: Array.isArray(it.categories) ? it.categories : [],
          behaviors: Array.isArray(it.behaviors) ? it.behaviors : [],
          sources: Array.isArray(it.sources) ? it.sources : [],
          tags: Array.isArray(it.tags) ? it.tags : [],
          components: Array.isArray(it.components) ? it.components : [],
          slots: Array.isArray(it.slots) ? it.slots : [],
        };
        if (trackList) allKeys.push(iid);
      });
    }

    async function loadCatalogPage(offset) {
      if (loadingPage) return [];
      loadingPage = true;
      try {
        const res = await fetchJson(api(`/api/v1/catalog/index?offset=${offset}&limit=${PAGE_SIZE}`));
        icon = res.icon || icon;
        catalogTotal = Number(res.total || res.count || 0);
        const items = res.items || [];
        applyCatalogItems(items, true);
        return items;
      } finally {
        loadingPage = false;
      }
    }

    async function loadAssets() {
      assets = {};
      allKeys = [];
      loadedKeys = new Set();
      listMode = 'all';
      searchTotal = 0;
      await loadCatalogPage(0);
      const total = catalogTotal || allKeys.length;
      el('stats').textContent = `${total} items. Showing 0/0.`;
    }

    async function initFromUrl() {
      const params = new URLSearchParams(window.location.search || '');
      const item = params.get('item');
      const q = params.get('q');
      if (q) {
        el('q').value = q;
        await runSearch(q);
        return;
      }
      if (item) {
        el('q').value = item;
        await runSearch(item);
        openItem(item).catch(e => setError(String(e)));
      }
    }

    el('btnSearch').onclick = () => {
      setError('');
      const q = el('q').value;
      runSearch(q).catch(e => setError(String(e)));
    };

    el('btnAll').onclick = () => {
      try {
        setError('');
        el('q').value = '';
        listMode = 'all';
        searchTotal = 0;
        renderList(listKeys());
      } catch (e) { setError(String(e)); }
    };

    el('q').addEventListener('keydown', (e) => {
      if (e.key === 'Enter') el('btnSearch').click();
    });

    const labelSel = el('labelMode');
    if (labelSel) {
      try { labelSel.value = state.labelMode || 'en'; } catch (e) {}
      labelSel.onchange = () => setLabelMode(labelSel.value).catch(e => setError(String(e)));
    }

    (async () => {
      try {
        await loadMeta();
        await loadAssets();
        await ensureI18nNames(state.labelMode);
        installInfiniteScroll();
        renderList(listKeys());
        await initFromUrl();
      } catch (e) {
        setError(String(e));
      }
    })();
  </script>
</body>
</html>
"""


def render_catalog_html(app_root: str = "") -> str:
    """Render the Catalog UI page."""
    from html import escape as _esc

    root = str(app_root or "")
    css = _SHARED_CSS.replace("__WAGSTAFF_APP_ROOT__", root)
    return _CATALOG_TEMPLATE.replace("__WAGSTAFF_APP_ROOT__", _esc(root)).replace("__SHARED_CSS__", css)



def render_index_html(app_root: str = "") -> str:
    """Render the UI page.

    app_root:
      - ""       normal direct serving
      - "/xxx"   reverse proxy mount path
    """
    root = str(app_root or "")
    css = _SHARED_CSS.replace("__WAGSTAFF_APP_ROOT__", root)
    return _INDEX_TEMPLATE.replace("__WAGSTAFF_APP_ROOT__", escape(root)).replace("__SHARED_CSS__", css)


_COOKING_TEMPLATE = r"""<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="app-root" content="__WAGSTAFF_APP_ROOT__" />
  <title>Wagstaff WebCraft - Cooking</title>
  <style>
__SHARED_CSS__
  </style>
</head>
<body>
  <header class="header">
    <div class="topbar">
      <div class="topbar-left">
        <div class="brand">Wagstaff <span class="brand-sub">Field Manual</span></div>
        <div class="nav-links">
          <a id="navCraft" class="nav-link" href="#">Craft</a>
          <a id="navCooking" class="nav-link active" href="#">Cooking</a>
          <a id="navCatalog" class="nav-link" href="#">Catalog</a>
        </div>
      </div>
      <div class="topbar-right">
        <div class="label-toggle">
          <span class="muted" id="labelModeLabel">Label</span>
          <select id="labelMode">
            <option value="en">EN</option>
            <option value="zh">中文</option>
            <option value="id">ID</option>
          </select>
        </div>
        <div class="meta" id="meta"></div>
      </div>
    </div>
    <div class="subbar">
      <div class="subbar-left">
        <div class="page-title">Cooking Lab</div>
        <div class="page-sub">Recipe rules and cookpot tools</div>
      </div>
      <div class="subbar-right">
        <div class="search">
          <input id="q" type="text" placeholder="Search: meatballs | ing:berries | tag:honeyed | type:FOODTYPE.MEAT" />
          <button id="btnSearch" class="primary">Search</button>
        </div>
      </div>
    </div>
  </header>

  <div class="layout">
    <div class="panel panel--filters">
      <div class="panel-head">
        <div class="panel-title" id="groupTitle">FoodTypes</div>
        <div class="panel-actions">
          <button id="btnToggle" class="btn ghost">Toggle</button>
        </div>
      </div>
      <div class="list" id="groupList"></div>
    </div>

    <div class="panel panel--list" id="listPanel">
      <div class="panel-head">
        <div class="panel-title" id="listTitle">Recipes</div>
        <span class="small muted" id="listCount"></span>
      </div>
      <div class="list" id="recipeList"></div>
    </div>

    <div class="panel panel--primary" id="detailPanel">
      <div class="panel-head">
        <div class="panel-title"><span id="detailTitle">Details / Tools</span></div>
        <button class="btn ghost back" id="btnBackList">Back to list</button>
      </div>
      <div class="detail">
        <div id="detail"></div>

        <div class="tool-card">
          <div class="small muted" id="inventoryHelp">Available ingredients (for search)</div>
          <textarea id="inv" placeholder="berries=2\ncarrot=3\nmeat=1"></textarea>
          <div style="display:flex; gap:8px; margin-top:8px;">
            <button id="btnFind" class="primary" style="flex:1;">Find cookable</button>
            <button id="btnShowAll" style="flex:1;">Show all</button>
          </div>
        </div>

        <div class="tool-card">
          <div class="small muted" id="slotsHelp">Cookpot slots (requires total = 4)</div>
          <textarea id="slots" placeholder="carrot=2\nberries=1\nbutterflywings=1"></textarea>
          <button id="btnSim" class="primary" style="width:100%; margin-top:8px;">Simulate</button>
        </div>

        <div class="tool-card">
          <div class="small muted">Results</div>
          <div id="out" class="small"></div>
        </div>

        <div class="err" id="err"></div>
      </div>
    </div>
  </div>

  <script>
    const APP_ROOT = (document.querySelector('meta[name="app-root"]')?.content || '').replace(/\/+$/,'');
    const api = (path) => APP_ROOT + path;

    const el = (id) => document.getElementById(id);
    const isNarrow = () => window.matchMedia('(max-width: 860px)').matches;
    const focusPanel = (id) => {
      if (!isNarrow()) return;
      const node = el(id);
      if (node) node.scrollIntoView({ behavior: 'smooth', block: 'start' });
    };
    const focusDetail = () => focusPanel('detailPanel');
    const focusList = () => focusPanel('listPanel');
    const backBtn = el('btnBackList');
    if (backBtn) backBtn.onclick = () => focusList();

    function setError(msg) {
      el('err').textContent = msg || '';
    }

    function parseInventory(text) {
      const out = {};
      const raw = (text || '').trim();
      if (!raw) return out;

      const parts = raw
        .split(/[,\n]/g)
        .map(s => s.trim())
        .filter(Boolean);

      for (const p of parts) {
        const m = p.match(/^([^=\s]+)\s*(?:=|\s)\s*([0-9]+(?:\.[0-9]+)?)$/);
        if (!m) continue;
        const k = m[1].trim();
        const v = parseFloat(m[2]);
        if (!k || !Number.isFinite(v) || v <= 0) continue;
        out[k] = v;
      }
      return out;
    }

    function parseSlots(text) {
      const raw = (text || '').trim();
      if (!raw) return {};

      // prefer explicit counts
      const asInv = parseInventory(raw);
      if (Object.keys(asInv).length) return asInv;

      // fallback: "a, b, c" means each counts as 1
      const out = {};
      const parts = raw
        .split(/[,\n]/g)
        .map(s => s.trim())
        .filter(Boolean);

      for (const p of parts) {
        out[p] = (out[p] || 0) + 1;
      }
      return out;
    }

    async function fetchJson(url, opts) {
      const r = await fetch(url, opts || {});
      if (!r.ok) {
        const t = await r.text();
        throw new Error(`HTTP ${r.status} ${r.statusText}\n${t}`);
      }
      return await r.json();
    }

    function escHtml(s) {
      return String(s ?? '').replace(/[&<>"']/g, (c) => ({
        '&': '&amp;',
        '<': '&lt;',
        '>': '&gt;',
        '"': '&quot;',
        "'": '&#39;',
      }[c]));
    }

    async function loadAssets() {
      try {
        const res = await fetchJson(api('/api/v1/assets'));
        state.assets = res.assets || {};
        state.icon = res.icon || null;
      } catch (e) {
        state.assets = {};
        state.icon = null;
      }
    }

    function _iconUrls(iid) {
      const cfg = state.icon || {};
      const mode = String(cfg.mode || 'off');
      const enc = encodeURIComponent(iid);
      const staticBaseRaw = String(cfg.static_base || '/static/data/icons');
      const staticBase = (APP_ROOT && staticBaseRaw.startsWith('/') && !staticBaseRaw.startsWith(APP_ROOT + '/'))
        ? (APP_ROOT + staticBaseRaw)
        : staticBaseRaw;
      const apiBase = String(cfg.api_base || '/api/v1/icon');
      const staticUrl = api(`${staticBase}/${enc}.png`);
      const apiUrl = api(`${apiBase}/${enc}.png`);

      if (mode === 'dynamic') return { src: apiUrl, fallback: '' };
      if (mode === 'static') return { src: staticUrl, fallback: apiUrl };
      if (mode === 'auto') return { src: staticUrl, fallback: apiUrl };
      return { src: '', fallback: '' };
    }

    function iconError(img) {
      try {
        const fb = img?.dataset?.fallback || '';
        const tried = img?.dataset?.fallbackTried || '';
        if (fb && !tried) {
          img.dataset.fallbackTried = '1';
          img.src = fb;
          return;
        }
        img.style.display = 'none';
        const nxt = img.nextElementSibling;
        if (nxt) nxt.style.display = 'flex';
      } catch (e) {
        // ignore
      }
    }

    function _altId(iid) {
      if (!iid) return '';
      const s = String(iid);
      if (s.includes('_')) return s.replace(/_/g,'');
      return '';
    }

    function getI18nName(iid) {
      const mp = (state.i18nNames && state.i18nNames.zh) ? state.i18nNames.zh : null;
      if (!mp) return '';
      const k = String(iid || '').trim();
      if (!k) return '';
      const lo = k.toLowerCase();
      const a1 = _altId(k);
      const a2 = _altId(lo);
      return mp[k] || mp[lo] || (a1 ? mp[a1] : '') || (a2 ? mp[a2] : '') || '';
    }

    async function ensureI18nNames(mode) {
      if (String(mode || '') !== 'zh') return;
      if (state.i18nLoaded && state.i18nLoaded.zh) return;
      const enabled = Boolean(state.i18n && state.i18n.enabled);
      if (!enabled) return;
      try {
        const res = await fetchJson(api('/api/v1/i18n/names/zh'));
        state.i18nNames.zh = res.names || {};
        state.i18nLoaded.zh = true;
      } catch (e) {
        state.i18nLoaded.zh = false;
      }
    }

    // ui i18n (cooking)
    function uiLang() {
      return (state.labelMode === 'zh') ? 'zh' : 'en';
    }

    async function ensureUiStrings(lang) {
      const l = String(lang || '').trim();
      if (!l) return;
      if (state.uiLoaded && state.uiLoaded[l]) return;
      try {
        const res = await fetchJson(api(`/api/v1/i18n/ui/${encodeURIComponent(l)}`));
        state.uiStrings[l] = res.strings || {};
        state.uiLoaded[l] = true;
      } catch (e) {
        state.uiStrings[l] = {};
        state.uiLoaded[l] = false;
      }
    }

    function t(key, fallback) {
      const l = uiLang();
      const mp = (state.uiStrings && state.uiStrings[l]) ? state.uiStrings[l] : {};
      return (mp && mp[key]) ? mp[key] : (fallback || key || '');
    }

    function applyUiStrings() {
      const navCraft = el('navCraft');
      if (navCraft) navCraft.textContent = t('nav.craft', 'Craft');
      const navCooking = el('navCooking');
      if (navCooking) navCooking.textContent = t('nav.cooking', 'Cooking');
      const navCatalog = el('navCatalog');
      if (navCatalog) navCatalog.textContent = t('nav.catalog', 'Catalog');
      const label = el('labelModeLabel');
      if (label) label.textContent = t('label.mode', 'Label');
      const btnSearch = el('btnSearch');
      if (btnSearch) btnSearch.textContent = t('btn.search', 'Search');
      const btnToggle = el('btnToggle');
      if (btnToggle) btnToggle.textContent = t('btn.toggle', 'Toggle');
      const listTitle = el('listTitle');
      if (listTitle) {
        const txt = listTitle.textContent || '';
        if (!txt.includes(':') && !txt.includes('(')) {
          listTitle.textContent = t('cooking.list.recipes', txt || 'Recipes');
        }
      }
      const groupTitle = el('groupTitle');
      if (groupTitle) {
        if (state.mode === 'foodtypes') groupTitle.textContent = t('cooking.group.foodtypes', 'FoodTypes');
        else if (state.mode === 'tags') groupTitle.textContent = t('cooking.group.tags', 'Tags');
        else groupTitle.textContent = t('cooking.group.all', 'All');
      }
      const detailTitle = el('detailTitle');
      if (detailTitle) detailTitle.textContent = t('cooking.detail.title', 'Details / Tools');
      const invHelp = el('inventoryHelp');
      if (invHelp) invHelp.textContent = t('cooking.inventory.help', 'Available ingredients (for search)');
      const slotsHelp = el('slotsHelp');
      if (slotsHelp) slotsHelp.textContent = t('cooking.slots.help', 'Cookpot slots (requires total = 4)');
      const input = el('q');
      if (input) input.placeholder = t('cooking.search.placeholder', input.placeholder || '');
      const inv = el('inv');
      if (inv) inv.placeholder = t('cooking.inventory.placeholder', inv.placeholder || '');
      const slots = el('slots');
      if (slots) slots.placeholder = t('cooking.slots.placeholder', slots.placeholder || '');
      const btnFind = el('btnFind');
      if (btnFind) btnFind.textContent = t('btn.find_cookable', 'Find cookable');
      const btnShowAll = el('btnShowAll');
      if (btnShowAll) btnShowAll.textContent = t('btn.show_all', 'Show all');
      const btnSim = el('btnSim');
      if (btnSim) btnSim.textContent = t('btn.simulate', 'Simulate');
    }

    async function fetchTuningTrace(prefix) {
      if (!state.tuningTraceEnabled) return {};
      const pfx = String(prefix || '').trim();
      if (!pfx) return {};
      const res = await fetchJson(api(`/api/v1/tuning/trace?prefix=${encodeURIComponent(pfx)}`));
      const traces = res.traces || {};
      for (const k in traces) {
        if (!Object.prototype.hasOwnProperty.call(traces, k)) continue;
        state.tuningTrace[k] = traces[k];
      }
      return traces;
    }

    function applyLabelModeUI() {
      const sel = el('labelMode');
      if (!sel) return;
      const enabled = Boolean(state.i18n && state.i18n.enabled);
      const optZh = sel.querySelector('option[value="zh"]');
      if (optZh) optZh.disabled = !enabled;
      if (!enabled && state.labelMode === 'zh') {
        state.labelMode = 'en';
        try { localStorage.setItem('ws_label_mode', state.labelMode); } catch (e) {}
      }
      sel.value = state.labelMode || 'en';
    }

    function resolveLabel(iid, enName, zhName) {
      const mode = String(state.labelMode || 'en');
      if (mode === 'id') return iid;
      if (mode === 'zh' && zhName) return zhName;
      return enName || iid;
    }

    async function setLabelMode(mode) {
      state.labelMode = String(mode || 'en');
      try { localStorage.setItem('ws_label_mode', state.labelMode); } catch (e) {}
      applyLabelModeUI();
      await ensureI18nNames(state.labelMode);
      await ensureUiStrings(uiLang());
      applyUiStrings();
      renderRecipeList();
      renderRecipeDetail(state.activeRecipeData);
    }

    function renderItem(id) {
      const iid = String(id || '').trim();
      if (!iid) return '';
      const m = (state.assets && state.assets[iid]) ? state.assets[iid] : null;
      const enName = (m && m.name) ? m.name : iid;
      const zhName = getI18nName(iid);
      const name = resolveLabel(iid, enName, zhName);

      const tipParts = [`id:${iid}`];
      if (enName && enName !== iid) tipParts.push(`en:${enName}`);
      if (zhName && zhName !== enName && zhName !== iid) tipParts.push(`zh:${zhName}`);
      if (m && m.image) tipParts.push(`img:${m.image}`);
      if (m && m.atlas) tipParts.push(`atlas:${m.atlas}`);
      const tip = escHtml(tipParts.join(' | '));

      const { src, fallback } = _iconUrls(iid);
      const iconChar = (m && (m.image || m.atlas)) ? '🖼️' : '📦';

      if (!src) {
        return `<span class="itemRef" title="${tip}">` +
          `<span class="itemIcon"><span class="itemIconFallback" style="display:flex;">${iconChar}</span></span>` +
          `<span class="itemLabel">${escHtml(name)}</span></span>`;
      }

      const fbAttr = fallback ? ` data-fallback="${escHtml(fallback)}"` : '';
      return `<span class="itemRef" title="${tip}">` +
        `<span class="itemIcon">` +
          `<img class="itemIconImg" src="${escHtml(src)}"${fbAttr} onerror="iconError(this)" alt="" />` +
          `<span class="itemIconFallback">${iconChar}</span>` +
        `</span>` +
        `<span class="itemLabel">${escHtml(name)}</span>` +
      `</span>`;
    }


    const state = {
      mode: 'foodtypes', // foodtypes | tags | all
      groups: [],
      activeGroup: null,
      recipes: [],
      activeRecipe: null,
      activeRecipeData: null,
      assets: {},
      icon: null, // {mode, static_base, api_base}

      // label mode: en | zh | id (persisted in localStorage)
      labelMode: localStorage.getItem('ws_label_mode') || 'en',
      i18n: null,         // meta from /api/v1/meta (set in loadMeta)
      i18nNames: {},      // {lang: {id: name}}
      i18nLoaded: {},     // {lang: true}
      tuningTrace: {},    // {trace_key: trace}
      tuningTraceEnabled: false,
      uiStrings: {},      // {lang: {key: text}}
      uiLoaded: {},       // {lang: true}
    };

    function renderGroupList() {
      const box = el('groupList');
      box.innerHTML = '';
      for (const g of state.groups) {
        const div = document.createElement('div');
        div.className = 'item' + (state.activeGroup === g.name ? ' active' : '');
        div.innerHTML = `<span class="name">${g.name}</span><span class="meta">${g.count ?? ''}</span>`;
        div.onclick = () => selectGroup(g.name);
        box.appendChild(div);
      }
    }

    function renderRecipeList() {
      const box = el('recipeList');
      box.innerHTML = '';
      el('listCount').textContent = state.recipes.length ? `${state.recipes.length}` : '';
      for (const nm of state.recipes) {
        const div = document.createElement('div');
        div.className = 'item' + (state.activeRecipe === nm ? ' active' : '');
        div.innerHTML = `<span class="name">${renderItem(nm)}</span><span class="meta"></span>`;
        div.onclick = () => selectRecipe(nm);
        box.appendChild(div);
      }
    }

    function renderRecipeDetail(rec) {
      if (!rec) {
        el('detail').innerHTML = `<div class="muted">${escHtml(t('cooking.detail.empty', 'Select a recipe.'))}</div>`;
        return;
      }

      const tags = (rec.tags || []).map(x => `<span class="chip">${x}</span>`).join('');
      const card = (rec.card_ingredients || []).map(row => {
        const item = row[0];
        const cnt = row[1];
        return `<div class="line"><span>•</span><span>${renderItem(item)} <span class="mono">x${escHtml(cnt)}</span></span></div>`;
      }).join('');


      const rule = rec.rule || null;

      function renderRule(rule, includeTitle = true) {
        if (!rule) return '';
        const kind = escHtml(rule.kind || '');
        const expr = escHtml(rule.expr || '');
        const cons = rule.constraints || null;
        const title = includeTitle
          ? `<div class="section-title">${escHtml(t('cooking.rule.title', 'Rule'))}${kind ? ` (${kind})` : ''}</div>`
          : '';

        let consHtml = '';
        if (cons) {
          const tags = (cons.tags || []).map(c => `<div class="line"><span>•</span><span class="mono">${escHtml(c.text || '')}</span></div>`).join('');
          const names = (cons.names || []).map(c => `<div class="line"><span>•</span><span class="mono">${escHtml(c.text || '')}</span></div>`).join('');
          const unp = (cons.unparsed || []).map(x => `<div class="line"><span>•</span><span class="mono">${escHtml(x)}</span></div>`).join('');
          const any = Boolean(tags || names || unp);
          consHtml = `
            <div style="margin-top:8px;">
              <div class="section-title">${escHtml(t('cooking.rule.constraints', 'Constraints (best-effort)'))}</div>
              ${tags ? `<div><div class="small muted">${escHtml(t('cooking.rule.constraints.tags', 'tags'))}</div><div class="list-lines">${tags}</div></div>` : ''}
              ${names ? `<div style="margin-top:6px;"><div class="small muted">${escHtml(t('cooking.rule.constraints.names', 'names'))}</div><div class="list-lines">${names}</div></div>` : ''}
              ${unp ? `<div style="margin-top:6px;"><div class="small muted">${escHtml(t('cooking.rule.constraints.unparsed', 'unparsed'))}</div><div class="list-lines">${unp}</div></div>` : ''}
              ${any ? '' : '<span class="muted">-</span>'}
            </div>
          `;
        }

        return `
          ${title}
          <div class="mono small" style="white-space:pre-wrap; line-height:1.35;">${expr || '<span class="muted">-</span>'}</div>
          ${consHtml}
        `;
      }

      const cardBody = card
        ? `<div class="list-lines">${card}</div>`
        : (rule ? renderRule(rule, false) : '<span class="muted">-</span>');
      const tuning = rec._tuning || {};
      const traceKey = (field) => rec?.name ? `cooking:${rec.name}:${field}` : '';
      const traceCache = state.tuningTrace || {};
      const fields = ['hunger', 'health', 'sanity', 'perishtime', 'cooktime'];

      function traceForField(field) {
        const raw = rec ? rec[field] : null;
        if (raw && typeof raw === 'object' && (raw.trace || raw.expr || raw.value !== undefined)) return raw;
        if (tuning && tuning[field]) return tuning[field];
        const key = traceKey(field);
        return key ? traceCache[key] : null;
      }

      function renderStat(field) {
        const raw = rec ? rec[field] : null;
        const tr = traceForField(field);
        const expr = tr ? (tr.expr ?? raw ?? '') : (raw ?? '');
        const val = tr && (tr.value !== null && tr.value !== undefined) ? tr.value : raw;
        const hasVal = (val !== null && val !== undefined && val !== '');
        const showExpr = expr && String(expr) !== String(val);
        const titleAttr = showExpr ? ` title="${escHtml(expr)}"` : '';

        const main = hasVal
          ? `<span class="mono"${titleAttr}>${escHtml(val)}</span>`
          : `<span class="mono">${escHtml(expr ?? '')}</span>`;

        const enabled = Boolean(state.tuningTraceEnabled);
        const key = traceKey(field);
        const btn = key
          ? `<button class="btn" data-cook-trace="${escHtml(field)}" ${enabled ? '' : 'disabled'} style="margin-left:6px; padding:2px 6px; font-size:11px;">${escHtml(t('btn.trace', 'Trace'))}</button>`
          : '';

        const details = tr
          ? `<details style="margin-top:6px;"><summary class="small muted">${escHtml(t('label.trace', 'Trace'))}</summary><pre>${escHtml(JSON.stringify(tr, null, 2))}</pre></details>`
          : '';

        const actions = btn ? `<span class="stat-actions">${btn}</span>` : '';
        return `<div class="stat-row">${main}${actions}</div>${details}`;
      }

      const extraRule = (card && rule)
        ? `<div style="margin-top:10px;">${renderRule(rule, true)}</div>`
        : '';
      const foodType = String(rec.foodtype || '').replace('FOODTYPE.','');
      const heroMeta = foodType ? `<span class="pill">${escHtml(foodType)}</span>` : '<span class="muted">-</span>';
      const statRows = [
        {
          label: t('label.priority', 'Priority'),
          value: `<span class="mono">${escHtml(rec.priority ?? '')}</span>`,
        },
        { label: t('label.hunger', 'Hunger'), value: renderStat('hunger') },
        { label: t('label.health', 'Health'), value: renderStat('health') },
        { label: t('label.sanity', 'Sanity'), value: renderStat('sanity') },
        { label: t('label.perish', 'Perish'), value: renderStat('perishtime') },
        { label: t('label.cooktime', 'Cooktime'), value: renderStat('cooktime') },
      ];
      const statCards = statRows.map(row => `
        <div class="stat-card">
          <div class="stat-label">${escHtml(row.label)}</div>
          <div class="stat-value">${row.value}</div>
        </div>
      `).join('');

      el('detail').innerHTML = `
        <div class="detail-hero">
          <div>
            <div class="hero-title">${renderItem(rec.name || '')}</div>
            <div class="hero-sub">${escHtml(foodType || '-')}</div>
          </div>
          <div class="hero-meta">${heroMeta}</div>
        </div>
        <div class="stat-grid">
          ${statCards}
        </div>
        <div class="section">
          <div class="section-title">${escHtml(t('label.tags', 'Tags'))}</div>
          <div class="chips">${tags || '<span class="muted">-</span>'}</div>
        </div>
        <div class="section">
          <div class="section-title">${escHtml(card ? t('cooking.card.ingredients', 'Card ingredients') : (rule ? t('cooking.rule.conditional', 'Recipe rule (conditional)') : t('cooking.card.ingredients', 'Card ingredients')))}</div>
          ${cardBody}
          ${extraRule}
        </div>
      `;

      for (const btn of el('detail').querySelectorAll('button[data-cook-trace]')) {
        const field = btn.getAttribute('data-cook-trace');
        if (!field || !rec.name) continue;
        btn.onclick = async () => {
          try {
            setError('');
            await fetchTuningTrace(`cooking:${rec.name}:${field}`);
            renderRecipeDetail(rec);
          } catch (e) {
            setError(String(e));
          }
        };
      }
    }

    async function loadMeta() {
      const m = await fetchJson(api('/api/v1/meta'));
      state.i18n = (m && m.i18n) ? m.i18n : { enabled: false };
      state.tuningTraceEnabled = Boolean(m && m.tuning_trace_enabled);
      applyLabelModeUI();
      await ensureUiStrings(uiLang());
      applyUiStrings();
      const sha = m.scripts_sha256_12 ? `sha:${m.scripts_sha256_12}` : '';
      const ae = m.analyzer_enabled ? 'analyzer:on' : 'analyzer:off';
      const te = m.tuning_enabled ? 'tuning:on' : 'tuning:off';
      el('meta').textContent = `${sha} | mode:${m.engine_mode || ''} | files:${m.scripts_file_count || ''} | ${ae} | ${te}`;
    }

    async function loadGroups() {
      setError('');

      if (state.mode === 'foodtypes') {
        el('groupTitle').textContent = t('cooking.group.foodtypes', 'FoodTypes');
        const res = await fetchJson(api('/api/v1/cooking/foodtypes'));
        state.groups = (res.foodtypes || []).map(t => ({ name: t.name, count: t.count }));
      } else if (state.mode === 'tags') {
        el('groupTitle').textContent = t('cooking.group.tags', 'Tags');
        const res = await fetchJson(api('/api/v1/cooking/tags'));
        state.groups = (res.tags || []).map(t => ({ name: t.name, count: t.count }));
      } else {
        el('groupTitle').textContent = t('cooking.group.all', 'All');
        const res = await fetchJson(api('/api/v1/cooking/recipes'));
        state.groups = [{ name: 'ALL', count: res.count || '' }];
      }

      state.activeGroup = null;
      state.recipes = [];
      state.activeRecipe = null;
      state.activeRecipeData = null;
      renderGroupList();
      renderRecipeList();
      renderRecipeDetail(null);
    }

    async function selectGroup(name) {
      setError('');
      state.activeGroup = name;
      renderGroupList();

      let url = '';
      if (state.mode === 'foodtypes') url = api(`/api/v1/cooking/foodtypes/${encodeURIComponent(name)}/recipes`);
      else if (state.mode === 'tags') url = api(`/api/v1/cooking/tags/${encodeURIComponent(name)}/recipes`);
      else url = api('/api/v1/cooking/recipes');

      const res = await fetchJson(url);
      state.recipes = (res.recipes || []);
      state.activeRecipe = null;
      state.activeRecipeData = null;

      el('listTitle').textContent = (state.mode === 'all')
        ? t('cooking.list.all_recipes', 'All recipes')
        : t('cooking.list.recipes', 'Recipes');
      renderRecipeList();
      renderRecipeDetail(null);
    }

    async function selectRecipe(name) {
      setError('');
      state.activeRecipe = name;
      renderRecipeList();
      const res = await fetchJson(api(`/api/v1/cooking/recipes/${encodeURIComponent(name)}`));
      state.activeRecipeData = res.recipe || null;
      // ensure name always present
      if (state.activeRecipeData && !state.activeRecipeData.name) state.activeRecipeData.name = name;
      renderRecipeDetail(state.activeRecipeData);
      focusDetail();
    }

    async function doSearch() {
      setError('');
      const q = el('q').value.trim();
      if (!q) return;
      const res = await fetchJson(api(`/api/v1/cooking/recipes/search?q=${encodeURIComponent(q)}&limit=200`));
      const results = (res.results || []).map(r => r.name).filter(Boolean);
      state.recipes = results;
      state.activeGroup = null;
      state.activeRecipe = null;
      state.activeRecipeData = null;
      renderGroupList();
      renderRecipeList();
      renderRecipeDetail(null);
      el('listTitle').textContent = `${t('label.search', 'Search')}: ${q}`;
    }

    async function showAll() {
      setError('');
      const res = await fetchJson(api('/api/v1/cooking/recipes'));
      state.recipes = (res.recipes || []);
      state.activeGroup = null;
      state.activeRecipe = null;
      state.activeRecipeData = null;
      renderGroupList();
      renderRecipeList();
      renderRecipeDetail(null);
      el('listTitle').textContent = t('cooking.list.all_recipes', 'All recipes');
    }

    async function doFind() {
      setError('');
      const inv = parseInventory(el('inv').value);
      const res = await fetchJson(api('/api/v1/cooking/find'), {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ inventory: inv, limit: 200 }),
      });

      const cookable = res.cookable || [];
      state.recipes = cookable;
      state.activeGroup = null;
      state.activeRecipe = null;
      state.activeRecipeData = null;
      renderGroupList();
      renderRecipeList();
      renderRecipeDetail(null);

      el('listTitle').textContent = `${t('cooking.list.cookable', 'Cookable')} (${cookable.length})`;
      el('out').innerHTML = res.note ? `<div class="muted">${res.note}</div>` : '';
    }

    async function doSimulate() {
      setError('');
      const slots = parseSlots(el('slots').value);
      const res = await fetchJson(api('/api/v1/cooking/simulate'), {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ slots: slots, return_top: 20 }),
      });

      if (!res.ok) {
        el('out').innerHTML = `<div class="err">${res.error || 'simulation_failed'} (total=${res.total ?? ''})</div>`;
        return;
      }

      const result = res.result || '(none)';
      const reason = res.reason || '';
      const cand = res.candidates || [];
      const lines = cand.length
        ? cand.map(c => `• ${renderItem(c.name)} (p=${escHtml(c.priority)}, w=${escHtml(c.weight)})`).join('<br/>')
        : '<span class="muted">No candidates (fallback).</span>';

      el('out').innerHTML = `
        <div class="ok">Result: ${renderItem(result)} <span class="muted">${reason ? '('+reason+')' : ''}</span></div>
        <div class="small muted" style="margin-top:6px;">Top matches</div>
        <div class="mono">${lines}</div>
      `;

      // auto-select result if exists
      if (res.recipe) {
        state.activeRecipe = result;
        state.activeRecipeData = res.recipe;
        if (state.activeRecipeData && !state.activeRecipeData.name) state.activeRecipeData.name = result;
        renderRecipeList();
        renderRecipeDetail(state.activeRecipeData);
      }
    }

    function toggleMode() {
      if (state.mode === 'foodtypes') state.mode = 'tags';
      else if (state.mode === 'tags') state.mode = 'all';
      else state.mode = 'foodtypes';
      loadGroups().catch(e => setError(String(e)));
    }

    // wire
    const navCraft = document.getElementById('navCraft');
    if (navCraft) navCraft.href = APP_ROOT + '/';

    const navCooking = document.getElementById('navCooking');
    if (navCooking) navCooking.href = APP_ROOT + '/cooking';

    const navCatalog = document.getElementById('navCatalog');
    if (navCatalog) navCatalog.href = APP_ROOT + '/catalog';


    const labelSel = el('labelMode');
    if (labelSel) {
      try { labelSel.value = state.labelMode || 'en'; } catch (e) {}
      labelSel.onchange = () => setLabelMode(labelSel.value).catch(e => setError(String(e)));
    }

    el('btnToggle').onclick = toggleMode;
    el('btnSearch').onclick = () => doSearch().catch(e => setError(String(e)));
    el('q').addEventListener('keydown', (e) => { if (e.key === 'Enter') doSearch().catch(err => setError(String(err))); });
    el('btnFind').onclick = () => doFind().catch(e => setError(String(e)));
    el('btnSim').onclick = () => doSimulate().catch(e => setError(String(e)));
    el('btnShowAll').onclick = () => showAll().catch(e => setError(String(e)));

    function initFromUrl() {
      const params = new URLSearchParams(window.location.search || '');
      const recipe = params.get('recipe');
      const q = params.get('q');
      if (recipe) {
        selectRecipe(recipe).catch(e => setError(String(e)));
        return;
      }
      if (q) {
        el('q').value = q;
        doSearch().catch(e => setError(String(e)));
      }
    }

    // init
    (async () => {
      try {
        await loadMeta();
        await ensureI18nNames(state.labelMode);
        await loadAssets();
        await loadGroups();
        await showAll();
        initFromUrl();
      } catch (e) {
        setError(String(e));
      }
    })();
  </script>
</body>
</html>
"""


def render_cooking_html(app_root: str = "") -> str:
    """Render the Cooking UI page."""
    from html import escape as _esc

    root = str(app_root or "")
    css = _SHARED_CSS.replace("__WAGSTAFF_APP_ROOT__", root)
    return _COOKING_TEMPLATE.replace("__WAGSTAFF_APP_ROOT__", _esc(root)).replace("__SHARED_CSS__", css)
```

### File: core/__init__.py
- mode: full
- size_bytes: 61
- sha256_12: ac551446262f

```py
# -*- coding: utf-8 -*-
"""Core package for Wagstaff-Lab."""
```

### File: core/analyzer.py
- mode: full
- size_bytes: 53880
- sha256_12: 0237e6589e2c

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Lua parsing primitives + domain analyzers for Wagstaff-Lab.

Core goals
- Robust scanning: skip comments/strings/long-brackets.
- Balanced parsing: brackets + Lua block keywords (function/if/for/while/repeat/do/end/until).
- Practical AST-lite: parse Lua table constructors into (array, map) for data-driven extraction.
- Extract function calls with balanced parentheses (supports member calls obj:Method()).

Public API (intended stable)
- strip_lua_comments(text) -> str
- split_top_level(text, sep=',') -> List[str]
- find_matching(text, open_idx, open_ch, close_ch) -> Optional[int]
- parse_lua_string(expr) -> Optional[str]
- parse_lua_expr(expr) -> Any
- parse_lua_table(inner) -> LuaTableValue
- LuaCallExtractor(content).iter_calls(...)
- TuningResolver(content)
- LuaAnalyzer(content, path=None).get_report()
- CookingRecipeAnalyzer(content).recipes
- CookingIngredientAnalyzer(content).ingredients
"""

from __future__ import annotations

import bisect
import math
import re
from dataclasses import dataclass
from typing import Any, Dict, Iterator, List, Optional, Sequence, Tuple, Union

__all__ = [
    # scanning helpers
    "strip_lua_comments",
    "split_top_level",
    "find_matching",
    # expr parsing
    "parse_lua_string",
    "parse_lua_expr",
    "parse_lua_table",
    "LuaRaw",
    "LuaTableValue",
    "lua_to_python",
    # call extraction
    "LuaCall",
    "LuaCallExtractor",
    # tuning
    "TuningResolver",
    # domain parsers
    "LootParser",
    "WidgetParser",
    "StringParser",
    "PrefabParser",
    "LuaAnalyzer",
    # cooking
    "CookingRecipeAnalyzer",
    "CookingIngredientAnalyzer",
]


# ============================================================
# 0) Low-level Lua scanning helpers
# ============================================================

_LUA_KEYWORDS = {
    "and", "break", "do", "else", "elseif", "end", "false", "for", "function", "goto",
    "if", "in", "local", "nil", "not", "or", "repeat", "return", "then", "true", "until", "while",
}


def _is_ident_start(ch: str) -> bool:
    return ch == "_" or ("A" <= ch <= "Z") or ("a" <= ch <= "z")


def _is_ident_char(ch: str) -> bool:
    return _is_ident_start(ch) or ("0" <= ch <= "9")


def _long_bracket_level(text: str, i: int) -> Optional[int]:
    """
    If text[i:] starts a Lua long-bracket opener: [=*[ , return '=' count; else None.
    Examples: [[ -> 0, [=[ -> 1, [==[ -> 2
    """
    n = len(text)
    if i >= n or text[i] != "[":
        return None
    j = i + 1
    while j < n and text[j] == "=":
        j += 1
    if j < n and text[j] == "[":
        return j - i - 1
    return None


def _skip_long_bracket(text: str, i: int, level: int) -> int:
    """Skip Lua long-bracket string/comment starting at i. Return next index."""
    n = len(text)
    opener_len = 2 + level
    start = i + opener_len
    close_pat = "]" + ("=" * level) + "]"
    end = text.find(close_pat, start)
    if end == -1:
        return n
    return end + len(close_pat)


def _skip_short_string(text: str, i: int, quote: str) -> int:
    """Skip '...' or "...", supporting backslash escapes. Return next index."""
    n = len(text)
    i += 1
    while i < n:
        ch = text[i]
        if ch == "\\":
            i += 2
            continue
        if ch == quote:
            return i + 1
        i += 1
    return n


def _skip_comment(text: str, i: int) -> int:
    """i points at '-' and text[i:i+2]=='--'. Skip a line or block comment. Return next index."""
    n = len(text)
    if not text.startswith("--", i):
        return i

    # Block comment: --[=*[ ... ]=*]
    if i + 2 < n and text[i + 2] == "[":
        level = _long_bracket_level(text, i + 2)
        if level is not None:
            return _skip_long_bracket(text, i + 2, level)

    # Line comment
    nl = text.find("\n", i + 2)
    return n if nl == -1 else nl + 1


def _skip_string_or_long_string(text: str, i: int) -> Optional[int]:
    """If position i starts a string/long-string, return next index; else None."""
    if i >= len(text):
        return None
    ch = text[i]
    if ch in ("'", '"'):
        return _skip_short_string(text, i, ch)
    if ch == "[":
        level = _long_bracket_level(text, i)
        if level is not None:
            return _skip_long_bracket(text, i, level)
    return None


def strip_lua_comments(text: str) -> str:
    """
    Remove Lua comments while preserving line breaks (keeps line numbers stable).
    Strings/long-strings are preserved.
    """
    if not text:
        return ""
    n = len(text)
    out: List[str] = []
    i = 0
    while i < n:
        if text.startswith("--", i):
            j = _skip_comment(text, i)
            out.append("\n" * text[i:j].count("\n"))
            i = j
            continue
        nxt = _skip_string_or_long_string(text, i)
        if nxt is not None:
            out.append(text[i:nxt])
            i = nxt
            continue
        out.append(text[i])
        i += 1
    return "".join(out)


# ============================================================
# 1) Balanced splitting (commas at top-level), with Lua block awareness
# ============================================================

def _split_top_level(text: str, sep: str = ",") -> List[str]:
    """
    Split by sep at top level.

    Top level means:
    - not in (), {}, []
    - not in strings/comments/long-strings
    - not inside Lua blocks (function/if/for/while/repeat/do ... end/until)

    This is critical for safely splitting function call arguments in DST scripts.
    """
    if not text:
        return []

    n = len(text)
    parts: List[str] = []
    start = 0
    i = 0

    bracket_stack: List[str] = []
    block_stack: List[Tuple[str, bool]] = []  # (kind, awaiting_do)

    def _push_block(kind: str) -> None:
        block_stack.append((kind, False))

    def _push_loop(kind: str) -> None:
        block_stack.append((kind, True))

    def _on_do() -> None:
        if block_stack and block_stack[-1][0] in ("for", "while") and block_stack[-1][1]:
            kind, _ = block_stack[-1]
            block_stack[-1] = (kind, False)
        else:
            _push_block("do")

    def _on_end() -> None:
        if block_stack:
            block_stack.pop()

    def _on_until() -> None:
        # close the nearest repeat
        for idx in range(len(block_stack) - 1, -1, -1):
            if block_stack[idx][0] == "repeat":
                del block_stack[idx:]
                return

    while i < n:
        if text.startswith("--", i):
            i = _skip_comment(text, i)
            continue

        nxt = _skip_string_or_long_string(text, i)
        if nxt is not None:
            i = nxt
            continue

        ch = text[i]

        if ch in "({[":
            if ch == "[":
                level = _long_bracket_level(text, i)
                if level is not None:
                    i = _skip_long_bracket(text, i, level)
                    continue
            bracket_stack.append(ch)
            i += 1
            continue

        if ch in ")}]":
            want = {")": "(", "}": "{", "]": "["}[ch]
            if bracket_stack and bracket_stack[-1] == want:
                bracket_stack.pop()
            i += 1
            continue

        # block keywords
        if _is_ident_start(ch):
            j = i + 1
            while j < n and _is_ident_char(text[j]):
                j += 1
            word = text[i:j]
            if word == "function":
                _push_block("function")
            elif word == "if":
                _push_block("if")
            elif word == "for":
                _push_loop("for")
            elif word == "while":
                _push_loop("while")
            elif word == "repeat":
                _push_block("repeat")
            elif word == "do":
                _on_do()
            elif word == "end":
                _on_end()
            elif word == "until":
                _on_until()
            i = j
            continue

        if ch == sep and not bracket_stack and not block_stack:
            parts.append(text[start:i].strip())
            start = i + 1
            i += 1
            continue

        i += 1

    tail = text[start:].strip()
    if tail:
        parts.append(tail)
    return parts


def split_top_level(text: str, sep: str = ",") -> List[str]:
    """Public wrapper for _split_top_level."""
    return _split_top_level(text, sep)


def _find_matching(text: str, open_idx: int, open_ch: str, close_ch: str) -> Optional[int]:
    """Find the matching closing bracket for open_ch at open_idx. Skip strings/comments/long brackets."""
    n = len(text)
    if open_idx >= n or text[open_idx] != open_ch:
        return None

    stack: List[str] = [open_ch]
    i = open_idx + 1
    while i < n and stack:
        if text.startswith("--", i):
            i = _skip_comment(text, i)
            continue
        nxt = _skip_string_or_long_string(text, i)
        if nxt is not None:
            i = nxt
            continue

        ch = text[i]
        if ch in "({[":
            if ch == "[":
                level = _long_bracket_level(text, i)
                if level is not None:
                    i = _skip_long_bracket(text, i, level)
                    continue
            stack.append(ch)
            i += 1
            continue

        if ch in ")}]":
            want = {")": "(", "}": "{", "]": "["}[ch]
            if stack and stack[-1] == want:
                stack.pop()
            i += 1
            continue

        i += 1

    if stack:
        return None
    return i - 1


def find_matching(text: str, open_idx: int, open_ch: str, close_ch: str) -> Optional[int]:
    """Public wrapper for _find_matching."""
    return _find_matching(text, open_idx, open_ch, close_ch)


# ============================================================
# 2) Expression parser (subset; practical for DST data tables)
# ============================================================

@dataclass
class LuaRaw:
    """Opaque expression (kept as raw text)."""
    text: str


@dataclass
class LuaTableValue:
    """Lua table constructor parsed into (array, map)."""
    array: List[Any]
    map: Dict[Any, Any]


def lua_to_python(v: Any) -> Any:
    """Recursively convert LuaTableValue/LuaRaw into plain Python types."""
    if isinstance(v, LuaRaw):
        return v.text
    if isinstance(v, LuaTableValue):
        arr = [lua_to_python(x) for x in v.array]
        mp = {lua_to_python(k): lua_to_python(val) for k, val in v.map.items()}
        if mp and arr:
            return {"__array__": arr, **mp}
        if mp:
            return mp
        return arr
    if isinstance(v, list):
        return [lua_to_python(x) for x in v]
    if isinstance(v, dict):
        return {lua_to_python(k): lua_to_python(val) for k, val in v.items()}
    return v


_NUM_RE = re.compile(r"^[+-]?(?:\d+\.\d*|\d*\.\d+|\d+)(?:[eE][+-]?\d+)?$")


def _parse_lua_string(expr: str) -> Optional[str]:
    expr = (expr or "").strip()
    if len(expr) >= 2 and expr[0] == expr[-1] and expr[0] in ("'", '"'):
        body = expr[1:-1]
        body = body.replace(r"\\", "\\").replace(r"\'", "'").replace(r"\"", '"')
        return body
    if expr.startswith("["):
        level = _long_bracket_level(expr, 0)
        if level is not None:
            opener_len = 2 + level
            close_pat = "]" + ("=" * level) + "]"
            end = expr.find(close_pat, opener_len)
            if end != -1:
                return expr[opener_len:end]
    return None


def parse_lua_string(expr: str) -> Optional[str]:
    """Public wrapper: parse a Lua string literal (short or long bracket)."""
    return _parse_lua_string(expr)


def parse_lua_expr(expr: str) -> Any:
    """
    Parse a subset of Lua expressions into Python types:
    - string/long-string -> str
    - number -> int/float
    - true/false/nil -> bool/None
    - table constructor -> LuaTableValue
    - function (...) ... end -> LuaRaw("<function>")
    - identifier/dotted path / everything else -> LuaRaw(expr)
    """
    expr = (expr or "").strip()
    if not expr:
        return LuaRaw("")

    if expr.startswith("function"):
        sig_end = expr.find(")")
        if sig_end != -1 and sig_end < 160:
            return LuaRaw(expr[: sig_end + 1] + " ... end")
        return LuaRaw("<function>")

    if expr == "nil":
        return None
    if expr in ("true", "false"):
        return expr == "true"

    s = _parse_lua_string(expr)
    if s is not None:
        return s

    if _NUM_RE.match(expr):
        try:
            f = float(expr)
            return int(f) if f.is_integer() else f
        except Exception:
            return LuaRaw(expr)

    if expr.startswith("{"):
        close = _find_matching(expr, 0, "{", "}")
        if close is None:
            return LuaRaw(expr)
        inner = expr[1:close]
        return parse_lua_table(inner)

    if re.match(r"^[A-Za-z_][A-Za-z0-9_\.]*$", expr):
        return LuaRaw(expr)

    return LuaRaw(expr)


def parse_lua_table(inner: str) -> LuaTableValue:
    """
    Parse the inside of { ... } (without outer braces).
    Returns LuaTableValue(array, map).
    """
    inner = strip_lua_comments(inner)

    array: List[Any] = []
    mp: Dict[Any, Any] = {}

    for item in _split_top_level(inner, ","):
        item = (item or "").strip()
        if not item:
            continue

        # key = value
        m = re.match(r"^([A-Za-z_][A-Za-z0-9_]*)\s*=\s*(.+)$", item, flags=re.DOTALL)
        if m:
            key = m.group(1)
            mp[key] = parse_lua_expr(m.group(2))
            continue

        # ["key"] = value (also long bracket keys)
        m = re.match(r'^\[\s*([\'"].*?[\'"]|\[=*\[.*?\]=*\])\s*\]\s*=\s*(.+)$', item, flags=re.DOTALL)
        if m:
            key_raw = m.group(1)
            key = _parse_lua_string(key_raw) or LuaRaw(key_raw)
            mp[key] = parse_lua_expr(m.group(2))
            continue

        # [expr] = value
        m = re.match(r"^\[\s*(.+?)\s*\]\s*=\s*(.+)$", item, flags=re.DOTALL)
        if m:
            mp[LuaRaw(m.group(1).strip())] = parse_lua_expr(m.group(2))
            continue

        # array entry
        array.append(parse_lua_expr(item))

    return LuaTableValue(array=array, map=mp)


# ============================================================
# 3) Lua call extractor (NAME(...) and obj:Method(...))
# ============================================================

@dataclass(frozen=True)
class LuaCall:
    name: str
    full_name: str
    start: int
    end: int
    open_paren: int
    close_paren: int
    args: str
    arg_list: List[str]
    line: int
    col: int


class LuaCallExtractor:
    """
    Extract Lua function calls with balanced parentheses, skipping comments/strings/long strings.

    Supports:
    - NAME(...)
    - obj.NAME(...)
    - obj:NAME(...)
    """

    def __init__(self, content: str):
        self.content = content or ""
        self._line_starts: Optional[List[int]] = None

    def iter_calls(
        self,
        names: Union[str, Sequence[str]],
        *,
        include_member_calls: bool = True,
        match_full_name: bool = False,
    ) -> Iterator[LuaCall]:
        if isinstance(names, str):
            targets = {names}
        else:
            targets = set(names)

        text = self.content
        n = len(text)
        i = 0

        while i < n:
            if text.startswith("--", i):
                i = _skip_comment(text, i)
                continue

            nxt = _skip_string_or_long_string(text, i)
            if nxt is not None:
                i = nxt
                continue

            ch = text[i]
            if _is_ident_start(ch):
                # first ident
                j = i + 1
                while j < n and _is_ident_char(text[j]):
                    j += 1
                first = text[i:j]
                if first in _LUA_KEYWORDS:
                    i = j
                    continue

                full = first
                last = first
                k = j

                if include_member_calls:
                    # ".ident" / ":ident" chain
                    while True:
                        kk = k
                        while kk < n and text[kk].isspace():
                            kk += 1
                        if kk < n and text[kk] in ".:":
                            sep = text[kk]
                            kk += 1
                            while kk < n and text[kk].isspace():
                                kk += 1
                            if kk < n and _is_ident_start(text[kk]):
                                jj = kk + 1
                                while jj < n and _is_ident_char(text[jj]):
                                    jj += 1
                                seg = text[kk:jj]
                                full = full + sep + seg
                                last = seg
                                k = jj
                                continue
                        break

                hit = (full in targets) if match_full_name else (last in targets)
                if hit:
                    kk = k
                    while kk < n and text[kk].isspace():
                        kk += 1
                    if kk < n and text[kk] == "(":
                        close = _find_matching(text, kk, "(", ")")
                        if close is not None:
                            args = text[kk + 1: close]
                            arg_list = self.split_args(args)
                            line, col = self._line_col(i)
                            yield LuaCall(
                                name=last,
                                full_name=full,
                                start=i,
                                end=close + 1,
                                open_paren=kk,
                                close_paren=close,
                                args=args,
                                arg_list=arg_list,
                                line=line,
                                col=col,
                            )
                            i = close + 1
                            continue

                i = k
                continue

            i += 1

    def extract_calls(self, names: Union[str, Sequence[str]], **kwargs: Any) -> List[LuaCall]:
        return list(self.iter_calls(names, **kwargs))

    def split_args(self, args: str) -> List[str]:
        return [p for p in _split_top_level(args, ",") if p]

    def _ensure_line_starts(self) -> None:
        if self._line_starts is not None:
            return
        self._line_starts = [0]
        for m in re.finditer("\n", self.content):
            self._line_starts.append(m.end())

    def _line_col(self, pos: int) -> Tuple[int, int]:
        self._ensure_line_starts()
        assert self._line_starts is not None
        idx = bisect.bisect_right(self._line_starts, pos) - 1
        line_start = self._line_starts[idx]
        return idx + 1, (pos - line_start) + 1


# ============================================================
# 4) TuningResolver (chain + simple arithmetic evaluation)
# ============================================================

_ARITH_TOKEN_RE = re.compile(r"\s*(\d+\.\d+|\d+|[A-Za-z_][A-Za-z0-9_\.]*|\*\*|\^|[+\-*/()])\s*")


class TuningResolver:
    """
    Lightweight resolver for DST `scripts/tuning.lua`.

    Goals
    - Parse common constant assignments:
        - `local NAME = <rhs>`  (UPPER_CASE only)
        - `TUNING.NAME = <rhs>`
    - Resolve numeric chains and simple arithmetic expressions.
    - Provide *traceable* resolution (for UI/wiki), not only final numbers.

    Notes
    - This is intentionally conservative: if an expression can't be proven safe and numeric,
      resolution returns None rather than guessing.
    """

    _REF_PAT = re.compile(
        r"TUNING\.([A-Za-z0-9_]+)|TUNING\[\s*([\'\"])([A-Za-z0-9_]+)\2\s*\]"
    )

    def __init__(self, content: str):
        self.raw_map: Dict[str, Any] = {}
        self.local_map: Dict[str, Any] = {}
        if content:
            self._parse_tuning(content)

    # --------------------------
    # Parsing
    # --------------------------

    def _parse_tuning(self, content: str) -> None:
        clean = strip_lua_comments(content)

        # locals (allow lowercase; many tuning constants depend on lower vars like calories_per_day)
        for m in re.finditer(r"^\s*local\s+([A-Za-z0-9_]+)\s*=\s*(.+?)\s*$", clean, flags=re.MULTILINE):
            name, rhs = m.group(1), m.group(2)
            rhs = rhs.strip().rstrip(",")
            val = self._parse_rhs(rhs)
            if val is not None:
                self.local_map[name] = val

        # TUNING.KEY = rhs
        for m in re.finditer(r"^\s*TUNING\.([A-Z0-9_]+)\s*=\s*(.+?)\s*$", clean, flags=re.MULTILINE):
            key, rhs = m.group(1), m.group(2)
            rhs = rhs.strip().rstrip(",")
            val = self._parse_rhs(rhs)
            self.raw_map[key] = val if val is not None else rhs

        # TUNING = { KEY = rhs, ... }
        for m_table in re.finditer(r"\bTUNING\s*=\s*\{", clean):
            open_idx = clean.find("{", m_table.start())
            close_idx = find_matching(clean, open_idx, "{", "}")
            if close_idx is None:
                continue
            inner = clean[open_idx + 1 : close_idx]
            for m in re.finditer(r"^\s*([A-Z0-9_]+)\s*=\s*(.+?)\s*(?:,|$)", inner, flags=re.MULTILINE):
                key, rhs = m.group(1), m.group(2)
                rhs = rhs.strip().rstrip(",")
                val = self._parse_rhs(rhs)
                if key not in self.raw_map:
                    self.raw_map[key] = val if val is not None else rhs

    def _parse_rhs(self, rhs: str) -> Optional[Any]:
        rhs = (rhs or "").strip().rstrip(",")
        if not rhs:
            return None
        if rhs in ("true", "false"):
            return rhs == "true"
        if rhs == "nil":
            return None

        s = _parse_lua_string(rhs)
        if s is not None:
            return s

        if _NUM_RE.match(rhs):
            try:
                f = float(rhs)
                return int(f) if f.is_integer() else f
            except Exception:
                return None

        # keep as raw string expression / symbol
        return rhs

    # --------------------------
    # Resolution (internal)
    # --------------------------

    @staticmethod
    def _norm_key(ref: str) -> str:
        ref = (ref or "").strip()
        return ref[7:] if ref.startswith("TUNING.") else ref

    def _resolve_ref(self, ref: str, depth: int = 8) -> Optional[Union[int, float]]:
        """Resolve a ref/expression to a number (or None)."""
        if depth <= 0:
            return None
        ref = (ref or "").strip()
        if not ref:
            return None

        # numeric literal
        if _NUM_RE.match(ref):
            try:
                f = float(ref)
                return int(f) if f.is_integer() else f
            except Exception:
                return None

        # math.* function calls (limited whitelist)
        m_call = re.match(r"^math\.([A-Za-z_][A-Za-z0-9_]*)\((.*)\)$", ref)
        if m_call:
            fn = m_call.group(1).lower()
            args_raw = m_call.group(2)
            args: List[Optional[Union[int, float]]] = []
            for part in _split_top_level(args_raw, sep=","):
                part = part.strip()
                if not part:
                    continue
                args.append(self._resolve_ref(part, depth - 1))
            # only proceed if all args resolved
            if any(a is None for a in args):
                return None
            vals = [float(a) for a in args if a is not None]
            try:
                if fn == "abs" and len(vals) == 1:
                    return abs(vals[0])
                if fn == "floor" and len(vals) == 1:
                    return math.floor(vals[0])
                if fn == "ceil" and len(vals) == 1:
                    return math.ceil(vals[0])
                if fn == "sqrt" and len(vals) == 1:
                    return math.sqrt(vals[0])
                if fn == "max" and vals:
                    return max(vals)
                if fn == "min" and vals:
                    return min(vals)
                if fn in ("pow",) and len(vals) == 2:
                    return math.pow(vals[0], vals[1])
            except Exception:
                return None
            return None

        # direct symbol (TUNING.X / local X)
        if re.match(r"^[A-Za-z_][A-Za-z0-9_\.]*$", ref):
            key = self._norm_key(ref)
            v = self.raw_map.get(key, self.local_map.get(key))
            if isinstance(v, (int, float)):
                return v
            if isinstance(v, str) and v and v != ref:
                # symbol chain (A -> B) or expression
                if re.match(r"^[A-Za-z_][A-Za-z0-9_\.]*$", v):
                    return self._resolve_ref(v, depth - 1)
                return self._resolve_ref(v, depth - 1)
            return None

        # arithmetic expression (conservative tokenizer)
        py_parts: List[str] = []
        for tok in _ARITH_TOKEN_RE.findall(ref):
            tok = tok.strip()
            if not tok:
                continue

            # Lua exponent
            if tok == "^":
                py_parts.append("**")
                continue
            if tok in {"+", "-", "*", "/", "(", ")", "**"}:
                py_parts.append(tok)
                continue
            if _NUM_RE.match(tok):
                py_parts.append(tok)
                continue

            val = self._resolve_ref(tok, depth - 1)
            if val is None:
                return None
            py_parts.append(str(val))

        expr_py = "".join(py_parts)
        # Safety: only numbers + operators
        if re.search(r"[^0-9\.\+\-\*\/\(\)eE]", expr_py):
            return None
        try:
            out = eval(expr_py, {"__builtins__": {}}, {})
            if isinstance(out, (int, float)):
                if isinstance(out, float) and out.is_integer():
                    return int(out)
                return out
        except Exception:
            return None
        return None

    # --------------------------
    # Public APIs
    # --------------------------

    def explain(self, key: str, max_hops: int = 10) -> Tuple[str, Optional[Union[int, float]]]:
        """Return (chain_text, resolved_value)."""
        key = self._norm_key(key)
        if not key:
            return "", None

        chain: List[str] = []
        visited = set()
        cur = key

        for _ in range(max_hops):
            if cur in visited:
                chain.append(f"{cur} (loop)")
                break
            visited.add(cur)

            v = self.raw_map.get(cur, self.local_map.get(cur))
            if v is None:
                chain.append(cur)
                break

            chain.append(cur)

            if isinstance(v, (int, float)):
                chain.append(str(v))
                return " -> ".join(chain), v

            if isinstance(v, str):
                chain.append(v)
                if re.match(r"^[A-Za-z_][A-Za-z0-9_\.]*$", v):
                    cur = self._norm_key(v)
                    continue
                val = self._resolve_ref(v)
                if val is not None:
                    chain.append(str(val))
                    return " -> ".join(chain), val
                break

            chain.append(str(v))
            break

        # fallback try resolve the symbol itself (handles local->expr cases)
        val = self._resolve_ref(key)
        return " -> ".join(chain) if chain else key, val

    def trace_key(self, key: str, max_hops: int = 16) -> Dict[str, Any]:
        """Structured trace for a single TUNING key."""
        key0 = key
        key = self._norm_key(key)
        steps: List[Dict[str, Any]] = []
        visited = set()
        cur = key

        for _ in range(max_hops):
            if not cur:
                break
            if cur in visited:
                steps.append({"key": cur, "raw": None, "note": "loop"})
                break
            visited.add(cur)

            v = self.raw_map.get(cur, self.local_map.get(cur))
            steps.append({"key": cur, "raw": v})

            if isinstance(v, (int, float)):
                chain = " -> ".join([str(s.get("key") or "") for s in steps] + [str(v)])
                return {"key": key0, "normalized": key, "value": v, "steps": steps, "chain": chain}

            if isinstance(v, str) and re.match(r"^[A-Za-z_][A-Za-z0-9_\.]*$", v):
                cur = self._norm_key(v)
                continue

            # expression or unknown
            if isinstance(v, str):
                val = self._resolve_ref(v)
                return {
                    "key": key0,
                    "normalized": key,
                    "value": val,
                    "steps": steps + [{"key": "<expr>", "raw": v, "value": val}],
                    "chain": " -> ".join([str(s.get("key") or s.get("raw") or "") for s in steps] + [v, str(val)]),
                }
            break

        # fallback
        val = self._resolve_ref(key)
        return {
            "key": key0,
            "normalized": key,
            "value": val,
            "steps": steps,
            "chain": " -> ".join([str(s.get("key") or s.get("raw") or "") for s in steps if s.get("key")] + ([str(val)] if val is not None else [])),
        }

    def trace_expr(self, expr: str) -> Dict[str, Any]:
        """Trace an arbitrary expression containing TUNING refs."""
        expr = (expr or "").strip()
        refs = []
        for m in self._REF_PAT.finditer(expr):
            k = m.group(1) or m.group(3)
            if k and k not in refs:
                refs.append(k)

        ref_traces: Dict[str, Any] = {}
        for k in refs:
            ref_traces[k] = self.trace_key(k)

        value = self._resolve_ref(expr)

        # best-effort normalized expression (TUNING.X -> number)
        expr_resolved = expr
        for k in refs:
            v = ref_traces.get(k, {}).get("value")
            if isinstance(v, (int, float)):
                expr_resolved = re.sub(
                    rf"\bTUNING\.{re.escape(k)}\b",
                    str(v),
                    expr_resolved,
                )
                expr_resolved = re.sub(
                    rf"TUNING\[\s*([\'\"])\s*{re.escape(k)}\s*\1\s*\]",
                    str(v),
                    expr_resolved,
                )

        return {
            "expr": expr,
            "value": value,
            "expr_resolved": expr_resolved,
            "refs": ref_traces,
            "expr_chain": " ; ".join(sorted([rt.get("chain") or "" for rt in ref_traces.values() if rt])),
        }

    def enrich(self, text: str) -> str:
        """Inline enrichment: replace `TUNING.X` in text with `TUNING.X (chain)` when resolvable."""
        if not text or "TUNING" not in text:
            return text

        def repl(m: re.Match) -> str:
            key = m.group(1) or m.group(3)
            if not key:
                return m.group(0)
            chain, val = self.explain(key)
            if val is None:
                return f"TUNING.{key}"
            return f"TUNING.{key} ({chain})"

        return self._REF_PAT.sub(repl, text)


# ============================================================
# 5) Domain parsers (Prefab / Loot / Widgets / Strings)
# ============================================================

class BaseParser:
    def __init__(self, content: str, path: Optional[str] = None):
        self.path = path
        self.content = content or ""
        self.clean = strip_lua_comments(self.content)

    def _extract_requires(self) -> List[str]:
        return re.findall(r'require\s*\(?\s*["\'](.*?)["\']\s*\)?', self.clean)


class LootParser(BaseParser):
    """Parse shared loot tables + simple loot helpers."""
    def parse(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {"type": "loot", "table_name": None, "entries": []}
        extractor = LuaCallExtractor(self.content)

        for call in extractor.iter_calls("SetSharedLootTable"):
            if not call.arg_list:
                continue
            name = parse_lua_string(call.arg_list[0]) or None
            if name:
                data["table_name"] = name
            if len(call.arg_list) >= 2:
                tbl = parse_lua_expr(call.arg_list[1])
                if isinstance(tbl, LuaTableValue):
                    for row in tbl.array:
                        if isinstance(row, LuaTableValue) and len(row.array) >= 2:
                            item = row.array[0]
                            chance = row.array[1]
                            if isinstance(item, str) and isinstance(chance, (int, float)):
                                data["entries"].append({"item": item, "chance": float(chance), "method": "TableData"})

        for call in extractor.iter_calls(["AddRandomLoot", "AddRandomLootTable"]):
            if len(call.arg_list) >= 2:
                item = parse_lua_string(call.arg_list[0])
                w = parse_lua_expr(call.arg_list[1])
                if isinstance(item, str) and isinstance(w, (int, float)):
                    data["entries"].append({"item": item, "weight": float(w), "method": "Random"})

        for call in extractor.iter_calls("AddChanceLoot"):
            if len(call.arg_list) >= 2:
                item = parse_lua_string(call.arg_list[0])
                c = parse_lua_expr(call.arg_list[1])
                if isinstance(item, str) and isinstance(c, (int, float)):
                    data["entries"].append({"item": item, "chance": float(c), "method": "Chance"})

        return data


class WidgetParser(BaseParser):
    def parse(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {"type": "widget", "classes": [], "dependencies": self._extract_requires()}
        for name, parent in re.findall(r"local\s+([A-Za-z0-9_]+)\s*=\s*Class\s*\(\s*([A-Za-z0-9_]+)", self.clean):
            data["classes"].append({"name": name, "parent": parent})
        return data


class StringParser(BaseParser):
    def parse(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {"type": "strings", "roots": [], "includes": self._extract_requires()}
        roots = set()
        roots.update(re.findall(r"STRINGS\.([A-Z0-9_]+)\s*=\s*\{", self.clean))
        roots.update(re.findall(r"STRINGS\.([A-Z0-9_]+)\s*=\s*['\"]", self.clean))
        data["roots"] = sorted(roots)
        return data


class PrefabParser(BaseParser):
    def parse(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {
            "type": "prefab",
            "assets": [],
            "components": [],
            "helpers": [],
            "stategraph": None,
            "brain": None,
            "events": [],
            "tags": [],
            "prefab_name": None,
        }

        extractor = LuaCallExtractor(self.content)

        for call in extractor.iter_calls("Prefab"):
            if call.arg_list:
                nm = parse_lua_string(call.arg_list[0])
                if nm:
                    data["prefab_name"] = nm
                    break

        for call in extractor.iter_calls("Asset"):
            if len(call.arg_list) >= 2:
                t = parse_lua_string(call.arg_list[0])
                p = parse_lua_string(call.arg_list[1])
                if isinstance(t, str) and isinstance(p, str):
                    data["assets"].append({"type": t, "path": p})

        m = re.search(r"SetBrain\s*\(\s*require\s*\(\s*['\"](.*?)['\"]\s*\)\s*\)", self.clean)
        if m:
            data["brain"] = m.group(1)
        m = re.search(r"SetStateGraph\s*\(\s*['\"](.*?)['\"]\s*\)", self.clean)
        if m:
            data["stategraph"] = m.group(1)

        data["events"] = re.findall(r'EventHandler\s*\(\s*["\']([^"\']+)["\']\s*,', self.clean)
        data["helpers"] = sorted(set(re.findall(r"^\s*(Make[A-Za-z0-9_]+)\s*\(", self.content, flags=re.MULTILINE)))

        tags: List[str] = []
        for call in extractor.iter_calls("AddTag"):
            if call.arg_list:
                tg = parse_lua_string(call.arg_list[0])
                if tg:
                    tags.append(tg)
        data["tags"] = sorted(set(tags))

        comps = set()
        for call in extractor.iter_calls("AddComponent"):
            if call.arg_list:
                cn = parse_lua_string(call.arg_list[0])
                if cn:
                    comps.add(cn)

        for comp_name in sorted(comps):
            comp_data = {"name": comp_name, "methods": [], "properties": []}

            method_pat = re.compile(r"components\." + re.escape(comp_name) + r"[:\.]([A-Za-z0-9_]+)\s*\((.*?)\)", re.DOTALL)
            for m_name, m_args in method_pat.findall(self.clean):
                clean_args = re.sub(r"\s+", " ", m_args).strip()
                if len(clean_args) > 60:
                    clean_args = clean_args[:57] + "..."
                comp_data["methods"].append(f"{m_name}({clean_args})")

            prop_pat = re.compile(r"components\." + re.escape(comp_name) + r"\.([A-Za-z0-9_]+)\s*=\s*([^=\n]+)")
            for p_name, p_val in prop_pat.findall(self.clean):
                comp_data["properties"].append(f"{p_name} = {p_val.strip()}")

            data["components"].append(comp_data)

        return data


class LuaAnalyzer:
    """Facade: choose best strategy based on content + optional path."""
    def __init__(self, content: str, path: Optional[str] = None):
        self.content = content or ""
        self.path = path
        self.parser = self._select_strategy()

    def _select_strategy(self) -> BaseParser:
        p = (self.path or "").replace("\\", "/")
        c = self.content

        if p.startswith("scripts/widgets/") or p.startswith("scripts/screens/"):
            return WidgetParser(c, p)
        if p.startswith("scripts/strings"):
            return StringParser(c, p)
        if p.startswith("scripts/prefabs/"):
            return PrefabParser(c, p)

        if "Class(Widget" in c or "Class(Screen" in c or 'require "widgets/' in c or "require('widgets/" in c:
            return WidgetParser(c, p)
        if "return Prefab" in c or "Prefab(" in c:
            return PrefabParser(c, p)
        if "STRINGS." in c and "STRINGS.CHARACTERS" in c:
            return StringParser(c, p)
        if "SetSharedLootTable" in c or "AddChanceLoot" in c:
            return LootParser(c, p)
        return PrefabParser(c, p)

    def get_report(self) -> Dict[str, Any]:
        return self.parser.parse()


# ============================================================
# 6) Cooking recipe analyzer (preparedfoods*.lua)
# ============================================================

# ============================================================
# 6) Cooking recipe analyzer (preparedfoods*.lua)
# ============================================================

def _iter_named_table_blocks(parent_table_body: str) -> Iterable[Tuple[str, str]]:
    """
    Iterate top-level `name = { ... }` blocks inside a parent table body (WITHOUT outer braces).

    This is stricter than a regex: it skips strings/comments and respects nested braces.
    """
    text = parent_table_body or ""
    n = len(text)
    i = 0
    depth = 0

    while i < n:
        if text.startswith("--", i):
            i = _skip_comment(text, i)
            continue

        nxt = _skip_string_or_long_string(text, i)
        if nxt is not None:
            i = nxt
            continue

        ch = text[i]

        if ch == "{":
            depth += 1
            i += 1
            continue
        if ch == "}":
            depth = max(0, depth - 1)
            i += 1
            continue

        if depth == 0:
            # skip whitespace/commas between entries
            if ch.isspace() or ch == ",":
                i += 1
                continue

            if _is_ident_start(ch):
                j = i + 1
                while j < n and _is_ident_char(text[j]):
                    j += 1
                name = text[i:j]

                k = j
                while k < n and text[k].isspace():
                    k += 1
                if k < n and text[k] == "=":
                    k += 1
                    while k < n and text[k].isspace():
                        k += 1
                    if k < n and text[k] == "{":
                        open_idx = k
                        close_idx = _find_matching(text, open_idx, "{", "}")
                        if close_idx is None:
                            i = j
                            continue
                        body = text[open_idx + 1: close_idx]
                        yield name, body
                        i = close_idx + 1
                        continue

                i = j
                continue

        i += 1


def _find_lua_function_end(text: str, fn_start: int) -> Optional[int]:
    """Return index right after the `end` that closes the function started at fn_start."""
    if fn_start < 0 or fn_start >= len(text):
        return None
    if not text.startswith("function", fn_start):
        return None

    n = len(text)
    i = fn_start

    bracket_stack: List[str] = []
    block_stack: List[Tuple[str, bool]] = []  # (kind, awaiting_do)

    def _push_block(kind: str) -> None:
        block_stack.append((kind, False))

    def _push_loop(kind: str) -> None:
        block_stack.append((kind, True))

    def _on_do() -> None:
        if block_stack and block_stack[-1][0] in ("for", "while") and block_stack[-1][1]:
            kind, _ = block_stack[-1]
            block_stack[-1] = (kind, False)
        else:
            _push_block("do")

    def _on_end() -> None:
        if block_stack:
            block_stack.pop()

    def _on_until() -> None:
        # close the nearest repeat
        for idx in range(len(block_stack) - 1, -1, -1):
            if block_stack[idx][0] == "repeat":
                del block_stack[idx:]
                return

    # consume the initial 'function'
    _push_block("function")
    i += len("function")

    while i < n and block_stack:
        if text.startswith("--", i):
            i = _skip_comment(text, i)
            continue
        nxt = _skip_string_or_long_string(text, i)
        if nxt is not None:
            i = nxt
            continue

        ch = text[i]

        # bracket stack (keep keywords inside parentheses from confusing us less; still scan keywords)
        if ch in "({[":
            if ch == "[":
                level = _long_bracket_level(text, i)
                if level is not None:
                    i = _skip_long_bracket(text, i, level)
                    continue
            bracket_stack.append(ch)
            i += 1
            continue

        if ch in ")}]":
            want = {")": "(", "}": "{", "]": "["}[ch]
            if bracket_stack and bracket_stack[-1] == want:
                bracket_stack.pop()
            i += 1
            continue

        if _is_ident_start(ch):
            j = i + 1
            while j < n and _is_ident_char(text[j]):
                j += 1
            word = text[i:j]

            if word == "function":
                _push_block("function")
            elif word == "if":
                _push_block("if")
            elif word == "for":
                _push_loop("for")
            elif word == "while":
                _push_loop("while")
            elif word == "repeat":
                _push_block("repeat")
            elif word == "do":
                _on_do()
            elif word == "end":
                _on_end()
                if not block_stack:
                    return j
            elif word == "until":
                _on_until()
                if not block_stack:
                    return j

            i = j
            continue

        i += 1

    return None


def _extract_test_return_expr(entry_body: str) -> Optional[str]:
    """Extract the boolean return expression from `test = function(...) return <expr> end`."""
    if not entry_body:
        return None

    m = re.search(r"\btest\s*=\s*function\b", entry_body)
    if not m:
        return None

    fn_start = m.end() - len("function")
    fn_end = _find_lua_function_end(entry_body, fn_start)
    if fn_end is None:
        return None

    fn_src = entry_body[fn_start:fn_end]
    clean = strip_lua_comments(fn_src)

    mret = re.search(r"\breturn\b\s*([\s\S]*?)\bend\b", clean)
    if not mret:
        return None

    expr = mret.group(1).strip()
    expr = re.sub(r"\s+", " ", expr)
    return expr or None


def _parse_rule_constraints(expr: str) -> Dict[str, Any]:
    """Best-effort extraction of common `names.*` / `tags.*` constraints from test-return expr."""
    expr = (expr or "").strip()
    out: Dict[str, Any] = {"raw": expr, "tags": [], "names": [], "unparsed": []}
    if not expr:
        return out

    # Normalize spaces to reduce corner cases
    e = re.sub(r"\s+", " ", expr)

    seen = set()

    # comparisons: tags.X <op> (number|nil|identifier)
    cmp_pat = re.compile(
        r"\b(?P<scope>tags|names)\.(?P<key>[A-Za-z0-9_]+)\s*(?P<op>==|~=|<=|>=|<|>)\s*(?P<rhs>[^\s\)\]]+)"
    )
    for m in cmp_pat.finditer(e):
        scope = m.group("scope")
        key = m.group("key")
        op = m.group("op")
        rhs = m.group("rhs").rstrip(",")
        rhs_norm: Any
        if rhs == "nil":
            rhs_norm = None
        elif _NUM_RE.match(rhs):
            try:
                rhs_norm = float(rhs)
                if isinstance(rhs_norm, float) and rhs_norm.is_integer():
                    rhs_norm = int(rhs_norm)
            except Exception:
                rhs_norm = rhs
        else:
            rhs_norm = rhs

        rec = (scope, key, op, str(rhs_norm))
        if rec in seen:
            continue
        seen.add(rec)
        out[scope].append({"key": key, "op": op, "value": rhs_norm, "text": m.group(0)})

    # presence (truthy): tags.X / names.X
    pres_pat = re.compile(r"\b(?P<scope>tags|names)\.(?P<key>[A-Za-z0-9_]+)\b(?!\s*(==|~=|<=|>=|<|>))")
    for m in pres_pat.finditer(e):
        scope = m.group("scope")
        key = m.group("key")
        rec = (scope, key, ">", 0)
        if rec in seen:
            continue
        seen.add(rec)
        out[scope].append({"key": key, "op": ">", "value": 0, "text": m.group(0)})

    # negated presence: not tags.X / not names.X
    neg_pat = re.compile(r"\bnot\s+(?P<scope>tags|names)\.(?P<key>[A-Za-z0-9_]+)\b")
    for m in neg_pat.finditer(e):
        scope = m.group("scope")
        key = m.group("key")
        rec = (scope, key, "==", 0)
        if rec in seen:
            continue
        seen.add(rec)
        out[scope].append({"key": key, "op": "==", "value": 0, "text": m.group(0)})

    return out


class CookingRecipeAnalyzer:
    """
    Parse preparedfoods*.lua (data-driven part).

    Extract stable fields for wiki/web:
    - priority/weight/foodtype/hunger/health/sanity/perishtime/cooktime/tags
    - card_def.ingredients -> card_ingredients: list[[item, count], ...]
    - rule constraints (best-effort): `test = function(...) return ... end`
    """

    STABLE_KEYS = (
        "priority",
        "weight",
        "foodtype",
        "hunger",
        "health",
        "sanity",
        "perishtime",
        "cooktime",
        "tags",
    )

    def __init__(self, content: str):
        self.content = content or ""
        self.recipes: Dict[str, Dict[str, Any]] = {}
        if content:
            self._parse()

    def _parse(self) -> None:
        # most files: local foods = { ... }
        m = re.search(r"local\s+foods\s*=\s*\{", self.content)
        if not m:
            return
        open_idx = m.end() - 1
        close_idx = _find_matching(self.content, open_idx, "{", "}")
        if close_idx is None:
            return

        inner = self.content[open_idx + 1: close_idx]

        for name, body in _iter_named_table_blocks(inner):
            tbl = parse_lua_table(body)
            if not isinstance(tbl, LuaTableValue):
                continue

            mp = tbl.map
            out: Dict[str, Any] = {}

            for key in self.STABLE_KEYS:
                if key in mp:
                    out[key] = lua_to_python(mp[key])

            # card_def.ingredients -> card_ingredients
            card = mp.get("card_def")
            if isinstance(card, LuaTableValue):
                ing = card.map.get("ingredients")
                if isinstance(ing, LuaTableValue):
                    rows: List[List[Any]] = []
                    for r in ing.array:
                        if isinstance(r, LuaTableValue) and len(r.array) >= 2:
                            rows.append([lua_to_python(r.array[0]), lua_to_python(r.array[1])])
                    if rows:
                        out["card_ingredients"] = rows

            # rule constraints (test-return expr)
            test_expr = _extract_test_return_expr(body)
            if test_expr:
                out["rule"] = {
                    "kind": "test_return",
                    "expr": test_expr,
                    "constraints": _parse_rule_constraints(test_expr),
                }

            if out:
                self.recipes[name] = out


# ============================================================
# 7) Cooking ingredient analyzer (ingredients.lua / cooking.lua)
# ============================================================

_ING_ID_RE = re.compile(r"^[a-z0-9_]+$")


def _clean_ingredient_id(value: Any) -> Optional[str]:
    if value is None:
        return None
    raw = str(value).strip()
    if not raw:
        return None
    raw = raw.lower()
    if not _ING_ID_RE.match(raw):
        return None
    return raw


def _coerce_tag_value(value: Any) -> Optional[float]:
    if isinstance(value, bool):
        return 1.0 if value else 0.0
    if isinstance(value, (int, float)):
        return float(value)
    if isinstance(value, str) and _NUM_RE.match(value):
        try:
            return float(value)
        except Exception:
            return None
    return None


def _parse_tag_table(tags: Any) -> Tuple[Dict[str, float], Dict[str, str]]:
    if not isinstance(tags, LuaTableValue):
        return {}, {}
    out: Dict[str, float] = {}
    expr: Dict[str, str] = {}

    for key, value in tags.map.items():
        k = lua_to_python(key)
        if not isinstance(k, str):
            continue
        k = k.strip().lower()
        if not k:
            continue
        v = lua_to_python(value)
        num = _coerce_tag_value(v)
        if num is None:
            expr[k] = str(v)
        else:
            out[k] = num

    for entry in tags.array:
        k = lua_to_python(entry)
        if not isinstance(k, str):
            continue
        k = k.strip().lower()
        if not k or k in out or k in expr:
            continue
        out[k] = 1.0

    return out, expr


def _extract_table_by_pattern(content: str, pattern: str) -> Optional[LuaTableValue]:
    m = re.search(pattern, content)
    if not m:
        return None
    open_idx = content.find("{", m.end() - 1)
    if open_idx < 0:
        return None
    close_idx = _find_matching(content, open_idx, "{", "}")
    if close_idx is None:
        return None
    inner = content[open_idx + 1 : close_idx]
    try:
        return parse_lua_table(inner)
    except Exception:
        return None


def _find_ingredients_table(content: str) -> Optional[LuaTableValue]:
    patterns = [
        r"(?:^|\b)local\s+ingredients\s*=\s*\{",
        r"(?:^|\b)ingredients\s*=\s*\{",
        r"(?:^|\b)INGREDIENTS\s*=\s*\{",
        r"\bcooking\.ingredients\s*=\s*\{",
    ]
    for pat in patterns:
        tbl = _extract_table_by_pattern(content, pat)
        if isinstance(tbl, LuaTableValue):
            return tbl

    cooking_tbl = _extract_table_by_pattern(content, r"(?:^|\b)local\s+cooking\s*=\s*\{")
    if not isinstance(cooking_tbl, LuaTableValue):
        cooking_tbl = _extract_table_by_pattern(content, r"(?:^|\b)cooking\s*=\s*\{")
    if isinstance(cooking_tbl, LuaTableValue):
        ing = cooking_tbl.map.get("ingredients")
        if isinstance(ing, LuaTableValue):
            return ing

    return None


class CookingIngredientAnalyzer:
    """Parse cooking ingredient definitions and extract tag contributions."""

    def __init__(self, content: str, *, source: str = ""):
        self.content = content or ""
        self.source = source or ""
        self.ingredients: Dict[str, Dict[str, Any]] = {}
        if content:
            self._parse()

    def _parse(self) -> None:
        tbl = _find_ingredients_table(self.content)
        if not isinstance(tbl, LuaTableValue):
            return

        for key, value in (tbl.map or {}).items():
            ing_id = _clean_ingredient_id(lua_to_python(key))
            if not ing_id:
                continue

            out: Dict[str, Any] = {"id": ing_id}

            if isinstance(value, LuaTableValue):
                tags, tag_expr = _parse_tag_table(value.map.get("tags"))
                if tags:
                    out["tags"] = tags
                if tag_expr:
                    out["tags_expr"] = tag_expr

                for field in ("name", "atlas", "image", "prefab", "foodtype"):
                    if field in value.map:
                        out[field] = lua_to_python(value.map[field])

            if self.source:
                out["sources"] = [self.source]

            if len(out) > 1:
                self.ingredients[ing_id] = out
```

### File: core/craft_recipes.py
- mode: full
- size_bytes: 28234
- sha256_12: fce8d1e871d7

```py
# -*- coding: utf-8 -*-
"""core/craft_recipes.py

Crafting recipes (Recipe/Recipe2/AddRecipe2) + recipe filter organization.

Why this module exists
- `scripts/recipes*.lua` and `scripts/recipes_filter.lua` are data sources.
- UI layers (wiki/GUI/web) need a stable, query-friendly Python representation.

Design goals (M0)
- Reuse `core/analyzer.py` Lua parsing primitives (single source of truth).
- Keep outputs JSON-serializable for catalog/index (M2).

Public API (expected by existing CLI)
- CraftRecipeDB.get(name)
- CraftRecipeDB.list_by_tab(tab)
- CraftRecipeDB.list_by_filter(filter)
- CraftRecipeDB.list_by_builder_tag(tag)
- CraftRecipeDB.list_by_tech(tech)

New (M2)
- CraftRecipeDB.list_by_ingredient(item)
- CraftRecipeDB.craftable(inventory)
- CraftRecipeDB.missing_for(recipe, inventory)
- CraftRecipeDB.to_dict() / CraftRecipeDB.from_dict()
"""

from __future__ import annotations

from collections import defaultdict
from dataclasses import dataclass
import json
import re
from typing import Any, Dict, Iterable, List, Mapping, Optional, Sequence, Set, Tuple

from core.analyzer import (
    LuaCallExtractor,
    LuaRaw,
    LuaTableValue,
    find_matching,
    lua_to_python,
    parse_lua_expr,
    parse_lua_string,
    strip_lua_comments,
)

__all__ = [
    "CraftRecipeDB",
    "parse_filter_defs",
]


# =========================================================
# Regex helpers
# =========================================================

_TECH_TOKEN_RE = re.compile(r"\bTECH\.[A-Z0-9_]+\b")
_TAB_TOKEN_RE = re.compile(r"\bRECIPETABS\.[A-Z0-9_]+\b")
_FILTER_TOKEN_RE = re.compile(r"\bCRAFTING_FILTERS\.([A-Z0-9_]+)\b")
_FILTER_ASSIGN_RE = re.compile(r"\bCRAFTING_FILTERS\.([A-Z0-9_]+)\.recipes\s*=\s*\{", re.MULTILINE)

# string literals inside a table list; recipes_filter.lua uses plain quoted names
_QUOTED_STR_RE = re.compile(r"([\"'])([^\"']+)\1")

# If a "{ ... }" argument contains '=', it is most likely a config table not a filter list.
# This heuristic is intentionally conservative.


# =========================================================
# Data model helpers
# =========================================================

def _dedup_preserve(seq: Iterable[str]) -> List[str]:
    out: List[str] = []
    seen: Set[str] = set()
    for x in seq:
        if not x:
            continue
        if x in seen:
            continue
        seen.add(x)
        out.append(x)
    return out


def _looks_like_kv_table(expr_text: str) -> bool:
    s = (expr_text or "").strip()
    return s.startswith("{") and ("=" in s)


def _extract_first_token(rx: re.Pattern[str], text: str) -> Optional[str]:
    m = rx.search(text or "")
    return m.group(0) if m else None


_NUM_RE = re.compile(r"^[+-]?(?:\d+\.?\d*|\d*\.?\d+)(?:[eE][+-]?\d+)?$")


def _to_amount(expr_text: str) -> Tuple[Optional[float], str]:
    """Return (amount_num, amount_expr)."""
    raw = (expr_text or "").strip() or "1"

    # Fast path numeric
    if _NUM_RE.match(raw):
        try:
            return float(raw), raw
        except Exception:
            return None, raw

    v = parse_lua_expr(raw)
    if isinstance(v, (int, float)):
        return float(v), raw

    # LuaRaw with a numeric string
    if isinstance(v, LuaRaw) and _NUM_RE.match(v.text.strip()):
        try:
            return float(v.text.strip()), raw
        except Exception:
            pass

    return None, raw


def _parse_string_list(v: Any) -> List[str]:
    """Try to turn a Lua table value into a list[str]."""
    if isinstance(v, LuaTableValue):
        out: List[str] = []
        for x in v.array:
            if isinstance(x, str):
                out.append(x)
            elif isinstance(x, LuaRaw):
                # keep raw symbol if it looks like a string constant
                out.append(x.text)
            else:
                py = lua_to_python(x)
                if isinstance(py, str):
                    out.append(py)
        return _dedup_preserve(out)

    py = lua_to_python(v)
    if isinstance(py, list):
        return _dedup_preserve([str(x) for x in py if x is not None])

    return []


def _parse_config_fields(tbl: LuaTableValue) -> Dict[str, Any]:
    """Extract commonly useful fields from a recipe config table."""
    out: Dict[str, Any] = {}

    for k, v in (tbl.map or {}).items():
        if not isinstance(k, str):
            continue

        if k in {
            "builder_tag",
            "builder_skill",
            "station_tag",
            "product",
            "placer",
            "image",
            "atlas",
            "nounlock",
            "numtogive",
            "min_spacing",
            "testfn",  # sometimes exists
        }:
            out[k] = lua_to_python(v)
        elif k in {"builder_tags"}:
            out[k] = _parse_string_list(v)
        # Keep unknown keys out for now (index bloat).

    # normalize: builder_tags may be an object/dict if table is keyed; accept only list
    if "builder_tags" in out and not isinstance(out["builder_tags"], list):
        out.pop("builder_tags", None)

    return out


def _parse_filters_from_text(expr_text: str) -> List[str]:
    if not expr_text:
        return []

    filters: List[str] = []

    # CRAFTING_FILTERS.NAME tokens
    filters += [m.group(1) for m in _FILTER_TOKEN_RE.finditer(expr_text)]

    # quoted uppercase strings (rare but exists in some mods)
    for q in re.findall(r"[\"']([A-Z0-9_]+)[\"']", expr_text):
        if q and q.upper() == q:
            filters.append(q)

    return _dedup_preserve([f.upper() for f in filters if f])


# =========================================================
# Parsing: recipes.lua / recipes2.lua
# =========================================================


def _parse_ingredients_from_expr(expr_text: str) -> Tuple[List[Dict[str, Any]], List[str]]:
    """Extract Ingredient("item", amount) calls.

    Returns (ingredients, unresolved_items).

    Ingredient amount is stored as:
    - amount: original expression string
    - amount_num: parsed float if possible (else None)
    """
    if not expr_text:
        return [], []

    out: List[Dict[str, Any]] = []
    unresolved: List[str] = []

    ex = LuaCallExtractor(expr_text)
    for call in ex.iter_calls(["Ingredient"], include_member_calls=False):
        if not call.arg_list:
            continue

        item_expr = call.arg_list[0].strip()
        item = parse_lua_string(item_expr) or item_expr

        if len(call.arg_list) >= 2:
            amount_expr = call.arg_list[1]
        else:
            amount_expr = "1"

        amount_num, amount_raw = _to_amount(amount_expr)

        rec = {
            "item": item,
            "amount": amount_raw,
            "amount_num": amount_num,
        }
        out.append(rec)

        if amount_num is None:
            unresolved.append(str(item))

    return out, _dedup_preserve(unresolved)


def _init_recipe_record(name: str) -> Dict[str, Any]:
    return {
        "name": name,
        "product": name,  # default: in most DST recipes, name == prefab product
        "ingredients": [],
        "ingredients_unresolved": [],
        "tech": "UNKNOWN",
        "tab": "UNKNOWN",  # assigned later from filter membership
        "filters": [],
        "builder_tag": None,
        "builder_tags": [],
        "builder_skill": None,
        "station_tag": None,
        "sources": [],
        # optional metadata (for GUI)
        "image": None,
        "atlas": None,
        "placer": None,
        "nounlock": None,
        "numtogive": None,
    }


def _parse_recipe_call(call_name: str, args: Sequence[str]) -> Optional[Dict[str, Any]]:
    """Parse a Recipe/Recipe2/AddRecipe2 call into a recipe record."""
    if not args:
        return None

    name = parse_lua_string(args[0])
    if not name:
        return None

    rec = _init_recipe_record(name)
    rec["sources"].append(call_name)

    # ingredients: usually arg[1]
    if len(args) >= 2:
        ing, unresolved = _parse_ingredients_from_expr(args[1])
        if ing:
            rec["ingredients"] = ing
        if unresolved:
            rec["ingredients_unresolved"] = unresolved

    # tech: usually arg[2], but also scan whole call for TECH.X
    tech = None
    if len(args) >= 3:
        tech = _extract_first_token(_TECH_TOKEN_RE, args[2])
    if tech is None:
        tech = _extract_first_token(_TECH_TOKEN_RE, " ".join(args))
    if tech:
        rec["tech"] = tech

    # explicit RECIPETABS (legacy) if present
    tab = _extract_first_token(_TAB_TOKEN_RE, " ".join(args))
    if tab:
        rec["tab"] = tab

    # parse remaining args: config tables and/or explicit filter lists
    for a in args[2:]:
        a = (a or "").strip()
        if not a.startswith("{"):
            # Sometimes filters are passed as plain symbols; token-scan anyway.
            fs = _parse_filters_from_text(a)
            if fs:
                rec["filters"] = _dedup_preserve(list(rec.get("filters", [])) + fs)
            continue

        v = parse_lua_expr(a)
        if isinstance(v, LuaTableValue) and _looks_like_kv_table(a):
            fields = _parse_config_fields(v)
            for k, val in fields.items():
                if k == "builder_tags":
                    rec["builder_tags"] = _dedup_preserve(list(rec.get("builder_tags") or []) + list(val or []))
                    continue
                if val is None:
                    continue
                if rec.get(k) in (None, "UNKNOWN", [], {}):
                    rec[k] = val
                else:
                    # avoid overwriting unless empty
                    pass

            # product override
            if fields.get("product"):
                rec["product"] = fields.get("product")

        else:
            fs = _parse_filters_from_text(a)
            if fs:
                rec["filters"] = _dedup_preserve(list(rec.get("filters", [])) + fs)

    # Normalize builder_tags
    if rec.get("builder_tag"):
        rec["builder_tags"] = _dedup_preserve(list(rec.get("builder_tags") or []) + [str(rec["builder_tag"])])

    return rec


def parse_craft_recipes(recipes_lua: str, recipes2_lua: str) -> Dict[str, Dict[str, Any]]:
    """Parse craft recipes from recipes.lua + recipes2.lua.

    - recipes.lua: Recipe/Recipe2
    - recipes2.lua: AddRecipe2

    Returns dict: name -> recipe_record
    """
    out: Dict[str, Dict[str, Any]] = {}

    for src, fnames in ((recipes_lua or "", ["Recipe", "Recipe2"]), (recipes2_lua or "", ["AddRecipe2"])):
        if not src:
            continue
        ex = LuaCallExtractor(src)
        for call in ex.iter_calls(fnames, include_member_calls=False):
            rec = _parse_recipe_call(call.name, call.arg_list)
            if not rec:
                continue
            name = rec["name"]
            if name not in out:
                out[name] = rec
            else:
                # Merge: later source wins for missing fields; union for lists.
                cur = out[name]
                cur["sources"] = _dedup_preserve(list(cur.get("sources", [])) + list(rec.get("sources", [])))

                # ingredients: keep first non-empty
                if (not cur.get("ingredients")) and rec.get("ingredients"):
                    cur["ingredients"] = rec["ingredients"]

                # union unresolved
                cur["ingredients_unresolved"] = _dedup_preserve(
                    list(cur.get("ingredients_unresolved") or []) + list(rec.get("ingredients_unresolved") or [])
                )

                # prefer concrete tech
                if cur.get("tech") in (None, "", "UNKNOWN") and rec.get("tech") not in (None, "", "UNKNOWN"):
                    cur["tech"] = rec["tech"]

                # union filters
                cur["filters"] = _dedup_preserve(list(cur.get("filters") or []) + list(rec.get("filters") or []))

                # fill other scalar fields if empty
                for k in (
                    "builder_tag",
                    "builder_skill",
                    "station_tag",
                    "product",
                    "tab",
                    "image",
                    "atlas",
                    "placer",
                    "nounlock",
                    "numtogive",
                ):
                    if cur.get(k) in (None, "", "UNKNOWN") and rec.get(k) not in (None, "", "UNKNOWN"):
                        cur[k] = rec[k]

                # builder_tags union
                cur["builder_tags"] = _dedup_preserve(list(cur.get("builder_tags") or []) + list(rec.get("builder_tags") or []))

    return out


# =========================================================
# Parsing: recipes_filter.lua
# =========================================================


def parse_filter_defs(src: str) -> List[Dict[str, Any]]:
    """Parse the CRAFTING_FILTER_DEFS table as an ordered list of dicts."""
    if not src:
        return []

    clean = strip_lua_comments(src)
    idx = clean.find("CRAFTING_FILTER_DEFS")
    if idx == -1:
        return []

    brace = clean.find("{", idx)
    if brace == -1:
        return []

    end = find_matching(clean, brace, "{", "}")
    if end is None:
        return []

    block = clean[brace : end + 1]
    tbl = parse_lua_expr(block)
    if not isinstance(tbl, LuaTableValue):
        return []

    defs: List[Dict[str, Any]] = []
    for entry in tbl.array:
        if not isinstance(entry, LuaTableValue):
            continue
        d: Dict[str, Any] = {}
        for k, v in entry.map.items():
            if isinstance(k, str):
                d[k] = lua_to_python(v)
        if d:
            defs.append(d)

    return defs


def _parse_filter_order(src: str) -> List[str]:
    defs = parse_filter_defs(src)
    order: List[str] = []
    for d in defs:
        nm = d.get("name")
        if isinstance(nm, str) and nm:
            order.append(nm.upper())
    return order


def _parse_filter_recipe_lists(src: str) -> Dict[str, List[str]]:
    """Parse `CRAFTING_FILTERS.X.recipes = { ... }` lists."""
    out: Dict[str, List[str]] = {}
    if not src:
        return out

    clean = strip_lua_comments(src)

    for m in _FILTER_ASSIGN_RE.finditer(clean):
        flt = m.group(1).upper()
        brace = m.end() - 1
        end = find_matching(clean, brace, "{", "}")
        if end is None:
            continue
        inner = clean[brace + 1 : end]
        names = [sm.group(2) for sm in _QUOTED_STR_RE.finditer(inner)]
        # recipes list is typically plain strings (prefab names)
        out[flt] = _dedup_preserve(names)

    return out


def _parse_filter_bindings_by_calls(src: str) -> Dict[str, List[str]]:
    """Parse AddRecipeToFilter(s) calls.

    Returns: recipe_name -> [filters...]
    """
    out: Dict[str, List[str]] = defaultdict(list)
    if not src:
        return out

    ex = LuaCallExtractor(src)
    for call in ex.iter_calls(["AddRecipeToFilter", "AddRecipeToFilters"], include_member_calls=False):
        args = call.arg_list
        if not args:
            continue

        # recipe name is usually the first non-UPPERCASE string literal
        recipe_name: Optional[str] = None
        for a in args:
            s = parse_lua_string(a)
            if s and not s.isupper():
                recipe_name = s
                break
        if recipe_name is None:
            for a in args:
                s = parse_lua_string(a)
                if s:
                    recipe_name = s
                    break
        if not recipe_name:
            continue

        filters: List[str] = []
        for a in args:
            filters += _parse_filters_from_text(a)

        if filters:
            out[recipe_name] = _dedup_preserve(list(out.get(recipe_name, [])) + filters)

    return out


# =========================================================
# CraftRecipeDB (public)
# =========================================================


class CraftRecipeDB:
    """Queryable craft recipe database.

    Build sources:
    - recipes.lua / recipes2.lua (Recipe/Recipe2/AddRecipe2)
    - recipes_filter.lua (filters order + filter membership)

    Notes
    - `tab` is derived from filter order: first non-special filter in membership.
    - `filters` holds all known filter memberships.
    """

    _SPECIAL_FILTERS = {"FAVORITES", "CRAFTING_STATION", "SPECIAL_EVENT", "MODS", "CHARACTER", "EVERYTHING"}

    def __init__(self, *args, **kwargs):
        """Supported initializers:

        - CraftRecipeDB(recipes_lua=..., recipes2_lua=..., recipes_filter_lua=...)
        - CraftRecipeDB(recipes_lua, recipes2_lua, recipes_filter_lua)
        - CraftRecipeDB(recipes_lua, recipes_filter_lua)  # legacy fallback
        """
        recipes_lua = kwargs.get("recipes_lua", "")
        recipes2_lua = kwargs.get("recipes2_lua", "")
        recipes_filter_lua = kwargs.get("recipes_filter_lua", "")

        if args:
            if len(args) == 1:
                recipes_lua = args[0]
            elif len(args) == 2:
                recipes_lua = args[0]
                recipes_filter_lua = args[1]
            else:
                recipes_lua = args[0]
                recipes2_lua = args[1]
                recipes_filter_lua = args[2]

        self.recipes: Dict[str, Dict[str, Any]] = {}
        self.aliases: Dict[str, str] = {}

        self.filter_defs: List[Dict[str, Any]] = []
        self.filter_order: List[str] = []
        self.tab_order: List[str] = []

        self.by_tab: Dict[str, List[str]] = defaultdict(list)
        self.by_filter: Dict[str, List[str]] = defaultdict(list)
        self.by_tech: Dict[str, List[str]] = defaultdict(list)
        self.by_builder_tag: Dict[str, List[str]] = defaultdict(list)
        self.by_ingredient: Dict[str, List[str]] = defaultdict(list)

        self._build(recipes_lua or "", recipes2_lua or "", recipes_filter_lua or "")

    # -----------------
    # build
    # -----------------

    def _build(self, recipes_lua: str, recipes2_lua: str, recipes_filter_lua: str) -> None:
        # 1) base recipes
        self.recipes = parse_craft_recipes(recipes_lua, recipes2_lua)

        # 2) aliases
        for name in self.recipes.keys():
            self.aliases[name.lower()] = name
            self.aliases[name.replace("_", "").lower()] = name

        # 3) filter defs + membership
        self.filter_defs = parse_filter_defs(recipes_filter_lua)
        self.filter_order = _parse_filter_order(recipes_filter_lua)
        filter_lists = _parse_filter_recipe_lists(recipes_filter_lua)
        call_bindings = _parse_filter_bindings_by_calls(recipes_filter_lua)

        # membership: recipe -> filters
        membership: Dict[str, Set[str]] = {name: set(map(str.upper, (self.recipes[name].get("filters") or []))) for name in self.recipes.keys()}

        # from `CRAFTING_FILTERS.X.recipes = {...}`
        for flt, rlist in filter_lists.items():
            for r in rlist:
                if r in membership:
                    membership[r].add(flt)

        # from AddRecipeToFilter(s)
        for r, fs in call_bindings.items():
            if r in membership:
                for f in fs:
                    membership[r].add(f.upper())

        # 4) finalize per recipe: filters, tab
        for name, rec in self.recipes.items():
            fset = membership.get(name, set())
            # include whatever was already present
            rec["filters"] = sorted(_dedup_preserve([f.upper() for f in fset if f]))

            # choose tab: first non-special in defs order
            chosen: Optional[str] = None
            for f in self.filter_order:
                if f in fset and f not in self._SPECIAL_FILTERS:
                    chosen = f
                    break
            if chosen is None:
                # fallback: any in order
                for f in self.filter_order:
                    if f in fset:
                        chosen = f
                        break
            rec["tab"] = chosen or rec.get("tab") or "UNKNOWN"

            # normalize builder_tags again (after merges)
            if rec.get("builder_tag"):
                rec["builder_tags"] = _dedup_preserve(list(rec.get("builder_tags") or []) + [str(rec["builder_tag"])])
            else:
                rec["builder_tags"] = _dedup_preserve(list(rec.get("builder_tags") or []))

        # 5) build indices
        # by_filter / by_tab
        for name, rec in self.recipes.items():
            for f in rec.get("filters", []) or []:
                self.by_filter[str(f).upper()].append(name)

            t = str(rec.get("tab") or "UNKNOWN").upper()
            self.by_tab[t].append(name)

            # by_tech
            tech = str(rec.get("tech") or "UNKNOWN")
            if tech.upper().startswith("TECH."):
                tech = tech.split(".", 1)[1]
            self.by_tech[tech.upper()].append(name)

            # by_builder_tag(s)
            for bt in rec.get("builder_tags") or []:
                if bt:
                    self.by_builder_tag[str(bt).lower()].append(name)

            # by_ingredient
            for ing in rec.get("ingredients") or []:
                it = ing.get("item")
                if it:
                    self.by_ingredient[str(it).lower()].append(name)

        # sort & unique
        for mp in (self.by_filter, self.by_tab, self.by_tech, self.by_builder_tag, self.by_ingredient):
            for k in list(mp.keys()):
                mp[k] = sorted(set(mp[k]))

        # tab order: filter_order excluding specials
        self.tab_order = [f for f in self.filter_order if f and f not in self._SPECIAL_FILTERS]

    # -----------------
    # Public query API
    # -----------------

    def __len__(self) -> int:
        return len(self.recipes)

    def get(self, query_name: str) -> Tuple[Optional[str], Optional[Dict[str, Any]]]:
        if not query_name:
            return None, None
        q = query_name.strip().lower()
        canonical = self.aliases.get(q) or self.aliases.get(q.replace("_", ""))
        if not canonical:
            return None, None
        return canonical, self.recipes.get(canonical)

    def list_tabs(self) -> List[str]:
        return list(self.tab_order)

    def list_filters(self) -> List[str]:
        return list(self.filter_order)

    def list_by_tab(self, tab: str) -> List[str]:
        key = (tab or "").strip().upper()
        # allow TECH/RECIPETABS raw
        if key.startswith("RECIPETABS."):
            key = key.split(".", 1)[1]
        return list(self.by_tab.get(key, []))

    def list_by_filter(self, flt: str) -> List[str]:
        key = (flt or "").strip().upper()
        if key.startswith("CRAFTING_FILTERS."):
            key = key.split(".", 1)[1]
        return list(self.by_filter.get(key, []))

    def list_by_builder_tag(self, tag: str) -> List[str]:
        key = (tag or "").strip().lower()
        return list(self.by_builder_tag.get(key, []))

    def list_by_tech(self, tech: str) -> List[str]:
        t = (tech or "").strip()
        if t.upper().startswith("TECH."):
            t = t.split(".", 1)[1]
        return list(self.by_tech.get(t.upper(), []))

    def list_by_ingredient(self, item: str) -> List[str]:
        key = (item or "").strip().lower()
        return list(self.by_ingredient.get(key, []))

    # -----------------
    # Craft planner (M2)
    # -----------------

    def missing_for(self, recipe_name: str, inventory: Mapping[str, float]) -> List[Dict[str, Any]]:
        """Return missing ingredients for a recipe under a given inventory.

        Inventory is a mapping item->count (int/float).

        If an ingredient has non-numeric amount (amount_num is None), it is returned
        as missing with reason="unresolved_amount".
        """
        _, rec = self.get(recipe_name)
        if not rec:
            return []

        inv = {str(k).lower(): float(v) for k, v in (inventory or {}).items()}

        missing: List[Dict[str, Any]] = []
        for ing in rec.get("ingredients") or []:
            item = str(ing.get("item") or "").lower()
            if not item:
                continue
            need_num = ing.get("amount_num")
            need_expr = ing.get("amount")
            have = inv.get(item, 0.0)

            if need_num is None:
                missing.append({"item": item, "need": need_expr, "have": have, "reason": "unresolved_amount"})
                continue

            if have + 1e-9 < float(need_num):
                missing.append({"item": item, "need": need_num, "have": have, "reason": "insufficient"})

        return missing

    def craftable(
        self,
        inventory: Mapping[str, float],
        *,
        builder_tag: Optional[str] = None,
        strict: bool = True,
    ) -> List[str]:
        """List craftable recipes.

        - builder_tag: if set, only recipes that are not character-locked or match builder_tag.
        - strict: if True, recipes with unresolved ingredient amounts are excluded.
        """
        inv = {str(k).lower(): float(v) for k, v in (inventory or {}).items()}
        bt = builder_tag.strip().lower() if builder_tag else None

        out: List[str] = []
        for name, rec in self.recipes.items():
            # builder constraints
            if bt:
                tags = [str(x).lower() for x in (rec.get("builder_tags") or [])]
                if tags and bt not in tags:
                    continue

            miss = self.missing_for(name, inv)
            if not miss:
                out.append(name)
            else:
                if strict:
                    continue
                # if not strict, allow unresolved-only
                if all(m.get("reason") == "unresolved_amount" for m in miss):
                    out.append(name)

        return sorted(out)

    # -----------------
    # Serialization (M2)
    # -----------------

    def to_dict(self) -> Dict[str, Any]:
        """JSON-serializable snapshot (do not include derived indices)."""
        return {
            "schema": 1,
            "recipes": self.recipes,
            "aliases": self.aliases,
            "filter_defs": self.filter_defs,
            "filter_order": self.filter_order,
        }

    @classmethod
    def from_dict(cls, data: Mapping[str, Any]) -> "CraftRecipeDB":
        """Load from `to_dict()` output."""
        obj = cls(recipes_lua="", recipes2_lua="", recipes_filter_lua="")

        obj.recipes = {str(k): v for k, v in (data.get("recipes") or {}).items()}
        obj.aliases = {str(k): str(v) for k, v in (data.get("aliases") or {}).items()}
        obj.filter_defs = list(data.get("filter_defs") or [])
        obj.filter_order = [str(x).upper() for x in (data.get("filter_order") or [])]
        obj.tab_order = [f for f in obj.filter_order if f and f not in obj._SPECIAL_FILTERS]

        # rebuild indices
        obj.by_tab = defaultdict(list)
        obj.by_filter = defaultdict(list)
        obj.by_tech = defaultdict(list)
        obj.by_builder_tag = defaultdict(list)
        obj.by_ingredient = defaultdict(list)

        for name, rec in obj.recipes.items():
            for f in rec.get("filters", []) or []:
                obj.by_filter[str(f).upper()].append(name)
            t = str(rec.get("tab") or "UNKNOWN").upper()
            obj.by_tab[t].append(name)

            tech = str(rec.get("tech") or "UNKNOWN")
            if tech.upper().startswith("TECH."):
                tech = tech.split(".", 1)[1]
            obj.by_tech[tech.upper()].append(name)

            for bt in rec.get("builder_tags") or []:
                if bt:
                    obj.by_builder_tag[str(bt).lower()].append(name)

            for ing in rec.get("ingredients") or []:
                it = ing.get("item")
                if it:
                    obj.by_ingredient[str(it).lower()].append(name)

        for mp in (obj.by_filter, obj.by_tab, obj.by_tech, obj.by_builder_tag, obj.by_ingredient):
            for k in list(mp.keys()):
                mp[k] = sorted(set(mp[k]))

        return obj

    def dumps(self, *, indent: int = 2, ensure_ascii: bool = False) -> str:
        return json.dumps(self.to_dict(), ensure_ascii=ensure_ascii, indent=indent)
```

### File: core/engine.py
- mode: full
- size_bytes: 15955
- sha256_12: 9dce78e27eb2

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""WagstaffEngine (core)

This module is intentionally UI-agnostic.

Responsibilities
- Mount DST scripts source (zip or folder) with a consistent "scripts/..." namespace.
- Provide fast `read_file()` + `find_file()` primitives.
- Load small, stable databases:
  - TuningResolver (scripts/tuning.lua)
  - CraftRecipeDB (scripts/recipes.lua + scripts/recipes2.lua + scripts/recipes_filter.lua)
  - CookingRecipeAnalyzer (scripts/preparedfoods.lua + scripts/prefabs/preparedfoods.lua)
  - CookingIngredientAnalyzer (scripts/ingredients.lua + scripts/cooking.lua)

Design notes
- Engine must be usable by CLI, GUI, and Web layers.
- Avoid hard dependency on Rich (it is optional). Use `silent=True` to suppress logs.
"""

from __future__ import annotations

import logging
import os
import zipfile
from functools import lru_cache
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Optional project config (exists in repo under core/utils.py)
try:
    from core.utils import wagstaff_config  # type: ignore
except Exception:  # pragma: no cover
    wagstaff_config = None  # type: ignore

from core.analyzer import CookingIngredientAnalyzer, CookingRecipeAnalyzer, LuaAnalyzer, TuningResolver
from core.craft_recipes import CraftRecipeDB

logger = logging.getLogger(__name__)


def _expanduser(p: Optional[str]) -> Optional[str]:
    return os.path.expanduser(p) if p else None


def _merge_cooking_ingredients(base: Dict[str, Dict], extra: Dict[str, Dict]) -> Dict[str, Dict]:
    out: Dict[str, Dict] = {}
    for iid, row in (base or {}).items():
        if not isinstance(row, dict):
            continue
        merged = dict(row)
        merged.setdefault("id", iid)
        out[str(iid)] = merged

    for iid, row in (extra or {}).items():
        if not isinstance(row, dict):
            continue
        key = str(iid)
        if key not in out:
            merged = dict(row)
            merged.setdefault("id", key)
            out[key] = merged
            continue

        cur = dict(out[key])
        cur.setdefault("id", key)

        sources: List[str] = []
        for src in cur.get("sources") or []:
            if src not in sources:
                sources.append(src)
        for src in row.get("sources") or []:
            if src not in sources:
                sources.append(src)
        if sources:
            cur["sources"] = sources

        tags = dict(cur.get("tags") or {})
        for tag, val in (row.get("tags") or {}).items():
            if tag not in tags or tags.get(tag) in (None, 0, 0.0):
                tags[tag] = val
        if tags:
            cur["tags"] = tags

        tags_expr = dict(cur.get("tags_expr") or {})
        for tag, val in (row.get("tags_expr") or {}).items():
            if tag not in tags_expr:
                tags_expr[tag] = val
        if tags_expr:
            cur["tags_expr"] = tags_expr

        for field in ("name", "atlas", "image", "prefab", "foodtype"):
            if field not in cur and field in row:
                cur[field] = row[field]

        out[key] = cur

    return out


class WagstaffEngine:
    """Main entry used by CLI / devtools / GUI / Web.

    Parameters
    - load_db: load tuning + recipe DBs (and cooking recipes).
    - silent: suppress all logs.
    - dst_root: optional DST root path (overrides config).
    - scripts_zip: optional scripts zip path (highest priority).
    - scripts_dir: optional scripts folder path (highest priority for folder mode).
    - prefer_local_bundles: search project-root bundle drops first.
    """

    def __init__(
        self,
        load_db: bool = True,
        silent: bool = False,
        *,
        dst_root: Optional[str] = None,
        scripts_zip: Optional[str] = None,
        scripts_dir: Optional[str] = None,
        prefer_local_bundles: bool = True,
        encoding: str = "utf-8",
    ):
        self.encoding = encoding
        self.silent = bool(silent)

        self.mode: str = ""  # 'zip' | 'folder'
        self.source: object = None  # ZipFile or folder path (str)
        self.file_list: List[str] = []

        # basename index for fast fuzzy find
        self._basename_index: Dict[str, List[str]] = {}

        self.tuning: Optional[TuningResolver] = None
        self.recipes: Optional[CraftRecipeDB] = None
        self.cooking_recipes: Dict[str, Dict] = {}
        self.cooking_ingredients: Dict[str, Dict] = {}

        self._init_source(
            dst_root=dst_root,
            scripts_zip=scripts_zip,
            scripts_dir=scripts_dir,
            prefer_local_bundles=prefer_local_bundles,
        )
        self._build_basename_index()

        if load_db:
            self._init_databases()

    # --------------------------------------------------------
    # Context manager
    # --------------------------------------------------------

    def __enter__(self) -> "WagstaffEngine":
        return self

    def __exit__(self, exc_type, exc, tb) -> None:
        self.close()

    # --------------------------------------------------------
    # Source mounting
    # --------------------------------------------------------

    def _project_root(self) -> Path:
        """Best-effort repo root.

        - Prefer wagstaff_config.project_root when available.
        - Fallback to core/.. (engine.py is expected under core/).
        """
        if wagstaff_config is not None and hasattr(wagstaff_config, "project_root"):
            try:
                return Path(str(wagstaff_config.project_root)).resolve()
            except Exception:
                pass
        # engine.py is usually core/engine.py
        return Path(__file__).resolve().parent.parent

    def _detect_candidates(self, dst_root: Optional[str], prefer_local_bundles: bool) -> Tuple[List[str], List[str]]:
        """Return (zip_candidates, dir_candidates)."""
        pr = self._project_root()

        dst_root = _expanduser(dst_root)
        if dst_root is None and wagstaff_config is not None:
            try:
                dst_root = _expanduser(wagstaff_config.get("PATHS", "DST_ROOT"))
            except Exception:
                dst_root = None

        zip_candidates: List[str] = []
        dir_candidates: List[str] = []

        # Prefer local bundle drops for faster iteration
        if prefer_local_bundles:
            zip_candidates += [
                str(pr / "scripts-no-language-pac.zip"),
                str(pr / "scripts_no_language.zip"),
                str(pr / "scripts.zip"),
                str(pr / "data" / "databundles" / "scripts.zip"),
            ]
            dir_candidates += [
                str(pr / "scripts"),
            ]

        if dst_root:
            zip_candidates += [
                os.path.join(dst_root, "data", "databundles", "scripts.zip"),
                os.path.join(dst_root, "data", "databundles", "scripts_no_language.zip"),
            ]
            dir_candidates += [
                os.path.join(dst_root, "data", "scripts"),
            ]

        return zip_candidates, dir_candidates

    def _log(self, msg: str) -> None:
        if not self.silent:
            logger.info(msg)

    def _init_source(
        self,
        *,
        dst_root: Optional[str],
        scripts_zip: Optional[str],
        scripts_dir: Optional[str],
        prefer_local_bundles: bool,
    ) -> None:
        # explicit overrides
        if scripts_zip:
            zp = _expanduser(scripts_zip)
            if zp and os.path.exists(zp):
                self.mode = "zip"
                self.source = zipfile.ZipFile(zp, "r")
                self.file_list = list(getattr(self.source, "namelist")())
                self._log(f"Mounted scripts zip: {zp}")
                return

        if scripts_dir:
            dp = _expanduser(scripts_dir)
            if dp and os.path.isdir(dp):
                self.mode = "folder"
                self.source = dp
                self.file_list = self._walk_folder(dp)
                self._log(f"Mounted scripts folder: {dp}")
                return

        zip_candidates, dir_candidates = self._detect_candidates(dst_root, prefer_local_bundles)

        for zp in zip_candidates:
            if zp and os.path.exists(zp):
                self.mode = "zip"
                self.source = zipfile.ZipFile(zp, "r")
                self.file_list = list(getattr(self.source, "namelist")())
                self._log(f"Mounted scripts zip: {zp}")
                return

        for dp in dir_candidates:
            if dp and os.path.isdir(dp):
                self.mode = "folder"
                self.source = dp
                self.file_list = self._walk_folder(dp)
                self._log(f"Mounted scripts folder: {dp}")
                return

        raise FileNotFoundError("Cannot find scripts source (zip or folder).")

    def _walk_folder(self, folder: str) -> List[str]:
        folder = os.path.abspath(folder)
        out: List[str] = []
        for root, _, files in os.walk(folder):
            for name in files:
                full = os.path.join(root, name)
                rel = os.path.relpath(full, folder).replace("\\", "/")
                out.append("scripts/" + rel)  # normalize namespace
        return out

    def _build_basename_index(self) -> None:
        mp: Dict[str, List[str]] = {}
        for p in self.file_list:
            if not p.endswith(".lua"):
                continue
            base = os.path.basename(p)
            key = base.replace(".lua", "").replace("_", "").lower()
            mp.setdefault(key, []).append(p)
        self._basename_index = mp

    # --------------------------------------------------------
    # IO
    # --------------------------------------------------------

    def _normalize_path_candidates(self, path: str) -> List[str]:
        p = (path or "").replace("\\", "/").lstrip("/")
        if not p:
            return []
        if p.startswith("scripts/"):
            return [p, p.replace("scripts/", "", 1)]
        return [p, "scripts/" + p]

    @lru_cache(maxsize=4096)
    def read_file(self, path: str) -> Optional[str]:
        """Read a UTF-8 text file from the mounted source.

        Accepts paths with or without the "scripts/" prefix.
        Returns None if not found.
        """
        candidates = self._normalize_path_candidates(path)
        if not candidates:
            return None

        try:
            if self.mode == "zip":
                zf: zipfile.ZipFile = self.source  # type: ignore[assignment]
                for p in candidates:
                    if p in self.file_list:
                        return zf.read(p).decode(self.encoding, errors="replace")
                return None

            # folder
            base: str = self.source  # type: ignore[assignment]
            for p in candidates:
                real = os.path.join(base, p.replace("scripts/", "", 1))
                if os.path.exists(real):
                    with open(real, "r", encoding=self.encoding, errors="replace") as f:
                        return f.read()
        except Exception:
            return None

        return None

    def find_file(self, name: str, fuzzy: bool = True) -> Optional[str]:
        """Find a file by short name.

        Examples
        - armorwood -> scripts/prefabs/armorwood.lua (or armor_wood.lua)
        - prefabs/armorwood.lua -> scripts/prefabs/armorwood.lua

        Returns a path in the normalized namespace (usually "scripts/...").
        """
        if not name:
            return None
        q = name.replace("\\", "/").strip()
        if not q:
            return None

        # direct hit if user passed a path
        for cand in self._normalize_path_candidates(q):
            if cand in self.file_list:
                return cand

        base = q.replace(".lua", "")
        candidates = [
            f"scripts/prefabs/{base}.lua",
            f"scripts/{base}.lua",
            f"scripts/{base}",
        ]
        for c in candidates:
            if c in self.file_list:
                return c

        if not fuzzy:
            return None

        key = os.path.basename(base).replace("_", "").lower()
        hits = self._basename_index.get(key)
        if hits:
            # prefer prefabs if ambiguous
            if len(hits) == 1:
                return hits[0]
            pref = [h for h in hits if h.startswith("scripts/prefabs/")]
            if len(pref) == 1:
                return pref[0]
            return hits[0]

        # final fallback: scan
        target = key
        for fname in self.file_list:
            if not fname.endswith(".lua"):
                continue
            b = os.path.basename(fname).replace(".lua", "").replace("_", "").lower()
            if b == target:
                return fname

        return None

    def close(self) -> None:
        if self.mode == "zip" and self.source is not None:
            try:
                self.source.close()  # type: ignore[attr-defined]
            except Exception:
                pass

    # --------------------------------------------------------
    # DB initialization
    # --------------------------------------------------------

    def _init_databases(self) -> None:
        self._log("Loading tuning / crafting / cooking databases...")

        t_content = self.read_file("scripts/tuning.lua") or self.read_file("tuning.lua") or ""
        self.tuning = TuningResolver(t_content)

        r1 = self.read_file("scripts/recipes.lua") or self.read_file("recipes.lua") or ""
        r2 = self.read_file("scripts/recipes2.lua") or self.read_file("recipes2.lua") or ""
        rf = self.read_file("scripts/recipes_filter.lua") or self.read_file("recipes_filter.lua") or ""
        self.recipes = CraftRecipeDB(recipes_lua=r1, recipes2_lua=r2, recipes_filter_lua=rf)

        # cooking recipes (optional)
        food_src = self.read_file("scripts/preparedfoods.lua") or ""
        if food_src:
            self.cooking_recipes.update(CookingRecipeAnalyzer(food_src).recipes)

        food_prefab_src = self.read_file("scripts/prefabs/preparedfoods.lua") or ""
        if food_prefab_src:
            # prefab file often contains the same table; merge (prefab wins)
            self.cooking_recipes.update(CookingRecipeAnalyzer(food_prefab_src).recipes)

        ing_path = "scripts/ingredients.lua"
        ing_src = self.read_file(ing_path)
        if not ing_src:
            ing_path = "ingredients.lua"
            ing_src = self.read_file(ing_path)
        if ing_src:
            self.cooking_ingredients = CookingIngredientAnalyzer(ing_src, source=ing_path).ingredients

        cook_path = "scripts/cooking.lua"
        cook_src = self.read_file(cook_path)
        if not cook_src:
            cook_path = "cooking.lua"
            cook_src = self.read_file(cook_path)
        if cook_src:
            extra = CookingIngredientAnalyzer(cook_src, source=cook_path).ingredients
            if extra:
                self.cooking_ingredients = _merge_cooking_ingredients(self.cooking_ingredients, extra)

    # --------------------------------------------------------
    # High-level helpers
    # --------------------------------------------------------

    def analyze_prefab(self, item_name: str) -> Optional[Dict]:
        """High-level prefab analysis (LuaAnalyzer + tuning enrichment)."""
        path = self.find_file(item_name, fuzzy=True)
        if not path:
            return None

        content = self.read_file(path)
        if not content:
            return None

        data = LuaAnalyzer(content, path=path).get_report()

        if self.tuning:
            for comp in data.get("components", []) or []:
                comp["properties"] = [self.tuning.enrich(p) for p in comp.get("properties", [])]
                comp["methods"] = [self.tuning.enrich(m) for m in comp.get("methods", [])]

        return data
```

### File: core/indexers/__init__.py
- mode: full
- size_bytes: 48
- sha256_12: e7fb45ee44bb

```py
# -*- coding: utf-8 -*-
"""Indexers package."""
```

### File: core/indexers/catalog_index.py
- mode: full
- size_bytes: 7063
- sha256_12: ea5d556592d6

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Catalog index builder (core).

Build a compact, search-friendly index from wagstaff_catalog_v2.json.
"""

from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

from core.schemas.meta import build_meta

def _dedup_preserve_order(items: Iterable[str]) -> List[str]:
    out: List[str] = []
    seen = set()
    for x in items:
        if not x:
            continue
        if x in seen:
            continue
        out.append(x)
        seen.add(x)
    return out


def load_icon_index(path: Optional[Path]) -> Dict[str, str]:
    if path is None:
        return {}
    p = Path(path)
    if not p.exists() or not p.is_file():
        return {}
    try:
        doc = json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return {}
    icons = doc.get("icons") if isinstance(doc, dict) else None
    if not isinstance(icons, dict):
        return {}
    out: Dict[str, str] = {}
    for k, v in icons.items():
        if not k or not isinstance(k, str):
            continue
        if isinstance(v, dict) and v.get("png"):
            out[k] = str(v.get("png"))
    return out


def _build_item_list(
    catalog: Dict[str, Any],
    *,
    icon_index: Optional[Dict[str, str]] = None,
) -> List[Dict[str, Any]]:
    items_obj = catalog.get("items") or {}
    assets_obj = catalog.get("assets") or {}

    if not isinstance(items_obj, dict):
        items_obj = {}
    if not isinstance(assets_obj, dict):
        assets_obj = {}

    icon_index = icon_index or {}

    ids: List[str] = []
    ids.extend([str(k) for k in items_obj.keys() if k])
    ids.extend([str(k) for k in assets_obj.keys() if k])
    ids.extend([str(k) for k in icon_index.keys() if k])
    ids = _dedup_preserve_order(ids)

    out: List[Dict[str, Any]] = []

    for iid in ids:
        if not iid:
            continue
        item = items_obj.get(iid) if isinstance(items_obj.get(iid), dict) else {}
        asset = assets_obj.get(iid) if isinstance(assets_obj.get(iid), dict) else {}
        asset = asset or (item.get("assets") if isinstance(item, dict) else {}) or {}
        name = asset.get("name") or item.get("name") or iid
        icon = asset.get("icon") or asset.get("image") or icon_index.get(iid)
        entry = {
            "id": iid,
            "name": name,
            "image": asset.get("image") or icon,
            "icon": icon,
            "has_icon": bool(icon),
            "icon_only": bool(iid not in items_obj),
            "kind": item.get("kind"),
            "categories": item.get("categories") or [],
            "behaviors": item.get("behaviors") or [],
            "sources": item.get("sources") or [],
            "tags": item.get("tags") or [],
            "components": item.get("components") or [],
            "slots": item.get("slots") or [],
        }
        out.append(entry)

    out.sort(key=lambda x: x.get("id") or "")
    return out


def _build_indexes(items: List[Dict[str, Any]]) -> Dict[str, Dict[str, List[str]]]:
    by_kind: Dict[str, List[str]] = {}
    by_category: Dict[str, List[str]] = {}
    by_behavior: Dict[str, List[str]] = {}
    by_source: Dict[str, List[str]] = {}
    by_component: Dict[str, List[str]] = {}
    by_tag: Dict[str, List[str]] = {}
    by_slot: Dict[str, List[str]] = {}

    def _as_list(val: Any) -> List[str]:
        if isinstance(val, str):
            return [val]
        if isinstance(val, (list, tuple, set)):
            return [str(x) for x in val if x]
        return []

    def _push(bucket: Dict[str, List[str]], key: Optional[str], iid: str) -> None:
        if not key:
            return
        bucket.setdefault(str(key), []).append(iid)

    for item in items:
        iid = str(item.get("id") or "").strip()
        if not iid:
            continue
        kind = item.get("kind")
        if kind:
            _push(by_kind, str(kind), iid)
        for cat in _as_list(item.get("categories")):
            _push(by_category, cat, iid)
        for beh in _as_list(item.get("behaviors")):
            _push(by_behavior, beh, iid)
        for src in _as_list(item.get("sources")):
            _push(by_source, src, iid)
        for comp in _as_list(item.get("components")):
            _push(by_component, comp, iid)
        for tag in _as_list(item.get("tags")):
            _push(by_tag, tag, iid)
        for slot in _as_list(item.get("slots")):
            _push(by_slot, slot, iid)

    for bucket in (by_kind, by_category, by_behavior, by_source, by_component, by_tag, by_slot):
        for k in list(bucket.keys()):
            bucket[k] = sorted(_dedup_preserve_order(bucket[k]))

    return {
        "by_kind": by_kind,
        "by_category": by_category,
        "by_behavior": by_behavior,
        "by_source": by_source,
        "by_component": by_component,
        "by_tag": by_tag,
        "by_slot": by_slot,
    }


def build_catalog_index(
    catalog: Dict[str, Any],
    *,
    icon_index: Optional[Dict[str, str]] = None,
) -> Dict[str, Any]:
    items = _build_item_list(catalog, icon_index=icon_index)
    indexes = _build_indexes(items)

    items_total = len(items)
    icon_only = len([i for i in items if i.get("icon_only")])
    icons_total = len([i for i in items if i.get("has_icon")])

    meta_src = catalog.get("meta") if isinstance(catalog, dict) else {}
    meta_src = meta_src if isinstance(meta_src, dict) else {}

    meta = build_meta(
        schema=1,
        tool="build_catalog_index",
        sources={
            "catalog": "wagstaff_catalog_v2.json",
            "scripts_zip": meta_src.get("scripts_zip"),
            "scripts_dir": meta_src.get("scripts_dir"),
        },
        extra={
            "catalog_schema": int(catalog.get("schema_version") or meta_src.get("schema") or 0),
            "scripts_sha256_12": meta_src.get("scripts_sha256_12"),
            "scripts_zip": meta_src.get("scripts_zip"),
            "scripts_dir": meta_src.get("scripts_dir"),
        },
    )

    return {
        "schema_version": 1,
        "meta": meta,
        "counts": {
            "items_total": items_total,
            "items_with_icon": icons_total,
            "icon_only": icon_only,
        },
        "items": items,
        "indexes": indexes,
    }


def render_index_summary(index_doc: Dict[str, Any]) -> str:
    meta = index_doc.get("meta") or {}
    counts = index_doc.get("counts") or {}
    lines = []
    lines.append("# Wagstaff Catalog Index Summary")
    lines.append("")
    lines.append("## Meta")
    lines.append("```yaml")
    lines.append(f"schema_version: {index_doc.get('schema_version')}")
    lines.append(f"catalog_schema: {meta.get('catalog_schema')}")
    lines.append(f"scripts_sha256_12: {meta.get('scripts_sha256_12')}")
    lines.append("```")
    lines.append("")
    lines.append("## Counts")
    lines.append("```yaml")
    for k, v in counts.items():
        lines.append(f"{k}: {v}")
    lines.append("```")
    return "\n".join(lines) + "\n"
```

### File: core/indexers/catalog_v2.py
- mode: full
- size_bytes: 25944
- sha256_12: 30128b52ab7b

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Catalog v2 builder (core).

Generates an item-centric, taggable catalog from DST scripts and data.
"""

from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Set, Tuple
import re

from core.analyzer import LuaCallExtractor, LootParser, PrefabParser, _split_top_level, strip_lua_comments, _skip_string_or_long_string
from core.indexers.shared import _sha256_12_file
from core.craft_recipes import CraftRecipeDB
from core.tagging import TagProfile, apply_overrides, infer_tags, load_tag_overrides
from core.schemas.catalog_v2 import WagstaffCatalogV2
from core.schemas.meta import build_meta


SCHEMA_VERSION = 2
_ID_RE = re.compile(r"^[a-z0-9_]+$")

TUNING_FIELDS = (
    "hunger",
    "health",
    "sanity",
    "perishtime",
    "cooktime",
    "temperature",
    "temperatureduration",
    "fuelvalue",
    "maxsize",
)

_STAT_METHODS = {
    "weapon": {
        "SetDamage": [("weapon_damage", 0)],
        "SetRange": [("weapon_range_min", 0), ("weapon_range_max", 1)],
        "SetAttackRange": [("weapon_range", 0)],
    },
    "combat": {
        "SetDefaultDamage": [("combat_damage", 0)],
        "SetAttackPeriod": [("attack_period", 0)],
        "SetRange": [("attack_range", 0), ("attack_range_max", 1)],
        "SetAreaDamage": [("area_damage", 0)],
    },
    "finiteuses": {
        "SetMaxUses": [("uses_max", 0)],
        "SetUses": [("uses", 0)],
    },
    "armor": {
        "InitCondition": [("armor_condition", 0), ("armor_absorption", 1)],
        "SetCondition": [("armor_condition", 0)],
        "SetAbsorption": [("armor_absorption", 0)],
    },
    "edible": {
        "SetHealth": [("edible_health", 0)],
        "SetHunger": [("edible_hunger", 0)],
        "SetSanity": [("edible_sanity", 0)],
    },
    "perishable": {
        "SetPerishTime": [("perish_time", 0)],
    },
    "fueled": {
        "SetFuelLevel": [("fuel_level", 0)],
        "InitializeFuelLevel": [("fuel_level", 0)],
        "SetMaxFuel": [("fuel_max", 0)],
    },
    "equippable": {
        "SetDapperness": [("dapperness", 0)],
        "SetEquipSlot": [("equip_slot", 0)],
        "SetWalkSpeedMult": [("equip_walk_speed_mult", 0)],
        "SetRunSpeedMult": [("equip_run_speed_mult", 0)],
        "SetRestrictedTag": [("equip_restricted_tag", 0)],
        "SetPreventUnequipping": [("equip_prevent_unequip", 0)],
        "SetEquipStack": [("equip_stack", 0)],
        "SetInsulated": [("equip_insulated", 0)],
        "SetEquippedMoisture": [("equip_moisture", 0)],
        "SetMaxEquippedMoisture": [("equip_moisture_max", 0)],
    },
    "insulator": {
        "SetInsulation": [("insulation", 0)],
        "SetWinterInsulation": [("insulation_winter", 0)],
        "SetSummerInsulation": [("insulation_summer", 0)],
    },
    "waterproofer": {
        "SetEffectiveness": [("waterproof", 0)],
    },
    "light": {
        "SetRadius": [("light_radius", 0)],
        "SetIntensity": [("light_intensity", 0)],
        "SetFalloff": [("light_falloff", 0)],
    },
    "stackable": {
        "SetMaxSize": [("stack_size", 0)],
    },
    "health": {
        "SetMaxHealth": [("health_max", 0)],
    },
    "sanity": {
        "SetMax": [("sanity_max", 0)],
        "SetRate": [("sanity_rate", 0)],
    },
    "sanityaura": {
        "SetAura": [("sanity_aura", 0)],
    },
    "hunger": {
        "SetMax": [("hunger_max", 0)],
        "SetRate": [("hunger_rate", 0)],
    },
    "locomotor": {
        "SetWalkSpeed": [("walk_speed", 0)],
        "SetRunSpeed": [("run_speed", 0)],
        "SetExternalSpeedMultiplier": [("speed_multiplier", 2)],
        "SetSpeedMultiplier": [("speed_multiplier", 0)],
    },
    "rechargeable": {
        "SetRechargeTime": [("recharge_time", 0)],
        "SetChargeTime": [("recharge_time", 0)],
        "SetMaxCharge": [("recharge_max", 0)],
        "SetPercent": [("recharge_percent", 0)],
        "SetCharge": [("recharge_charge", 0)],
    },
    "heater": {
        "SetHeat": [("heat", 0)],
        "SetRadius": [("heat_radius", 0)],
        "SetThermics": [("heater_exothermic", 0), ("heater_endothermic", 1)],
        "SetShouldFalloff": [("heat_falloff", 0)],
        "SetHeatRadiusCutoff": [("heat_radius_cutoff", 0)],
        "SetEquippedHeat": [("equipped_heat", 0)],
        "SetCarriedHeat": [("carried_heat", 0)],
        "SetCarriedHeatMultiplier": [("carried_heat_multiplier", 0)],
        "SetHeatRate": [("heat_rate", 0)],
    },
    "planardamage": {
        "SetBaseDamage": [("planar_damage_base", 0)],
        "SetBonusDamage": [("planar_damage_bonus", 0)],
        "SetDamage": [("planar_damage", 0)],
    },
    "planararmor": {
        "SetAbsorption": [("planar_absorption", 0)],
        "SetBaseAbsorption": [("planar_absorption_base", 0)],
    },
    "workable": {
        "SetWorkLeft": [("work_left", 0)],
    },
}

_STAT_PROPERTIES = {
    "weapon": {"damage": "weapon_damage"},
    "combat": {"defaultdamage": "combat_damage"},
    "finiteuses": {"maxuses": "uses_max", "uses": "uses"},
    "armor": {"absorption": "armor_absorption", "condition": "armor_condition"},
    "edible": {
        "healthvalue": "edible_health",
        "hungervalue": "edible_hunger",
        "sanityvalue": "edible_sanity",
    },
    "perishable": {"perishtime": "perish_time"},
    "fueled": {"maxfuel": "fuel_max"},
    "equippable": {
        "dapperness": "dapperness",
        "equipslot": "equip_slot",
        "walkspeedmult": "equip_walk_speed_mult",
        "runspeedmult": "equip_run_speed_mult",
        "restrictedtag": "equip_restricted_tag",
        "preventunequipping": "equip_prevent_unequip",
        "equipstack": "equip_stack",
        "insulated": "equip_insulated",
        "equippedmoisture": "equip_moisture",
        "maxequippedmoisture": "equip_moisture_max",
        "is_magic_dapperness": "equip_magic_dapperness",
    },
    "insulator": {"insulation": "insulation"},
    "waterproofer": {"effectiveness": "waterproof"},
    "light": {"radius": "light_radius", "intensity": "light_intensity", "falloff": "light_falloff"},
    "stackable": {"maxsize": "stack_size"},
    "health": {"maxhealth": "health_max"},
    "sanity": {"max": "sanity_max", "rate": "sanity_rate"},
    "sanityaura": {"aura": "sanity_aura"},
    "hunger": {"max": "hunger_max", "rate": "hunger_rate"},
    "locomotor": {"walkspeed": "walk_speed", "runspeed": "run_speed"},
    "rechargeable": {
        "recharge_time": "recharge_time",
        "chargetime": "recharge_time",
        "percent": "recharge_percent",
        "charge": "recharge_charge",
        "maxcharge": "recharge_max",
        "maxrecharge": "recharge_max",
        "total": "recharge_max",
        "current": "recharge_charge",
    },
    "heater": {
        "heat": "heat",
        "radius": "heat_radius",
        "equippedheat": "equipped_heat",
        "carriedheat": "carried_heat",
        "carriedheatfn": "carried_heat",
        "carriedheatmultiplier": "carried_heat_multiplier",
        "heatrate": "heat_rate",
        "radius_cutoff": "heat_radius_cutoff",
        "exothermic": "heater_exothermic",
        "endothermic": "heater_endothermic",
    },
    "planardamage": {"basedamage": "planar_damage_base", "bonusdamage": "planar_damage_bonus", "damage": "planar_damage"},
    "planararmor": {"absorption": "planar_absorption", "baseabsorption": "planar_absorption_base"},
    "workable": {"workleft": "work_left"},
}


def _clean_id(x: Any) -> Optional[str]:
    if not isinstance(x, str):
        return None
    s = x.strip().lower()
    if not s or not _ID_RE.match(s):
        return None
    return s


def _collect_craft_sets(craft: CraftRecipeDB) -> Dict[str, Set[str]]:
    recipe_ids: Set[str] = set()
    product_ids: Set[str] = set()
    ingredient_ids: Set[str] = set()

    for name, rec in (getattr(craft, "recipes", {}) or {}).items():
        nm = _clean_id(name)
        if nm:
            recipe_ids.add(nm)
        if not isinstance(rec, dict):
            continue
        prod = _clean_id(rec.get("product"))
        if prod:
            product_ids.add(prod)
        for ing in rec.get("ingredients", []) or []:
            item = _clean_id((ing or {}).get("item"))
            if item:
                ingredient_ids.add(item)

    return {
        "recipe_ids": recipe_ids,
        "product_ids": product_ids,
        "ingredient_ids": ingredient_ids,
    }


def _collect_cooking_sets(cooking: Dict[str, Any]) -> Dict[str, Set[str]]:
    recipe_ids: Set[str] = set()
    ingredient_ids: Set[str] = set()

    for name, rec in (cooking or {}).items():
        nm = _clean_id(name)
        if nm:
            recipe_ids.add(nm)
        if not isinstance(rec, dict):
            continue
        for row in (rec.get("card_ingredients") or []):
            if not isinstance(row, (list, tuple)) or not row:
                continue
            item = _clean_id(row[0])
            if item:
                ingredient_ids.add(item)

    return {
        "recipe_ids": recipe_ids,
        "ingredient_ids": ingredient_ids,
    }


def _scan_loot_items(engine: Any) -> Set[str]:
    items: Set[str] = set()
    patterns = ("SetSharedLootTable", "AddChanceLoot", "AddRandomLoot", "AddRandomLootTable")

    for path in getattr(engine, "file_list", []) or []:
        if not str(path).endswith(".lua"):
            continue
        p = str(path)
        if "loot" not in p and "prefabs" not in p:
            continue
        content = engine.read_file(p) or ""
        if not content:
            continue
        if not any(tok in content for tok in patterns):
            continue
        try:
            rep = LootParser(content, path=p).parse()
        except Exception:
            continue
        for entry in rep.get("entries") or []:
            item = _clean_id(entry.get("item"))
            if item:
                items.add(item)

    return items


def _select_asset(prefab_assets: List[Dict[str, Any]]) -> Dict[str, str]:
    atlas = None
    image = None
    for a in prefab_assets:
        t = str(a.get("type") or "").upper()
        p = str(a.get("path") or "")
        if not p:
            continue
        if t == "ATLAS" and atlas is None:
            atlas = p
        if t == "IMAGE" and image is None:
            image = p
    out: Dict[str, str] = {}
    if atlas:
        out["atlas"] = atlas
    if image:
        out["image"] = image
    return out


def _resolve_tuning_field(
    value: Any,
    *,
    tuning: Any,
    mode: str,
    trace_sink: Optional[Dict[str, Any]] = None,
    trace_key: Optional[str] = None,
) -> Any:
    if not tuning or not isinstance(value, str) or "TUNING." not in value:
        return value
    try:
        trace = tuning.trace_expr(value)
    except Exception:
        return value

    if trace_sink is not None and trace_key:
        trace_sink[trace_key] = trace

    if mode == "full":
        return {"value": trace.get("value"), "expr": trace.get("expr"), "trace": trace}

    # value_only
    return trace.get("value") if trace.get("value") is not None else value


def _parse_number(expr: str) -> Optional[float]:
    if not expr:
        return None
    s = str(expr).strip()
    if not s:
        return None
    try:
        if re.match(r"^[+-]?\d+(\.\d+)?$", s):
            val = float(s)
            return int(val) if val.is_integer() else val
    except Exception:
        return None
    return None


def _resolve_stat_expr(
    expr: str,
    *,
    tuning: Any,
    mode: str,
    trace_sink: Optional[Dict[str, Any]] = None,
    trace_key: Optional[str] = None,
) -> Dict[str, Any]:
    out: Dict[str, Any] = {"expr": expr}
    if not expr:
        return out

    if tuning and isinstance(expr, str) and "TUNING." in expr:
        try:
            trace = tuning.trace_expr(expr)
        except Exception:
            trace = {"expr": expr, "value": None, "expr_resolved": expr, "refs": {}}
        if trace_sink is not None and trace_key:
            trace_sink[trace_key] = trace
        out["value"] = trace.get("value")
        out["expr_resolved"] = trace.get("expr_resolved") or expr
        if mode == "full":
            out["trace"] = trace
        if trace_key:
            out["trace_key"] = trace_key
        return out

    expr_norm = str(expr).strip()
    if expr_norm in ("true", "false"):
        out["value"] = expr_norm == "true"
        out["expr_resolved"] = expr_norm
        return out

    num = _parse_number(expr)
    if num is not None:
        out["value"] = num
    out["expr_resolved"] = expr
    return out


def _score_stat_expr(expr: str) -> int:
    if not expr:
        return 0
    if "TUNING." in expr:
        return 3
    if str(expr).strip() in ("true", "false"):
        return 2
    if _parse_number(expr) is not None:
        return 2
    return 1


def _scan_assignment_expr(text: str, start: int) -> str:
    n = len(text)
    i = start
    depth = 0
    started = False
    while i < n:
        nxt = _skip_string_or_long_string(text, i)
        if nxt is not None:
            started = True
            i = nxt
            continue
        ch = text[i]
        if not started and ch.isspace():
            i += 1
            continue
        started = True
        if ch == "\n" and depth == 0:
            break
        if ch == ";" and depth == 0:
            break
        if ch in "([{":
            depth += 1
        elif ch in ")]}":
            depth = max(0, depth - 1)
        i += 1
    return text[start:i].strip().rstrip(",")


def _extract_component_aliases(clean: str) -> Dict[str, str]:
    aliases: Dict[str, str] = {}
    for m in re.finditer(
        r"\blocal\s+([A-Za-z0-9_]+)\s*=\s*(?:inst|self)[.:]AddComponent\(\s*['\"]([A-Za-z0-9_]+)['\"]",
        clean,
    ):
        aliases[m.group(1)] = m.group(2).lower()
    for m in re.finditer(
        r"\b([A-Za-z0-9_]+)\s*=\s*(?:inst|self)[.:]AddComponent\(\s*['\"]([A-Za-z0-9_]+)['\"]",
        clean,
    ):
        if m.group(1) not in aliases:
            aliases[m.group(1)] = m.group(2).lower()
    for m in re.finditer(r"\blocal\s+([A-Za-z0-9_]+)\s*=\s*(?:inst|self)\.components\.([A-Za-z0-9_]+)", clean):
        aliases[m.group(1)] = m.group(2).lower()
    for m in re.finditer(r"\b([A-Za-z0-9_]+)\s*=\s*(?:inst|self)\.components\.([A-Za-z0-9_]+)", clean):
        if m.group(1) not in aliases:
            aliases[m.group(1)] = m.group(2).lower()
    return aliases


def _extract_component_stat_exprs(content: str) -> Dict[str, str]:
    rep = PrefabParser(content).parse()
    comp_names = {
        str((comp or {}).get("name") or "").strip().lower()
        for comp in (rep.get("components") or [])
    }
    comp_names.discard("")

    clean = strip_lua_comments(content or "")
    aliases = _extract_component_aliases(clean)
    if not comp_names:
        comp_names = {m.group(1).lower() for m in re.finditer(r"\bcomponents\.([A-Za-z0-9_]+)\b", clean)}

    out: Dict[str, str] = {}
    scores: Dict[str, int] = {}

    method_names = {m for cmap in _STAT_METHODS.values() for m in cmap.keys()}
    extractor = LuaCallExtractor(content)
    for call in extractor.iter_calls(method_names, include_member_calls=True):
        cname = None
        m = re.search(r"\bcomponents\.([A-Za-z0-9_]+)\b", call.full_name)
        if m:
            cname = m.group(1).lower()
        else:
            root = re.split(r"[.:]", call.full_name, 1)[0]
            cname = aliases.get(root)
        if not cname:
            continue
        if comp_names and cname not in comp_names:
            continue
        mapping = _STAT_METHODS.get(cname, {}).get(call.name)
        if not mapping:
            continue
        for stat_key, idx in mapping:
            if idx >= len(call.arg_list):
                continue
            expr = (call.arg_list[idx] or "").strip()
            if not expr:
                continue
            score = _score_stat_expr(expr)
            if (stat_key not in out) or (score >= scores.get(stat_key, 0)):
                out[stat_key] = expr
                scores[stat_key] = score

    for cname in sorted(comp_names):
        prop_map = _STAT_PROPERTIES.get(cname, {})
        if not prop_map:
            continue

        prop_pat = re.compile(rf"\bcomponents\.{re.escape(cname)}\.([A-Za-z0-9_]+)\s*=")
        for m in prop_pat.finditer(clean):
            prop = m.group(1).strip().lower()
            stat_key = prop_map.get(prop)
            if not stat_key:
                continue
            expr = _scan_assignment_expr(clean, m.end())
            if not expr:
                continue
            score = _score_stat_expr(expr)
            if (stat_key not in out) or (score >= scores.get(stat_key, 0)):
                out[stat_key] = expr
                scores[stat_key] = score

        for alias, comp in aliases.items():
            if comp != cname:
                continue
            alias_pat = re.compile(rf"\b{re.escape(alias)}\.([A-Za-z0-9_]+)\s*=")
            for m in alias_pat.finditer(clean):
                prop = m.group(1).strip().lower()
                stat_key = prop_map.get(prop)
                if not stat_key:
                    continue
                expr = _scan_assignment_expr(clean, m.end())
                if not expr:
                    continue
                score = _score_stat_expr(expr)
                if (stat_key not in out) or (score >= scores.get(stat_key, 0)):
                    out[stat_key] = expr
                    scores[stat_key] = score

    if "heat_radius" not in out and "heat_radius_cutoff" in out:
        out["heat_radius"] = out["heat_radius_cutoff"]
        scores["heat_radius"] = scores.get("heat_radius_cutoff", 0)

    return out


def _infer_sources(
    *,
    item_id: str,
    craft_products: Set[str],
    cooking_recipes: Set[str],
    loot_items: Set[str],
    components: Set[str],
    tags: Set[str],
) -> Set[str]:
    sources: Set[str] = set()
    if item_id in craft_products:
        sources.add("craft")
    if item_id in cooking_recipes:
        sources.add("cook")
    if item_id in loot_items:
        sources.add("loot")
    if tags & {"event", "festival"}:
        sources.add("event")
    if tags & {"plant", "tree"} or "pickable" in components:
        sources.add("natural")
    if tags & {"character", "monster", "animal", "smallcreature", "largecreature", "epic"}:
        sources.add("spawn")
    return sources


def build_catalog_v2(
    *,
    engine: Any,
    resource_index: Dict[str, Any],
    tag_overrides_path: Optional[str] = None,
    tuning_mode: str = "value_only",
    include_tuning_trace: bool = False,
) -> Tuple[WagstaffCatalogV2, Optional[Dict[str, Any]]]:

    prefabs = resource_index.get("prefabs") or {}
    prefab_items = prefabs.get("items") or {}
    icon_ids = set(resource_index.get("assets", {}).get("inventory_icons") or [])

    craft_sets = _collect_craft_sets(engine.recipes)
    cooking_sets = _collect_cooking_sets(engine.cooking_recipes or {})
    loot_items = _scan_loot_items(engine)

    cooking_ingredients_src = getattr(engine, "cooking_ingredients", {}) or {}
    cooking_ingredient_ids = {_clean_id(k) for k in cooking_ingredients_src.keys() if _clean_id(k)}

    all_ids = (
        set(prefab_items.keys())
        | icon_ids
        | craft_sets["product_ids"]
        | craft_sets["recipe_ids"]
        | craft_sets["ingredient_ids"]
        | cooking_sets["recipe_ids"]
        | cooking_sets["ingredient_ids"]
        | cooking_ingredient_ids
    )
    all_ids = {i for i in all_ids if _ID_RE.match(i)}

    overrides = load_tag_overrides(tag_overrides_path)
    prefab_stats_cache: Dict[str, Dict[str, str]] = {}

    tuning_trace: Optional[Dict[str, Any]] = {} if include_tuning_trace else None
    tuning = getattr(engine, "tuning", None)

    items_out: Dict[str, Any] = {}
    assets_out: Dict[str, Any] = {}

    for iid in sorted(all_ids):
        pf = prefab_items.get(iid) or {}
        components = set(pf.get("components") or [])
        tags = set(pf.get("tags") or [])
        prefab_files = sorted({str(x) for x in (pf.get("files") or []) if x})
        prefab_assets = [dict(a) for a in (pf.get("assets") or []) if isinstance(a, dict)]
        brains = sorted({str(x) for x in (pf.get("brains") or []) if x})
        stategraphs = sorted({str(x) for x in (pf.get("stategraphs") or []) if x})
        helpers = sorted({str(x) for x in (pf.get("helpers") or []) if x})
        sources = _infer_sources(
            item_id=iid,
            craft_products=craft_sets["product_ids"],
            cooking_recipes=cooking_sets["recipe_ids"],
            loot_items=loot_items,
            components=components,
            tags=tags,
        )
        profile = infer_tags(components=components, tags=tags, sources=sources)
        profile = apply_overrides(iid, profile, overrides)

        assets = _select_asset(pf.get("assets") or [])
        if iid in icon_ids:
            assets["icon"] = f"static/icons/{iid}.png"

        stat_exprs: Dict[str, str] = {}
        stat_scores: Dict[str, int] = {}
        for pfile in prefab_files:
            if pfile not in prefab_stats_cache:
                content = engine.read_file(pfile) or ""
                prefab_stats_cache[pfile] = _extract_component_stat_exprs(content) if content else {}
            for sk, sv in prefab_stats_cache.get(pfile, {}).items():
                score = _score_stat_expr(sv)
                if (sk not in stat_exprs) or (score >= stat_scores.get(sk, 0)):
                    stat_exprs[sk] = sv
                    stat_scores[sk] = score

        stats_out: Dict[str, Any] = {}
        for stat_key, expr in stat_exprs.items():
            trace_key = f"item:{iid}:stat:{stat_key}" if include_tuning_trace else None
            entry = _resolve_stat_expr(
                expr,
                tuning=tuning,
                mode=tuning_mode,
                trace_sink=tuning_trace,
                trace_key=trace_key,
            )
            entry["key"] = stat_key
            stats_out[stat_key] = entry

        items_out[iid] = {
            "id": iid,
            "kind": profile.kind,
            "categories": sorted(profile.categories),
            "behaviors": sorted(profile.behaviors),
            "sources": sorted(profile.sources),
            "slots": sorted(profile.slots),
            "components": sorted(components),
            "tags": sorted(tags),
            "assets": assets or {},
            "prefab_files": prefab_files,
            "prefab_assets": prefab_assets,
            "brains": brains,
            "stategraphs": stategraphs,
            "helpers": helpers,
            "stats": stats_out,
        }
        if assets:
            assets_out[iid] = dict(assets)

    # craft (enrich ingredients)
    craft_doc = engine.recipes.to_dict() if engine.recipes else {}
    craft_recipes = craft_doc.get("recipes") or {}

    for name, rec in craft_recipes.items():
        if not isinstance(rec, dict):
            continue
        for ing in rec.get("ingredients", []) or []:
            if not isinstance(ing, dict):
                continue
            expr = ing.get("amount")
            if isinstance(expr, str) and "TUNING." in expr and tuning is not None:
                key = f"craft:{name}:ingredient:{ing.get('item')}"
                val = _resolve_tuning_field(expr, tuning=tuning, mode=tuning_mode, trace_sink=tuning_trace, trace_key=key)
                ing["amount_value"] = val if isinstance(val, (int, float)) else None
                if tuning_mode == "full" and isinstance(val, dict):
                    ing["amount_trace"] = val.get("trace")
            elif ing.get("amount_num") is not None:
                ing["amount_value"] = ing.get("amount_num")

    # cooking (enrich tuning fields)
    cooking_doc: Dict[str, Any] = {}
    for name, rec in (engine.cooking_recipes or {}).items():
        if not isinstance(rec, dict):
            continue
        out = dict(rec)
        for field in TUNING_FIELDS:
            if field in out:
                key = f"cooking:{name}:{field}"
                out[field] = _resolve_tuning_field(
                    out[field], tuning=tuning, mode=tuning_mode, trace_sink=tuning_trace, trace_key=key
                )
        cooking_doc[name] = out

    cooking_ingredients_doc: Dict[str, Any] = {}
    for iid, raw in (cooking_ingredients_src or {}).items():
        if not isinstance(raw, dict):
            continue
        out = dict(raw)
        out.setdefault("id", str(iid))
        cooking_ingredients_doc[str(iid)] = out

    scripts_zip = getattr(getattr(engine, "source", None), "filename", None)
    scripts_sha = _sha256_12_file(Path(scripts_zip)) if scripts_zip else None

    scripts_dir = getattr(engine, "source", None) if getattr(engine, "mode", "") == "folder" else None
    sources = {
        "resource_index": "wagstaff_resource_index_v1.json",
        "scripts_zip": scripts_zip,
        "scripts_dir": scripts_dir,
    }
    meta = build_meta(
        schema=SCHEMA_VERSION,
        tool="build_catalog_v2",
        sources=sources,
        extra={
            "tuning_mode": tuning_mode,
            "scripts_sha256_12": scripts_sha,
            "scripts_zip": scripts_zip,
            "scripts_dir": scripts_dir,
        },
    )

    stats = {
        "items_total": len(items_out),
        "assets_total": len(assets_out),
        "craft_recipes": len(craft_recipes),
        "cooking_recipes": len(cooking_doc),
        "cooking_ingredients": len(cooking_ingredients_doc),
        "loot_items": len(loot_items),
    }

    catalog = WagstaffCatalogV2(
        schema_version=SCHEMA_VERSION,
        meta=meta,
        items=items_out,
        assets=assets_out,
        craft=craft_doc,
        cooking=cooking_doc,
        cooking_ingredients=cooking_ingredients_doc,
        stats=stats,
    )

    return catalog, tuning_trace
```

### File: core/indexers/i18n_index.py
- mode: full
- size_bytes: 5194
- sha256_12: 552388a832ee

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""i18n index helpers (core).

Used by devtools to build data/index/wagstaff_i18n_v1.json.
"""

from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, Iterable, Optional, List


_NAMES_PREFIX = "STRINGS.NAMES."


def _po_unquote(s: str) -> str:
    """Unquote a PO string literal line segment."""

    s = (s or "").strip()
    if not (s.startswith('"') and s.endswith('"')):
        return ""
    inner = s[1:-1]
    out: List[str] = []
    i = 0
    while i < len(inner):
        ch = inner[i]
        if ch == "\\" and i + 1 < len(inner):
            nxt = inner[i + 1]
            if nxt == "n":
                out.append("\n")
            elif nxt == "t":
                out.append("\t")
            elif nxt == "r":
                out.append("\r")
            elif nxt == '"':
                out.append('"')
            elif nxt == "\\":
                out.append("\\")
            else:
                out.append(nxt)
            i += 2
            continue
        out.append(ch)
        i += 1
    return "".join(out)


def parse_po(text: str) -> Dict[str, str]:
    """Parse a PO file and return mapping: msgctxt -> msgstr.

    Notes
    - Only keep entries with non-empty msgctxt and msgstr.
    - For plural forms, take msgstr[0] only.
    """

    lines = (text or "").splitlines()
    cur: Dict[str, Any] = {}
    last_key: Optional[str] = None
    out: Dict[str, str] = {}

    def commit() -> None:
        nonlocal cur, last_key
        ctx = cur.get("msgctxt")
        msgstr = cur.get("msgstr")
        if isinstance(ctx, str) and ctx and isinstance(msgstr, str) and msgstr:
            out[ctx] = msgstr
        cur = {}
        last_key = None

    for raw in lines:
        line = raw.rstrip("\n")
        s = line.strip()
        if not s:
            commit()
            continue
        if s.startswith("#"):
            continue

        if s.startswith("msgctxt "):
            cur["msgctxt"] = _po_unquote(s[len("msgctxt ") :].strip())
            last_key = "msgctxt"
            continue

        if s.startswith("msgid "):
            cur["msgid"] = _po_unquote(s[len("msgid ") :].strip())
            last_key = "msgid"
            continue

        if s.startswith("msgid_plural "):
            cur["msgid_plural"] = _po_unquote(s[len("msgid_plural ") :].strip())
            last_key = "msgid_plural"
            continue

        if s.startswith("msgstr["):
            rb = s.find("]")
            idx_s = s[len("msgstr[") : rb].strip() if rb != -1 else ""
            try:
                idx = int(idx_s)
            except Exception:
                idx = -1
            if idx == 0:
                rest = s[rb + 1 :].strip() if rb != -1 else ""
                cur["msgstr"] = _po_unquote(rest)
                last_key = "msgstr"
            else:
                last_key = None
            continue

        if s.startswith("msgstr "):
            cur["msgstr"] = _po_unquote(s[len("msgstr ") :].strip())
            last_key = "msgstr"
            continue

        if s.startswith('"') and last_key:
            cur[last_key] = str(cur.get(last_key) or "") + _po_unquote(s)
            continue

    commit()
    return out


def _normalize_key(key: str) -> str:
    return str(key or "").strip().lower()


def extract_name_table(po_text: str) -> Dict[str, str]:
    """Return normalized key -> localized name."""

    ctx_map = parse_po(po_text or "")
    names: Dict[str, str] = {}
    for ctx, val in ctx_map.items():
        if not isinstance(ctx, str) or not ctx.startswith(_NAMES_PREFIX):
            continue
        key = _normalize_key(ctx[len(_NAMES_PREFIX) :])
        if not key:
            continue
        v = str(val or "").strip()
        if not v:
            continue
        names[key] = v
        if "_" in key:
            names.setdefault(key.replace("_", ""), v)
    return names


def build_item_name_map(po_text: str, *, item_ids: Optional[Iterable[str]] = None) -> Dict[str, str]:
    """Build item_id -> localized name mapping from PO content."""

    raw = extract_name_table(po_text or "")
    if not raw:
        return {}
    if item_ids is None:
        return dict(raw)

    out: Dict[str, str] = {}
    for iid in item_ids:
        if not iid:
            continue
        k1 = _normalize_key(iid)
        if not k1:
            continue
        k2 = k1.replace("_", "")
        v = raw.get(k1) or raw.get(k2)
        if v:
            out[str(iid)] = v
    return out


def load_ui_strings(path: Path) -> Dict[str, Dict[str, str]]:
    """Load UI strings JSON: {lang: {key: text}}."""

    p = Path(path)
    if not p.exists() or not p.is_file():
        return {}
    try:
        doc = json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return {}
    if not isinstance(doc, dict):
        return {}

    out: Dict[str, Dict[str, str]] = {}
    for lang, mp in doc.items():
        if not isinstance(mp, dict):
            continue
        l = _normalize_key(lang)
        if not l:
            continue
        out[l] = {str(k): str(v) for k, v in mp.items() if k and v}
    return out
```

### File: core/indexers/resource_index.py
- mode: full
- size_bytes: 17170
- sha256_12: fd0cfebe2c3b

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Resource index builder (core).

Collects a structured inventory of DST scripts and data resources.
"""

from __future__ import annotations

from collections import Counter, defaultdict
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Set, Tuple
import os
import re
import xml.etree.ElementTree as ET
import zipfile

from core.analyzer import LuaCallExtractor, parse_lua_string, strip_lua_comments
from core.schemas.meta import build_meta


SCHEMA_VERSION = 1
_ID_RE = re.compile(r"^[a-z0-9_]+$")

SCRIPT_KINDS = [
    ("prefab", "scripts/prefabs/"),
    ("prefab_postinit", "scripts/prefabs_postinit/"),
    ("component", "scripts/components/"),
    ("stategraph", "scripts/stategraphs/"),
    ("brain", "scripts/brains/"),
    ("behaviour", "scripts/behaviours/"),
    ("widget", "scripts/widgets/"),
    ("screen", "scripts/screens/"),
    ("map", "scripts/map/"),
    ("scenario", "scripts/scenarios/"),
    ("string", "scripts/strings"),
    ("language", "scripts/languages/"),
    ("tuning", "scripts/tuning.lua"),
    ("recipe", "scripts/recipes"),
    ("tool", "scripts/tools/"),
    ("util", "scripts/util/"),
]


def _classify_script(path: str) -> str:
    p = (path or "").replace("\\", "/")
    for kind, prefix in SCRIPT_KINDS:
        if prefix.endswith(".lua"):
            if p.endswith(prefix):
                return kind
        elif p.startswith(prefix):
            return kind
    return "other"


def _scan_scripts(file_list: Iterable[str]) -> Dict[str, Any]:
    files = [str(f) for f in file_list]
    lua_files = [f for f in files if f.endswith(".lua")]

    by_kind: Dict[str, List[str]] = defaultdict(list)
    items: List[Dict[str, str]] = []
    top_dir = Counter()
    second_dir = Counter()

    for f in lua_files:
        kind = _classify_script(f)
        items.append({"path": f, "kind": kind})
        by_kind[kind].append(f)

        clean = f[8:] if f.startswith("scripts/") else f
        parts = clean.split("/")
        if len(parts) == 1:
            top_dir["[root]"] += 1
        else:
            top_dir[parts[0]] += 1
            if len(parts) >= 2:
                second_dir[f"{parts[0]}/{parts[1]}"] += 1

    categories = {k: len(v) for k, v in by_kind.items()}

    top_dirs = [{"dir": d, "count": c} for d, c in top_dir.most_common(40)]
    top_second = [{"dir": d, "count": c} for d, c in second_dir.most_common(60)]

    return {
        "total_files": len(files),
        "lua_files": len(lua_files),
        "categories": categories,
        "top_dirs": top_dirs,
        "top_second_level": top_second,
        "files": items,
        "by_kind": dict(by_kind),
    }


def _parse_prefab_file(content: str) -> Dict[str, Any]:
    clean = strip_lua_comments(content or "")
    extractor = LuaCallExtractor(clean)

    prefabs: Set[str] = set()
    skipped = 0
    for call in extractor.iter_calls("Prefab", include_member_calls=False):
        if not call.arg_list:
            continue
        nm = parse_lua_string(call.arg_list[0])
        if isinstance(nm, str) and nm:
            n = nm.strip().lower()
            if _ID_RE.match(n):
                prefabs.add(n)
            else:
                skipped += 1

    assets: List[Dict[str, str]] = []
    for call in extractor.iter_calls("Asset", include_member_calls=False):
        if len(call.arg_list) < 2:
            continue
        t = parse_lua_string(call.arg_list[0])
        p = parse_lua_string(call.arg_list[1])
        if isinstance(t, str) and isinstance(p, str):
            assets.append({"type": t, "path": p})

    tags: Set[str] = set()
    for call in extractor.iter_calls("AddTag"):
        if call.arg_list:
            tg = parse_lua_string(call.arg_list[0])
            if isinstance(tg, str) and tg:
                tags.add(tg.strip().lower())

    components: Set[str] = set()
    for call in extractor.iter_calls("AddComponent"):
        if call.arg_list:
            cn = parse_lua_string(call.arg_list[0])
            if isinstance(cn, str) and cn:
                components.add(cn.strip().lower())

    brain = None
    m = re.search(r"SetBrain\s*\(\s*require\s*\(\s*['\"](.*?)['\"]\s*\)\s*\)", clean)
    if m:
        brain = m.group(1)

    stategraph = None
    m = re.search(r"SetStateGraph\s*\(\s*['\"](.*?)['\"]\s*\)", clean)
    if m:
        stategraph = m.group(1)

    helpers = sorted(set(re.findall(r"^\s*(Make[A-Za-z0-9_]+)\s*\(", content or "", flags=re.MULTILINE)))

    return {
        "prefabs": prefabs,
        "prefabs_skipped": skipped,
        "assets": assets,
        "tags": tags,
        "components": components,
        "brain": brain,
        "stategraph": stategraph,
        "helpers": helpers,
    }


def _scan_prefabs(engine: Any) -> Dict[str, Any]:
    prefab_files = [
        f for f in getattr(engine, "file_list", []) if str(f).startswith("scripts/prefabs/") and str(f).endswith(".lua")
    ]

    prefab_items: Dict[str, Dict[str, Any]] = {}
    file_entries: List[Dict[str, Any]] = []
    skipped_total = 0

    for path in prefab_files:
        content = engine.read_file(path) or ""
        if not content:
            continue

        parsed = _parse_prefab_file(content)
        prefabs = set(parsed["prefabs"])

        if not prefabs:
            base = str(path).split("/")[-1].rsplit(".lua", 1)[0].strip().lower()
            if _ID_RE.match(base):
                prefabs.add(base)

        file_entries.append(
            {
                "path": path,
                "prefabs": sorted(prefabs),
                "components": sorted(parsed["components"]),
                "tags": sorted(parsed["tags"]),
                "assets_count": len(parsed["assets"]),
            }
        )

        skipped_total += int(parsed.get("prefabs_skipped", 0) or 0)

        for pf in prefabs:
            entry = prefab_items.setdefault(
                pf,
                {
                    "files": [],
                    "components": set(),
                    "tags": set(),
                    "assets": [],
                    "brains": set(),
                    "stategraphs": set(),
                    "helpers": set(),
                },
            )
            if path not in entry["files"]:
                entry["files"].append(path)
            entry["components"].update(parsed["components"])
            entry["tags"].update(parsed["tags"])
            entry["helpers"].update(parsed["helpers"])
            if parsed.get("brain"):
                entry["brains"].add(parsed["brain"])
            if parsed.get("stategraph"):
                entry["stategraphs"].add(parsed["stategraph"])

            asset_keys = {f"{a.get('type')}:{a.get('path')}" for a in entry["assets"]}
            for a in parsed["assets"]:
                key = f"{a.get('type')}:{a.get('path')}"
                if key not in asset_keys:
                    entry["assets"].append(a)
                    asset_keys.add(key)

    # normalize sets -> lists
    for pf, entry in prefab_items.items():
        entry["components"] = sorted(entry["components"])
        entry["tags"] = sorted(entry["tags"])
        entry["brains"] = sorted(entry["brains"])
        entry["stategraphs"] = sorted(entry["stategraphs"])
        entry["helpers"] = sorted(entry["helpers"])

    return {
        "total_files": len(prefab_files),
        "total_prefabs": len(prefab_items),
        "prefabs_skipped": skipped_total,
        "items": prefab_items,
        "files": file_entries,
    }


def _scan_inventory_icons(dst_root: Path) -> Tuple[Set[str], List[str]]:
    icons: Set[str] = set()
    xmls: List[str] = []
    data_dir = dst_root / "data"
    img_dir = data_dir / "images"
    bundle_zip = data_dir / "databundles" / "images.zip"

    def _parse_xml_bytes(label: str, data: bytes) -> None:
        try:
            root = ET.fromstring(data)
        except Exception:
            return
        for el in root.findall(".//Element"):
            name = el.attrib.get("name")
            if name:
                n = name.strip().lower()
                if n.endswith(".tex"):
                    n = n[:-4]
                if _ID_RE.match(n):
                    icons.add(n)
        if label and label not in xmls:
            xmls.append(label)

    if bundle_zip.exists():
        try:
            with zipfile.ZipFile(bundle_zip, "r") as zf:
                for name in zf.namelist():
                    base = os.path.basename(name)
                    if not base.startswith("inventoryimages") or not base.endswith(".xml"):
                        continue
                    try:
                        _parse_xml_bytes(
                            (bundle_zip.relative_to(dst_root).as_posix() + ":" + name),
                            zf.read(name),
                        )
                    except Exception:
                        continue
        except Exception:
            pass

    if img_dir.is_dir():
        for p in sorted(img_dir.glob("inventoryimages*.xml")):
            try:
                _parse_xml_bytes(p.relative_to(dst_root).as_posix(), p.read_bytes())
            except Exception:
                continue

    return icons, xmls


def _scan_data_dir(
    dst_root: Path,
    *,
    include_files: bool = False,
    max_files: int = 0,
) -> Dict[str, Any]:
    data_dir = dst_root / "data"
    if not data_dir.is_dir():
        return {}

    top_dirs: Dict[str, Dict[str, int]] = defaultdict(lambda: {"files": 0, "bytes": 0})
    ext_counts: Dict[str, Dict[str, int]] = defaultdict(lambda: {"files": 0, "bytes": 0})
    file_list: List[Dict[str, Any]] = []
    total_files = 0
    total_bytes = 0

    for root, _, files in os.walk(data_dir):
        for name in files:
            full = Path(root) / name
            try:
                st = full.stat()
            except Exception:
                continue
            size = int(st.st_size)
            rel = full.relative_to(data_dir).as_posix()
            total_files += 1
            total_bytes += size

            parts = rel.split("/")
            top = parts[0] if parts else "[root]"
            top_dirs[top]["files"] += 1
            top_dirs[top]["bytes"] += size

            ext = Path(name).suffix.lower() or "<no_ext>"
            ext_counts[ext]["files"] += 1
            ext_counts[ext]["bytes"] += size

            if include_files:
                file_list.append(
                    {
                        "path": rel,
                        "bytes": size,
                        "ext": ext,
                        "dir": top,
                    }
                )

    top_dirs_list = [{"dir": k, "files": v["files"], "bytes": v["bytes"]} for k, v in top_dirs.items()]
    top_dirs_list.sort(key=lambda x: x["files"], reverse=True)

    ext_list = [{"ext": k, "files": v["files"], "bytes": v["bytes"]} for k, v in ext_counts.items()]
    ext_list.sort(key=lambda x: x["files"], reverse=True)

    if include_files:
        file_list.sort(key=lambda x: x["path"])
        if max_files and len(file_list) > max_files:
            file_list = file_list[:max_files]

    return {
        "total_files": total_files,
        "total_bytes": total_bytes,
        "top_dirs": top_dirs_list,
        "top_exts": ext_list,
        "files": file_list if include_files else None,
    }


def _scan_bundles(
    dst_root: Path,
    *,
    include_entries: bool = False,
    max_entries: int = 0,
) -> List[Dict[str, Any]]:
    bundles_dir = dst_root / "data" / "databundles"
    if not bundles_dir.is_dir():
        return []

    out: List[Dict[str, Any]] = []
    for zp in sorted(bundles_dir.glob("*.zip")):
        try:
            with zipfile.ZipFile(zp, "r") as zf:
                infos = zf.infolist()
                total_bytes = sum(i.file_size for i in infos)
                entries = None
                if include_entries:
                    entries = [{"path": i.filename, "bytes": int(i.file_size)} for i in infos]
                    if max_entries and len(entries) > max_entries:
                        entries = entries[:max_entries]
                out.append({"file": zp.name, "entries": len(infos), "bytes": total_bytes, "files": entries})
        except Exception:
            out.append({"file": zp.name, "entries": -1, "bytes": -1, "files": None})
    return out


def build_resource_index(
    *,
    engine: Any,
    dst_root: Path,
    include_data_files: bool = False,
    max_data_files: int = 0,
    include_bundle_files: bool = False,
    max_bundle_files: int = 0,
) -> Dict[str, Any]:
    files = list(getattr(engine, "file_list", []) or [])
    scripts = _scan_scripts(files)
    prefabs = _scan_prefabs(engine)
    icons, icon_sources = _scan_inventory_icons(dst_root)
    data_scan = _scan_data_dir(dst_root, include_files=include_data_files, max_files=max_data_files)
    bundle_scan = _scan_bundles(dst_root, include_entries=include_bundle_files, max_entries=max_bundle_files)

    meta = build_meta(
        schema=SCHEMA_VERSION,
        tool="build_resource_index",
        sources={
            "dst_root": str(dst_root),
            "scripts_zip": getattr(getattr(engine, "source", None), "filename", None),
            "scripts_dir": getattr(engine, "source", None) if getattr(engine, "mode", "") == "folder" else None,
        },
        extra={
            "engine_mode": getattr(engine, "mode", ""),
            "scripts_file_count": len(files),
            "dst_root": str(dst_root),
            "scripts_zip": getattr(getattr(engine, "source", None), "filename", None),
            "scripts_dir": getattr(engine, "source", None) if getattr(engine, "mode", "") == "folder" else None,
        },
    )

    if data_scan:
        meta["data_file_count"] = data_scan.get("total_files")
        meta["data_total_bytes"] = data_scan.get("total_bytes")

    return {
        "schema_version": SCHEMA_VERSION,
        "meta": meta,
        "scripts": scripts,
        "prefabs": prefabs,
        "assets": {
            "inventory_icons": sorted(icons),
            "inventory_atlases": icon_sources,
        },
        "data": data_scan,
        "bundles": bundle_scan,
    }


def render_resource_index_summary(index: Dict[str, Any]) -> str:
    meta = index.get("meta") or {}
    scripts = index.get("scripts") or {}
    prefabs = index.get("prefabs") or {}
    assets = index.get("assets") or {}
    data = index.get("data") or {}
    bundles = index.get("bundles") or []

    lines: List[str] = []
    lines.append("# Wagstaff Resource Index Summary")
    lines.append("")
    lines.append("## Meta")
    lines.append("```yaml")
    lines.append(f"generated: {meta.get('generated')}")
    lines.append(f"dst_root: {meta.get('dst_root')}")
    lines.append(f"engine_mode: {meta.get('engine_mode')}")
    if meta.get("scripts_zip"):
        lines.append(f"scripts_zip: {meta.get('scripts_zip')}")
    if meta.get("scripts_dir"):
        lines.append(f"scripts_dir: {meta.get('scripts_dir')}")
    lines.append(f"scripts_file_count: {meta.get('scripts_file_count')}")
    if meta.get("data_file_count") is not None:
        lines.append(f"data_file_count: {meta.get('data_file_count')}")
    if meta.get("data_total_bytes") is not None:
        lines.append(f"data_total_bytes: {meta.get('data_total_bytes')}")
    lines.append("```")

    lines.append("")
    lines.append("## Scripts")
    lines.append("")
    lines.append("```yaml")
    lines.append(f"total_files: {scripts.get('total_files')}")
    lines.append(f"lua_files: {scripts.get('lua_files')}")
    lines.append("```")

    lines.append("")
    lines.append("### Script Categories")
    lines.append("")
    lines.append("| Category | Count |")
    lines.append("|---|---:|")
    for k, v in sorted((scripts.get("categories") or {}).items(), key=lambda x: x[0]):
        lines.append(f"| {k} | {v} |")

    lines.append("")
    lines.append("## Prefabs")
    lines.append("")
    lines.append("```yaml")
    lines.append(f"prefab_files: {prefabs.get('total_files')}")
    lines.append(f"prefabs_total: {prefabs.get('total_prefabs')}")
    lines.append(f"prefabs_skipped: {prefabs.get('prefabs_skipped')}")
    lines.append("```")

    lines.append("")
    lines.append("## Assets")
    lines.append("")
    lines.append("```yaml")
    lines.append(f"inventory_icons: {len(assets.get('inventory_icons') or [])}")
    lines.append(f"inventory_atlases: {len(assets.get('inventory_atlases') or [])}")
    lines.append("```")

    if data:
        lines.append("")
        lines.append("## Data Summary")
        lines.append("")
        lines.append("```yaml")
        lines.append(f"total_files: {data.get('total_files')}")
        lines.append(f"total_bytes: {data.get('total_bytes')}")
        lines.append("```")

    if bundles:
        lines.append("")
        lines.append("## Bundles")
        lines.append("")
        lines.append("| Bundle | Entries | Bytes |")
        lines.append("|---|---:|---:|")
        for row in bundles:
            lines.append(f"| {row.get('file')} | {row.get('entries')} | {row.get('bytes')} |")

    return "\n".join(lines) + "\n"
```

### File: core/indexers/shared.py
- mode: full
- size_bytes: 2072
- sha256_12: a6599a86dc03

```py
# -*- coding: utf-8 -*-
"""Shared helpers for indexers and scans."""

from __future__ import annotations

import hashlib
import re
from pathlib import Path
from typing import Any, Dict, Optional

from core.analyzer import find_matching, parse_lua_table


_ID_RE = re.compile(r"^[a-z0-9_]+$")


def _sha256_12_file(path: Path, chunk_size: int = 1024 * 1024) -> Optional[str]:
    try:
        h = hashlib.sha256()
        with path.open("rb") as f:
            while True:
                chunk = f.read(chunk_size)
                if not chunk:
                    break
                h.update(chunk)
        return h.hexdigest()[:12]
    except Exception:
        return None


def _is_simple_id(s: str) -> bool:
    return bool(s) and bool(_ID_RE.match(s))


def _extract_strings_names(engine: Any) -> Dict[str, str]:
    """Extract STRINGS.NAMES mapping from scripts/strings.lua."""
    src = (
        engine.read_file("scripts/strings.lua")
        or engine.read_file("strings.lua")
        or ""
    )
    if not src:
        return {}

    m = re.search(r"\bSTRINGS\s*=\s*\{", src)
    if not m:
        return {}
    strings_open = src.find("{", m.end() - 1)
    if strings_open < 0:
        return {}
    strings_close = find_matching(src, strings_open, "{", "}")
    if strings_close is None:
        return {}

    block = src[strings_open: strings_close + 1]
    m2 = re.search(r"(?<![A-Za-z0-9_])NAMES\s*=\s*\{", block)
    if not m2:
        return {}

    names_open = strings_open + m2.end() - 1
    names_close = find_matching(src, names_open, "{", "}")
    if names_close is None:
        return {}

    inner = src[names_open + 1 : names_close]
    try:
        names_tbl = parse_lua_table(inner)
    except Exception:
        return {}

    out: Dict[str, str] = {}
    for k, v in (names_tbl.map or {}).items():
        if not isinstance(k, str):
            continue
        if not isinstance(v, str):
            continue
        kid = k.strip().lower()
        if not _is_simple_id(kid):
            continue
        out[kid] = v
    return out
```

### File: core/klei_atlas_tex.py
- mode: full
- size_bytes: 17536
- sha256_12: 14b3a7105299

```py
# -*- coding: utf-8 -*-
"""klei_atlas_tex.py

A small, self-contained parser for:
- Klei atlas XML files (e.g. images/inventoryimages.xml)
- Klei TEX (KTEX) texture files (e.g. images/inventoryimages.tex)

Primary goal
- Extract a named atlas element (e.g. "armor_wood.tex") into a normal PNG.

Important correctness notes
- Klei atlas v coordinates count *up from the bottom* (v=0 is bottom).
  This is a common gotcha in DST modding discussions.
- TEX files are commonly stored with premultiplied alpha. For inventory/craft
  icons, unpremultiplying the cropped icon usually produces the expected
  appearance.

This module intentionally has no Wagstaff-specific imports.
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple

import struct
import xml.etree.ElementTree as ET

from PIL import Image


# -----------------------------
# Atlas XML
# -----------------------------


@dataclass(frozen=True)
class AtlasElement:
    name: str
    u1: float
    u2: float
    v1: float
    v2: float


@dataclass(frozen=True)
class Atlas:
    """Parsed atlas XML."""

    texture_filename: str
    elements: Dict[str, AtlasElement]

    def get(self, name: str) -> Optional[AtlasElement]:
        if not name:
            return None
        return self.elements.get(name)


def _xml_find_first(root: ET.Element, tag_local_name: str) -> Optional[ET.Element]:
    # Namespace-tolerant lookup
    return root.find(f".//{{*}}{tag_local_name}")


def _xml_find_all(root: ET.Element, tag_local_name: str) -> List[ET.Element]:
    return list(root.findall(f".//{{*}}{tag_local_name}"))


def parse_atlas_xml(xml_text: str) -> Atlas:
    """Parse a Klei atlas XML into an Atlas object."""

    root = ET.fromstring(xml_text)

    tex_node = _xml_find_first(root, "Texture")
    tex_filename = (tex_node.get("filename") if tex_node is not None else None) or ""

    elements: Dict[str, AtlasElement] = {}
    for el in _xml_find_all(root, "Element"):
        name = (el.get("name") or "").strip()
        if not name:
            continue
        try:
            u1 = float(el.get("u1") or "0")
            u2 = float(el.get("u2") or "0")
            v1 = float(el.get("v1") or "0")
            v2 = float(el.get("v2") or "0")
        except Exception:
            continue

        elements[name] = AtlasElement(name=name, u1=u1, u2=u2, v1=v1, v2=v2)

    return Atlas(texture_filename=tex_filename, elements=elements)


def atlas_uv_to_box(
    elem: AtlasElement,
    tex_w: int,
    tex_h: int,
    *,
    invert_v: bool = True,
) -> Tuple[int, int, int, int]:
    """Convert atlas UVs into a PIL crop box (left, top, right, bottom).

    Atlas coordinates:
      - u: 0..1 left->right
      - v: 0..1 top->bottom (for DST inventory atlases); some atlases use bottom-origin.

    PIL image coordinates:
      - (0,0) is top-left
    """

    x1 = int(round(elem.u1 * tex_w))
    x2 = int(round(elem.u2 * tex_w))

    if invert_v:
        y1_from_bottom = int(round(elem.v1 * tex_h))
        y2_from_bottom = int(round(elem.v2 * tex_h))
        top = tex_h - y2_from_bottom
        bottom = tex_h - y1_from_bottom
    else:
        y1 = int(round(elem.v1 * tex_h))
        y2 = int(round(elem.v2 * tex_h))
        top = min(y1, y2)
        bottom = max(y1, y2)

    # Normalize / clamp
    left = max(0, min(tex_w, min(x1, x2)))
    right = max(0, min(tex_w, max(x1, x2)))
    top2 = max(0, min(tex_h, min(top, bottom)))
    bottom2 = max(0, min(tex_h, max(top, bottom)))

    return left, top2, right, bottom2


# -----------------------------
# KTEX (Klei TEX)
# -----------------------------


class KTexError(RuntimeError):
    pass


@dataclass(frozen=True)
class KTexMipmap:
    width: int
    height: int
    pitch: int
    data_size: int
    data_offset: int


def _parse_ktex_variant(data: bytes, *, variant: str) -> Optional[Tuple[List[KTexMipmap], int]]:
    """Try parsing KTEX mipmap table.

    Returns:
      (mipmaps, end_offset) or None
    """

    if len(data) < 8:
        return None

    if data[:4] != b"KTEX":
        return None

    specs = struct.unpack_from("<I", data, 4)[0]

    if variant == "pre":
        mipmap_count = (specs >> 9) & 0xF
    elif variant == "post":
        mipmap_count = (specs >> 13) & 0x1F
    else:
        raise ValueError(f"unknown variant: {variant}")

    if mipmap_count <= 0:
        return None

    off = 8
    mips_meta: List[Tuple[int, int, int, int]] = []
    for _ in range(mipmap_count):
        if off + 10 > len(data):
            return None
        w, h, pitch, size = struct.unpack_from("<HHHI", data, off)
        off += 10
        if w <= 0 or h <= 0 or size <= 0:
            return None
        mips_meta.append((int(w), int(h), int(pitch), int(size)))

    data_off = off
    mips: List[KTexMipmap] = []
    for (w, h, pitch, size) in mips_meta:
        if data_off + size > len(data):
            return None
        mips.append(KTexMipmap(width=w, height=h, pitch=pitch, data_size=size, data_offset=data_off))
        data_off += size

    return mips, data_off


def parse_ktex(data: bytes) -> List[KTexMipmap]:
    """Parse a KTEX file and return mipmap descriptors.

    The KTEX header has two known variants (pre-caves-update and post-caves-update)
    which differ only in how the bitfield encodes mipmap_count.

    We attempt both and pick the one that yields the most plausible layout.

    Source for header bitfield layouts:
      - Stexatlaser project README (KTEX format section)
    """

    if len(data) < 8 or data[:4] != b"KTEX":
        raise KTexError("Not a KTEX file")

    candidates: List[Tuple[int, str, List[KTexMipmap], int]] = []
    for variant in ("post", "pre"):
        res = _parse_ktex_variant(data, variant=variant)
        if not res:
            continue
        mips, end_off = res
        # score: prefer layouts that consume most bytes (small remainder)
        remainder = abs(len(data) - end_off)
        candidates.append((remainder, variant, mips, end_off))

    if not candidates:
        raise KTexError("Failed to parse KTEX mipmap table")

    candidates.sort(key=lambda x: (x[0], 0 if x[1] == "post" else 1))
    _, _, mips, _ = candidates[0]
    return mips


def _infer_tex_payload_format(width: int, height: int, data_size: int, pitch: int) -> str:
    """Infer payload format from (w,h,data_size,pitch).

    Returns one of: "RGBA", "RGB", "DXT1", "DXT5".

    Many DST textures are DXT5.
    """

    w = int(width)
    h = int(height)
    if w <= 0 or h <= 0 or data_size <= 0:
        return ""

    rgba_size = w * h * 4
    rgb_size = w * h * 3

    blocks_w = (w + 3) // 4
    blocks_h = (h + 3) // 4
    dxt1_size = blocks_w * blocks_h * 8
    dxt5_size = blocks_w * blocks_h * 16

    # Exact matches first
    if data_size == rgba_size:
        return "RGBA"
    if data_size == rgb_size:
        return "RGB"
    if data_size == dxt1_size:
        return "DXT1"
    if data_size == dxt5_size:
        return "DXT5"

    # Heuristic via pitch
    if pitch in (w * 4, (w * 4) + 2):
        return "RGBA"
    if pitch in (w * 3, (w * 3) + 2):
        return "RGB"
    if pitch == blocks_w * 8 and data_size <= dxt1_size:
        return "DXT1"
    if pitch == blocks_w * 16 and data_size <= dxt5_size:
        return "DXT5"

    return ""


def _rgb565_to_rgb888(c: int) -> Tuple[int, int, int]:
    r = ((c >> 11) & 0x1F) * 255 // 31
    g = ((c >> 5) & 0x3F) * 255 // 63
    b = (c & 0x1F) * 255 // 31
    return int(r), int(g), int(b)


def _decompress_dxt1(payload: bytes, width: int, height: int) -> bytes:
    """Decompress DXT1 blocks into RGBA8888 bytes."""

    w = int(width)
    h = int(height)
    blocks_w = (w + 3) // 4
    blocks_h = (h + 3) // 4

    out = bytearray(w * h * 4)
    off = 0

    for by in range(blocks_h):
        for bx in range(blocks_w):
            if off + 8 > len(payload):
                raise KTexError("DXT1 payload truncated")

            c0, c1 = struct.unpack_from("<HH", payload, off)
            bits = struct.unpack_from("<I", payload, off + 4)[0]
            off += 8

            r0, g0, b0 = _rgb565_to_rgb888(c0)
            r1, g1, b1 = _rgb565_to_rgb888(c1)

            colors = [
                (r0, g0, b0, 255),
                (r1, g1, b1, 255),
            ]

            if c0 > c1:
                colors.append(((2 * r0 + r1) // 3, (2 * g0 + g1) // 3, (2 * b0 + b1) // 3, 255))
                colors.append(((r0 + 2 * r1) // 3, (g0 + 2 * g1) // 3, (b0 + 2 * b1) // 3, 255))
            else:
                colors.append(((r0 + r1) // 2, (g0 + g1) // 2, (b0 + b1) // 2, 255))
                colors.append((0, 0, 0, 0))

            # Indices: 2 bits each, little-endian, row-major
            idx_bits = bits
            for py in range(4):
                for px in range(4):
                    idx = idx_bits & 0x3
                    idx_bits >>= 2

                    x = bx * 4 + px
                    y = by * 4 + py
                    if x >= w or y >= h:
                        continue

                    o = (y * w + x) * 4
                    r, g, b, a = colors[idx]
                    out[o + 0] = r
                    out[o + 1] = g
                    out[o + 2] = b
                    out[o + 3] = a

    return bytes(out)


def _decompress_dxt5(payload: bytes, width: int, height: int) -> bytes:
    """Decompress DXT5 blocks into RGBA8888 bytes."""

    w = int(width)
    h = int(height)
    blocks_w = (w + 3) // 4
    blocks_h = (h + 3) // 4

    out = bytearray(w * h * 4)
    off = 0

    for by in range(blocks_h):
        for bx in range(blocks_w):
            if off + 16 > len(payload):
                raise KTexError("DXT5 payload truncated")

            a0 = payload[off]
            a1 = payload[off + 1]
            alpha_bits = int.from_bytes(payload[off + 2 : off + 8], "little")

            # Alpha palette
            alphas = [0] * 8
            alphas[0] = a0
            alphas[1] = a1
            if a0 > a1:
                # 6 interpolated values
                alphas[2] = (6 * a0 + 1 * a1) // 7
                alphas[3] = (5 * a0 + 2 * a1) // 7
                alphas[4] = (4 * a0 + 3 * a1) // 7
                alphas[5] = (3 * a0 + 4 * a1) // 7
                alphas[6] = (2 * a0 + 5 * a1) // 7
                alphas[7] = (1 * a0 + 6 * a1) // 7
            else:
                # 4 interpolated, then 0 and 255
                alphas[2] = (4 * a0 + 1 * a1) // 5
                alphas[3] = (3 * a0 + 2 * a1) // 5
                alphas[4] = (2 * a0 + 3 * a1) // 5
                alphas[5] = (1 * a0 + 4 * a1) // 5
                alphas[6] = 0
                alphas[7] = 255

            # Color block (DXT1-style)
            c0, c1 = struct.unpack_from("<HH", payload, off + 8)
            color_bits = struct.unpack_from("<I", payload, off + 12)[0]

            r0, g0, b0 = _rgb565_to_rgb888(c0)
            r1, g1, b1 = _rgb565_to_rgb888(c1)

            # In DXT5, colors are always 4-color interpolations (alpha is separate)
            colors = [
                (r0, g0, b0),
                (r1, g1, b1),
                ((2 * r0 + r1) // 3, (2 * g0 + g1) // 3, (2 * b0 + b1) // 3),
                ((r0 + 2 * r1) // 3, (g0 + 2 * g1) // 3, (b0 + 2 * b1) // 3),
            ]

            off += 16

            a_bits = alpha_bits
            c_bits = color_bits
            for py in range(4):
                for px in range(4):
                    a_idx = a_bits & 0x7
                    a_bits >>= 3

                    c_idx = c_bits & 0x3
                    c_bits >>= 2

                    x = bx * 4 + px
                    y = by * 4 + py
                    if x >= w or y >= h:
                        continue

                    r, g, b = colors[c_idx]
                    a = alphas[a_idx]

                    o = (y * w + x) * 4
                    out[o + 0] = r
                    out[o + 1] = g
                    out[o + 2] = b
                    out[o + 3] = a

    return bytes(out)


def decode_ktex_to_image(tex_bytes: bytes) -> Image.Image:
    """Decode KTEX to a PIL RGBA image using mipmap level 0."""

    mips = parse_ktex(tex_bytes)
    mip0 = mips[0]

    payload = tex_bytes[mip0.data_offset : mip0.data_offset + mip0.data_size]
    fmt = _infer_tex_payload_format(mip0.width, mip0.height, mip0.data_size, mip0.pitch)
    if not fmt:
        raise KTexError(
            f"Unsupported/unknown TEX payload format (w={mip0.width}, h={mip0.height}, size={mip0.data_size}, pitch={mip0.pitch})"
        )

    if fmt == "RGBA":
        rgba = payload
        if len(rgba) < mip0.width * mip0.height * 4:
            raise KTexError("RGBA payload truncated")
        rgba = rgba[: mip0.width * mip0.height * 4]
    elif fmt == "RGB":
        if len(payload) < mip0.width * mip0.height * 3:
            raise KTexError("RGB payload truncated")
        rgb = payload[: mip0.width * mip0.height * 3]
        # expand to RGBA
        out = bytearray(mip0.width * mip0.height * 4)
        j = 0
        for i in range(0, len(rgb), 3):
            out[j + 0] = rgb[i + 0]
            out[j + 1] = rgb[i + 1]
            out[j + 2] = rgb[i + 2]
            out[j + 3] = 255
            j += 4
        rgba = bytes(out)
    elif fmt == "DXT1":
        rgba = _decompress_dxt1(payload, mip0.width, mip0.height)
    else:
        rgba = _decompress_dxt5(payload, mip0.width, mip0.height)

    return Image.frombytes("RGBA", (mip0.width, mip0.height), rgba)


# -----------------------------
# Extraction helpers
# -----------------------------


def unpremultiply_alpha_rgba(img: Image.Image) -> Image.Image:
    """Return a new image with straight (unpremultiplied) alpha.

    This is applied *after* cropping for performance (icons are small).
    """

    if img.mode != "RGBA":
        img = img.convert("RGBA")

    raw = bytearray(img.tobytes())
    for i in range(0, len(raw), 4):
        a = raw[i + 3]
        if a == 0 or a == 255:
            continue
        # Avoid rounding to >255
        raw[i + 0] = min(255, (raw[i + 0] * 255) // a)
        raw[i + 1] = min(255, (raw[i + 1] * 255) // a)
        raw[i + 2] = min(255, (raw[i + 2] * 255) // a)

    return Image.frombytes("RGBA", img.size, bytes(raw))


def fix_ktex_orientation(img: Image.Image) -> Image.Image:
    """Fix KTEX orientation for UI output."""

    try:
        return img.transpose(Image.FLIP_TOP_BOTTOM)
    except Exception:
        return img


def extract_atlas_element(
    atlas: Atlas,
    tex_image: Image.Image,
    element_name: str,
    *,
    unpremultiply: bool = True,
    invert_v: bool = True,
) -> Optional[Image.Image]:
    """Crop a named element from an atlas texture image."""

    el = atlas.get(element_name)
    if not el:
        return None

    w, h = tex_image.size
    left, top, right, bottom = atlas_uv_to_box(el, w, h, invert_v=invert_v)
    if right <= left or bottom <= top:
        return None

    cropped = tex_image.crop((left, top, right, bottom))
    cropped = fix_ktex_orientation(cropped)
    if unpremultiply:
        try:
            cropped = unpremultiply_alpha_rgba(cropped)
        except Exception:
            # If anything goes wrong, still return the cropped image.
            pass
    return cropped


def resolve_tex_path_from_atlas(xml_path: Path, atlas: Atlas) -> Optional[Path]:
    """Resolve the atlas <Texture filename="..."> into a filesystem path."""

    fn = (atlas.texture_filename or "").strip()
    if not fn:
        # Common fallback: same basename as xml
        return xml_path.with_suffix(".tex")

    # If XML stores full-ish path, try as-is relative to xml parent.
    p = Path(fn)
    if p.is_absolute():
        return p

    return (xml_path.parent / p).resolve()


def write_element_png(
    *,
    atlas_xml_path: Path,
    tex_path: Path,
    element_name: str,
    out_png_path: Path,
    unpremultiply: bool = True,
    overwrite: bool = False,
) -> bool:
    """Extract one element and write a PNG.

    Returns True on success.
    """

    if out_png_path.exists() and not overwrite:
        return True

    xml_text = atlas_xml_path.read_text(encoding="utf-8", errors="ignore")
    atlas = parse_atlas_xml(xml_text)

    tex_bytes = tex_path.read_bytes()
    tex_image = decode_ktex_to_image(tex_bytes)

    cropped = extract_atlas_element(atlas, tex_image, element_name, unpremultiply=unpremultiply)
    if cropped is None:
        return False

    out_png_path.parent.mkdir(parents=True, exist_ok=True)
    cropped.save(out_png_path, format="PNG")
    return True


def pick_first_existing(names: Iterable[str], available: Dict[str, AtlasElement]) -> Optional[str]:
    for n in names:
        if not n:
            continue
        if n in available:
            return n
    return None


# =========================================================
# PNG writer helper (added by hotfix)
# =========================================================

def write_png(img, out_path):
    '''Write a PIL Image to PNG, ensuring parent directories exist.

    This is intentionally tiny and dependency-light (relies on Pillow already
    used by the atlas/tex pipeline).
    '''
    from pathlib import Path

    p = Path(out_path)
    p.parent.mkdir(parents=True, exist_ok=True)

    # Ensure RGBA to avoid mode issues on some Pillow builds
    try:
        img.save(str(p), format="PNG")
    except Exception:
        img.convert("RGBA").save(str(p), format="PNG")
```

### File: core/schemas/__init__.py
- mode: full
- size_bytes: 47
- sha256_12: 54ea79a6fc22

```py
# -*- coding: utf-8 -*-
"""Schemas package."""
```

### File: core/schemas/catalog_v2.py
- mode: full
- size_bytes: 824
- sha256_12: 1dc18eed6fb8

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Catalog v2 data model."""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict


@dataclass
class WagstaffCatalogV2:
    schema_version: int
    meta: Dict[str, Any]
    items: Dict[str, Any]
    assets: Dict[str, Any]
    craft: Dict[str, Any]
    cooking: Dict[str, Any]
    cooking_ingredients: Dict[str, Any]
    stats: Dict[str, Any]

    def to_dict(self) -> Dict[str, Any]:
        return {
            "schema_version": int(self.schema_version),
            "meta": self.meta,
            "items": self.items,
            "assets": self.assets,
            "craft": self.craft,
            "cooking": self.cooking,
            "cooking_ingredients": self.cooking_ingredients,
            "stats": self.stats,
        }
```

### File: core/schemas/meta.py
- mode: full
- size_bytes: 697
- sha256_12: c48fab200453

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Shared metadata helpers for index artifacts."""

from __future__ import annotations

from datetime import datetime
from typing import Any, Dict, Optional


def now_iso() -> str:
    return datetime.now().astimezone().isoformat(timespec="seconds")


def build_meta(
    *,
    schema: int,
    tool: str,
    sources: Optional[Dict[str, Any]] = None,
    extra: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    meta: Dict[str, Any] = {
        "schema": int(schema),
        "generated": now_iso(),
        "tool": str(tool),
    }
    if sources:
        meta["sources"] = sources
    if extra:
        meta.update(extra)
    return meta
```

### File: core/tagging.py
- mode: full
- size_bytes: 5775
- sha256_12: 9c009d2318ee

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Tag inference and overrides for catalog v2."""

from __future__ import annotations

from dataclasses import dataclass, field
from fnmatch import fnmatchcase
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Set


KIND_ORDER = ["character", "creature", "structure", "plant", "item", "fx", "unknown"]

CREATURE_TAGS = {
    "monster",
    "animal",
    "smallcreature",
    "largecreature",
    "epic",
    "hostile",
    "bird",
    "animal",
    "scarytoprey",
}

PLANT_TAGS = {"plant", "tree", "crop", "flower", "berrybush", "mushroom"}

STRUCTURE_TAGS = {"structure", "wall", "house", "ruins"}

FX_TAGS = {"fx", "noclick", "notarget"}


COMP_BEHAVIORS = {
    "equippable": "equippable",
    "edible": "edible",
    "stackable": "stackable",
    "burnable": "burnable",
    "perishable": "perishable",
    "repairable": "repairable",
    "fuel": "fuel",
    "tradable": "tradable",
    "hauntable": "hauntable",
    "deployable": "deployable",
}

COMP_CATEGORIES = {
    "weapon": "weapon",
    "armor": "armor",
    "edible": "food",
    "container": "container",
    "inventory": "container",
    "light": "light",
    "fueled": "light",
    "deployable": "deployable",
    "trap": "trap",
    "boat": "boat",
    "farmplanttendable": "farm",
    "tool": "tool",
}

TAG_CATEGORIES = {
    "weapon": "weapon",
    "armor": "armor",
    "food": "food",
    "cookable": "food",
    "magic": "magic",
    "container": "container",
    "boat": "boat",
    "decor": "decor",
    "toy": "toy",
    "cattoy": "toy",
    "light": "light",
    "deploykititem": "deployable",
}


@dataclass
class TagProfile:
    kind: str = "unknown"
    categories: Set[str] = field(default_factory=set)
    behaviors: Set[str] = field(default_factory=set)
    sources: Set[str] = field(default_factory=set)
    slots: Set[str] = field(default_factory=set)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "kind": self.kind,
            "categories": sorted(self.categories),
            "behaviors": sorted(self.behaviors),
            "sources": sorted(self.sources),
            "slots": sorted(self.slots),
        }


def _pick_kind(kind: str, tags: Set[str], components: Set[str]) -> str:
    if "character" in tags:
        return "character"
    if tags & CREATURE_TAGS or {"brain", "health", "combat"} <= components:
        return "creature"
    if tags & STRUCTURE_TAGS:
        return "structure"
    if tags & PLANT_TAGS or "pickable" in components or "crop" in components:
        return "plant"
    if tags & FX_TAGS:
        return "fx"
    if "inventoryitem" in components:
        return "item"
    return kind or "unknown"


def infer_tags(
    *,
    components: Iterable[str],
    tags: Iterable[str],
    sources: Iterable[str],
    kind_hint: Optional[str] = None,
) -> TagProfile:
    comps = {str(c).lower() for c in components if c}
    tgs = {str(t).lower() for t in tags if t}
    srcs = {str(s).lower() for s in sources if s}

    profile = TagProfile(kind=kind_hint or "unknown")
    profile.kind = _pick_kind(profile.kind, tgs, comps)

    for c in comps:
        beh = COMP_BEHAVIORS.get(c)
        if beh:
            profile.behaviors.add(beh)
        cat = COMP_CATEGORIES.get(c)
        if cat:
            profile.categories.add(cat)

    for t in tgs:
        cat = TAG_CATEGORIES.get(t)
        if cat:
            profile.categories.add(cat)

    if profile.kind == "item" and "food" in profile.categories and "edible" not in profile.behaviors:
        profile.categories.add("resource")

    profile.sources.update(srcs)
    return profile


def load_tag_overrides(path: Optional[str]) -> List[Dict[str, Any]]:
    if not path:
        return []
    try:
        import json

        data = json.loads(Path(path).read_text(encoding="utf-8"))
        rules = data.get("rules") or []
        return [r for r in rules if isinstance(r, dict)]
    except Exception:
        return []


def _apply_field(
    profile: TagProfile,
    field: str,
    *,
    add: Optional[Iterable[str]] = None,
    remove: Optional[Iterable[str]] = None,
    set_to: Optional[Iterable[str]] = None,
) -> None:
    if field == "kind":
        if set_to:
            profile.kind = str(list(set_to)[0])
        return

    target: Set[str]
    if field == "categories":
        target = profile.categories
    elif field == "behaviors":
        target = profile.behaviors
    elif field == "sources":
        target = profile.sources
    elif field == "slots":
        target = profile.slots
    else:
        return

    if set_to is not None:
        target.clear()
        for x in set_to:
            if x:
                target.add(str(x))
    if add:
        for x in add:
            if x:
                target.add(str(x))
    if remove:
        for x in remove:
            if x:
                target.discard(str(x))


def apply_overrides(item_id: str, profile: TagProfile, rules: List[Dict[str, Any]]) -> TagProfile:
    if not rules:
        return profile

    iid = str(item_id or "").strip()
    if not iid:
        return profile

    for rule in rules:
        pat = str(rule.get("match") or "").strip()
        if not pat:
            continue
        if pat != iid and not fnmatchcase(iid, pat):
            continue

        add = rule.get("add") or {}
        remove = rule.get("remove") or {}
        set_to = rule.get("set") or {}

        for field in ("kind", "categories", "behaviors", "sources", "slots"):
            _apply_field(
                profile,
                field,
                add=add.get(field),
                remove=remove.get(field),
                set_to=set_to.get(field),
            )
        break

    return profile
```

### File: core/utils.py
- mode: full
- size_bytes: 1041
- sha256_12: d7d80440b8ab

```py
import configparser
import os
from pathlib import Path

class ConfigLoader:
    def __init__(self):
        # 自动定位项目根目录 (假设 utils.py 在 core/ 下)
        self.project_root = Path(__file__).resolve().parent.parent
        self.config_path = self.project_root / "conf" / "settings.ini"
        
        self.config = configparser.ConfigParser()
        if not self.config_path.exists():
            raise FileNotFoundError(f"❌ 配置文件丢失: {self.config_path}")
        
        self.config.read(self.config_path)

    def get(self, section, key):
        """获取配置值并自动展开用户路径 (~)"""
        val = self.config.get(section, key, fallback=None)
        if val and "~" in val:
            return os.path.expanduser(val)
        return val

# 单例模式：直接导出的实例
wagstaff_config = ConfigLoader()

# === 测试代码 ===
if __name__ == "__main__":
    print(f"Project Root: {wagstaff_config.project_root}")
    print(f"DST Path: {wagstaff_config.get('PATHS', 'DST_ROOT')}")
```

### File: devtools/snapshot.py
- mode: full
- size_bytes: 51404
- sha256_12: 6411307db9d8

```py
#!/usr/bin/env python3
"""Wagstaff-Lab Snapshot (v4.4)

Goal:
- Provide LLM-friendly snapshots by default.
- Provide two primary modes:
  - llm: LLM-friendly snapshot (project overview + core/apps full + non-core interfaces/head)
  - archive: archival snapshot (full content as much as possible + optional zip bundle)
- Provide custom templates via JSON config (growth-friendly).

Default behavior:
- `wagstaff snap` => llm template (LLM-friendly) => writes project_context.txt
- Use --focus to narrow the snapshot scope (repeatable).
- Use section switches to reduce noise.

Template config:
- Default path: conf/snapshot_templates.json
- See the example template file for schema.
"""

from __future__ import annotations

import argparse
import ast
import copy
import fnmatch
import hashlib
import json
import os
import platform
import re
import subprocess
import sys
import time
import textwrap
import zipfile
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

PROJECT_ROOT = Path(__file__).resolve().parent.parent
DEFAULT_CONFIG = PROJECT_ROOT / "conf" / "snapshot_templates.json"

DEFAULT_IGNORE_DIRS = {
    ".git",
    "__pycache__",
    ".pytest_cache",
    "logs",
    "env",
    "venv",
    ".idea",
    ".vscode",
    "node_modules",
    "dist",
    "build",
}

DEFAULT_IGNORE_FILES = {
    "project_context.txt",
    ".DS_Store",
    "id_rsa",
    "id_ed25519",
    "known_hosts",
}

# Conservative binary-ish extensions we almost never want in an LLM snapshot.
DEFAULT_IGNORE_GLOBS = [
    "data/snapshots/**",
    "**/*.swp",
    "**/*.swo",
    "**/*.tmp",
    "**/*.bak",
    "**/*.log",
    "**/*.zip",
    "**/*.tar",
    "**/*.tar.gz",
    "**/*.gz",
    "**/*.7z",
    "**/*.rar",
    "**/*.png",
    "**/*.jpg",
    "**/*.jpeg",
    "**/*.webp",
    "**/*.pdf",
    "**/*.mp4",
    "**/*.mov",
    "**/*.sqlite",
    "**/*.db",
    "**/.env",
    "**/.env.*",
    "**/*.pem",
    "**/*.key",
]

# Snapshot section switches (can be overridden per template).
DEFAULT_SECTIONS = {
    "config": True,
    "env": True,
    "overview": True,
    "tree": True,
    "inventory": True,
    "contents": True,
    "stats": True,
}

# LLM-friendly defaults (less noise).
LLM_SECTIONS = {
    "config": False,
    "env": True,
    "overview": True,
    "tree": True,
    "inventory": True,
    "contents": True,
    "stats": True,
}

# Minimal built-in templates (used if conf/snapshot_templates.json is missing).
_LLM_TEMPLATE = {
    "desc": "Builtin LLM-friendly template",
    "output": "project_context.txt",
    "redact": True,
    "include_reports": True,
    "hash": "embedded",
    "embed_order": "smart",
    "sections": dict(LLM_SECTIONS),
    "inventory": {"enabled": True, "scope": "included", "limit": 700},
    "pinned": [
        "PROJECT_STATUS.json",
        "README.md",
        "conf/settings.ini",
        "docs/guides/DEV_GUIDE.md",
        "docs/management/ROADMAP.md",
        "apps/cli/main.py",
        "apps/cli/registry.py",
    ],
    "max_file_bytes": 200000,
    "max_total_bytes": 1200000,
    "tree": {"max_depth": 8, "max_entries_per_dir": 250},
    "include_globs": [
        "README.md",
        "PROJECT_STATUS.json",
        ".gitignore",
        "conf/**/*.ini",
        "core/**/*.py",
        "apps/**/*.py",
        "devtools/**/*.py",
        "docs/**/*.md",
        "tests/**/*.py",
        "data/reports/**/*.md",
        "data/samples/**/*",
    ],
    "ignore_files": sorted(DEFAULT_IGNORE_FILES),
    "ignore_globs": list(DEFAULT_IGNORE_GLOBS),
    "rules": [
        {"match": "core/**/*.py", "mode": "full"},
        {"match": "apps/**/*.py", "mode": "full"},
        {"match": "devtools/**/*.py", "mode": "interface"},
        {"match": "docs/**/*.md", "mode": "head", "head_lines": 240},
        {"match": "data/reports/**/*.md", "mode": "head", "head_lines": 260},
        {"match": "**/*", "mode": "skip"},
    ],
}

BUILTIN_TEMPLATES = {
    "llm": _LLM_TEMPLATE,
    "core": copy.deepcopy(_LLM_TEMPLATE),
    "archive": {
        "desc": "Builtin archive template",
        "output": "data/snapshots/archive_{timestamp}.md",
        "make_zip": True,
        "zip_output": "data/snapshots/archive_{timestamp}.zip",
        "redact": True,
        "include_reports": True,
        "hash": "all",
        "embed_order": "path",
        "sections": dict(DEFAULT_SECTIONS),
        "inventory": {"enabled": True, "scope": "all", "limit": 2000},
        "max_file_bytes": 500000,
        "max_total_bytes": 20000000,
        "tree": {"max_depth": 30, "max_entries_per_dir": 1000},
        "include_globs": ["**/*"],
        "ignore_files": sorted(DEFAULT_IGNORE_FILES),
        "ignore_globs": list(DEFAULT_IGNORE_GLOBS),
        "rules": [{"match": "**/*", "mode": "full"}],
    },
}



@dataclass
class FileRecord:
    rel_posix: str
    abs_path: Path
    size_bytes: int
    sha256_12: str
    mode: str

    # Rule-derived knobs (cached per file to avoid repeated rule scans)
    head_lines: int = 200
    per_file_max_bytes: int = 200000

    # Render-time metadata
    rendered_bytes: int = 0
    truncated: bool = False
    note: str = ""
    approx_tokens: int = 0


def _now_ts() -> str:
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def _run_cmd(cmd: str) -> str:
    try:
        return subprocess.check_output(
            cmd,
            shell=True,
            text=True,
            cwd=str(PROJECT_ROOT),
            stderr=subprocess.DEVNULL,
        ).strip()
    except Exception:
        return "Unknown"


def get_system_fingerprint() -> str:
    info = []
    info.append(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    info.append(f"User: {os.getenv('USER', 'Unknown')}")
    info.append(f"Host: {platform.node()} ({platform.system()} {platform.release()})")
    info.append(f"Python: {platform.python_version()} ({sys.executable})")
    try:
        import rich  # type: ignore

        ver = getattr(rich, "__version__", "Installed (ver unknown)")
        info.append(f"Rich Ver: {ver}")
    except Exception:
        info.append("Rich Ver: Not Installed")
    return "\n".join(info)


def get_git_status() -> str:
    if not (PROJECT_ROOT / ".git").exists():
        return "Git: Not a repository"
    branch = _run_cmd("git rev-parse --abbrev-ref HEAD")
    commit = _run_cmd("git rev-parse --short HEAD")
    last_msg = _run_cmd("git log -1 --pretty=%B")
    is_dirty = _run_cmd("git status --porcelain") != ""
    dirty_mark = " [DIRTY]" if is_dirty else " [CLEAN]"
    return f"Branch: {branch}{dirty_mark}\nCommit: {commit}\nMessage: {last_msg}"


def _is_probably_binary(path: Path) -> bool:
    try:
        with open(path, "rb") as f:
            chunk = f.read(2048)
        if b"\x00" in chunk:
            return True
        # Heuristic: if too many non-text bytes, treat as binary.
        text_chars = bytearray({7, 8, 9, 10, 12, 13, 27} | set(range(0x20, 0x100)))
        nontext = chunk.translate(None, text_chars)
        return len(nontext) / max(len(chunk), 1) > 0.30
    except Exception:
        return True


_SECRET_KV_RE = re.compile(
    r"(?i)\b(password|passphrase|token|secret|api[_-]?key|client[_-]?secret|access[_-]?key)\b\s*[:=]\s*([^\n\r]+)"
)


def _redact(text: str) -> str:
    # Block private keys
    text = re.sub(
        r"-----BEGIN [A-Z ]*PRIVATE KEY-----.*?-----END [A-Z ]*PRIVATE KEY-----",
        "-----BEGIN PRIVATE KEY-----
<REDACTED>
-----END PRIVATE KEY-----",
        text,
        flags=re.DOTALL,
    )

    def _kv_sub(m: re.Match) -> str:
        key = m.group(1)
        return f"{key}=<REDACTED>"

    text = _SECRET_KV_RE.sub(_kv_sub, text)
    return text


def _sha256_12(path: Path) -> str:
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(1024 * 256), b""):
            h.update(chunk)
    return h.hexdigest()[:12]

DEFAULT_SHA_CACHE_PATH = PROJECT_ROOT / "data" / "snapshots" / ".snapshot_sha_cache.json"


def _load_sha_cache(cache_path: Path) -> Dict[str, Dict[str, Any]]:
    """Load SHA cache from disk (best-effort)."""
    try:
        if cache_path.exists():
            data = json.loads(cache_path.read_text(encoding="utf-8"))
            if isinstance(data, dict):
                # Ensure nested dicts
                out: Dict[str, Dict[str, Any]] = {}
                for k, v in data.items():
                    if isinstance(k, str) and isinstance(v, dict):
                        out[k] = v
                return out
    except Exception:
        pass
    return {}


def _save_sha_cache(cache_path: Path, cache: Dict[str, Dict[str, Any]]) -> None:
    """Persist SHA cache to disk (best-effort)."""
    try:
        _ensure_parent(cache_path)
        cache_path.write_text(json.dumps(cache, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")
    except Exception:
        # Cache is purely an optimization; ignore failures
        return


def _sha256_12_cached(path: Path, rel_posix: str, cache: Dict[str, Dict[str, Any]]) -> str:
    """Compute sha256_12 with a simple stat-based cache."""
    try:
        st = path.stat()
        mtime_ns = int(getattr(st, "st_mtime_ns", int(st.st_mtime * 1e9)))
        size = int(st.st_size)
    except Exception:
        return "Unknown"

    entry = cache.get(rel_posix)
    if isinstance(entry, dict):
        try:
            if int(entry.get("mtime_ns", -1)) == mtime_ns and int(entry.get("size", -2)) == size:
                val = entry.get("sha256_12")
                if isinstance(val, str) and len(val) == 12:
                    return val
        except Exception:
            pass

    try:
        sha = _sha256_12(path)
    except Exception:
        sha = "Unknown"

    cache[rel_posix] = {"mtime_ns": mtime_ns, "size": size, "sha256_12": sha}
    return sha


def _estimate_tokens(text: str) -> int:
    """Rough token estimate (useful for context-window sizing).

    Heuristic:
    - ASCII chars ~ 1 token / 4 chars
    - Non-ASCII chars ~ 1 token / char (works better for CJK)
    """
    if not text:
        return 0
    n = len(text)
    non_ascii = sum(1 for ch in text if ord(ch) > 127)
    ascii_cnt = n - non_ascii
    # ceil-ish without math import
    return int(non_ascii + (ascii_cnt + 3) // 4)


def _posix_rel(path: Path) -> str:
    return path.relative_to(PROJECT_ROOT).as_posix()


def _match_glob(rel_posix: str, pattern: str) -> bool:
    """Glob matching with stable ** semantics.

    Semantics:
    - If pattern has no '/', treat it as a basename pattern.
    - '**' matches 0..N path segments (unlike pathlib.Path.match which may require >=1).
    - Other segments use fnmatch-style wildcards.
    """
    rel_posix = rel_posix.lstrip("/")
    pattern = str(pattern or "").lstrip("/")

    if not pattern:
        return False

    # Basename-only pattern: match only the filename.
    if "/" not in pattern:
        name = rel_posix.rsplit("/", 1)[-1]
        return fnmatch.fnmatchcase(name, pattern)

    path_parts = rel_posix.split("/") if rel_posix else []
    pat_parts = pattern.split("/") if pattern else []

    def rec(i: int, j: int) -> bool:
        if i == len(pat_parts):
            return j == len(path_parts)

        pat = pat_parts[i]

        if pat == "**":
            # Match zero segments
            if rec(i + 1, j):
                return True
            # Match one segment and keep '**' active
            return j < len(path_parts) and rec(i, j + 1)

        if j >= len(path_parts):
            return False

        if fnmatch.fnmatchcase(path_parts[j], pat):
            return rec(i + 1, j + 1)

        return False

    return rec(0, 0)

def _load_templates(config_path: Path) -> Dict[str, Any]:
    if config_path.exists():
        try:
            data = json.loads(config_path.read_text(encoding="utf-8"))
            if isinstance(data, dict) and isinstance(data.get("templates"), dict):
                return data
        except Exception:
            pass
    # Fallback
    return {
        "version": 1,
        "defaults": {
            "mode_to_template": {
                "llm": "llm",
                "core": "llm",
                "archive": "archive",
                "custom": "llm",
            }
        },
        "templates": BUILTIN_TEMPLATES,
    }


def _resolve_template(templates_doc: Dict[str, Any], mode: str, template_name: Optional[str]) -> Tuple[str, Dict[str, Any]]:
    templates = templates_doc.get("templates", {})
    if template_name:
        if template_name not in templates:
            raise SystemExit(f"Unknown template: {template_name}")
        return template_name, templates[template_name]

    defaults = templates_doc.get("defaults", {}).get("mode_to_template", {})
    picked = defaults.get(mode, mode)
    if picked in templates:
        return picked, templates[picked]

    if mode in templates:
        return mode, templates[mode]

    # Compatibility: allow llm/core aliasing when only one exists.
    if mode == "core" and "llm" in templates:
        return "llm", templates["llm"]
    if mode == "llm" and "core" in templates:
        return "core", templates["core"]

    # Fallback to core
    return "core", templates.get("core", BUILTIN_TEMPLATES["core"])


def _ensure_parent(path: Path) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)


def _dedupe_list(items: Iterable[str]) -> List[str]:
    out: List[str] = []
    seen: set[str] = set()
    for item in items:
        s = str(item)
        if s in seen:
            continue
        seen.add(s)
        out.append(s)
    return out


def _normalize_focus_globs(raw: Iterable[str]) -> List[str]:
    globs: List[str] = []
    for val in raw:
        s = str(val).strip()
        if not s:
            continue
        s = s.replace("\\", "/").lstrip("/")
        if re.search(r"[*?\[]", s):
            globs.append(s)
            continue
        p = (PROJECT_ROOT / s).resolve()
        try:
            rel = p.relative_to(PROJECT_ROOT).as_posix()
        except Exception:
            rel = s
        if p.exists():
            if p.is_dir():
                globs.append(rel.rstrip("/") + "/**")
            else:
                globs.append(rel)
        else:
            globs.append(s)
    return _dedupe_list(globs)


def _simplify_include_globs(include_globs: List[str]) -> List[str]:
    globs = [str(g).strip() for g in (include_globs or []) if str(g).strip()]
    out: List[str] = []
    seen: set[str] = set()
    for g in globs:
        if g in seen:
            continue
        seen.add(g)
        out.append(g)

    # Common redundancy: if include-all is present, additional include globs are unnecessary
    if any(g in {"**", "**/*"} for g in out):
        return ["**/*"]

    return out


def _derive_prunable_ignore_prefixes(ignore_globs: List[str]) -> List[str]:
    """Best-effort directory pruning from ignore globs.

    If an ignore glob is of the form 'path/to/dir/**' (no wildcard in the prefix),
    we can prune that subtree during os.walk for speed.
    """
    prefixes: List[str] = []
    wildcard_re = re.compile(r"[*?\[]")
    for pat in ignore_globs or []:
        pat = str(pat).strip().lstrip("/")
        if not pat:
            continue
        if not pat.endswith("/**") and not pat.endswith("/**/*"):
            continue
        prefix = pat[:-3] if pat.endswith("/**") else pat[:-5]
        if not prefix:
            continue
        if wildcard_re.search(prefix):
            continue
        prefixes.append(prefix)
    # Longer prefixes first to match more specifically
    prefixes.sort(key=len, reverse=True)
    return prefixes


def _iter_candidates(
    include_globs: List[str],
    *,
    ignore_dirs: set[str],
    ignore_files: set[str],
    ignore_globs: List[str],
) -> List[Path]:
    """Iterate candidate files with a single filesystem walk.

    This is substantially faster than multiple Path.glob() passes when include_globs grows.
    """
    include_globs = _simplify_include_globs(include_globs)
    if not include_globs:
        return []

    include_all = include_globs == ["**/*"]

    # Separate basename patterns (no '/') vs full path patterns
    basename_pats: List[str] = []
    path_pats: List[str] = []
    if not include_all:
        for pat in include_globs:
            if "/" in pat:
                path_pats.append(pat)
            else:
                basename_pats.append(pat)

    prunable_prefixes = _derive_prunable_ignore_prefixes(ignore_globs)

    files: List[Path] = []

    for root, dirs, filenames in os.walk(PROJECT_ROOT, topdown=True, followlinks=False):
        # Rel path for pruning (posix)
        try:
            rel_root = Path(root).relative_to(PROJECT_ROOT).as_posix()
        except Exception:
            rel_root = ""

        # Prune by ignore_dirs (name-based)
        if dirs:
            dirs[:] = [d for d in dirs if d not in ignore_dirs]

        # Prune by ignore_globs-derived subtree prefixes
        if rel_root:
            for pref in prunable_prefixes:
                if rel_root == pref or rel_root.startswith(pref + "/"):
                    dirs[:] = []
                    filenames = []
                    break

        for name in filenames:
            if name in ignore_files:
                continue

            abs_path = Path(root) / name
            try:
                rel = abs_path.relative_to(PROJECT_ROOT).as_posix()
            except Exception:
                continue

            # Ignore globs (fast reject)
            ignored = False
            for pat in ignore_globs:
                if _match_glob(rel, pat):
                    ignored = True
                    break
            if ignored:
                continue

            # Include filter
            if include_all:
                files.append(abs_path)
                continue

            ok = False
            if basename_pats:
                for pat in basename_pats:
                    if fnmatch.fnmatchcase(name, pat):
                        ok = True
                        break
            if (not ok) and path_pats:
                for pat in path_pats:
                    if _match_glob(rel, pat):
                        ok = True
                        break
            if ok:
                files.append(abs_path)

    files.sort(key=lambda p: _posix_rel(p))
    return files


def _should_ignore(path: Path, ignore_files: set[str], ignore_globs: List[str], ignore_dirs: set[str]) -> bool:
    """Return True if a file path should be ignored."""
    try:
        rel = _posix_rel(path)
    except Exception:
        return True

    # Ignore by directory segment (relative path only)
    parts = rel.split("/")
    for seg in parts[:-1]:
        if seg in ignore_dirs:
            return True

    if path.name in ignore_files:
        return True

    for pat in ignore_globs:
        if _match_glob(rel, pat):
            return True

    return False


def _pick_rule(rel_posix: str, rules: List[Dict[str, Any]]) -> Dict[str, Any]:
    for r in rules:
        pat = r.get("match")
        if not pat:
            continue
        if _match_glob(rel_posix, pat):
            return r
    return {"mode": "skip"}


def _read_text_limited(path: Path, max_bytes: int) -> Tuple[str, bool]:
    # Returns (text, truncated)
    size = path.stat().st_size
    truncated = size > max_bytes
    with open(path, "rb") as f:
        data = f.read(max_bytes if truncated else size)
    try:
        text = data.decode("utf-8", errors="replace")
    except Exception:
        text = data.decode(errors="replace")
    return text, truncated


def _read_head_lines(path: Path, head_lines: int) -> Tuple[str, bool]:
    lines: List[str] = []
    truncated = False
    try:
        with open(path, "r", encoding="utf-8", errors="replace") as f:
            for i, line in enumerate(f):
                if i >= head_lines:
                    truncated = True
                    break
                lines.append(line.rstrip("\n"))
    except Exception:
        # binary or unreadable
        return "[Unreadable]", True
    return "\n".join(lines), truncated


def _safe_unparse(node: ast.AST) -> str:
    try:
        return ast.unparse(node)  # type: ignore[attr-defined]
    except Exception:
        return "..."


def _format_args(args: ast.arguments) -> str:
    parts: List[str] = []

    def fmt_arg(a: ast.arg, default: Optional[ast.AST]) -> str:
        s = a.arg
        if a.annotation is not None:
            s += f": {_safe_unparse(a.annotation)}"
        if default is not None:
            d = _safe_unparse(default)
            if len(d) > 40:
                d = d[:37] + "..."
            s += f"={d}"
        return s

    # Positional-only
    posonly = getattr(args, "posonlyargs", [])
    if posonly:
        defaults_pad = [None] * (len(posonly) + len(args.args) - len(args.defaults)) + list(args.defaults)
        for a, d in zip(posonly, defaults_pad[: len(posonly)]):
            parts.append(fmt_arg(a, d))
        parts.append("/")

    # Positional or keyword
    all_pos = list(args.args)
    defaults_pad = [None] * (len(posonly) + len(all_pos) - len(args.defaults)) + list(args.defaults)
    # defaults for args start after posonly
    for idx, a in enumerate(all_pos):
        d = defaults_pad[len(posonly) + idx]
        parts.append(fmt_arg(a, d))

    # vararg
    if args.vararg is not None:
        va = "*" + args.vararg.arg
        if args.vararg.annotation is not None:
            va += f": {_safe_unparse(args.vararg.annotation)}"
        parts.append(va)
    elif args.kwonlyargs:
        parts.append("*")

    # kw-only
    for a, d in zip(args.kwonlyargs, args.kw_defaults):
        parts.append(fmt_arg(a, d))

    # kwarg
    if args.kwarg is not None:
        ka = "**" + args.kwarg.arg
        if args.kwarg.annotation is not None:
            ka += f": {_safe_unparse(args.kwarg.annotation)}"
        parts.append(ka)

    return ", ".join(parts)


def _first_doc_line(doc: Optional[str], max_len: int = 120) -> str:
    if not doc:
        return ""
    line = doc.strip().splitlines()[0].strip()
    if len(line) > max_len:
        line = line[: max_len - 3] + "..."
    return line


def _extract_python_interface(path: Path, max_chars: int = 40000) -> str:
    src = path.read_text(encoding="utf-8", errors="replace")
    try:
        tree = ast.parse(src)
    except Exception as e:
        head, _ = _read_head_lines(path, 200)
        return f"# [Interface Extraction Failed]\n# {e}\n\n" + head

    out: List[str] = []
    mod_doc = ast.get_docstring(tree)
    if mod_doc:
        out.append('"""' + _first_doc_line(mod_doc) + '"""')
        out.append("")

    # Constants (simple Assign to ALLCAPS)
    consts: List[str] = []
    for node in tree.body:
        if isinstance(node, ast.Assign):
            for t in node.targets:
                if isinstance(t, ast.Name) and t.id.isupper():
                    try:
                        v = _safe_unparse(node.value)
                        if len(v) > 80:
                            v = v[:77] + "..."
                        consts.append(f"{t.id} = {v}")
                    except Exception:
                        consts.append(f"{t.id} = ...")
    if consts:
        out.append("# Constants")
        out.extend(consts[:40])
        if len(consts) > 40:
            out.append(f"# ... {len(consts)-40} more")
        out.append("")

    # Functions / Classes
    for node in tree.body:
        if isinstance(node, ast.FunctionDef):
            sig = _format_args(node.args)
            ret = f" -> {_safe_unparse(node.returns)}" if node.returns is not None else ""
            doc = _first_doc_line(ast.get_docstring(node))
            out.append(f"def {node.name}({sig}){ret}:")
            out.append(f"    \"\"\"{doc}\"\"\"" if doc else "    ...")
            out.append("")
        elif isinstance(node, ast.ClassDef):
            bases = [
                _safe_unparse(b)
                for b in node.bases
                if not (isinstance(b, ast.Name) and b.id == "object")
            ]
            base_s = f"({', '.join(bases)})" if bases else ""
            doc = _first_doc_line(ast.get_docstring(node))
            out.append(f"class {node.name}{base_s}:")
            out.append(f"    \"\"\"{doc}\"\"\"" if doc else "    ...")

            # Methods
            methods: List[str] = []
            for sub in node.body:
                if isinstance(sub, ast.FunctionDef):
                    if sub.name.startswith("__") and sub.name.endswith("__"):
                        continue
                    msig = _format_args(sub.args)
                    mret = f" -> {_safe_unparse(sub.returns)}" if sub.returns is not None else ""
                    mdoc = _first_doc_line(ast.get_docstring(sub))
                    line = f"    def {sub.name}({msig}){mret}:"
                    if mdoc:
                        line += f"  # {mdoc}"
                    methods.append(line)
            if methods:
                out.extend(methods[:60])
                if len(methods) > 60:
                    out.append(f"    # ... {len(methods)-60} more")
            out.append("")

    text = "\n".join(out).strip() + "\n"
    if len(text) > max_chars:
        return text[: max_chars - 200] + "\n\n# [TRUNCATED: interface too large]\n"
    return text


def _render_tree(root: Path, prefix: str, depth: int, max_depth: int, max_entries: int,
                 ignore_dirs: set[str], ignore_files: set[str], ignore_globs: List[str]) -> str:
    if depth > max_depth:
        return f"{prefix}└── ... (max depth reached)\n"

    try:
        children = [p for p in sorted(root.iterdir(), key=lambda p: p.name.lower())]
    except PermissionError:
        return f"{prefix}└── [Permission Denied]\n"

    # Filter ignored
    filtered: List[Path] = []
    for p in children:
        if p.name in ignore_dirs and p.is_dir():
            continue
        if p.name in ignore_files and p.is_file():
            continue
        rel = _posix_rel(p) if p.exists() else p.name
        if any(_match_glob(rel, pat) for pat in ignore_globs):
            continue
        filtered.append(p)

    omitted = 0
    if len(filtered) > max_entries:
        omitted = len(filtered) - max_entries
        filtered = filtered[:max_entries]

    lines: List[str] = []
    for i, p in enumerate(filtered):
        pointer = "├── " if i < len(filtered) - 1 else "└── "
        lines.append(f"{prefix}{pointer}{p.name}")
        if p.is_dir():
            extension = "│   " if pointer == "├── " else "    "
            sub = _render_tree(
                p,
                prefix=prefix + extension,
                depth=depth + 1,
                max_depth=max_depth,
                max_entries=max_entries,
                ignore_dirs=ignore_dirs,
                ignore_files=ignore_files,
                ignore_globs=ignore_globs,
            )
            lines.append(sub.rstrip("\n"))

    if omitted:
        lines.append(f"{prefix}└── ... ({omitted} entries omitted)")

    return "\n".join(lines) + "\n"


def _extract_registry_tools() -> Optional[List[Dict[str, Any]]]:
    reg_path = PROJECT_ROOT / "apps" / "cli" / "registry.py"
    if not reg_path.exists():
        return None
    try:
        src = reg_path.read_text(encoding="utf-8", errors="replace")
        tree = ast.parse(src)
        for node in tree.body:
            if isinstance(node, ast.Assign):
                for t in node.targets:
                    if isinstance(t, ast.Name) and t.id == "TOOLS":
                        return ast.literal_eval(node.value)  # type: ignore[arg-type]
    except Exception:
        return None
    return None


def _render_tools_overview(tools: Optional[List[Dict[str, Any]]]) -> str:
    if not tools:
        return "(registry tools not available)"

    # Keep it simple to control size.
    headers = ["alias", "file", "type", "desc", "usage"]
    rows: List[List[str]] = []
    for t in tools:
        rows.append([
            str(t.get("alias") or ""),
            str(t.get("file") or ""),
            str(t.get("type") or ""),
            str(t.get("desc") or ""),
            str(t.get("usage") or ""),
        ])

    # Column widths
    widths = [len(h) for h in headers]
    for r in rows:
        for i, cell in enumerate(r):
            widths[i] = min(48, max(widths[i], len(cell)))

    def fmt_row(r: List[str]) -> str:
        out = []
        for i, cell in enumerate(r):
            s = cell.replace("\n", " ").strip()
            if len(s) > widths[i]:
                s = s[: widths[i] - 3] + "..."
            out.append(s.ljust(widths[i]))
        return " | ".join(out)

    lines = [fmt_row(headers), "-+-".join(["-" * w for w in widths])]
    lines.extend(fmt_row(r) for r in rows)
    return "\n".join(lines)


def _render_project_status() -> str:
    status_path = PROJECT_ROOT / "PROJECT_STATUS.json"
    if not status_path.exists():
        return "No project status file found."

    try:
        data = json.loads(status_path.read_text(encoding="utf-8"))
    except Exception:
        return "Error reading project status."

    lines: List[str] = []

    manifesto = data.get("DEV_MANIFESTO") or data.get("guidelines") or []
    if isinstance(manifesto, list) and manifesto:
        lines.append("DEV MANIFESTO:")
        for rule in manifesto:
            lines.append(f"* {rule}")
        lines.append("-" * 20)

    objective = data.get("OBJECTIVE") or data.get("objective")
    lines.append(f"OBJECTIVE: {objective}")

    tasks_todo = data.get("TASKS_TODO")
    tasks_done = data.get("TASKS_DONE")
    if isinstance(tasks_todo, list) or isinstance(tasks_done, list):
        todo_list = tasks_todo if isinstance(tasks_todo, list) else []
        done_list = tasks_done if isinstance(tasks_done, list) else []
        if todo_list:
            lines.append("\nTASKS TODO:")
            for t in todo_list:
                lines.append(f"- {t}")
        if done_list:
            lines.append("\nTASKS DONE:")
            for t in done_list:
                lines.append(f"- {t}")
    else:
        tasks = data.get("tasks", [])
        if isinstance(tasks, list) and tasks:
            lines.append("\nTASKS:")
            for i, t in enumerate(tasks):
                if isinstance(t, dict):
                    mark = "[x]" if t.get("status") == "done" else "[ ]"
                    desc = t.get("desc")
                    lines.append(f"{i}. {mark} {desc}")
                else:
                    lines.append(f"- {t}")

    logs = data.get("RECENT_LOGS") or data.get("logs") or []
    if isinstance(logs, list) and logs:
        lines.append("\nRECENT LOGS:")
        for l in logs[-5:]:
            lines.append(f"- {l}")

    return "\n".join(lines)


def _render_file_inventory(records: List[FileRecord], limit: int = 500) -> str:
    # Inventory is useful for LLM context even if contents are truncated.
    headers = ["mode", "bytes", "sha256_12", "path"]

    rows: List[List[str]] = []
    for r in records[:limit]:
        rows.append([
            r.mode + ("*" if r.truncated else ""),
            str(r.size_bytes),
            r.sha256_12,
            r.rel_posix,
        ])
    if len(records) > limit:
        rows.append(["...", "", "", f"({len(records)-limit} more omitted)"])

    widths = [len(h) for h in headers]
    for row in rows:
        for i, cell in enumerate(row):
            widths[i] = min(80, max(widths[i], len(cell)))

    def fmt_row(row: List[str]) -> str:
        cells: List[str] = []
        for i, cell in enumerate(row):
            s = cell
            if len(s) > widths[i]:
                s = s[: widths[i] - 3] + "..."
            cells.append(s.ljust(widths[i]))
        return " | ".join(cells)

    lines = [fmt_row(headers), "-+-".join(["-" * w for w in widths])]
    lines.extend(fmt_row(r) for r in rows)
    return "\n".join(lines)


def _write_zip(zip_path: Path, records: List[FileRecord]) -> None:
    _ensure_parent(zip_path)
    with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as z:
        # Include a manifest
        manifest = {
            "generated": datetime.now().isoformat(timespec="seconds"),
            "project_root": str(PROJECT_ROOT),
            "files": [
                {
                    "path": r.rel_posix,
                    "mode": r.mode,
                    "size_bytes": r.size_bytes,
                    "sha256_12": r.sha256_12,
                }
                for r in records
                if r.mode != "skip"
            ],
        }
        z.writestr("manifest.json", json.dumps(manifest, ensure_ascii=False, indent=2))

        # Add raw files
        for r in records:
            if r.mode == "skip":
                continue
            # Only archive repo files (text), skip binaries defensively.
            if _is_probably_binary(r.abs_path):
                continue
            z.write(r.abs_path, arcname=r.rel_posix)


def main() -> None:
    parser = argparse.ArgumentParser(description="Wagstaff-Lab snapshot generator (llm/archive/custom via templates).")
    parser.add_argument("--mode", choices=["llm", "core", "archive", "custom"], default="llm")
    parser.add_argument("--template", help="Template name from conf/snapshot_templates.json")
    parser.add_argument("--config", default=str(DEFAULT_CONFIG), help="Path to snapshot template config JSON")
    parser.add_argument("--output", help="Override output path")
    parser.add_argument("--list-templates", action="store_true", help="List available templates and exit")
    parser.add_argument("--focus", action="append", help="Limit snapshot to specific paths/globs (repeatable)")
    parser.add_argument("--no-redact", action="store_true", help="Disable secret redaction")
    parser.add_argument("--zip", action="store_true", help="Force creating zip bundle when supported")
    parser.add_argument("--hash", choices=["all", "embedded", "none"], help="Override hashing mode (all/embedded/none)")
    parser.add_argument("--no-env", action="store_true", help="Disable environment diagnostics section")
    parser.add_argument("--no-overview", action="store_true", help="Disable project overview section")
    parser.add_argument("--no-tree", action="store_true", help="Disable project tree section")
    parser.add_argument("--no-inventory", action="store_true", help="Disable file inventory section")
    parser.add_argument("--no-contents", action="store_true", help="Disable file contents section")
    parser.add_argument("--no-stats", action="store_true", help="Disable snapshot stats section")
    parser.add_argument("--verbose", action="store_true", help="Include template config section")
    parser.add_argument("--plan", action="store_true", help="Print a JSON plan summary and exit (no snapshot written)")

    args = parser.parse_args()

    t0 = time.perf_counter()

    cfg_path = Path(args.config)
    templates_doc = _load_templates(cfg_path)

    if args.list_templates:
        tpls = templates_doc.get("templates", {})
        print("Available templates:")
        for name, t in sorted(tpls.items(), key=lambda x: x[0]):
            print(f"- {name}: {t.get('desc', '')}")
        return

    tpl_name, tpl = _resolve_template(templates_doc, args.mode, args.template)

    ts = _now_ts()

    out_str = args.output or str(tpl.get("output", "project_context.txt"))
    out_str = out_str.replace("{timestamp}", ts)
    output_path = PROJECT_ROOT / out_str

    make_zip = bool(tpl.get("make_zip", False)) or bool(args.zip)
    zip_output = tpl.get("zip_output")
    zip_path: Optional[Path] = None
    if make_zip:
        if isinstance(zip_output, str) and zip_output:
            zip_path = PROJECT_ROOT / zip_output.replace("{timestamp}", ts)
        else:
            zip_path = output_path.with_suffix(".zip")

    # Template controls
    focus_globs = _normalize_focus_globs(args.focus or [])
    include_globs = _simplify_include_globs(list(tpl.get("include_globs") or []))
    if focus_globs:
        include_globs = _simplify_include_globs(
            ["PROJECT_STATUS.json", "README.md", "conf/settings.ini"] + focus_globs
        )

    ignore_dirs = set(DEFAULT_IGNORE_DIRS) | set(tpl.get("ignore_dirs") or [])
    ignore_files = set(tpl.get("ignore_files") or list(DEFAULT_IGNORE_FILES))
    ignore_globs = list(tpl.get("ignore_globs") or list(DEFAULT_IGNORE_GLOBS))

    # Always ignore generated artifacts to avoid snapshot recursion
    ignore_files.add(output_path.name)
    if zip_path is not None:
        ignore_files.add(zip_path.name)
        try:
            ignore_globs.append(zip_path.relative_to(PROJECT_ROOT).as_posix())
        except Exception:
            pass

    # Optional reports toggle (hard exclude)
    if not bool(tpl.get("include_reports", True)):
        ignore_globs.append("data/reports/**")

    redact_enabled = bool(tpl.get("redact", True)) and (not args.no_redact)

    max_file_bytes = int(tpl.get("max_file_bytes", 200000))
    max_total_bytes = int(tpl.get("max_total_bytes", 1200000))

    tree_cfg = tpl.get("tree") or {}
    tree_max_depth = int(tree_cfg.get("max_depth", 8))
    tree_max_entries = int(tree_cfg.get("max_entries_per_dir", 250))

    rules = list(tpl.get("rules") or [])
    if focus_globs:
        focus_rules = [{"match": pat, "mode": "full"} for pat in focus_globs]
        rules = focus_rules + rules

    # Hashing / ordering / inventory knobs
    hash_mode = str(args.hash or tpl.get("hash") or tpl.get("hash_mode") or "all").strip().lower()
    if hash_mode not in {"all", "embedded", "none"}:
        hash_mode = "all"

    embed_order = str(tpl.get("embed_order", "path")).strip().lower()
    if embed_order not in {"path", "mode", "smart"}:
        embed_order = "path"

    pinned = list(tpl.get("pinned") or [])
    if focus_globs:
        pinned = _dedupe_list(focus_globs + pinned)

    tpl_sections = tpl.get("sections")
    if isinstance(tpl_sections, dict):
        sections = dict(DEFAULT_SECTIONS)
        for key, val in tpl_sections.items():
            if key in sections:
                sections[key] = bool(val)
    else:
        sections = dict(LLM_SECTIONS if args.mode in {"llm", "core"} else DEFAULT_SECTIONS)

    if args.verbose:
        sections["config"] = True
    if args.no_env:
        sections["env"] = False
    if args.no_overview:
        sections["overview"] = False
    if args.no_tree:
        sections["tree"] = False
    if args.no_inventory:
        sections["inventory"] = False
    if args.no_contents:
        sections["contents"] = False
    if args.no_stats:
        sections["stats"] = False

    inv_cfg = tpl.get("inventory") or {}
    inv_enabled = bool(inv_cfg.get("enabled", True)) and sections["inventory"]
    inv_scope = str(inv_cfg.get("scope", "all")).strip().lower()
    inv_limit = int(inv_cfg.get("limit", 700))

    sha_cache_path = DEFAULT_SHA_CACHE_PATH
    if isinstance(tpl.get("hash_cache"), str) and tpl.get("hash_cache"):
        sha_cache_path = PROJECT_ROOT / str(tpl.get("hash_cache"))

    sha_cache: Dict[str, Dict[str, Any]] = {}
    if hash_mode in {"all", "embedded"}:
        sha_cache = _load_sha_cache(sha_cache_path)

    if not args.plan:
        print(f"📸 Generating snapshot: mode={args.mode}, template={tpl_name}, output={output_path}")

    # 1) Collect candidates (single walk, already filtered by ignore_files/ignore_globs/ignore_dirs)
    t_scan0 = time.perf_counter()
    candidates = _iter_candidates(
        include_globs,
        ignore_dirs=ignore_dirs,
        ignore_files=ignore_files,
        ignore_globs=ignore_globs,
    )
    t_scan_ms = int((time.perf_counter() - t_scan0) * 1000)

    records: List[FileRecord] = []
    t_rec0 = time.perf_counter()
    for p in candidates:
        rel = _posix_rel(p)
        rule = _pick_rule(rel, rules)
        mode = str(rule.get("mode", "skip")).strip() or "skip"
        if mode not in {"full", "interface", "head", "skip"}:
            mode = "skip"

        try:
            size = p.stat().st_size
        except Exception:
            continue

        head_lines = int(rule.get("head_lines", 200))
        per_file = int(rule.get("max_file_bytes", max_file_bytes))

        sha = "-"
        if hash_mode == "all" and mode != "skip":
            sha = _sha256_12_cached(p, rel, sha_cache)

        records.append(
            FileRecord(
                rel_posix=rel,
                abs_path=p,
                size_bytes=size,
                sha256_12=sha,
                mode=mode,
                head_lines=head_lines,
                per_file_max_bytes=per_file,
            )
        )

    t_rec_ms = int((time.perf_counter() - t_rec0) * 1000)

    # Plan mode: emit JSON and exit (no file I/O except optional SHA cache)
    if args.plan:
        by_mode: Dict[str, Dict[str, int]] = {}
        for r in records:
            d = by_mode.setdefault(r.mode, {"count": 0, "size_bytes": 0})
            d["count"] += 1
            d["size_bytes"] += int(r.size_bytes)

        non_skip = [r for r in records if r.mode != "skip"]
        top_large = sorted(non_skip, key=lambda r: r.size_bytes, reverse=True)[:20]

        plan = {
            "mode": args.mode,
            "template": tpl_name,
            "config_file": str(cfg_path),
            "output": str(output_path.relative_to(PROJECT_ROOT)),
            "zip": {
                "enabled": bool(zip_path is not None),
                "output": str(zip_path.relative_to(PROJECT_ROOT)) if zip_path is not None else None,
            },
            "redact_enabled": redact_enabled,
            "hash_mode": hash_mode,
            "embed_order": embed_order,
            "sections": sections,
            "focus": focus_globs,
            "limits": {"max_file_bytes": max_file_bytes, "max_total_bytes": max_total_bytes},
            "tree": {"max_depth": tree_max_depth, "max_entries_per_dir": tree_max_entries},
            "include_globs": include_globs,
            "ignore_dirs": sorted(ignore_dirs),
            "ignore_files": sorted(ignore_files),
            "ignore_globs": ignore_globs,
            "rules_count": len(rules),
            "total_candidates": len(candidates),
            "included_records": len(records),
            "by_mode": by_mode,
            "timing_ms": {"scan": t_scan_ms, "records": t_rec_ms, "total": int((time.perf_counter() - t0) * 1000)},
            "top_largest_non_skip": [
                {"path": r.rel_posix, "mode": r.mode, "size_bytes": r.size_bytes} for r in top_large
            ],
        }

        if hash_mode == "all":
            _save_sha_cache(sha_cache_path, sha_cache)

        print(json.dumps(plan, ensure_ascii=False, indent=2))
        return

    # 2) Build report
    report: List[str] = []
    report.append("# Wagstaff-Lab Project Snapshot")
    report.append("")
    report.append(f"- Generated: {datetime.now().isoformat(timespec='seconds')}")
    report.append(f"- Mode: {args.mode}")
    report.append(f"- Template: {tpl_name}")
    if focus_globs:
        report.append(f"- Focus: {', '.join(focus_globs)}")

    section_idx = 0

    def add_section(title: str) -> None:
        nonlocal section_idx
        section_idx += 1
        report.append(f"\n## {section_idx}. {title}")

    eff = {
        "mode": args.mode,
        "template": tpl_name,
        "config_file": str(cfg_path),
        "output": str(output_path.relative_to(PROJECT_ROOT)),
        "zip": {
            "enabled": bool(zip_path is not None),
            "output": str(zip_path.relative_to(PROJECT_ROOT)) if zip_path is not None else None,
        },
        "redact_enabled": redact_enabled,
        "hash_mode": hash_mode,
        "embed_order": embed_order,
        "limits": {"max_file_bytes": max_file_bytes, "max_total_bytes": max_total_bytes},
        "tree": {"max_depth": tree_max_depth, "max_entries_per_dir": tree_max_entries},
        "glob_semantics": {"**": "matches 0..N path segments"},
        "include_globs": include_globs,
        "ignore_dirs": sorted(ignore_dirs),
        "ignore_files": sorted(ignore_files),
        "ignore_globs": ignore_globs,
        "rules": rules,
        "sections": sections,
        "focus": focus_globs,
        "inventory": {"enabled": inv_enabled, "scope": inv_scope, "limit": inv_limit},
        "pinned": pinned,
    }

    if sections["config"]:
        add_section("Effective Template Config")
        report.append("```json")
        report.append(json.dumps(eff, ensure_ascii=False, indent=2))
        report.append("```")

    if sections["env"]:
        add_section("Environment Diagnostics")
        report.append("```yaml")
        report.append(get_system_fingerprint())
        report.append("-" * 20)
        report.append(get_git_status())
        report.append("```")

    if sections["overview"]:
        add_section("Project Overview")
        report.append("### Toolbox (apps/cli/registry.py)")
        report.append("```text")
        report.append(_render_tools_overview(_extract_registry_tools()))
        report.append("```")

        report.append("\n### Project Context (PROJECT_STATUS.json)")
        report.append("```text")
        report.append(_render_project_status())
        report.append("```")

    if sections["tree"]:
        add_section("Project Structure")
        report.append("```text")
        report.append(
            _render_tree(
                PROJECT_ROOT,
                prefix="",
                depth=0,
                max_depth=tree_max_depth,
                max_entries=tree_max_entries,
                ignore_dirs=ignore_dirs,
                ignore_files=ignore_files,
                ignore_globs=ignore_globs,
            ).rstrip("\n")
        )
        report.append("```")

    if inv_enabled:
        add_section("File Inventory")
        report.append("(mode: full/interface/head/skip; '*' means truncated when rendered)\n")
        report.append("```text")
        inv_records: List[FileRecord]
        if inv_scope in {"included", "non_skip", "nonskip"}:
            inv_records = [r for r in records if r.mode != "skip"]
        else:
            inv_records = records
        report.append(_render_file_inventory(inv_records, limit=inv_limit))
        report.append("```")

    t_render_ms = 0
    budget = max_total_bytes
    embedded_files = 0
    approx_total_tokens = 0

    if sections["contents"]:
        add_section("File Contents")

        # 3) Emit contents within budget
        t_render0 = time.perf_counter()

        embed_records = [r for r in records if r.mode != "skip"]

        def mode_prio(m: str) -> int:
            return {"full": 0, "interface": 1, "head": 2}.get(m, 9)

        if embed_order == "mode":
            embed_records.sort(key=lambda r: (mode_prio(r.mode), r.rel_posix))
        elif embed_order == "smart":
            def pin_rank(r: FileRecord) -> int:
                if not pinned:
                    return 10_000
                for i, pat in enumerate(pinned):
                    if pat and _match_glob(r.rel_posix, str(pat)):
                        return i
                return 10_000
            embed_records.sort(key=lambda r: (pin_rank(r), mode_prio(r.mode), r.rel_posix))
        # else: "path" keeps as-is (already sorted by path)

        for rec in embed_records:
            if _is_probably_binary(rec.abs_path):
                rec.note = "[skipped: binary]"
                continue

            mode = rec.mode
            content = ""
            truncated = False

            if mode == "head":
                content, truncated = _read_head_lines(rec.abs_path, head_lines=rec.head_lines)
            elif mode == "interface":
                if rec.abs_path.suffix.lower() == ".py":
                    content = _extract_python_interface(rec.abs_path)
                    truncated = False
                else:
                    content, truncated = _read_head_lines(rec.abs_path, head_lines=rec.head_lines)
            elif mode == "full":
                content, truncated = _read_text_limited(rec.abs_path, max_bytes=rec.per_file_max_bytes)
            else:
                continue

            if redact_enabled:
                content = _redact(content)

            # Optionally hash only embedded files
            if hash_mode == "embedded" and rec.sha256_12 == "-":
                rec.sha256_12 = _sha256_12_cached(rec.abs_path, rec.rel_posix, sha_cache)

            # Rough byte count for budget
            render_blob = content.encode("utf-8", errors="replace")
            needed = len(render_blob)

            # Keep a small overhead for section headers
            needed += 200

            if budget - needed < 0:
                rec.note = "[omitted: total budget exceeded]"
                continue

            budget -= needed
            rec.rendered_bytes = needed
            rec.truncated = truncated

            tok = _estimate_tokens(content)
            rec.approx_tokens = tok
            approx_total_tokens += tok

            embedded_files += 1

            report.append(f"\n### File: {rec.rel_posix}")
            report.append(f"- mode: {mode}")
            report.append(f"- size_bytes: {rec.size_bytes}")
            report.append(f"- sha256_12: {rec.sha256_12}")
            if truncated:
                report.append("- note: TRUNCATED")
            if rec.note and rec.note not in {"[skipped: binary]"}:
                report.append(f"- note: {rec.note}")
            report.append("")

            # code fence lang
            lang = rec.abs_path.suffix.lstrip(".")
            if lang == "ini":
                lang = "toml"
            if mode == "interface":
                lang = "py"

            report.append(f"```{lang}")
            report.append(content.rstrip("\n"))
            report.append("```")

        t_render_ms = int((time.perf_counter() - t_render0) * 1000)

    if sections["stats"]:
        add_section("Snapshot Stats")
        report.append("```yaml")
        report.append(f"total_candidates: {len(candidates)}")
        report.append(f"included_records: {len(records)}")
        report.append(f"embedded_files: {embedded_files}")
        report.append(f"hash_mode: {hash_mode}")
        report.append(f"embed_order: {embed_order}")
        report.append(f"timing_ms: {{scan: {t_scan_ms}, records: {t_rec_ms}, render: {t_render_ms}, total: {int((time.perf_counter() - t0) * 1000)}}}")
        report.append(f"approx_total_tokens: {approx_total_tokens}")
        report.append(f"max_total_bytes: {max_total_bytes}")
        report.append(f"bytes_remaining: {budget}")
        report.append("```")

    # 4) Write output
    _ensure_parent(output_path)
    output_path.write_text("\n".join(report) + "\n", encoding="utf-8")
    print(f"✅ Snapshot written: {output_path}")

    # Persist SHA cache (optimization only)
    if hash_mode in {"all", "embedded"}:
        _save_sha_cache(sha_cache_path, sha_cache)

    # 5) Optional zip bundle
    if zip_path is not None:
        try:
            _write_zip(zip_path, records)
            print(f"✅ Zip bundle written: {zip_path}")
        except Exception as e:
            print(f"⚠️  Zip bundle failed: {e}")


if __name__ == "__main__":
    main()
```

### File: devtools/__init__.py
- mode: interface
- size_bytes: 48
- sha256_12: 730483be1b04

```py
"""Devtools package."""
```

### File: devtools/build_catalog_index.py
- mode: interface
- size_bytes: 2031
- sha256_12: 4dd79b3fb540

```py
"""Build catalog index (compact listing + indexes)."""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent

def main() -> int:
    ...
```

### File: devtools/build_catalog_sqlite.py
- mode: interface
- size_bytes: 19031
- sha256_12: 7684a3d7a3c3

```py
"""Build SQLite catalog from wagstaff_catalog_v2.json."""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent

def _load_json(path: Path) -> Dict[str, Any]:
    ...

def _json_dumps(value: Any) -> str:
    ...

def _as_list(value: Any) -> List[str]:
    ...

def _iter_map_rows(obj: Any) -> Iterable[Tuple[str, str]]:
    ...

def _iter_item_rows(items_obj: Any) -> Iterable[Tuple[str, str, str, str, str, str, str, str, str]]:
    ...

def _iter_asset_rows(assets_obj: Any) -> Iterable[Tuple[str, str, str, str, str]]:
    ...

def _iter_item_list_rows(items_obj: Any) -> Iterable[Tuple[str, str]]:
    ...

def _iter_item_stat_rows(items_obj: Any) -> Iterable[Tuple[str, str, str, str, str, str, str]]:
    ...

def _iter_join_rows(items_obj: Any, field: str) -> Iterable[Tuple[str, str]]:
    ...

def _iter_craft_recipe_rows(craft_obj: Dict[str, Any]) -> Iterable[Tuple[str, str, str, str, str, str, str, str]]:
    ...

def _iter_craft_ingredient_rows(craft_obj: Dict[str, Any]) -> Iterable[Tuple[str, str, Optional[float], Optional[float], str]]:
    ...

def _iter_cooking_rows(cooking_obj: Any) -> Iterable[Tuple[str, float, float, str, str, str, str, str, str, str, str]]:
    ...

def _iter_cooking_ingredient_rows(cooking_obj: Any) -> Iterable[Tuple[str, str, str]]:
    ...

def _iter_catalog_index_rows(items: List[Dict[str, Any]]) -> Iterable[Tuple[str, str, str, str, int, int, str, str, str, str, str, str, str]]:
    ...

def _build_sqlite(catalog_path: Path, out_path: Path, icon_index_path: Optional[Path]) -> None:
    ...

def main() -> int:
    ...
```

### File: devtools/build_catalog_v2.py
- mode: interface
- size_bytes: 4808
- sha256_12: 0028e925694e

```py
"""Build Wagstaff catalog v2 (item-centric)."""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent

def _resolve_dst_root(arg: str | None) -> str | None:
    ...

def _load_resource_index(path: Path) -> dict:
    ...

def main() -> int:
    ...

def _render_summary(catalog: WagstaffCatalogV2) -> str:
    ...
```

### File: devtools/build_i18n_index.py
- mode: interface
- size_bytes: 9149
- sha256_12: 7f72ec505945

```py
"""Build Wagstaff i18n index (names + UI strings)."""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent
_PO_CANDIDATES = {'zh': ['scripts/languages/chinese_s.po', 'languages/chinese_s.po']}

def _resolve_dst_root(arg: Optional[str]) -> Optional[str]:
    ...

def _read_po_from_zip(zip_path: Path, candidates: List[str]) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    ...

def _read_po_from_dir(dir_path: Path, candidates: List[str]) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    ...

def _file_sig(path: Path) -> str:
    ...

def _zip_sig(zip_path: Path, inner: str) -> str:
    ...

def _resolve_po(*, lang: str, po_path: Optional[str], scripts_zip: Optional[str], scripts_dir: Optional[str], dst_root: Optional[str]) -> Tuple[Optional[str], Optional[str], Optional[str], Optional[str]]:
    """Return (po_source, inner, text, sig)."""

def _load_item_ids(catalog_path: Path, icon_index_path: Optional[Path]) -> List[str]:
    ...

def main() -> int:
    ...
```

### File: devtools/build_icons.py
- mode: interface
- size_bytes: 27213
- sha256_12: 57d30abe8b2a

```py
"""build_icons.py (v1.3) - reduce missing by supporting:"""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent

def _norm(p: str) -> str:
    ...

def _expand(p: Optional[str]) -> Optional[str]:
    ...

def _ensure_dir(p: Path) -> None:
    ...

def _default_catalog_path() -> Path:
    ...

def _default_out_dir() -> Path:
    ...

def _default_index_path() -> Path:
    ...

def _databundles_dir(dst_root: str) -> Path:
    ...

def _data_dir(dst_root: str) -> Path:
    ...

def _auto_bundles(dst_root: str) -> List[Path]:
    ...

def _read_ini_dst_root(ini_path: str) -> Optional[str]:
    ...

def _strip_tex_suffix(name: str) -> str:
    ...

def _is_inventory_atlas(path: str, extra_globs: Sequence[str]) -> bool:
    ...

def _to_pil(img_obj):
    """Convert decoder output to PIL.Image.Image."""

def _unpremultiply_rgba(pil_img):
    """Unpremultiply alpha using numpy (fast)."""

class Bundle:
    ...

class BundleFS:
    ...
    def close(self) -> None:
    def resolve(self, path: str, *, base_dir: Optional[str]=None) -> Optional[Tuple[int, str]]:
    def read(self, resolved: Tuple[int, str]) -> Optional[bytes]:
    def scan_paths(self) -> Iterable[str]:

class LocalFS:
    """Read loose files under data_dir (DST_ROOT/data)."""
    def _build_index(self) -> None:
    def resolve(self, path: str, *, base_dir: Optional[str]=None) -> Optional[Path]:
    def read(self, resolved: Path) -> Optional[bytes]:
    def scan_inventory_atlas_xmls(self, extra_globs: Sequence[str]) -> List[str]:  # Return paths relative to data_dir, like 'images/inventoryimages.xml'

class ResourceFS:
    """Combined resolver:"""
    def resolve(self, path: str, *, base_dir: Optional[str]=None) -> Optional[Tuple[str, Union[Tuple[int, str], Path]]]:
    def read(self, resolved: Tuple[str, Union[Tuple[int, str], Path]]) -> Optional[bytes]:

def _parse_atlas_xml(xml_bytes: bytes) -> Tuple[Optional[str], Dict[str, Dict[str, float]]]:
    ...

def _crop_uv(tex_img_pil, uv: Dict[str, float], *, invert_v: bool=True):
    """Crop using atlas UVs."""

def _collect_catalog_ids(catalog_path: Path) -> Set[str]:
    ...

def main() -> None:
    ...
```

### File: devtools/build_resource_index.py
- mode: interface
- size_bytes: 3236
- sha256_12: 9a78b5a4bbe4

```py
"""Build resource index from DST scripts + data folders."""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent

def _resolve_dst_root(arg: str | None) -> str | None:
    ...

def main() -> int:
    ...
```

### File: devtools/catalog_quality.py
- mode: interface
- size_bytes: 14996
- sha256_12: 7e13eec0b0fb

```py
"""Catalog quality/coverage report."""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent

def _load_json(path: Path) -> Dict[str, Any]:
    ...

def _collect_component_keys() -> Dict[str, Set[str]]:
    ...

def _norm_id(x: str) -> str:
    ...

def _trace_keys(trace_doc: Dict[str, Any]) -> Set[str]:
    ...

def _stat_trace_key(item_id: str, stat_key: str, entry: Dict[str, Any]) -> str:
    ...

def _sample(items: Set[str], limit: int=20) -> List[str]:
    ...

def build_report(*, catalog_doc: Dict[str, Any], icon_index: Dict[str, str], i18n_doc: Dict[str, Any], trace_doc: Dict[str, Any]) -> Dict[str, Any]:
    ...

def render_report_md(doc: Dict[str, Any]) -> str:
    ...

def main() -> int:
    ...
```

### File: devtools/codemap.py
- mode: interface
- size_bytes: 6312
- sha256_12: fd216e4f7e67

```py
"""Wagstaff-Lab DST Code Map (Report)"""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent
REPORT_DIR = PROJECT_ROOT / 'data' / 'reports'

def _now_iso() -> str:
    ...

def _file_size(engine: WagstaffEngine, path: str) -> int:
    ...

def build_codemap(engine: WagstaffEngine) -> Dict[str, object]:
    ...

def render_md(doc: Dict[str, object]) -> str:
    ...

def main() -> None:
    ...
```

### File: devtools/quality_gate.py
- mode: interface
- size_bytes: 9571
- sha256_12: 43c44fe987d3

```py
"""Quality gate for Wagstaff artifacts (lightweight validation + report)."""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent

def _load_json(path: Path) -> Optional[Dict[str, Any]]:
    ...

def _as_dict(v: Any) -> Dict[str, Any]:
    ...

def _as_list(v: Any) -> List[Any]:
    ...

def _ratio(n: int, d: int) -> float:
    ...

def _check_catalog(doc: Dict[str, Any], min_items: int) -> Tuple[Dict[str, Any], List[Tuple[str, str]]]:
    ...

def _check_catalog_index(doc: Dict[str, Any], items_total: int) -> Tuple[Dict[str, Any], List[Tuple[str, str]]]:
    ...

def _check_icon_index(doc: Dict[str, Any], min_icons: int) -> Tuple[Dict[str, Any], List[Tuple[str, str]]]:
    ...

def _check_i18n(doc: Dict[str, Any], items_total: int, min_ratio: float) -> Tuple[Dict[str, Any], List[Tuple[str, str]]]:
    ...

def _check_tuning_trace(doc: Dict[str, Any]) -> Tuple[Dict[str, Any], List[Tuple[str, str]]]:
    ...

def render_report(*, inputs: Dict[str, str], summary: Dict[str, Any], issues: List[Tuple[str, str]]) -> str:
    ...

def main() -> int:
    ...
```

### File: devtools/raw_scan.py
- mode: interface
- size_bytes: 29218
- sha256_12: c09c6650e75b

```py
"""DST raw data coverage scan."""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent
REPORT_DIR = PROJECT_ROOT / 'data' / 'reports'
_ID_RE = re.compile('^[a-z0-9_]+$')

def _now_iso() -> str:
    ...

def _norm_id(val: str) -> str:
    ...

def _scan_inventory_icons(dst_root: Path) -> Tuple[Set[str], List[str]]:
    ...

def _scan_data_dir(dst_root: Path, *, top_n_ext: int=20, top_n_files: int=30, include_files: bool=False, max_files: int=0) -> Dict[str, Any]:
    ...

def _scan_data_bundles(dst_root: Path, *, include_entries: bool=False, max_entries: int=0) -> List[Dict[str, Any]]:
    ...

def _scan_scripts_overview(engine: WagstaffEngine) -> Dict[str, Any]:
    ...

def _collect_prefab_data(engine: WagstaffEngine) -> Dict[str, Any]:
    ...

def _coverage_counts(base: Set[str], target: Set[str]) -> Dict[str, Any]:
    ...

def _sample_missing(base: Set[str], target: Set[str], limit: int=40) -> Dict[str, Any]:
    ...

def _safe_str(val: Optional[str]) -> Optional[str]:
    ...

def _craft_sets(engine: WagstaffEngine) -> Dict[str, Set[str]]:
    ...

def _cooking_sets(engine: WagstaffEngine) -> Dict[str, Any]:
    ...

def build_report(engine: WagstaffEngine, *, dst_root: Path, top_n: int=25, data_full: bool=False, data_max_files: int=0, bundle_full: bool=False, bundle_max_files: int=0) -> Dict[str, Any]:
    ...

def render_md(doc: Dict[str, Any]) -> str:
    ...

def main() -> None:
    ...
```

### File: devtools/reporter.py
- mode: interface
- size_bytes: 4751
- sha256_12: 50594fb292b8

```py
# Constants
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
REPORT_DIR = os.path.join(PROJECT_ROOT, 'data', 'reports')

class WagstaffReporter:
    ...
    def _ensure_report_dir(self):
    def generate_asset_report(self):  # 扫描全服资产分布
    def generate_recipe_report(self):  # 扫描配方分布
```

### File: devtools/sampler.py
- mode: interface
- size_bytes: 14606
- sha256_12: 2cc68ca2e29a

```py
"""Wagstaff-Lab Sample Pack Generator"""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent
OUT_DIR = PROJECT_ROOT / 'data' / 'samples'
REPORT_DIR = PROJECT_ROOT / 'data' / 'reports'
DEFAULT_CATEGORIES = ['STRINGS', 'Widgets', 'Brains', 'Stategraphs', 'LootTables', 'Components']

def _now_iso() -> str:
    ...

def _now_ts() -> str:
    ...

def _sha256_12_text(text: str) -> str:
    ...

def _safe_read_asset_registry(path: Path) -> Dict[str, List[str]]:
    """Parse data/reports/asset_registry.md into {Category: [file1, file2, ...]}."""

def _file_size(engine: WagstaffEngine, path: str) -> int:
    ...

def _choose_files(engine: WagstaffEngine, category: str, n: int, registry_map: Dict[str, List[str]], rng: random.Random) -> List[str]:
    ...

def _pick_snippet_lines(lines: List[str], patterns: Sequence[re.Pattern], snippet_blocks: int, context_lines: int, rng: random.Random) -> List[Tuple[int, int]]:
    """Return a list of (start_idx, end_idx_exclusive) ranges."""

def _render_snippet(lines: List[str], start: int, end: int) -> str:
    ...

def _cap_text(text: str, max_chars: int) -> Tuple[str, bool]:
    ...

class FileSample:
    ...

def build_sample_pack(categories: List[str], n_files_per_category: int, head_lines: int, snippet_blocks: int, context_lines: int, max_chars_per_file: int, max_total_chars: int, seed: int) -> Tuple[str, Dict[str, object]]:
    ...

def main() -> None:
    ...
```

### File: devtools/serve_webcraft.py
- mode: interface
- size_bytes: 5481
- sha256_12: 3b73ccd15fd9

```py
"""Run WebCraft server (FastAPI + Uvicorn)."""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent

def _detect_lan_ip() -> str:
    """Best-effort LAN IP discovery (no external network required)."""

def _find_sqlite_peer(path: Path) -> Path | None:
    ...

def main() -> None:
    ...
```

### File: devtools/snapshot_gui.py
- mode: interface
- size_bytes: 66096
- sha256_12: 3ba389c54d32

```py
"""snapshot_gui.py"""

# Constants
MODE_FULL = 'full'
MODE_INTERFACE = 'interface'
MODE_HEAD = 'head'
MODE_SKIP = 'skip'
MODE_LABELS = {MODE_FULL: 'Full', MODE_INTERFACE: 'Interface', MODE_HEAD: 'Head', MODE_SKIP...
MODE_COLOR_TAG = {MODE_FULL: 'mode_full', MODE_INTERFACE: 'mode_interface', MODE_HEAD: 'mode_h...
PROFILE_MANUAL = 'Manual'
PROFILE_LLM_BEST = 'LLM Best (balanced)'
PROFILE_LLM_DEEP = 'LLM Deep (more code)'
PROFILE_ARCHIVE = 'Archive (full + zip)'
PROFILE_AUDIT = 'Audit (inventory all)'
PROFILE_ORDER = [PROFILE_MANUAL, PROFILE_LLM_BEST, PROFILE_LLM_DEEP, PROFILE_ARCHIVE, PROFILE...
_WILDCARD_CHARS_RE = re.compile('[*?\\[]')

def _find_project_root(start: Path) -> Path:
    """Best-effort project root discovery."""

def _guess_snapshot_py(project_root: Path) -> Optional[Path]:
    """Locate snapshot.py inside the project."""

def _load_snapshot_defaults(project_root: Path, snapshot_py: Optional[Path]) -> Tuple[set[str], set[str], List[str], Dict[str, Any]]:
    """Try to import snapshot.py to reuse DEFAULT_IGNORE_* and BUILTIN_TEMPLATES."""

class ModeSpec:
    ...
    def to_rule(self) -> Dict[str, Any]:

def _is_glob_like(pat: str) -> bool:
    ...

def _as_posix_rel(project_root: Path, abs_path: Path) -> str:
    ...

def _specificity_key(match_pat: str) -> Tuple[int, int, int]:
    """Sorting key for rules: more specific first."""

def _safe_int(s: str, default: int) -> int:
    ...

class SnapshotGUI(tk.Tk):
    ...
    def _build_styles(self) -> None:
    def _build_ui(self) -> None:
    def _status_text(self) -> str:
    def _rebuild_tree(self) -> None:
    def _on_open_node(self, event: tk.Event) -> None:
    def _populate_children_if_needed(self, item: str) -> None:
    def _populate_children(self, parent_item: str) -> None:
    def _effective_spec(self, rel: str) -> ModeSpec:  # Inheritance:
    def _update_item_display(self, item: str) -> None:
    def _update_loaded_subtree(self, item: str) -> None:
    def _on_select(self, event: tk.Event) -> None:
    def _selected_rels(self) -> List[str]:
    def _apply_mode(self, mode: str) -> None:
    def _clear_override(self) -> None:
    def _on_right_click(self, event: tk.Event) -> None:
    def _apply_profile_replace(self) -> None:  # Apply selected profile and REPLACE current overrides/settings.
    def _apply_profile_merge(self) -> None:  # Apply selected profile and MERGE into current overrides/settings.
    def _apply_profile(self, *, merge: bool) -> None:
    def _open_pinned_editor(self) -> None:  # Edit pinned paths (one per line).
    def _build_template_dict(self) -> Dict[str, Any]:  # Convert current GUI state into snapshot.py template dict.
    def _load_config_doc(self) -> Dict[str, Any]:
    def _merge_and_write_config(self, tpl_name: str, tpl_dict: Dict[str, Any]) -> None:
    def _save_config(self) -> None:
    def _preview_json(self) -> None:
    def _plan_snapshot(self) -> None:  # Run snapshot.py in --plan mode and show a compact summary.
    def _run_snapshot(self) -> None:
    def _try_load_existing_gui_template(self) -> None:  # Best-effort load:

def main() -> None:
    ...
```

### File: devtools/stats_gap_inspect.py
- mode: interface
- size_bytes: 13521
- sha256_12: 74dada835443

```py
"""Stats gap inspection for prefab assignments (heuristic)."""

# Constants
PROJECT_ROOT = Path(__file__).resolve().parent.parent

def _load_json(path: Path) -> Dict[str, Any]:
    ...

def _collect_component_keys() -> Dict[str, Set[str]]:
    ...

def _read_zip(zip_obj: Optional[zipfile.ZipFile], name: str) -> str:
    ...

def _read_file(path: Path) -> str:
    ...

def _load_prefab_source(*, zip_obj: Optional[zipfile.ZipFile], zip_paths: Set[str], rel_path: str) -> str:
    ...

def _extract_aliases(clean: str, comp: str) -> Set[str]:
    ...

def _classify_expr(expr: str) -> Set[str]:
    ...

def _inspect_component(*, comp: str, content: str, raw_lines: List[str]) -> List[Dict[str, Any]]:
    ...

def _summarize_item(records: List[Dict[str, Any]]) -> Dict[str, Any]:
    ...

def _build_report(*, catalog_doc: Dict[str, Any], components: List[str], scripts_zip: Optional[Path], max_records: int) -> Dict[str, Any]:
    ...

def _render_md(report: Dict[str, Any]) -> str:
    ...

def main() -> int:
    ...
```

### File: data/reports/catalog_quality_report.md
- mode: head
- size_bytes: 3351
- sha256_12: 2fbb1f8af721

```md
# Catalog Quality Report

## Counts
```yaml
items_total: 4954
assets_total: 3124
icons_total: 3106
all_ids_total: 4954
items_with_stats: 1392
stats_total: 4138
```

## Stats Coverage (by component)
```yaml
equippable: 143/255 (56.08%)
sanityaura: 142/190 (74.74%)
rechargeable: 18/23 (78.26%)
combat: 287/366 (78.42%)
stackable: 278/332 (83.73%)
heater: 31/34 (91.18%)
locomotor: 306/333 (91.89%)
planardamage: 98/103 (95.15%)
waterproofer: 30/31 (96.77%)
edible: 168/173 (97.11%)
finiteuses: 125/128 (97.66%)
workable: 450/458 (98.25%)
health: 340/346 (98.27%)
weapon: 153/153 (100.00%)
perishable: 139/139 (100.00%)
fueled: 88/88 (100.00%)
armor: 20/20 (100.00%)
insulator: 17/17 (100.00%)
hunger: 13/13 (100.00%)
sanity: 1/1 (100.00%)
```

## Stats Missing Items (sample)
```yaml
equippable: missing=112 sample=[axe, balloon, balloonparty, balloonparty_buff, balloonparty_confetti_balloon, balloonparty_confetti_cloud, batbat, batbat_bats, batbat_fantasy_fx, beeswax_spray]
combat: missing=79 sample=[babybeefalo, beehive, bernie_active, birds, boatrace_seastack, boatrace_seastack_monkey, butterfly, canary_poisoned, carrat, carrat_planted]
stackable: missing=54 sample=[bee, bilesplat, blowdart_fire, blowdart_pipe, blowdart_sleep, blowdart_walrus, blowdart_yellow, bomb_lunarplant, bomb_lunarplant_explode_fx, boneshard]
sanityaura: missing=48 sample=[alterguardian_phase1, alterguardian_phase1_lunarrift, alterguardian_phase1_lunarrift_gestalt, alterguardian_phase2, alterguardian_phase3, alterguardian_phase4_lunarrift, alterguardian_phase4_lunarrift_erupt_fx, alterguardian_phase4_lunarrift_slam_fx, bearger, beequeen]
locomotor: missing=27 sample=[bee, bilesplat, birds, bomb_lunarplant, bomb_lunarplant_explode_fx, buff_firefrenzy, butterfly, cannonball_rock, cannonball_rock_item, chum]
workable: missing=8 sample=[campfire, carnival_plaza, coldfire, junk_pile_big, junk_pile_blueprint, junk_pile_side, lureplant, quagmire_campfire]
health: missing=6 sample=[dropperweb, gingerbreadpig, gingerdeadpig, glommer, spiderhole, spiderhole_rock]
edible: missing=5 sample=[chum_aoe, chumpiece, manrabbit_tail, pigskin, slurper_pelt]
planardamage: missing=5 sample=[beefalo, beefalo_carry, player_common, winona_catapult, winona_catapult_item]
rechargeable: missing=5 sample=[battlesongs, beef_bell, pocketwatch_common, shadow_beef_bell, wortox_soul]
finiteuses: missing=3 sample=[spider_repellent, spider_whistle, spiderden_bedazzler]
heater: missing=3 sample=[campfirefire, fire, lavalight]
waterproofer: missing=1 sample=[raincoat]
```

## Tuning Trace Coverage
```yaml
items_tuning_exprs: 3009
items_with_trace: 3009
cooking_tuning_exprs: 254
cooking_with_trace: 254
```

## i18n Coverage
```yaml
zh:
  names: 2243
  items: 2243/4954
  all_ids: 2243/4954
```

## Top Stats (by frequency)
```yaml
work_left: 450
health_max: 341
combat_damage: 284
walk_speed: 278
stack_size: 278
attack_period: 196
attack_range: 176
edible_hunger: 168
run_speed: 156
edible_health: 153
weapon_damage: 153
sanity_aura: 142
perish_time: 139
uses: 125
uses_max: 124
planar_damage_base: 98
edible_sanity: 93
fuel_level: 88
equip_slot: 79
weapon_range_min: 67
weapon_range_max: 54
equip_walk_speed_mult: 52
attack_range_max: 47
dapperness: 36
waterproof: 30
equip_magic_dapperness: 25
heater_exothermic: 22
heater_endothermic: 22
equip_stack: 22
area_damage: 21
```
```

### File: data/reports/catalog_v2_summary.md
- mode: head
- size_bytes: 339
- sha256_12: e8deeacc65d6

```md
# Wagstaff Catalog v2 Summary

## Meta
```yaml
schema_version: 2
tuning_mode: value_only
scripts_zip: /home/steam/dontstarvetogether_dedicated_server/data/databundles/scripts.zip
scripts_dir: None
```

## Counts
```yaml
items_total: 4954
assets_total: 3124
craft_recipes: 878
cooking_recipes: 68
cooking_ingredients: 0
loot_items: 206
```
```

### File: data/reports/stats_gap_inspect.md
- mode: head
- size_bytes: 1124
- sha256_12: e0eead6dd5a4

```md
# Stats Gap Inspection

## Meta
```yaml
generated: 2026-01-16 17:02:09
scripts_zip: /home/steam/dontstarvetogether_dedicated_server/data/databundles/scripts.zip
components: ['equippable', 'rechargeable', 'heater']
```

## equippable
```yaml
missing: 112
with_records: 0
with_function: 0
with_conditional: 0
```

Sample items with no detected assignments:
```text
- axe
- balloon
- balloonparty
- balloonparty_buff
- balloonparty_confetti_balloon
- balloonparty_confetti_cloud
- batbat
- batbat_bats
- batbat_fantasy_fx
- beeswax_spray
- bishop
- bishop_nightmare
- boomerang
- bootleg
- brush
- bugnet
- bullkelp_root
- carnivalgame_feedchicks_food
- carnivalgame_feedchicks_nest
- carnivalgame_feedchicks_station
```

## rechargeable
```yaml
missing: 5
with_records: 0
with_function: 0
with_conditional: 0
```

Sample items with no detected assignments:
```text
- battlesongs
- beef_bell
- pocketwatch_common
- shadow_beef_bell
- wortox_soul
```

## heater
```yaml
missing: 3
with_records: 0
with_function: 0
with_conditional: 0
```

Sample items with no detected assignments:
```text
- campfirefire
- fire
- lavalight
```
```

### File: docs/architecture/WEBCRAFT_NETWORK_STACK.md
- mode: head
- size_bytes: 1594
- sha256_12: 049aed942a93

```md
# WebCraft 网络基建（FastAPI/ASGI）

目标：把 Web/GUI Craft 从“临时 stdlib server”升级为可扩展的系统级服务基座。

## 选型
- ASGI 框架：FastAPI
- 服务器：Uvicorn
- 中间件：GZip、可选 CORS
- 数据源：data/index/wagstaff_catalog_v2.json（item-centric 索引产物）

## 目录结构
- apps/webcraft/
  - app.py          FastAPI app factory
  - api.py          REST API 路由（/api/v1）
  - catalog_store.py  catalog 装载 + 内存索引
  - planner.py      craft planner（inventory -> craftable/missing）
  - ui.py           单页 UI（零构建）
  - settings.py     配置结构

- devtools/serve_webcraft.py  开发/部署启动器

## 启动
```bash
python3 devtools/serve_webcraft.py --host 0.0.0.0 --port 20000 --no-open
```

## 反向代理挂载（root_path）
若挂载在 /webcraft：
```bash
python3 devtools/serve_webcraft.py --root-path /webcraft --host 0.0.0.0 --port 20000
```

UI 与 API 都使用相同 root_path 前缀，前端以相对路径访问 `/api/v1/...`，避免 0.0.0.0 导致的跨机器交互失败。

## API
- GET /api/v1/meta
- GET /api/v1/craft/filters
- GET /api/v1/craft/tabs
- GET /api/v1/craft/tags
- GET /api/v1/craft/recipes/search?q=...
- GET /api/v1/craft/recipes/{name}
- POST /api/v1/craft/plan
- POST /api/v1/craft/missing

## 后续扩展建议
- 引入 “station/tech/skill tree” 规则：只扩展 planner + API，不改 UI 架构
- catalog 改为 SQLite：CatalogStore 层替换为 SQLiteStore（API/UI 无需变化）
- 加 websocket/SSE：用于索引重建、长任务进度推送
```

### File: docs/guides/CLI_GUIDE.md
- mode: head
- size_bytes: 2574
- sha256_12: 7d4c2ccec158

```md
# Wagstaff CLI Role Plan (v3)

Goal: make the CLI an engineering console with clear roles and low cognitive load.

Install entrypoint (once per env): `python -m pip install -e ".[cli]"`.

## 1. Role Layers

- **Dash (entry)**
  - Purpose: project overview and runtime snapshot (objective, tasks, artifacts, freshness, quality).
  - Command: `wagstaff dash`

- **Health (env/artifact checks)**
  - Purpose: verify config and key artifacts (info-only, no blocking).
  - Command: `wagstaff doctor`

- **Query (knowledge lookup)**
  - Purpose: query recipes/cooking/prefab analysis for day-to-day lookup.
  - Command: `wagstaff wiki`

- **Explore (source analysis)**
  - Purpose: inspect source structure and Lua parsing for parser development.
  - Command: `wagstaff exp`

- **Mgmt (project management)**
  - Purpose: show/sync milestones and active tasks.
  - Command: `wagstaff mgmt`
  - Tip: `wagstaff mgmt check` for DEV_GUIDE emphasis


- **Build (index outputs)**
  - Purpose: generate data/index + data/reports artifacts.
  - Commands:
    - `wagstaff resindex` resource index
    - `wagstaff catalog2` catalog v2
    - `wagstaff catindex` compact catalog index
    - `wagstaff i18n` i18n index
    - `wagstaff icons` icons + icon index

- **Quality (coverage checks)**
  - Purpose: coverage report + quality gate (default info-only).
  - Commands:
    - `wagstaff catqa`
    - `wagstaff quality`

- **Ops (service)**
  - Purpose: run WebCraft for UI validation.
  - Command: `wagstaff web`

- **Server (DST ops)**
  - Purpose: start/stop/update/backup/restore DST servers via screen.
  - Command: `wagstaff server` (interactive: `wagstaff server ui`)

- **Utility (support)**
  - Purpose: snapshots, reports, macro scans.
  - Commands: `wagstaff snap` / `wagstaff report` / `wagstaff map` / `wagstaff samples`

## 2. Command Overview

- Entry
  - `wagstaff` / `wagstaff dash`
- Build
  - `wagstaff resindex` / `wagstaff catalog2` / `wagstaff catindex`
  - `wagstaff i18n` / `wagstaff icons`
- Quality
  - `wagstaff catqa` / `wagstaff quality`
- Service
  - `wagstaff web`
- Server
  - `wagstaff server` / `wagstaff server ui`
- Query + Analysis
  - `wagstaff wiki` / `wagstaff exp`
- Management
  - `wagstaff mgmt`
- Utilities
  - `wagstaff snap` / `wagstaff report` / `wagstaff map` / `wagstaff samples`

## 3. Operating Principles

- CLI is for input/output orchestration; core parsing belongs in `core/`.
- Build artifacts always land in `data/`; CLI consumes `data/index` + `data/reports`.
- `wagstaff dash` is the default entry point (high density, non-blocking).
```

### File: docs/management/PROJECT_MANAGEMENT.md
- mode: head
- size_bytes: 4277
- sha256_12: 83b5d066f06b

```md
# Wagstaff-Lab 项目管理总览 (v3)

本文件是**执行层面的单一管理入口**。ROADMAP 仅保留长期方向，SPEC 仅描述数据/接口契约，PROJECT_STATUS 保持运行快照与近期记录。

## 0. 管理约定

- **战略方向**：`docs/management/ROADMAP.md`
- **数据契约**：`docs/specs/CATALOG_V2_SPEC.md`
- **执行管理**：`docs/management/PROJECT_MANAGEMENT.md`（本文件）
- **运行快照**：`PROJECT_STATUS.json`

说明：不再使用 pm 工具，统一以文档与 JSON 状态文件管理进度。
工具化入口：`wagstaff mgmt status|sync|dump`。
建议：`wagstaff mgmt check` 作为变更前的必跑检查。

## 1. L0 目标（North Star）

对 DST 资源实现**可迁移、可检索、可解释**的全面理解与展示，产物可被 Web/CLI/后续数据库直接消费。

## 2. L1 里程碑（Milestones）

- **M3.0 架构拆分与入口统一**（完成）
  - core/apps 分层、CLI dispatcher、pyproject 入口、Makefile 任务体系
- **M3.1 Catalog v2 基线与 WebCraft 接入**（完成）
  - Catalog v2、icon index、tuning trace、WebCraft UI/接口对接
- **M3.2 质量与覆盖率提升**（进行中）
  - stats 解析覆盖、i18n 覆盖、质量报告持续迭代
- **M3.3 WebCraft 体验深化**（规划中）
  - 参考标杆：Food Guide（模拟/探索/统计）、DST Item List（双语+调试 ID）、Wiki Craft 表格化呈现
  - 三入口体验：Catalog/Craft/Cooking 结构一致，探索/模拟/百科模式清晰
  - 解释性输出：规则/条件/trace 可视化，配方链路与用途说明
  - catalog 分页/缓存与搜索改造（已落地）
- **M3.4 存储升级准备**（规划中）
  - SQLite/Parquet 迁移计划与 schema 对齐
  - SQLite catalog 派生产物与 WebCraft SQLite 优先加载（已落地）
- **M3.5 服务器运维集成**（完成）
  - wagstaff server 与独立运维模块

## 3. L2 需求分层（Pillars → Epics）

### 数据基础
- **E1 资源索引**：scripts + data 扫描（完成）
- **E2 Catalog v2 构建**：items + craft + cooking + assets（完成）
- **E3 Tuning trace**：链路索引 + 按需加载（完成）
- **E4 Icon pipeline**：静态 icon + 动态回退（完成）

### 数据质量
- **E5 stats 覆盖扩展**：更多组件/属性/方法（进行中）
- **E6 i18n 覆盖扩展**：names/desc/quotes + UI 词条（进行中）
- **E7 质量报告与门禁**：catqa + quality_gate（完成）

### WebCraft 应用
- **E8 Catalog 列表/检索**：items + indexes（完成）
- **E9 Item 详情与 stats 展示**（完成）
- **E10 i18n UI**：语言切换（完成）
- **E11 Trace UI 按需加载**（完成）
- **E12 交互体验增强**（规划中）
  - 料理探索：食材驱动筛选 + 模拟结果 + 规则可解释
  - 列表密度：表格/卡片切换，中英文/调试 ID 同屏，快捷复制
  - 导航一致：统一 list/detail 框架，支持 URL 状态、键盘/移动端操作
  - 料理食材索引：解析 ingredients/cooking 定义，落盘 cooking_ingredients 标签与来源
  - 探索/模拟入口：百科为主，探索/模拟耦合；排序公式 + 接近可做解释

### 工程化与工具链
- **E13 CLI 统一入口**（完成）
- **E14 任务入口规范**（完成）
- **E15 Snapshot 规范**（完成）

### 服务器运维
- **E16 DST server 管理**（完成）

## 4. L3 当前任务（Active）

- **T-101**：stats 覆盖扩展（组件属性/方法解析补全）
- **T-102**：i18n 覆盖提升（names/desc/quotes + UI 文案）
- **T-103**：Catalog 质量报告迭代（覆盖率与缺口追踪）
- **T-104**：Cooking ingredient tags 解析与 catalog 落盘（ingredients.lua / cooking.lua）
- **T-105**：Cooking 探索/模拟重做（可做/接近可做 + 解释卡片 + 高密度切换）

## 5. 最近完成（摘要）

- wagstaff server 接入，运维模块独立化
- Catalog index v1 规范与 WebCraft API 契约补齐
- pyproject 入口统一、bin/installer 清理完成

## 6. 下一步建议（短期）

1. 以 stats 解析覆盖为主线，补齐关键组件（equippable/rechargeable/heater 等）
2. i18n 覆盖率提升，补齐 UI 词条并完善多语言元数据
3. 质量报告指标化：新增缺失原因统计与趋势对比
```

### File: docs/specs/CATALOG_V2_SPEC.md
- mode: head
- size_bytes: 11133
- sha256_12: 21f3544647f7
- note: TRUNCATED

```md
# Wagstaff Catalog v2 规范草案

目标：对 DST 做“全面理解与展示”，形成稳定可迁移的索引产物。

说明：本文件仅描述**数据/接口契约**；进度与迁移状态见 `docs/management/PROJECT_MANAGEMENT.md`。

## 1. 总体原则

- **全物品覆盖**：以 prefab 为基础实体，覆盖建筑/生物/角色/物品（不含皮肤）。
- **数据层不含语言**：名称/描述在独立 i18n index 中维护。
- **可迁移**：结构接近“可归一化表”，便于未来迁移到 SQLite/Parquet。
- **可追溯**：所有重要字段需要保留来源与构建元信息。
- **可裁剪**：可按需输出链路（trace）与结果（value）。

## 2. 产物目录建议

- `data/index/wagstaff_resource_index_v1.json`  
  原始资源索引（scripts + prefabs + data + bundles）。
- `data/index/wagstaff_catalog_v2.json`  
  主 Catalog（items + recipes + cooking + assets + tuning）。
- `data/index/wagstaff_catalog_v2.sqlite`  
  SQLite 版本（与 JSON 同构，便于运行时加载与后续迁移）。
- `data/index/wagstaff_catalog_index_v1.json`  
  紧凑索引（用于 WebCraft 列表/搜索与后续 DB 迁移）。
- `data/index/wagstaff_i18n_v1.json`  
  语言层索引（names/desc/quotes 等）。
- `data/index/tag_overrides_v1.json`  
  人工标签修订（可选）。
- `data/index/wagstaff_tuning_trace_v1.json`  
  独立链路索引（可选，便于裁剪）。

SQLite 产物表（派生，摘要）：
- `items`：`id/kind/categories/.../data`
- `item_stats`：`item_id/stat_key/expr/value_json/trace_key`
- `catalog_index`：`id/name/icon/kind/...`（列表/检索）
- `craft_recipes` / `craft_ingredients`
- `cooking_recipes` / `cooking_ingredients`

## 3. 核心实体草案

### 3.0.1 顶层结构（当前实现）

`wagstaff_catalog_v2.json` 顶层结构如下：
- `schema_version`
- `meta`
- `items`
- `assets`
- `craft`
- `cooking`
- `cooking_ingredients`
- `stats`

### 3.0 Meta (统一产物元信息)

建议字段：
- `schema`：产物版本号
- `generated`：构建时间 (ISO8601)
- `tool`：构建工具名
- `sources`：构建输入来源（scripts_zip / scripts_dir / resource_index 等）

当前实现额外字段：
- `tuning_mode`
- `scripts_sha256_12`
- `scripts_zip`
- `scripts_dir`

### 3.1 Item（统一实体）

每个 item 对应一个 prefab id，必要时允许 `aliases` 处理别名。

字段建议：
- `id`：prefab id（小写）
- `kind`：`character|creature|structure|item|plant|fx`
- `categories`：多值（见第 4 节）
- `behaviors`：多值（见第 4 节）
- `sources`：多值（craft/cook/loot/spawn/natural/event）
- `slots`：装备槽位（见第 4 节）
- `components`：prefab 组件名列表（用于行为推导）
- `tags`：prefab 标签（用于行为推导）
- `assets`：icon/atlas/image 等引用（可为空）
- `stats`：组件属性/方法推导出的关键数值（weapon_damage/uses/armor 等）
- `prefab_files`：prefab 源文件路径列表（用于溯源）
- `prefab_assets`：prefab Asset 原始声明（原始引用）
- `brains` / `stategraphs` / `helpers`：AI 与辅助函数线索

当前实现说明：
- `recipes` / `aliases` 尚未落盘。
- `stats` 单元结构为：
  - `expr`：原始表达式
  - `value`：解析值（可为空）
  - `expr_resolved`：解析后的表达式（可为空）
  - `trace_key`：可选，指向 trace 索引键

### 3.2 Recipe（Craft）

字段建议：
- `id` / `product` / `ingredients`
- `tab` / `filters` / `builder_tags` / `tech`
- `station_tag` / `builder_skill`
- `tuning`（对材料数量/消耗等可选追踪）

当前实现结构：
- `craft.schema`
- `craft.recipes`（每个 recipe 保留 `ingredients` + `amount_value`）
- `craft.aliases`
- `craft.filter_defs` / `craft.filter_order`

### 3.3 Cooking

字段建议：
- `id` / `card_ingredients` / `foodtype` / `tags`
- `priority` / `weight` / `cooktime`
- `hunger` / `health` / `sanity` / `perishtime`
- `tuning`（对上述字段）

当前实现说明：
- Cooking 字段在 `value_only` 下直接落盘数值。
- `tuning_mode=full` 时字段为 `{value, expr, trace}` 结构。

### 3.3.1 Cooking Ingredients

字段建议：
- `id`
- `tags`：料理标签贡献（如 meat/veggie/sweet/monster/egg）
- `tags_expr`：无法解析为数值的表达式（可选）
- `sources`：来源脚本列表（可选）
- `name` / `atlas` / `image` / `prefab` / `foodtype`（可选）

### 3.4 Assets

字段建议：
- `icons`：`{id: "static/icons/{id}.png"}`
- `atlas`/`image`/`build`/`bank` 等原始引用
- `sources`：来源路径（inventoryimages.xml / prefab Asset / data/*）

当前实现说明：
- `assets` 为 `{id: {icon, atlas?, image?}}` 的轻量映射。

### 3.5 I18n Index

字段建议：
- `names`：`{lang: {id: localized_name}}`
- `ui`：`{lang: {key: text}}`（WebCraft UI 词条）
- `meta`：构建来源（po 路径 / scripts.zip / ui.json）

### 3.6 Stats 解析覆盖面（当前实现）

- 组件方法解析：`weapon` / `combat` / `finiteuses` / `armor` / `edible` / `perishable` / `fueled` / `equippable` / `insulator` / `waterproofer` / `light` / `stackable` / `health` / `sanity` / `sanityaura` / `hunger` / `locomotor` / `rechargeable` / `heater` / `planardamage` / `planararmor` / `workable`
- 组件属性解析：覆盖 `equippable` / `edible` / `insulator` / `waterproofer` / `stackable` / `health` / `sanity` / `hunger` / `locomotor` / `planardamage` / `planararmor` / `workable` 等

## 4. 标签体系（建议）

### 4.1 kind（主类）
`character | creature | structure | item | plant | fx`

### 4.2 category（功能类别）
`weapon | armor | tool | food | resource | magic | container | light | deployable | trap | boat | farm | decor | toy`

### 4.3 behavior（组件行为）
`equippable | edible | stackable | burnable | perishable | repairable | fuel | tradable | hauntable | deployable`

### 4.4 source（来源）
`craft | cook | loot | spawn | natural | event`

### 4.5 slot（可选）
`head | body | hand | back`

## 5. TUNING trace 模式

字段可同时输出：
- `value`：数值（可直接展示）
- `expr`：原始表达式
- `trace`：链路结构（refs/steps/chain）

输出模式：
- `value_only`：只输出 value
- `full`：输出 value + trace

建议将 trace 拆分到 `wagstaff_tuning_trace_v1.json`，在需要时按 id 拉取。

当前实现说明：
- Trace 索引是 `{trace_key: trace}` 的映射。
- `trace_key` 形式：
  - `item:{id}:stat:{stat_key}`
  - `craft:{recipe}:ingredient:{item}`
  - `cooking:{recipe}:{field}`

## 6. tag overrides（人工修订）

建议结构示例见：`conf/samples/tag_overrides.example.json`

逻辑建议：
- `add`：追加标签
- `remove`：移除标签
- `set`：强制覆盖（必要时）

## 7. 迁移建议（上层改造）

- WebCraft `catalog` 页面读取 `wagstaff_catalog_v2.json` 的 `items`
- WebCraft 搜索改为 “items + recipes + cooking” 多源索引
- i18n 层独立加载（不依赖 catalog）
- icon 服务改为读取 `assets.icon` / icon index 统一入口
- CLI/wiki 使用 v2 结构，避免 direct prefab 解析
- 旧 v1 产物可删除（或仅保留构建回滚）

## 8. Catalog Index v1 规范（wagstaff_catalog_index_v1.json）

用途：提供 WebCraft 列表/搜索的紧凑索引，减少 UI 初始化负担。

### 8.1 顶层结构

```json
{
  "schema_version": 1,
  "meta": { ... },
  "counts": { "items_total": 0, "items_with_icon": 0, "icon_only": 0 },
  "items": [ ... ],
  "indexes": { ... }
}
```

### 8.2 meta（当前实现）

- `schema` / `generated` / `tool`
- `sources.catalog`: `wagstaff_catalog_v2.json`
- `sources.scripts_zip` / `sources.scripts_dir`
- `catalog_schema`: catalog v2 schema 版本
- `scripts_sha256_12` / `scripts_zip` / `scripts_dir`

### 8.3 items（紧凑条目）

每个条目结构：

```json
{
  "id": "spear",
  "name": "Spear",
  "image": "static/icons/spear.png",
  "icon": "static/icons/spear.png",
  "has_icon": true,
```

### File: tests/test_recipes.py
- mode: head
- size_bytes: 1653
- sha256_12: c854302c4b59

```py
#!/usr/bin/env python3
import sys
import time
from rich.console import Console
from rich.table import Table
import sys
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from core.engine import WagstaffEngine

console = Console()

def main():
    console.print("[bold blue]🧪 配方解析器验收测试 (基于 Wagstaff Engine)[/bold blue]")
    
    # 1. 启动引擎
    try:
        start_t = time.time()
        engine = WagstaffEngine(load_db=True)
        duration = (time.time() - start_t) * 1000
    except Exception as e:
        console.print(f"[red]引擎启动失败: {e}[/red]")
        return
    
    # 2. 统计
    count = len(engine.recipes.recipes)
    count_style = "green" if count > 500 else "red"
    
    console.print(f"加载耗时: [bold]{duration:.2f} ms[/bold]")
    console.print(f"发现配方: [{count_style}]{count}[/{count_style}]")

    # 3. 抽查
    check_list = ["spear", "armorwood", "hambat", "firestaff"]
    table = Table(title="关键物品验证", border_style="blue")
    table.add_column("Key", style="cyan")
    table.add_column("Name", style="dim")
    table.add_column("Ingredients", style="white")
    
    for item in check_list:
        real_name, data = engine.recipes.get(item)
        if data:
            ing_str = ", ".join([f"{i['item']}x{i['amount']}" for i in data['ingredients']])
            table.add_row(item, real_name, ing_str)
        else:
            table.add_row(item, "-", "[red]Not Found[/red]")
        
    console.print(table)

if __name__ == "__main__":
    main()
```

## 6. Snapshot Stats
```yaml
total_candidates: 77
included_records: 77
embedded_files: 75
hash_mode: embedded
embed_order: smart
timing_ms: {scan: 352, records: 4, render: 158, total: 972}
approx_total_tokens: 161963
max_total_bytes: 1500000
bytes_remaining: 842824
```
